Conference,Year,Title,Author,Affiliation
ICLR,2018,Deep Complex Networks,Chiheb Trabelsi,Montreal Institute for Learning Algorithms / Polytechnique Montréal
ICLR,2018,Deep Complex Networks,Olexa Bilaniuk,Université de Montréal
ICLR,2018,Deep Complex Networks,Ying Zhang,Element AI
ICLR,2018,Deep Complex Networks,Dmitrii Serdyuk,Montreal Institute for Learning Algorithms
ICLR,2018,Deep Complex Networks,Sandeep Subramanian,Université de Montréal
ICLR,2018,Deep Complex Networks,Joao Felipe Santos,Montreal Institute for Learning Algorithms
ICLR,2018,Deep Complex Networks,Soroush Mehri,"MSR, Montreal"
ICLR,2018,Deep Complex Networks,Negar Rostamzadeh,Element AI
ICLR,2018,Deep Complex Networks,Yoshua Bengio,University of Montreal
ICLR,2018,Deep Complex Networks,Chris Pal,Polytechnique Montréal & MILA
ICLR,2018,Universal Agent for Disentangling Environments and Tasks,Jiayuan Mao,Tsinghua University
ICLR,2018,Universal Agent for Disentangling Environments and Tasks,Honghua Dong,Tsinghua University
ICLR,2018,Universal Agent for Disentangling Environments and Tasks,Joseph J Lim,Stanford University
ICLR,2018,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,Xiang Wei,"School of Software Engineering, Beijing Jiaotong University"
ICLR,2018,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,Boqing Gong,University of Southern California
ICLR,2018,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,Zixia Liu,None
ICLR,2018,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,Wei Lu,None
ICLR,2018,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,Liqiang Wang,University of Central Florida
ICLR,2018,Fraternal Dropout,Konrad Zolna,"Universite de Montreal, Jagiellonian University"
ICLR,2018,Fraternal Dropout,Devansh Arpit,None
ICLR,2018,Fraternal Dropout,Dendi Suhubdy,University of Montreal
ICLR,2018,Fraternal Dropout,Yoshua Bengio,University of Montreal
ICLR,2018,Learning an Embedding Space for Transferable Robot Skills,Karol Hausman,University of Southern California
ICLR,2018,Learning an Embedding Space for Transferable Robot Skills,Jost Tobias Springenberg,University of Freiburg
ICLR,2018,Learning an Embedding Space for Transferable Robot Skills,ziyu wang,"Department of Computer Science, University of Oxford"
ICLR,2018,Learning an Embedding Space for Transferable Robot Skills,Nicolas Heess,None
ICLR,2018,Learning an Embedding Space for Transferable Robot Skills,Martin Riedmiller,None
ICLR,2018,Hierarchical Density Order Embeddings,Ben Athiwaratkun,Cornell University
ICLR,2018,Hierarchical Density Order Embeddings,Andrew G Wilson,None
ICLR,2018,Model compression via distillation and quantization,Antonio Polino,ETH Zurich
ICLR,2018,Model compression via distillation and quantization,Razvan Pascanu,DeepMind
ICLR,2018,Model compression via distillation and quantization,Dan Alistarh,None
ICLR,2018,Maximum a Posteriori Policy Optimisation,abbas abdolmaleki,Google DeepMind
ICLR,2018,Maximum a Posteriori Policy Optimisation,Jost Tobias Springenberg,University of Freiburg
ICLR,2018,Maximum a Posteriori Policy Optimisation,Nicolas Heess,None
ICLR,2018,Maximum a Posteriori Policy Optimisation,Yuval Tassa,Google DeepMind
ICLR,2018,Maximum a Posteriori Policy Optimisation,Remi Munos,DeepMind
ICLR,2018,MaskGAN: Better Text Generation via Filling in the _______,William Fedus,University of Montreal
ICLR,2018,MaskGAN: Better Text Generation via Filling in the _______,Ian Goodfellow,Google Brain
ICLR,2018,MaskGAN: Better Text Generation via Filling in the _______,Andrew Dai,Google Brain
ICLR,2018,Kronecker-factored Curvature Approximations for Recurrent Neural Networks,James Martens,DeepMind
ICLR,2018,Kronecker-factored Curvature Approximations for Recurrent Neural Networks,Jimmy Ba,University of Toronto
ICLR,2018,Kronecker-factored Curvature Approximations for Recurrent Neural Networks,Matthew Johnson,None
ICLR,2018,Scalable Private Learning with PATE,Nicolas Papernot,Pennsylvania State University
ICLR,2018,Scalable Private Learning with PATE,Shuang Song,"University of California, San Diego"
ICLR,2018,Scalable Private Learning with PATE,Ilya Mironov,Google
ICLR,2018,Scalable Private Learning with PATE,Ananth Raghunathan,Google
ICLR,2018,Scalable Private Learning with PATE,Kunal Talwar,Microsoft
ICLR,2018,Scalable Private Learning with PATE,Ulfar Erlingsson,Google Brain
ICLR,2018,Online Learning Rate Adaptation with Hypergradient Descent,Atilim Gunes Baydin,University of Oxford
ICLR,2018,Online Learning Rate Adaptation with Hypergradient Descent,Robert Cornish,Monash University
ICLR,2018,Online Learning Rate Adaptation with Hypergradient Descent,David Martínez,University of Oxford
ICLR,2018,Online Learning Rate Adaptation with Hypergradient Descent,Mark Schmidt,UBC
ICLR,2018,Online Learning Rate Adaptation with Hypergradient Descent,Frank Wood,University of British Columbia
ICLR,2018,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,Sjoerd van Steenkiste,The Swiss AI Lab - IDSIA
ICLR,2018,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,Michael Chang,"University of California, Berkeley"
ICLR,2018,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,Klaus Greff,IDSIA
ICLR,2018,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,Jürgen Schmidhuber,"NNAISENSE, Swiss AI Lab IDSIA (USI & SUPSI)"
ICLR,2018,Learning Awareness Models,Brandon Amos,Carnegie Mellon University
ICLR,2018,Learning Awareness Models,Laurent Dinh,Google
ICLR,2018,Learning Awareness Models,Serkan Cabi,DeepMind
ICLR,2018,Learning Awareness Models,Thomas Rothörl,None
ICLR,2018,Learning Awareness Models,Sergio Gómez Colmenarejo,Google DeepMind
ICLR,2018,Learning Awareness Models,Alistair M Muldal,DeepMind
ICLR,2018,Learning Awareness Models,Tom Erez,"Department of Computer Science, University of Washington"
ICLR,2018,Learning Awareness Models,Yuval Tassa,Google DeepMind
ICLR,2018,Learning Awareness Models,Nando d Freitas,None
ICLR,2018,Learning Awareness Models,Misha Denil,[ERROR]
ICLR,2018,On the regularization of Wasserstein GANs,Henning Petzka,None
ICLR,2018,On the regularization of Wasserstein GANs,Asja Fischer,Ruhr-Universität  Bochum
ICLR,2018,On the regularization of Wasserstein GANs,Denis Lukovnikov,None
ICLR,2018,Spatially Transformed Adversarial Examples,Chaowei Xiao,"University of Michigan, Ann Arbor"
ICLR,2018,Spatially Transformed Adversarial Examples,Jun-Yan Zhu,MIT CSAIL
ICLR,2018,Spatially Transformed Adversarial Examples,Bo Li,UC Berkeley
ICLR,2018,Spatially Transformed Adversarial Examples,Warren He,UC Berkeley
ICLR,2018,Spatially Transformed Adversarial Examples,Mingyan Liu,None
ICLR,2018,Spatially Transformed Adversarial Examples,dawn song,uc berkeley
ICLR,2018,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,Wieland Brendel,"University of Tuebingen, Germany"
ICLR,2018,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,Jonas Rauber,IMPRS for Intelligent Systems & University of Tübingen
ICLR,2018,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,,None
ICLR,2018,Communication Algorithms via Deep Learning,Hyeji Kim,University of Illinois at Urbana Champaign
ICLR,2018,Communication Algorithms via Deep Learning,Yihan Jiang,University of Washington
ICLR,2018,Communication Algorithms via Deep Learning,Ranvir B Rana,None
ICLR,2018,Communication Algorithms via Deep Learning,Sreeram Kannan,"University of Washington, Seattle"
ICLR,2018,Communication Algorithms via Deep Learning,Sewoong Oh,University of Illinois at Urbana-Champaign
ICLR,2018,Communication Algorithms via Deep Learning,Pramod Viswanath,None
ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Róbert Torfason,Swiss Federal Institute of Technology
ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Fabian Mentzer,ETH Zurich
ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Eirikur Agustsson,Swiss Federal Institute of Technology
ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Michael Tschannen,ETH Zurich
ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Radu Timofte,ETH Zurich
ICLR,2018,Towards Image Understanding from Deep Compression Without Decoding,Luc V Gool,None
ICLR,2018,Unsupervised Machine Translation Using Monolingual Corpora Only,Guillaume Lample,Facebook AI Research
ICLR,2018,Unsupervised Machine Translation Using Monolingual Corpora Only,,None
ICLR,2018,Unsupervised Machine Translation Using Monolingual Corpora Only,Ludovic Denoyer,LIP6 - University Pierre et Marie Curie -- Criteo Research
ICLR,2018,Unsupervised Machine Translation Using Monolingual Corpora Only,Marc'Aurelio Ranzato,Facebook AI Research
ICLR,2018,Boosting the Actor with Dual Critic,Bo Dai,Georgia Institute of Technology
ICLR,2018,Boosting the Actor with Dual Critic,Albert Shaw,Georgia Institute of Technology
ICLR,2018,Boosting the Actor with Dual Critic,Niao He,None
ICLR,2018,Boosting the Actor with Dual Critic,Lihong Li,Google Inc.
ICLR,2018,Boosting the Actor with Dual Critic,Le Song,None
ICLR,2018,A DIRT-T Approach to Unsupervised Domain Adaptation,Rui Shu,Stanford University
ICLR,2018,A DIRT-T Approach to Unsupervised Domain Adaptation,Hung H Bui,DeepMind
ICLR,2018,A DIRT-T Approach to Unsupervised Domain Adaptation,Hirokazu Narui,Stanford University
ICLR,2018,A DIRT-T Approach to Unsupervised Domain Adaptation,Stefano Ermon,Stanford University
ICLR,2018,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,Dejiao Zhang,University of Michigan
ICLR,2018,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,Haozhu Wang,University of Michigan
ICLR,2018,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,Mario Figueiredo,"Instituto de Telecomunicações, IST, University of Lisbon"
ICLR,2018,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,Laura Balzano,None
ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,Roy Fox,UC Berkeley
ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,Richard Shin,UC Berkeley
ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,Sanjay Krishnan,None
ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,Ken Goldberg,None
ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,dawn song,uc berkeley
ICLR,2018,Parametrized Hierarchical Procedures for Neural Programming,Ion Stoica,UC Berkeley
ICLR,2018,Auto-Encoding Sequential Monte Carlo,Tuan Anh Le,University of Oxford
ICLR,2018,Auto-Encoding Sequential Monte Carlo,Maximilian Igl,University of Oxford
ICLR,2018,Auto-Encoding Sequential Monte Carlo,Tom Rainforth,University of Oxford
ICLR,2018,Auto-Encoding Sequential Monte Carlo,Tom Jin,JP Morgan
ICLR,2018,Auto-Encoding Sequential Monte Carlo,Frank Wood,University of British Columbia
ICLR,2018,Syntax-Directed Variational Autoencoder for Structured Data,Hanjun Dai,Georgia Institute of Technology
ICLR,2018,Syntax-Directed Variational Autoencoder for Structured Data,Yingtao Tian,"State University of New York, Stony Brook"
ICLR,2018,Syntax-Directed Variational Autoencoder for Structured Data,Bo Dai,Georgia Institute of Technology
ICLR,2018,Syntax-Directed Variational Autoencoder for Structured Data,Steven Skiena,Stony Brook University
ICLR,2018,Syntax-Directed Variational Autoencoder for Structured Data,Le Song,None
ICLR,2018,Learn to Pay Attention,Saumya Jetley,University of Oxford
ICLR,2018,Learn to Pay Attention,Nick Lord,University of Oxford
ICLR,2018,Learn to Pay Attention,Namhoon Lee,University of Oxford
ICLR,2018,Learn to Pay Attention,Philip Torr,None
ICLR,2018,The power of deeper networks for expressing natural functions,David Rolnick,MIT
ICLR,2018,The power of deeper networks for expressing natural functions,Max Tegmark,None
ICLR,2018,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,Emmanuel d Bezenac,None
ICLR,2018,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,Arthur Pajot,Sorbonnes Universite
ICLR,2018,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,gallinari patrick,Sorbonne Universite
ICLR,2018,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,Hao Zhang,Xidian University
ICLR,2018,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,Bo Chen,Xidian University
ICLR,2018,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,Dandan Guo,Xidian University
ICLR,2018,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,Mingyuan Zhou,University of Texas at Austin
ICLR,2018,Divide and Conquer Networks,Alex Nowak,Universitat Politecnica de Catalunya
ICLR,2018,Divide and Conquer Networks,David Folqué Garcia,Universitat Politècnica de Catalunya
ICLR,2018,Divide and Conquer Networks,Joan Bruna,University of California Berkeley
ICLR,2018,Hierarchical Representations for Efficient Architecture Search,Hanxiao Liu,Carnegie Mellon University
ICLR,2018,Hierarchical Representations for Efficient Architecture Search,Karen Simonyan,DeepMind
ICLR,2018,Hierarchical Representations for Efficient Architecture Search,Oriol Vinyals,Google DeepMind
ICLR,2018,Hierarchical Representations for Efficient Architecture Search,Chrisantha Fernando,DeepMind
ICLR,2018,Hierarchical Representations for Efficient Architecture Search,Koray Kavukcuoglu,DeepMind
ICLR,2018,On the insufficiency of existing momentum schemes for Stochastic Optimization,Rahul Kidambi,"University of Washington, Seattle"
ICLR,2018,On the insufficiency of existing momentum schemes for Stochastic Optimization,Praneeth Netrapalli,Microsoft Research
ICLR,2018,On the insufficiency of existing momentum schemes for Stochastic Optimization,Prateek Jain,"University of Texas, Austin"
ICLR,2018,On the insufficiency of existing momentum schemes for Stochastic Optimization,Sham M Kakade,University of Washington
ICLR,2018,Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering,Elliot Meyerson,The University of Texas at Austin & Sentient Technologies
ICLR,2018,Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering,Risto Miikkulainen,The University of Texas at Austin and Sentient Technologies
ICLR,2018,Towards Deep Learning Models Resistant to Adversarial Attacks,Aleksander Madry,MIT
ICLR,2018,Towards Deep Learning Models Resistant to Adversarial Attacks,Aleksandar A Makelov,University of Cambridge
ICLR,2018,Towards Deep Learning Models Resistant to Adversarial Attacks,Ludwig Schmidt,University of California Berkeley
ICLR,2018,Towards Deep Learning Models Resistant to Adversarial Attacks,Dimitris Tsipras,MIT
ICLR,2018,Towards Deep Learning Models Resistant to Adversarial Attacks,Adrian Vladu,Boston University
ICLR,2018,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,Zhilin Yang,Carnegie Mellon University
ICLR,2018,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,Zihang Dai,Carnegie Mellon University
ICLR,2018,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,,None
ICLR,2018,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,William W Cohen,Carnegie Mellon University
ICLR,2018,Neural Speed Reading via Skim-RNN,Minjoon Seo,NAVER & U of Washington
ICLR,2018,Neural Speed Reading via Skim-RNN,Sewon Min,Seoul National University
ICLR,2018,Neural Speed Reading via Skim-RNN,Ali Farhadi,None
ICLR,2018,Neural Speed Reading via Skim-RNN,Hannaneh Hajishirzi,None
ICLR,2018,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,Greg Farquhar,University of Oxford
ICLR,2018,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,Tim Rocktaeschel,"Department of Computer Science, University College London"
ICLR,2018,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,Maximilian Igl,University of Oxford
ICLR,2018,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,Shimon Whiteson,University of Oxford
ICLR,2018,Gradient Estimators for Implicit Models,Yingzhen Li,University of Cambridge
ICLR,2018,Gradient Estimators for Implicit Models,Rich E Turner,University of Cambridge
ICLR,2018,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,Jianbo Ye,Pennsylvania State University
ICLR,2018,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,Xin Lu,Adobe
ICLR,2018,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,Zhe Lin,Adobe Research
ICLR,2018,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,James Z Wang,None
ICLR,2018,When is a Convolutional Filter Easy to Learn?,Simon S Du,Carnegie Mellon University
ICLR,2018,When is a Convolutional Filter Easy to Learn?,Jason D Lee,None
ICLR,2018,When is a Convolutional Filter Easy to Learn?,Yuandong Tian,"Google [X], Self-driving car"
ICLR,2018,MGAN: Training Generative Adversarial Nets with Multiple Generators,Quan Hoang,University of Massachusetts-Amherst
ICLR,2018,MGAN: Training Generative Adversarial Nets with Multiple Generators,Tu D Nguyen,Deakin University
ICLR,2018,MGAN: Training Generative Adversarial Nets with Multiple Generators,Trung Le,Centre for Pattern Recognition and Data Analytics (PRaDA)
ICLR,2018,MGAN: Training Generative Adversarial Nets with Multiple Generators,Dinh Phung,Deakin University
ICLR,2018,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,Yanshuai Cao,Borealis AI
ICLR,2018,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,Gavin Weiguang Ding,Borealis AI
ICLR,2018,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,Yik Chau Lui,Borealis AI
ICLR,2018,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,Ruitong Huang,University of Alberta
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Gabriel Barth-maron,Brown University
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Matthew Hoffman,Google
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,David Budden,DeepMind
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Will Dabney,Amazon
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Dan Horgan,DeepMind
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Dhruva TB Tirumala Bukkapatnam,DeepMind
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Alistair M Muldal,DeepMind
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Nicolas Heess,None
ICLR,2018,Distributed Distributional Deterministic Policy Gradients,Timothy Lillicrap,DeepMind & UCL
ICLR,2018,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,Evan Z Liu,Stanford University
ICLR,2018,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,Kelvin Guu,Stanford University
ICLR,2018,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,Panupong Pasupat,Stanford University
ICLR,2018,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,Tim Shi,Stanford University
ICLR,2018,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,Percy Liang,None
ICLR,2018,Learning a Generative Model for Validity in Complex Discrete Structures,David Janz,University of Cambridge
ICLR,2018,Learning a Generative Model for Validity in Complex Discrete Structures,Jos van der Westhuizen,Cambridge University
ICLR,2018,Learning a Generative Model for Validity in Complex Discrete Structures,Brooks Paige,Alan Turing Institute / University of Cambridge
ICLR,2018,Learning a Generative Model for Validity in Complex Discrete Structures,Matt J Kusner,Alan Turing Institute
ICLR,2018,Learning a Generative Model for Validity in Complex Discrete Structures,José Miguel Hernández Lobato,University of Cambridge
ICLR,2018,TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING,Wen Sun,Carnegie Mellon University
ICLR,2018,TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING,J. A Bagnell,None
ICLR,2018,TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING,Byron Boots,Georgia Institute of Technology
ICLR,2018,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,Yeming Wen,University of Toronto
ICLR,2018,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,Paul Vicol,University of Toronto
ICLR,2018,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,Jimmy Ba,University of Toronto
ICLR,2018,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,Dustin Tran,None
ICLR,2018,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,Roger Grosse,University of Toronto and Vector Institute
ICLR,2018,Lifelong Learning with Dynamically Expandable Networks,Jaehong Yoon,Ulsan National Institute of Science and Technology
ICLR,2018,Lifelong Learning with Dynamically Expandable Networks,Eunho Yang,Korea Advanced Institute of Science and Technology
ICLR,2018,Lifelong Learning with Dynamically Expandable Networks,Jeongtae Lee,UNIST
ICLR,2018,Lifelong Learning with Dynamically Expandable Networks,Sung Ju Hwang,KAIST
ICLR,2018,Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings,Kangwook Lee,KAIST
ICLR,2018,Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings,Hoon Kim,Korea Advanced Institute of Science and Technology
ICLR,2018,Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings,Changho Suh,KAIST
ICLR,2018,Quantitatively Evaluating GANs With Divergences Proposed for Training,Daniel Im,Janelia Research Campus
ICLR,2018,Quantitatively Evaluating GANs With Divergences Proposed for Training,He Ma,University of Guelph
ICLR,2018,Quantitatively Evaluating GANs With Divergences Proposed for Training,Graham W Taylor,University of Guelph
ICLR,2018,Quantitatively Evaluating GANs With Divergences Proposed for Training,Kristin Branson,California Institute of Technology
ICLR,2018,Attacking Binarized Neural Networks,Angus Galloway,University of Guelph
ICLR,2018,Attacking Binarized Neural Networks,Graham W Taylor,University of Guelph
ICLR,2018,Attacking Binarized Neural Networks,Medhat Moussa,University of Guelph
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Rajarshi Das,"University of Massachusetts, Amherst"
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Shehzaad Dhuliawala,"Department of Computer Science, University of Massachusetts, Amherst"
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Manzil Zaheer,Carnegie Mellon University
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Luke Vilnis,None
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Ishan Durugkar,"College of Information and Computer Science, University of Massachusetts, Amherst"
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Akshay Krishnamurthy,UMass Amherst
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Alex Smola,None
ICLR,2018,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,Andrew McCallum,WhizBang Labs
ICLR,2018,Zero-Shot Visual Imitation,Deepak Pathak,UC Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Parsa Mahmoudieh,UC Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Michael Luo,"University of California, Berkeley"
ICLR,2018,Zero-Shot Visual Imitation,Pulkit Agrawal,University of California Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Dian Chen,University of California Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Fred Shentu,None
ICLR,2018,Zero-Shot Visual Imitation,Evan Shelhamer,UC Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Jitendra Malik,UC Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Alyosha Efros,UC Berkeley
ICLR,2018,Zero-Shot Visual Imitation,Trevor Darrell,UC Berkeley
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Dipankar Das,Indian Institute of Technology Kharagpur
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Naveen Mellempudi,Intel Corporation
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Dheevatsa Mudigere,Intel Labs
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Dhiraj Kalamkar,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Sasi Avancha,Intel Technology India Pvt. Ltd.
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Kunal Banerjee,Intel
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Srinivas Sridharan,Intel Corporation
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Karthik Vaidyanathan,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Bharat Kaul,Intel Corporation
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Evangelos Georganas,Intel
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Alexander Heinecke,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Pradeep K Dubey,Intel Corporation
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Jesus Corbal,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Nikita Shustrov,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Roma Dubtsov,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Evarist Fomenko,None
ICLR,2018,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,Vadim Pirogov,Intel Corporation
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Aviv Tamar,Technion
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Khashayar Rohanimanesh,Osaro
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Yinlam Chow,DeepMind
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Chris Vigorito,"Osaro, Inc."
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Ben Goodrich,None
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Michael Kahane,None
ICLR,2018,Imitation Learning from Visual Data with Multiple Intentions,Derik Pridmore,None
ICLR,2018,Demystifying MMD GANs,Mikolaj Binkowski,Imperial College London
ICLR,2018,Demystifying MMD GANs,Dougal Sutherland,"Gatsby unit, University College London"
ICLR,2018,Demystifying MMD GANs,Michael Arbel,None
ICLR,2018,Demystifying MMD GANs,Arthur Gretton,University College London
ICLR,2018,A Framework for the Quantitative Evaluation of Disentangled Representations,Cian Eastwood,University of Edinburgh
ICLR,2018,A Framework for the Quantitative Evaluation of Disentangled Representations,Chris Williams,University of Edinburgh
ICLR,2018,Decision Boundary Analysis of Adversarial Examples,Warren He,UC Berkeley
ICLR,2018,Decision Boundary Analysis of Adversarial Examples,Bo Li,UC Berkeley
ICLR,2018,Decision Boundary Analysis of Adversarial Examples,dawn song,uc berkeley
ICLR,2018,Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning,Clemens Rosenbaum,UMass Amherst
ICLR,2018,Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning,Tim Klinger,IBM Research AI
ICLR,2018,Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning,Matt Riemer,IBM Research AI
ICLR,2018,Compositional Attention Networks for Machine Reasoning,Drew A. Hudson,Stanford University
ICLR,2018,Compositional Attention Networks for Machine Reasoning,Christopher Manning,"Computer Science Department, Stanford University"
ICLR,2018,Memory-based Parameter Adaptation,Pablo Sprechmann,DeepMind
ICLR,2018,Memory-based Parameter Adaptation,Siddhant Jayakumar,University of Cambridge
ICLR,2018,Memory-based Parameter Adaptation,Jack Rae,"DeepMind, University College London"
ICLR,2018,Memory-based Parameter Adaptation,Alexander Pritzel,None
ICLR,2018,Memory-based Parameter Adaptation,Adria P Badia,None
ICLR,2018,Memory-based Parameter Adaptation,Benigno Uria,None
ICLR,2018,Memory-based Parameter Adaptation,Oriol Vinyals,Google DeepMind
ICLR,2018,Memory-based Parameter Adaptation,Demis Hassabis,None
ICLR,2018,Memory-based Parameter Adaptation,Razvan Pascanu,DeepMind
ICLR,2018,Memory-based Parameter Adaptation,Charles Blundell,None
ICLR,2018,Semi-parametric topological memory for navigation,Nikolay Savinov,ETH Zurich
ICLR,2018,Semi-parametric topological memory for navigation,Alexey Dosovitskiy,Intel Labs
ICLR,2018,Semi-parametric topological memory for navigation,Vladlen Koltun,Intel Labs
ICLR,2018,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models,Jesse Engel,Google Brain
ICLR,2018,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models,Matthew D Hoffman,Adobe
ICLR,2018,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models,Adam Roberts,Google Brain
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Andrew Saxe,Harvard University
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Yamini Bansal,Harvard University
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Joel Dapello,Harvard University
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Madhu Advani,None
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Artemy Kolchinsky,Santa Fe Institute
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,Brendan D Tracey,Santa Fe Institute / MIT
ICLR,2018,On the Information Bottleneck Theory of Deep Learning,David D Cox,Harvard University
ICLR,2018,Sensitivity and Generalization in Neural Networks: an Empirical Study,Roman Novak,Google Brain
ICLR,2018,Sensitivity and Generalization in Neural Networks: an Empirical Study,Yasaman Bahri,Google Brain
ICLR,2018,Sensitivity and Generalization in Neural Networks: an Empirical Study,Dan Abolafia,Google Brain
ICLR,2018,Sensitivity and Generalization in Neural Networks: an Empirical Study,Jeffrey Pennington,Google Brain
ICLR,2018,Sensitivity and Generalization in Neural Networks: an Empirical Study,Jascha Sohl-Dickstein,Google Brain
ICLR,2018,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,Yujun Lin,Tsinghua University
ICLR,2018,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,song han,Stanford University
ICLR,2018,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,,None
ICLR,2018,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,Yu Wang,None
ICLR,2018,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,Bill Dally,NVIDIA & Stanford
ICLR,2018,Skip Connections Eliminate Singularities,Emin Orhan,Rice University
ICLR,2018,Skip Connections Eliminate Singularities,Xaq Pitkow,Baylor College of Medicine / Rice University
ICLR,2018,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,Yaguang Li,University of Southern California
ICLR,2018,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,Rose Yu,Caltech
ICLR,2018,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,Cyrus Shahabi,None
ICLR,2018,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,Yan Liu,None
ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Antoine Thomas Bosselut,University of Washington
ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Omer Levy,University of Washington
ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Ari Holtzman,New York University
ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Corin Ennis,University of Washington Bothell
ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Dieter Fox,NVIDIA Research / University of Washington
ICLR,2018,Simulating Action Dynamics with Neural Process Networks,Yejin Choi,University of Washington
ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Dmitrii Serdyuk,Montreal Institute for Learning Algorithms
ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Nan Rosemary Ke,"MILA, Polytechnique Montreal"
ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Alessandro Sordoni,Microsoft Research Montreal
ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Adam Trischler,None
ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Chris Pal,Polytechnique Montréal & MILA
ICLR,2018,Twin Networks: Matching the Future for Sequence Generation,Yoshua Bengio,University of Montreal
ICLR,2018,Deep Learning as a Mixed Convex-Combinatorial Optimization Problem,Abram Friesen,University of Washington
ICLR,2018,Deep Learning as a Mixed Convex-Combinatorial Optimization Problem,Pedro Domingos,University of Washington
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,Adams Wei Yu,Carnegie Mellon University
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,David Dohan,Google Brain
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,Thang Luong,Google Brain
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,Rui Zhao,Google Inc
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,Kai Chen,Google Inc.
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,Mohammad Norouzi,Google Brain
ICLR,2018,Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution,Quoc V Le,Google
ICLR,2018,Multi-Mention Learning for Reading Comprehension with Neural Cascades,Swabha Swayamdipta,Carnegie Mellon University
ICLR,2018,Multi-Mention Learning for Reading Comprehension with Neural Cascades,Ankur Parikh,Google
ICLR,2018,Multi-Mention Learning for Reading Comprehension with Neural Cascades,Tom Kwiatkowski,Google
ICLR,2018,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs",Sanjeev Arora,Princeton University and Institute for Advanced Study
ICLR,2018,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs",Misha Khodak,Princeton University
ICLR,2018,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs",Nikunj Saunshi,Princeton University
ICLR,2018,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs",Kiran Vodrahalli,Columbia University
ICLR,2018,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,Sandeep Subramanian,Université de Montréal
ICLR,2018,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,Adam Trischler,None
ICLR,2018,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,Yoshua Bengio,University of Montreal
ICLR,2018,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,Chris Pal,Polytechnique Montréal & MILA
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Shuohang Wang,Singapore Management University
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Mo Yu,IBM Research
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Jing Jiang,None
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Wei Zhang,IBM Research
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Xiaoxiao Guo,University of Michigan
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Shiyu Chang,None
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Zhiguo Wang,IBM Research AI
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Tim Klinger,IBM Research AI
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Gerald Tesauro,IBM Research
ICLR,2018,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,Murray Campbell,IBM Research
ICLR,2018,The Kanerva Machine: A Generative Distributed Memory,Yan Wu,DeepMind
ICLR,2018,The Kanerva Machine: A Generative Distributed Memory,Greg Wayne,None
ICLR,2018,The Kanerva Machine: A Generative Distributed Memory,Alex Graves,None
ICLR,2018,The Kanerva Machine: A Generative Distributed Memory,Timothy Lillicrap,DeepMind & UCL
ICLR,2018,Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data,William A Falcon,Columbia University
ICLR,2018,Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data,Henning Schulzrinne,Columbia University
ICLR,2018,Deep Active Learning for Named Entity Recognition,Yanyao Shen,UT Austin
ICLR,2018,Deep Active Learning for Named Entity Recognition,Hyokun Yun,Amazon
ICLR,2018,Deep Active Learning for Named Entity Recognition,Zachary Lipton,Carnegie Mellon University
ICLR,2018,Deep Active Learning for Named Entity Recognition,Yakov Kronrod,Amazon Web Services
ICLR,2018,Deep Active Learning for Named Entity Recognition,Anima anandkumar,Caltech / Amazon AI
ICLR,2018,Variational Network Quantization,Jan Achterhold,RWTH Aachen
ICLR,2018,Variational Network Quantization,Jan M Koehler,None
ICLR,2018,Variational Network Quantization,Anke Schmeink,None
ICLR,2018,Variational Network Quantization,Tim Genewein,Bosch Center for Artificial Intelligence
ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Ashwin Vijayakumar,Georgia Institute of Technology
ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Abhishek Mohta,Microsoft Research
ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Alex Polozov,Microsoft Research
ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Dhruv Batra,Georgia Tech / Facebook AI Research
ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Prateek Jain,"University of Texas, Austin"
ICLR,2018,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,Sumit Gulwani,None
ICLR,2018,Cascade Adversarial Machine Learning Regularized with a Unified Embedding,Taesik Na,Georgia Institute of Technology
ICLR,2018,Cascade Adversarial Machine Learning Regularized with a Unified Embedding,Jong Hwan Ko,Georgia Institute of Technology
ICLR,2018,Cascade Adversarial Machine Learning Regularized with a Unified Embedding,Saibal Mukhopadhyay,None
ICLR,2018,Training and Inference with Integers in Deep Neural Networks,Shuang Wu,Tsinghua University
ICLR,2018,Training and Inference with Integers in Deep Neural Networks,Guoqi Li,Tsinghua University
ICLR,2018,Training and Inference with Integers in Deep Neural Networks,Feng Chen,None
ICLR,2018,Training and Inference with Integers in Deep Neural Networks,Luping Shi,None
ICLR,2018,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization,Adam Earle,University of the Witwatersrand
ICLR,2018,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization,Andrew Saxe,Harvard University
ICLR,2018,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization,Benjamin Rosman,Council for Scientific and Industrial Research
ICLR,2018,A Simple Neural Attentive Meta-Learner,Nikhil Mishra,UC Berkeley
ICLR,2018,A Simple Neural Attentive Meta-Learner,Mostafa Rohaninejad,UC Berkeley
ICLR,2018,A Simple Neural Attentive Meta-Learner,Xi Chen,University of California Berkeley
ICLR,2018,A Simple Neural Attentive Meta-Learner,Pieter Abbeel,UC Berkeley / Embodied Intelligence
ICLR,2018,Dynamic Neural Program Embeddings for Program Repair,Ke Wang,"University of California, Davis"
ICLR,2018,Dynamic Neural Program Embeddings for Program Repair,Rishabh Singh,Google Brain
ICLR,2018,Dynamic Neural Program Embeddings for Program Repair,Zhendong Su,"University of California, Davis"
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Guneet S Dhillon,University of Texas at Austin
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Kamyar Azizzadenesheli,UCI-Stanford
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Zachary Lipton,Carnegie Mellon University
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Jeremy Bernstein,California Institute of Technology
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Jean Kossaifi,Imperial College London
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Aran Khanna,Amazon
ICLR,2018,Stochastic Activation Pruning for Robust Adversarial Defense,Anima anandkumar,Caltech / Amazon AI
ICLR,2018,Do GANs learn the distribution? Some Theory and Empirics,Sanjeev Arora,Princeton University and Institute for Advanced Study
ICLR,2018,Do GANs learn the distribution? Some Theory and Empirics,Andrej Risteski,None
ICLR,2018,Do GANs learn the distribution? Some Theory and Empirics,Yi Zhang,Princeton University
ICLR,2018,Learning Parametric Closed-Loop Policies for Markov Potential Games,Sergio Valcarcel Macua,PROWLER.io
ICLR,2018,Learning Parametric Closed-Loop Policies for Markov Potential Games,Javier Zazo,Universidad Politécnica de Madrid
ICLR,2018,Learning Parametric Closed-Loop Policies for Markov Potential Games,Santiago Zazo,None
ICLR,2018,Learning Approximate Inference Networks for Structured Prediction,Lifu Tu,Toyota Technological Institute at Chicago
ICLR,2018,Learning Approximate Inference Networks for Structured Prediction,Kevin Gimpel,Toyota Technological Institute at Chicago
ICLR,2018,Fidelity-Weighted Learning,Mostafa Dehghani,University of Amsterdam
ICLR,2018,Fidelity-Weighted Learning,Arash Mehrjou,Max Planck Institute for Intelligent Systems
ICLR,2018,Fidelity-Weighted Learning,Stephan Gouws,Google Brain
ICLR,2018,Fidelity-Weighted Learning,Jaap Kamps,University of Amsterdam
ICLR,2018,Fidelity-Weighted Learning,Bernhard Schoelkopf,Max Planck / Amazon
ICLR,2018,HexaConv,Emiel Hoogeboom,University of Amsterdam
ICLR,2018,HexaConv,Jorn Peters,University of Amsterdam
ICLR,2018,HexaConv,Taco Cohen,Qualcomm & University of Amsterdam
ICLR,2018,HexaConv,Max Welling,University of Amsterdam  &  Qualcomm
ICLR,2018,On the Convergence of Adam and Beyond,Sashank Reddi,Google
ICLR,2018,On the Convergence of Adam and Beyond,Satyen Kale,None
ICLR,2018,On the Convergence of Adam and Beyond,Sanjiv Kumar,"Google Research, NY"
ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Shiv Shankar,IIT Bombay
ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Vihari Piratla,IIT Bombay
ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Soumen Chakrabarti,None
ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Siddhartha Chaudhuri,Adobe Research/IIT Bombay
ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Preethi Jyothi,Indian Institute of Technology Bombay
ICLR,2018,Generalizing Across Domains via Cross-Gradient Training,Sunita Sarawagi,None
ICLR,2018,Understanding image motion with group representations,Andrew Jaegle,University of Pennsylvania
ICLR,2018,Understanding image motion with group representations,Stephen Phillips,University of Pennsylvania
ICLR,2018,Understanding image motion with group representations,Daphne Ippolito,University of Pennsylvania
ICLR,2018,Understanding image motion with group representations,Kostas Daniilidis,University of Pennsylvania
ICLR,2018,Matrix capsules with EM routing,Geoffrey E Hinton,None
ICLR,2018,Matrix capsules with EM routing,Sara Sabour,Google Brain
ICLR,2018,Matrix capsules with EM routing,Nicholas Frosst,Google Brain
ICLR,2018,Global Optimality Conditions for Deep Neural Networks,Chulhee (Charlie) Yun,MIT
ICLR,2018,Global Optimality Conditions for Deep Neural Networks,Suvrit Sra,Massachusetts Institute of Technology
ICLR,2018,Global Optimality Conditions for Deep Neural Networks,Ali Jadbabaie,University of Pennsylvania
ICLR,2018,A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks,Behnam Neyshabur,Toyota Technological Institute at Chicago
ICLR,2018,A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks,Srinadh Bhojanapalli,Toyota Technological Institute at Chicago
ICLR,2018,A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks,Nati Srebro,TTIC
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Lily Weng,Massachusetts Institute of Technology
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Huan Zhang,UC Davis
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Pin-Yu Chen,IBM Research AI
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Jinfeng Yi,Tencent AI Lab
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Dong Su,None
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Yupeng Gao,IBM
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Cho-Jui Hsieh,"University of Texas, Austin"
ICLR,2018,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Luca Daniel,None
ICLR,2018,Sobolev GAN,Youssef Mroueh,IBM Research AI
ICLR,2018,Sobolev GAN,Chun-Liang Li,"Machine Learning Department, Carnegie Mellon University"
ICLR,2018,Sobolev GAN,Tom Sercu,IBM Research AI
ICLR,2018,Sobolev GAN,Anant Raj,Max-Planck Institute for Intelligent Systems
ICLR,2018,Sobolev GAN,Yu Cheng,IBM Research AI
ICLR,2018,Divide-and-Conquer Reinforcement Learning,Dibya Ghosh,UC Berkeley
ICLR,2018,Divide-and-Conquer Reinforcement Learning,Avi Singh,"University of California, Berkeley"
ICLR,2018,Divide-and-Conquer Reinforcement Learning,Aravind Rajeswaran,University of Washington Seattle
ICLR,2018,Divide-and-Conquer Reinforcement Learning,Vikash Kumar,None
ICLR,2018,Divide-and-Conquer Reinforcement Learning,Sergey Levine,UC Berkeley
ICLR,2018,i-RevNet: Deep Invertible Networks,Joern-Henrik Jacobsen,University of Amsterdam
ICLR,2018,i-RevNet: Deep Invertible Networks,Arnold W Smeulders,None
ICLR,2018,i-RevNet: Deep Invertible Networks,Edouard Oyallon,INRIA Lille
ICLR,2018,Multi-View Data Generation Without View Supervision,Mickael Chen,Sorbonne Université - LIP6
ICLR,2018,Multi-View Data Generation Without View Supervision,Ludovic Denoyer,LIP6 - University Pierre et Marie Curie -- Criteo Research
ICLR,2018,Multi-View Data Generation Without View Supervision,thierry artieres,"Ecole Centrale Marseille, Aix Marseille Univ, Université de Toulon, CNRS, LIS, Marseille, France"
ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,Hao Liu,University of Electronic Science and Technology of China
ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,Yihao Feng,The University of Texas at Austin
ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,Yi Mao,None
ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,Denny Zhou,Google
ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,Jian Peng,"University of Illinois, Urbana Champaign"
ICLR,2018,Action-dependent Control Variates for Policy Optimization via Stein Identity,,None
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Christian Buck,University of Edinburgh
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Jannis Bulian,Google
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Massimiliano Ciaramita,Google
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Wojciech Gajewski,Google
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Andrea Gesmundo,University of Geneva
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Neil Houlsby,Google
ICLR,2018,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,Wei Wang.,None
ICLR,2018,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,Vitchyr Pong,UC Berkeley
ICLR,2018,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,Shixiang (Shane) Gu,University of Cambridge
ICLR,2018,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,Murtaza Dalal,"Electrical Engineering & Computer Science Department, University of California Berkeley"
ICLR,2018,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,Sergey Levine,UC Berkeley
ICLR,2018,Model-Ensemble Trust-Region Policy Optimization,Thanard Kurutach,University of California Berkeley
ICLR,2018,Model-Ensemble Trust-Region Policy Optimization,Ignasi Clavera,UC Berkeley
ICLR,2018,Model-Ensemble Trust-Region Policy Optimization,Yan Duan,OpenAI
ICLR,2018,Model-Ensemble Trust-Region Policy Optimization,Aviv Tamar,Technion
ICLR,2018,Model-Ensemble Trust-Region Policy Optimization,Pieter Abbeel,UC Berkeley / Embodied Intelligence
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Peter J Liu,None
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Mohammad Saleh,Google
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Etienne Pot,Google
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Ben Goodrich,Google
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Ryan Sepassi,Google Brain
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Lukasz Kaiser,Google
ICLR,2018,Generating Wikipedia by Summarizing Long Sequences,Noam Shazeer,Duke University
ICLR,2018,Neural Language Modeling by Jointly Learning Syntax and Lexicon,Yikang Shen,University of Montreal
ICLR,2018,Neural Language Modeling by Jointly Learning Syntax and Lexicon,Zhouhan Lin,University of Montreal
ICLR,2018,Neural Language Modeling by Jointly Learning Syntax and Lexicon,Chin-Wei Huang,University of Montreal
ICLR,2018,Neural Language Modeling by Jointly Learning Syntax and Lexicon,Aaron Courville,U. Montreal
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Bo Zong,NEC Laboratories America
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Qi Song,Washington State University
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Martin Min,NEC Labs America
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Wei Cheng,NEC Labs America
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Cristian Lumezanu,NEC Laboratories America
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Daeki Cho,None
ICLR,2018,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,Haifeng Chen,None
ICLR,2018,An efficient framework for learning sentence representations,Lajanugen Logeswaran,University of Michigan
ICLR,2018,An efficient framework for learning sentence representations,Honglak Lee,Google / U. Michigan
ICLR,2018,Latent Space Oddity: on the Curvature of Deep Generative Models,Georgios Arvanitidis,Technical University of Denmark
ICLR,2018,Latent Space Oddity: on the Curvature of Deep Generative Models,Lars K Hansen,None
ICLR,2018,Latent Space Oddity: on the Curvature of Deep Generative Models,Søren Hauberg,Technical University of Denmark
ICLR,2018,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,Anubhav Ashok,Carnegie Mellon University
ICLR,2018,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,Nicholas Rhinehart,Carnegie Mellon University
ICLR,2018,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,Fares Beainy,None
ICLR,2018,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,Kris M Kitani,Carnegie Mellon University
ICLR,2018,Variational Message Passing with Structured Inference Networks,Wu Lin,UBC
ICLR,2018,Variational Message Passing with Structured Inference Networks,Nicolas Daniel Hubacher,RIKEN
ICLR,2018,Variational Message Passing with Structured Inference Networks,Emtiyaz Khan,"RIKEN AIP, Tokyo"
ICLR,2018,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,Angeliki Lazaridou,DeepMind
ICLR,2018,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,Karl M Hermann,None
ICLR,2018,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,Karl Tuyls,DeepMind and University of Liverpool
ICLR,2018,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,Stephen Clark,DeepMind
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Irina Higgins,DeepMind
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Nicolas Sonnerat,DeepMind
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Loic Matthey,DeepMind
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Arka Pal,None
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Christopher P Burgess,University College London
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Matko Bošnjak,"Department of Computer Science, University College London"
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Murray Shanahan,None
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Matthew Botvinick,None
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,,None
ICLR,2018,SCAN: Learning Hierarchical Compositional Visual Concepts,Alexander Lerchner,DeepMind
ICLR,2018,The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings,Tomer Galanti,Tel Aviv University
ICLR,2018,The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings,Lior Wolf,Facebook AI Research
ICLR,2018,The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings,Sagie Benaim,Tel Aviv University
ICLR,2018,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,Aleksander Wieczorek,University of Basel
ICLR,2018,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,Mario Wieser,University of Basel
ICLR,2018,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,Damian Murezzan,University of Basel
ICLR,2018,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,Volker Roth,University of Basel
ICLR,2018,Learning From Noisy Singly-labeled Data,Ashish Khetan,University of Illinois Urbana Champaign
ICLR,2018,Learning From Noisy Singly-labeled Data,Zachary Lipton,Carnegie Mellon University
ICLR,2018,Learning From Noisy Singly-labeled Data,Anima anandkumar,Caltech / Amazon AI
ICLR,2018,Gaussian Process Behaviour in Wide Deep Neural Networks,Alexander Matthews,University of Cambridge
ICLR,2018,Gaussian Process Behaviour in Wide Deep Neural Networks,Jiri Hron,University of Cambridge
ICLR,2018,Gaussian Process Behaviour in Wide Deep Neural Networks,Mark Rowland,University of Cambridge
ICLR,2018,Gaussian Process Behaviour in Wide Deep Neural Networks,Rich E Turner,University of Cambridge
ICLR,2018,Gaussian Process Behaviour in Wide Deep Neural Networks,Zoubin Ghahramani,University of Cambridge & Uber
ICLR,2018,Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties,Yi Zhou,The Ohio State University
ICLR,2018,Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties,Yingbin Liang,The Ohio State University
ICLR,2018,Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy,Asit Mishra,Intel Labs
ICLR,2018,Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy,Debbie Marr,None
ICLR,2018,Wavelet Pooling for Convolutional Neural Networks,Travis Williams,North Carolina A&T State University
ICLR,2018,Wavelet Pooling for Convolutional Neural Networks,Robert Li,None
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Xingjun (Daniel) Ma,The University of Melbourne
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Bo Li,UC Berkeley
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Yisen Wang,Tsinghua University
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Sarah Erfani,The University of Melbourne
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Sudanthi Wijewickrema,The University of Melbourne
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Grant Schoenebeck,University of Michigan
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,dawn song,uc berkeley
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,Michael E Houle,National Institute of Informatics
ICLR,2018,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,James Bailey,University of Melbourne
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Wei Wen,Duke University
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Yuxiong He,Microsoft
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Samyam Rajbhandari,None
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Minjia Zhang,Ohio State University
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Wenhan Wang,None
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Fang Liu,None
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Bin Hu,Microsoft
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Yiran Chen,None
ICLR,2018,Learning Intrinsic Sparse Structures within Long Short-Term Memory,Hai Li,Duke University
ICLR,2018,FearNet: Brain-Inspired Model for Incremental Learning,Ronald Kemker,Rochester Institute of Technology
ICLR,2018,FearNet: Brain-Inspired Model for Incremental Learning,Chris Kanan,Rochester Institute of Technology
ICLR,2018,Variational Inference of Disentangled Latent Concepts from Unlabeled Observations,Abhishek Kumar,University of Maryland College Park
ICLR,2018,Variational Inference of Disentangled Latent Concepts from Unlabeled Observations,Prasanna Sattigeri,IBM Research
ICLR,2018,Variational Inference of Disentangled Latent Concepts from Unlabeled Observations,Avinash Balakrishnan,IBM Research AI
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Mengye Ren,University of Toronto
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Eleni Triantafillou,University of Toronto
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Sachin Ravi,Princeton University
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Jake Snell,None
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Kevin Swersky,Google Brain
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Joshua B Tenenbaum,None
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Hugo Larochelle,Google Brain
ICLR,2018,Meta-Learning for Semi-Supervised Few-Shot Classification,Richard Zemel,"Department of Computer Science, University of Toronto"
ICLR,2018,Neural Sketch Learning for Conditional Program Generation,Vijay Murali,Rice University
ICLR,2018,Neural Sketch Learning for Conditional Program Generation,Letao Qi,Rice University
ICLR,2018,Neural Sketch Learning for Conditional Program Generation,Swarat Chaudhuri,Rice University
ICLR,2018,Neural Sketch Learning for Conditional Program Generation,Chris Jermaine,None
ICLR,2018,Deep Neural Networks as Gaussian Processes,Jaehoon Lee,Google Brain
ICLR,2018,Deep Neural Networks as Gaussian Processes,Yasaman Bahri,Google Brain
ICLR,2018,Deep Neural Networks as Gaussian Processes,Roman Novak,Google Brain
ICLR,2018,Deep Neural Networks as Gaussian Processes,Samuel S Schoenholz,Google
ICLR,2018,Deep Neural Networks as Gaussian Processes,Jeffrey Pennington,Google Brain
ICLR,2018,Deep Neural Networks as Gaussian Processes,Jascha Sohl-Dickstein,Google Brain
ICLR,2018,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks,Krzysztof Choromanski,Google Brain Robotics
ICLR,2018,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks,Carlton Downey,Carnegie Mellon University
ICLR,2018,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks,Byron Boots,Georgia Institute of Technology
ICLR,2018,Expressive power of recurrent neural networks,Valentin Khrulkov,Skolkovo Institute of Science and Technology
ICLR,2018,Expressive power of recurrent neural networks,Alexander Novikov,National Research University Higher School of Economics
ICLR,2018,Expressive power of recurrent neural networks,Ivan Oseledets,Skolkovo Institute of Science and Technology
ICLR,2018,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,pouya Samangouei,"University of Maryland, College Park"
ICLR,2018,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,Maya Kabkab,University of Maryland
ICLR,2018,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,Rama Chellappa,University of Maryland
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Cathy Wu,UC Berkeley
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Aravind Rajeswaran,University of Washington Seattle
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Yan Duan,OpenAI
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Vikash Kumar,None
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Alexandre M Bayen,None
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Sham M Kakade,University of Washington
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Igor Mordatch,None
ICLR,2018,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,Pieter Abbeel,UC Berkeley / Embodied Intelligence
ICLR,2018,Certified Defenses against Adversarial Examples,Aditi Raghunathan,Stanford university
ICLR,2018,Certified Defenses against Adversarial Examples,Jacob Steinhardt,Stanford University
ICLR,2018,Certified Defenses against Adversarial Examples,Percy Liang,None
ICLR,2018,Semantic Interpolation in Implicit Models,Yannic Kilcher,ETH Zurich
ICLR,2018,Semantic Interpolation in Implicit Models,Aurelien Lucchi,Swiss Federal Institute of Technology
ICLR,2018,Semantic Interpolation in Implicit Models,Thomas Hofmann,None
ICLR,2018,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,Ben Eysenbach,Google
ICLR,2018,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,Shixiang (Shane) Gu,University of Cambridge
ICLR,2018,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,Julian Ibarz,google.com
ICLR,2018,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,Sergey Levine,UC Berkeley
ICLR,2018,Learning One-hidden-layer Neural Networks with Landscape Design,Rong Ge,Microsoft
ICLR,2018,Learning One-hidden-layer Neural Networks with Landscape Design,Jason Lee,University of Southern California
ICLR,2018,Learning One-hidden-layer Neural Networks with Landscape Design,Tengyu Ma,"Department of Computer Science, Princeton University"
ICLR,2018,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,Jacob Buckman,Google
ICLR,2018,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,Aurko Roy,Google
ICLR,2018,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,Colin Raffel,Google Brain
ICLR,2018,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,Ian Goodfellow,Google Brain
ICLR,2018,Training GANs with Optimism,Constantinos C Daskalakis,Massachusetts Institute of Technology
ICLR,2018,Training GANs with Optimism,Andrew Ilyas,Massachusetts Institute of Technology
ICLR,2018,Training GANs with Optimism,Vasilis Syrgkanis,Microsoft
ICLR,2018,Training GANs with Optimism,Haoyang Zeng,Massachusetts Institute of Technology
ICLR,2018,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning,Tianmin Shu,"University of California, Los Angeles"
ICLR,2018,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning,Caiming Xiong,Salesforce Research
ICLR,2018,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning,richard socher,SalesForce.com
ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Audrunas Gruslys,University of Cambridge
ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Will Dabney,Amazon
ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Mohammad Gheshlaghi Azar,DeepMind
ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Bilal Piot,DeepMind
ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Marc G Bellemare,DeepMind
ICLR,2018,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,Remi Munos,DeepMind
ICLR,2018,Distributed Prioritized Experience Replay,Dan Horgan,DeepMind
ICLR,2018,Distributed Prioritized Experience Replay,John Quan,DeepMind
ICLR,2018,Distributed Prioritized Experience Replay,David Budden,DeepMind
ICLR,2018,Distributed Prioritized Experience Replay,Gabriel Barth-maron,Brown University
ICLR,2018,Distributed Prioritized Experience Replay,Matteo Hessel,DeepMind
ICLR,2018,Distributed Prioritized Experience Replay,Hado van Hasselt,DeepMind
ICLR,2018,Distributed Prioritized Experience Replay,David Silver,None
ICLR,2018,Adversarial Dropout Regularization,Kuniaki Saito,The University of Tokyo
ICLR,2018,Adversarial Dropout Regularization,Yoshitaka Ushiku,University of Tokyo
ICLR,2018,Adversarial Dropout Regularization,Tatsuya Harada,The Univ. of Tokyo
ICLR,2018,Adversarial Dropout Regularization,Kate Saenko,Boston University
ICLR,2018,Countering Adversarial Images using Input Transformations,Chuan Guo,Cornell University
ICLR,2018,Countering Adversarial Images using Input Transformations,Mayank Rana,Facebook Inc.
ICLR,2018,Countering Adversarial Images using Input Transformations,Moustapha Cisse,Facebook
ICLR,2018,Countering Adversarial Images using Input Transformations,Laurens van der Maaten,Facebook AI Research
ICLR,2018,Generating Natural Adversarial Examples,Zhengli Zhao,"University of California, Irvine"
ICLR,2018,Generating Natural Adversarial Examples,Dheeru Dua,None
ICLR,2018,Generating Natural Adversarial Examples,Sameer Singh,"University of California, Irvine"
ICLR,2018,Spherical CNNs,Taco Cohen,Qualcomm & University of Amsterdam
ICLR,2018,Spherical CNNs,Mario Geiger,EPFL
ICLR,2018,Spherical CNNs,Jonas Koehler,University of Amsterdam
ICLR,2018,Spherical CNNs,Max Welling,University of Amsterdam  &  Qualcomm
ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Sainaa Sukhbaatar,New York University
ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Zeming Lin,None
ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Ilya Kostrikov,New York University
ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Gabriel Synnaeve,Ecole Normale Supérieure
ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Arthur Szlam,Facebook
ICLR,2018,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,Rob Fergus,Facebook / NYU
ICLR,2018,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs,Jamie Murdoch,UC Berkeley
ICLR,2018,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs,Peter J Liu,None
ICLR,2018,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs,Bin Yu,None
ICLR,2018,Unsupervised Neural Machine Translation,Mikel Artetxe,University of the Basque Country (UPV/EHU)
ICLR,2018,Unsupervised Neural Machine Translation,Gorka Labaka,University of the Baque Country (UPV/EHU)
ICLR,2018,Unsupervised Neural Machine Translation,Eneko Agirre,University of the Basque Country (UPV/EHU)
ICLR,2018,Unsupervised Neural Machine Translation,Kyunghyun Cho,New York University
ICLR,2018,Smooth Loss Functions for Deep Top-k Classification,Leonard Berrada,University of Oxford
ICLR,2018,Smooth Loss Functions for Deep Top-k Classification,Andrew Zisserman,University of Oxford
ICLR,2018,Smooth Loss Functions for Deep Top-k Classification,M. Pawan Kumar,University of Oxford
ICLR,2018,Synthetic and Natural Noise Both Break Neural Machine Translation,Yonatan Belinkov,MIT
ICLR,2018,Synthetic and Natural Noise Both Break Neural Machine Translation,Yonatan Bisk,University of Washington
ICLR,2018,Can Neural Networks Understand Logical Entailment?,Richard Evans,Imperial College London
ICLR,2018,Can Neural Networks Understand Logical Entailment?,David Saxton,DeepMind
ICLR,2018,Can Neural Networks Understand Logical Entailment?,David Amos,None
ICLR,2018,Can Neural Networks Understand Logical Entailment?,Pushmeet Kohli,Microsoft
ICLR,2018,Can Neural Networks Understand Logical Entailment?,Ed Grefenstette,DeepMind / UCL
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Zhilin Yang,Carnegie Mellon University
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Saizheng Zhang,University of Montreal
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Jack Urbanek,Facebook AI Research
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Will Feng,None
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Alexander Miller,Facebook AI Research
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Arthur Szlam,Facebook
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,Douwe Kiela,University of Cambridge
ICLR,2018,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,JASON Weston,Facebook AI Research
ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,William Fedus,University of Montreal
ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,Mihaela Rosca,DeepMind
ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,Balaji Lakshminarayanan,University College London
ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,Andrew Dai,Google Brain
ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,Shakir Mohamed,Google
ICLR,2018,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,Ian Goodfellow,Google Brain
ICLR,2018,Learning Latent Permutations with Gumbel-Sinkhorn Networks,gonzalo mena,Columbia University
ICLR,2018,Learning Latent Permutations with Gumbel-Sinkhorn Networks,David Belanger,Google Brain
ICLR,2018,Learning Latent Permutations with Gumbel-Sinkhorn Networks,Scott Linderman,Columbia University
ICLR,2018,Learning Latent Permutations with Gumbel-Sinkhorn Networks,Jasper Snoek,Google Brain
ICLR,2018,Can recurrent neural networks warp time?,Corentin Tallec,INRIA
ICLR,2018,Can recurrent neural networks warp time?,Yann Ollivier,None
ICLR,2018,Learning Differentially Private Recurrent Language Models,Brendan McMahan,Google
ICLR,2018,Learning Differentially Private Recurrent Language Models,Daniel Ramage,Google Research
ICLR,2018,Learning Differentially Private Recurrent Language Models,Kunal Talwar,Microsoft
ICLR,2018,Learning Differentially Private Recurrent Language Models,Li Zhang,None
ICLR,2018,Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking,Aleksandar Bojchevski,Technical University Munich
ICLR,2018,Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking,Stephan Günnemann,Technical University of Munich
ICLR,2018,SEARNN: Training RNNs with global-local losses,Rémi Leblond,INRIA
ICLR,2018,SEARNN: Training RNNs with global-local losses,Jean-Baptiste Alayrac,Inria / ENS
ICLR,2018,SEARNN: Training RNNs with global-local losses,Anton Osokin,"NRU HSE, Moscow, Russia"
ICLR,2018,SEARNN: Training RNNs with global-local losses,Simon Lacoste-Julien,"MILA, Université de Montréal"
ICLR,2018,Learning to Teach,Yang Fan,University of Science and Technology of China
ICLR,2018,Learning to Teach,Fei Tian,Microsoft Research
ICLR,2018,Learning to Teach,Tao Qin,Microsoft Research Asia
ICLR,2018,Learning to Teach,Tie-Yan Liu,Microsoft
ICLR,2018,Active Learning for Convolutional Neural Networks: A Core-Set Approach,Ozan Sener,Intel Labs
ICLR,2018,Active Learning for Convolutional Neural Networks: A Core-Set Approach,Silvio Savarese,None
ICLR,2018,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,Feiwen Zhu,nvidia
ICLR,2018,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,Jeff Pool,NVIDIA
ICLR,2018,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,Michael Andersch,None
ICLR,2018,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,Jeremy Appleyard,None
ICLR,2018,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,Feng Xie,NVIDIA
ICLR,2018,WRPN: Wide Reduced-Precision Networks,Asit Mishra,Intel Labs
ICLR,2018,WRPN: Wide Reduced-Precision Networks,Eriko Nurvitadhi,None
ICLR,2018,WRPN: Wide Reduced-Precision Networks,Jeffrey J Cook,None
ICLR,2018,WRPN: Wide Reduced-Precision Networks,Debbie Marr,None
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Wei Ping,Baidu Research
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Kainan Peng,None
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Andrew Gibiansky,None
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Sercan Arik,Baidu Research
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Ajay Kannan,None
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,SHARAN NARANG,Baidu Research
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,Jonathan Raiman,OpenAI
ICLR,2018,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,John Miller,UC Berkeley
ICLR,2018,Spectral Normalization for Generative Adversarial Networks,Takeru Miyato,"Preferred Networks, Inc."
ICLR,2018,Spectral Normalization for Generative Adversarial Networks,Toshiki Kataoka,"Preferred Networks, Inc."
ICLR,2018,Spectral Normalization for Generative Adversarial Networks,Masanori Koyama,Ritsumeikan University
ICLR,2018,Spectral Normalization for Generative Adversarial Networks,Yuichi Yoshida,National Institute of Informatics
ICLR,2018,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,Forough Arabshahi,"University of California, Irvine"
ICLR,2018,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,Sameer Singh,"University of California, Irvine"
ICLR,2018,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,Anima anandkumar,Caltech / Amazon AI
ICLR,2018,Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference,Sebastian Nowozin,Microsoft Research
ICLR,2018,Measuring the Intrinsic Dimension of Objective Landscapes,Chunyuan Li,Duke University
ICLR,2018,Measuring the Intrinsic Dimension of Objective Landscapes,Heerad Farkhoor,None
ICLR,2018,Measuring the Intrinsic Dimension of Objective Landscapes,Rosanne Liu,Uber AI Labs
ICLR,2018,Measuring the Intrinsic Dimension of Objective Landscapes,Jason Yosinski,None
ICLR,2018,A Hierarchical Model for Device Placement,Azalia Mirhoseini,Google Brain
ICLR,2018,A Hierarchical Model for Device Placement,Anna Goldie,Google Brain
ICLR,2018,A Hierarchical Model for Device Placement,Hieu Pham,Carnegie Mellon University
ICLR,2018,A Hierarchical Model for Device Placement,Benoit Steiner,None
ICLR,2018,A Hierarchical Model for Device Placement,Quoc V Le,Google
ICLR,2018,A Hierarchical Model for Device Placement,Jeff Dean,Google Brain
ICLR,2018,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,Manuel Molano-Mazon,IIT
ICLR,2018,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,Arno Onken,University of Edinburgh
ICLR,2018,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,Eugenio Piasini,University of Pennsylvania
ICLR,2018,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,Stefano Panzeri,Istituto Italiano di Tecnologia
ICLR,2018,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,Jie Chen,IBM Research
ICLR,2018,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,Tengfei Ma,IBM Research
ICLR,2018,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,Danica Xiao,IBM Research
ICLR,2018,Certifying Some Distributional Robustness with Principled Adversarial Training,Aman Sinha,Stanford University
ICLR,2018,Certifying Some Distributional Robustness with Principled Adversarial Training,Hong Namkoong,Stanford University
ICLR,2018,Certifying Some Distributional Robustness with Principled Adversarial Training,John Duchi,None
ICLR,2018,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning,Justin Fu,University of California Berkeley
ICLR,2018,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning,Katie Luo,None
ICLR,2018,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning,Sergey Levine,UC Berkeley
ICLR,2018,META LEARNING SHARED HIERARCHIES,Kevin Frans,OpenAI
ICLR,2018,META LEARNING SHARED HIERARCHIES,Jonathan Ho,None
ICLR,2018,META LEARNING SHARED HIERARCHIES,,None
ICLR,2018,META LEARNING SHARED HIERARCHIES,Pieter Abbeel,UC Berkeley / Embodied Intelligence
ICLR,2018,META LEARNING SHARED HIERARCHIES,John Schulman,None
ICLR,2018,Boundary Seeking GANs,R Devon Hjelm,University of Montreal
ICLR,2018,Boundary Seeking GANs,Athul P Jacob,Microsoft Research; MILA; University of Waterloo
ICLR,2018,Boundary Seeking GANs,Adam Trischler,None
ICLR,2018,Boundary Seeking GANs,Tong Che,Montreal Institute of Learning Algorithms
ICLR,2018,Boundary Seeking GANs,Kyunghyun Cho,New York University
ICLR,2018,Boundary Seeking GANs,Yoshua Bengio,University of Montreal
ICLR,2018,GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets,Jinsung Yoon,"University of California, Los Angeles"
ICLR,2018,GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets,James Jordan,None
ICLR,2018,GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets,Mihaela v Schaar,None
ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Florian Tramer,Stanford University
ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Alexey Kurakin,Moscow Institute of Physics and Technology
ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Nicolas Papernot,Pennsylvania State University
ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Ian Goodfellow,Google Brain
ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Dan Boneh,None
ICLR,2018,Ensemble Adversarial Training: Attacks and Defenses,Patrick McDaniel,None
ICLR,2018,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,Murat Kocaoglu,University of Texas at Austin
ICLR,2018,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,Christopher Snyder,University of Texas at Austin
ICLR,2018,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,Alex Dimakis,UT Austin
ICLR,2018,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,Sriram Vishwanath,None
ICLR,2018,Policy Optimization by Genetic Distillation,Tanmay Gangwani,"University of Illinois, Urbana Champaign"
ICLR,2018,Policy Optimization by Genetic Distillation,Jian Peng,"University of Illinois, Urbana Champaign"
ICLR,2018,Stochastic Variational Video Prediction,Mohammad Babaeizadeh,UIUC
ICLR,2018,Stochastic Variational Video Prediction,Chelsea Finn,University of California Berkeley
ICLR,2018,Stochastic Variational Video Prediction,Dumitru Erhan,Google Brain
ICLR,2018,Stochastic Variational Video Prediction,Roy H Campbell,None
ICLR,2018,Stochastic Variational Video Prediction,Sergey Levine,UC Berkeley
ICLR,2018,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Yang Song,Stanford University
ICLR,2018,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Taesup Kim,"MILA, Université de Montréal"
ICLR,2018,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Sebastian Nowozin,Microsoft Research
ICLR,2018,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Stefano Ermon,Stanford University
ICLR,2018,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Nate Kushman,Microsoft Research
ICLR,2018,Modular Continual Learning in a Unified Visual Environment,Kevin Feigelis,Stanford University
ICLR,2018,Modular Continual Learning in a Unified Visual Environment,Blue Sheffer,Stanford University
ICLR,2018,Modular Continual Learning in a Unified Visual Environment,Daniel L Yamins,Massachusetts Institute of Technology
ICLR,2018,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,Ofir Nachum,Google Brain
ICLR,2018,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,Mohammad Norouzi,Google Brain
ICLR,2018,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,Kelvin Xu,"University of California, Berkeley"
ICLR,2018,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,Dale Schuurmans,Google Brain / University of Alberta
ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Maruan Al-Shedivat,Carnegie Mellon University
ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Trapit Bansal,University of Massachusetts Amherst
ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Yuri Burda,OpenAI
ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Ilya Sutskever,OpenAI
ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Igor Mordatch,OpenAI
ICLR,2018,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,Pieter Abbeel,UC Berkeley / Embodied Intelligence
ICLR,2018,mixup: Beyond Empirical Risk Minimization,Hongyi Zhang,MIT
ICLR,2018,mixup: Beyond Empirical Risk Minimization,Moustapha Cisse,Facebook
ICLR,2018,mixup: Beyond Empirical Risk Minimization,Yann N Dauphin,None
ICLR,2018,mixup: Beyond Empirical Risk Minimization,David Lopez-Paz,Facebook AI Research
ICLR,2018,Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,Chelsea Finn,University of California Berkeley
ICLR,2018,Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,Sergey Levine,UC Berkeley
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Scott Reed,Google
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Yutian Chen,DeepMind
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Tom Paine,DeepMind
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Aaron v den,None
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Ali Eslami,DeepMind
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Danilo J Rezende,None
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Oriol Vinyals,Google DeepMind
ICLR,2018,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,Nando d Freitas,None
ICLR,2018,Interpretable Counting for Visual Question Answering,Alex Trott,Salesforce
ICLR,2018,Interpretable Counting for Visual Question Answering,Caiming Xiong,Salesforce Research
ICLR,2018,Interpretable Counting for Visual Question Answering,,None
ICLR,2018,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction,Da Xiao,"Beijing ColorfulClouds Technology Co., Ltd."
ICLR,2018,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction,Ruoyu Liao,"Beijing ColorfulClouds Technology Co., Ltd"
ICLR,2018,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction,Xingyuan Yuan,"Beijing ColorfulClouds Technology Co., Ltd."
ICLR,2018,Variational Continual Learning,Cuong Nguyen,University of Cambridge
ICLR,2018,Variational Continual Learning,Yingzhen Li,University of Cambridge
ICLR,2018,Variational Continual Learning,Thang Bui,University of Cambridge
ICLR,2018,Variational Continual Learning,Rich E Turner,University of Cambridge
ICLR,2018,Loss-aware Weight Quantization of Deep Networks,LU HOU,HKUST
ICLR,2018,Loss-aware Weight Quantization of Deep Networks,James Kwok,Hong Kong University of Science and Technology
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Dani Yogatama,Baidu
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,yishu miao,"Department of Computer Science, University of Oxford"
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Gábor Melis,DeepMind
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Wang Ling,None
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Adhi Kuncoro,University of Oxford and DeepMind
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Chris Dyer,DeepMind
ICLR,2018,Memory Architectures in Recurrent Neural Network Language Models,Phil Blunsom,None
ICLR,2018,Monotonic Chunkwise Attention,Chung-Cheng Chiu,Google
ICLR,2018,Monotonic Chunkwise Attention,Colin Raffel,Google Brain
ICLR,2018,On the State of the Art of Evaluation in Neural Language Models,Gábor Melis,DeepMind
ICLR,2018,On the State of the Art of Evaluation in Neural Language Models,Chris Dyer,DeepMind
ICLR,2018,On the State of the Art of Evaluation in Neural Language Models,Phil Blunsom,None
ICLR,2018,Fix your classifier: the marginal value of training the last weight layer,Elad Hoffer,Technion
ICLR,2018,Fix your classifier: the marginal value of training the last weight layer,Itay Hubara,Technion
ICLR,2018,Fix your classifier: the marginal value of training the last weight layer,Daniel Soudry,Technion
ICLR,2018,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,Yaniv Taigman,Facebook
ICLR,2018,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,Lior Wolf,Facebook AI Research
ICLR,2018,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,Adam Polyak,Facebook
ICLR,2018,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,Eliya Nachmani,Facebook AI Research
ICLR,2018,Learning Sparse Neural Networks through L_0 Regularization,Christos Louizos,University of Amsterdam
ICLR,2018,Learning Sparse Neural Networks through L_0 Regularization,Max Welling,University of Amsterdam  &  Qualcomm
ICLR,2018,Learning Sparse Neural Networks through L_0 Regularization,Diederik Kingma,OpenAI
ICLR,2018,A Scalable Laplace Approximation for Neural Networks,Hippolyt Ritter,University College London
ICLR,2018,A Scalable Laplace Approximation for Neural Networks,Aleksandar Botev,University College London
ICLR,2018,A Scalable Laplace Approximation for Neural Networks,David Barber,None
ICLR,2018,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,Kimin Lee,Korea Advanced Institute of Science and Technology (KAIST)
ICLR,2018,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,Honglak Lee,Google / U. Michigan
ICLR,2018,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,Kibok Lee,University of Michigan
ICLR,2018,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,Jinwoo Shin,None
ICLR,2018,Identifying Analogies Across Domains,Yedid Hoshen,Facebook AI Research
ICLR,2018,Identifying Analogies Across Domains,Lior Wolf,Facebook AI Research
ICLR,2018,Unsupervised Representation Learning by Predicting Image Rotations,Spyros Gidaris,Ecole des Ponts ParisTech (ENPC)
ICLR,2018,Unsupervised Representation Learning by Predicting Image Rotations,Praveer Singh,École des Ponts ParisTech
ICLR,2018,Unsupervised Representation Learning by Predicting Image Rotations,Nikos Komodakis,"Universite Paris-Est, Ecole des Ponts ParisTech"
ICLR,2018,On the importance of single directions for generalization,Ari Morcos,DeepMind
ICLR,2018,On the importance of single directions for generalization,David GT Barrett,DeepMind
ICLR,2018,On the importance of single directions for generalization,Neil C Rabinowitz,New York University
ICLR,2018,On the importance of single directions for generalization,Matthew Botvinick,None
ICLR,2018,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,Tao Shen,University of Technology Sydney
ICLR,2018,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,Tianyi Zhou,University of Washington
ICLR,2018,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,Guodong Long,University of Technology Sydney
ICLR,2018,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,,None
ICLR,2018,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,Chengqi Zhang,University of Technology Sydney
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Chen Xu,Peking University
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,jianqiang Yao,Alibaba Group
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Zhouchen Lin,Peking University
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Baigui Sun,Alibaba Group
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Yuanbin Cao,Alibaba.inc
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Zhirong Wang,None
ICLR,2018,Alternating Multi-bit Quantization for Recurrent Neural Networks,Hongbin Zha,None
ICLR,2018,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,Alon Brutzkus,Tel Aviv University
ICLR,2018,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,Amir Globerson,Hebrew University
ICLR,2018,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,Eran Malach,Hebrew University Jerusalem Israel
ICLR,2018,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,Shai Shalev-Shwartz,None
ICLR,2018,Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions,Nadav Cohen,Institute for Advanced Study
ICLR,2018,Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions,Ronen Tamari,Hebrew University
ICLR,2018,Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions,Amnon Shashua,Hebrew University of Jerusalem
ICLR,2018,Word translation without parallel data,Guillaume Lample,Facebook AI Research
ICLR,2018,Word translation without parallel data,,None
ICLR,2018,Word translation without parallel data,Marc'Aurelio Ranzato,Facebook AI Research
ICLR,2018,Word translation without parallel data,,None
ICLR,2018,Word translation without parallel data,Hervé Jégou,Facebook AI Research
ICLR,2018,Few-Shot Learning with Graph Neural Networks,Victor Garcia Satorras,University of Amsterdam
ICLR,2018,Few-Shot Learning with Graph Neural Networks,Joan Bruna,University of California Berkeley
ICLR,2018,Temporally Efficient Deep Learning with Spikes,Peter OConnor,University of Amsterdam
ICLR,2018,Temporally Efficient Deep Learning with Spikes,Stratis Gavves,University of Amsterdam
ICLR,2018,Temporally Efficient Deep Learning with Spikes,Matthias Reisser,University of Amsterdam
ICLR,2018,Temporally Efficient Deep Learning with Spikes,Max Welling,University of Amsterdam  &  Qualcomm
ICLR,2018,"Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks",Pratik A Chaudhari,"University of California, Los Angeles"
ICLR,2018,"Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks",Stefano Soatto,None
ICLR,2018,Understanding Deep Neural Networks with Rectified Linear Units,Raman Arora,Johns Hopkins University
ICLR,2018,Understanding Deep Neural Networks with Rectified Linear Units,Amitabh Basu,Johns Hopkins University
ICLR,2018,Understanding Deep Neural Networks with Rectified Linear Units,Poorya Mianjy,Johns Hopkins University
ICLR,2018,Understanding Deep Neural Networks with Rectified Linear Units,Anirbit Mukherjee,Johns Hopkins University
ICLR,2018,On Unifying Deep Generative Models,Zhiting Hu,Carnegie Mellon University
ICLR,2018,On Unifying Deep Generative Models,,None
ICLR,2018,On Unifying Deep Generative Models,,None
ICLR,2018,On Unifying Deep Generative Models,Eric P Xing,None
ICLR,2018,Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks,Shankar Krishnan,Google
ICLR,2018,Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks,Ying Xiao,Google
ICLR,2018,Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks,Rif A. Saurous,"Google, Inc."
ICLR,2018,Wasserstein Auto-Encoders,Ilya Tolstikhin,"Max Planck Institute for Intelligent Systems, Tuebingen"
ICLR,2018,Wasserstein Auto-Encoders,Olivier Bousquet,Google Brain
ICLR,2018,Wasserstein Auto-Encoders,Sylvain Gelly,Google Brain
ICLR,2018,Wasserstein Auto-Encoders,Bernhard Schoelkopf,Max Planck / Amazon
ICLR,2018,Guide Actor-Critic for Continuous Control,Voot Tangkaratt,RIKEN AIP
ICLR,2018,Guide Actor-Critic for Continuous Control,,None
ICLR,2018,Guide Actor-Critic for Continuous Control,Masashi Sugiyama,RIKEN / The University of Tokyo
ICLR,2018,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,Artemij Amiranashvili,University of Freiburg
ICLR,2018,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,Alexey Dosovitskiy,Intel Labs
ICLR,2018,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,Vladlen Koltun,Intel Labs
ICLR,2018,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,Thomas Brox,University of California Berkeley
ICLR,2018,Neural Map: Structured Memory for Deep Reinforcement Learning,Emilio Parisotto,Carnegie Mellon University
ICLR,2018,Neural Map: Structured Memory for Deep Reinforcement Learning,,None
ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Marlos C. Machado,University of Alberta
ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Clemens Rosenbaum,UMass Amherst
ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Xiaoxiao Guo,University of Michigan
ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Miao Liu,IBM
ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Gerald Tesauro,IBM Research
ICLR,2018,Eigenoption Discovery through the Deep Successor Representation,Murray Campbell,IBM Research
ICLR,2018,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",Tero Karras,NVIDIA
ICLR,2018,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",Timo Aila,NVIDIA
ICLR,2018,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",Samuli Laine,None
ICLR,2018,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",Jaakko Lehtinen,NVIDIA Research & Aalto University
ICLR,2018,Learning a neural response metric for retinal prosthesis,Nishal Shah,Indian Institute of Technology Delhi
ICLR,2018,Learning a neural response metric for retinal prosthesis,Sasidhar Madugula,None
ICLR,2018,Learning a neural response metric for retinal prosthesis,E.J. Chichilnisky,Stanford University
ICLR,2018,Learning a neural response metric for retinal prosthesis,Yoram Singer,Google Brain & Princeton University
ICLR,2018,Learning a neural response metric for retinal prosthesis,Jon Shlens,Google Brain
ICLR,2018,Self-ensembling for visual domain adaptation,Geoff W French,Kings College London
ICLR,2018,Self-ensembling for visual domain adaptation,Michal Mackiewicz,University of East Anglia
ICLR,2018,Self-ensembling for visual domain adaptation,Mark Fisher,None
ICLR,2018,PixelNN: Example-based Image Synthesis,Aayush Bansal,Carnegie Mellon University
ICLR,2018,PixelNN: Example-based Image Synthesis,Yaser Sheikh,None
ICLR,2018,PixelNN: Example-based Image Synthesis,Deva Ramanan,"School of Computer Science, Carnegie Mellon University"
ICLR,2018,Emergent Communication through Negotiation,Kris Cao,University of Cambridge
ICLR,2018,Emergent Communication through Negotiation,Angeliki Lazaridou,DeepMind
ICLR,2018,Emergent Communication through Negotiation,Marc Lanctot,None
ICLR,2018,Emergent Communication through Negotiation,Joel Z Leibo,DeepMind
ICLR,2018,Emergent Communication through Negotiation,Karl Tuyls,DeepMind and University of Liverpool
ICLR,2018,Emergent Communication through Negotiation,Stephen Clark,DeepMind
ICLR,2018,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game",Katrina Evtimova,New York University
ICLR,2018,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game",Andrew Drozdov,New York University
ICLR,2018,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game",Douwe Kiela,University of Cambridge
ICLR,2018,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game",Kyunghyun Cho,New York University
ICLR,2018,Stabilizing Adversarial Nets with Prediction Methods,Abhay Kumar Yadav,"University Of Maryland, College Park"
ICLR,2018,Stabilizing Adversarial Nets with Prediction Methods,Sohil Shah,"University of Maryland, College Park"
ICLR,2018,Stabilizing Adversarial Nets with Prediction Methods,Zheng Xu,"University of Maryland, College Park"
ICLR,2018,Stabilizing Adversarial Nets with Prediction Methods,David Jacobs,None
ICLR,2018,Stabilizing Adversarial Nets with Prediction Methods,Tom Goldstein,University of Maryland
ICLR,2018,Learning to Represent Programs with Graphs,Miltos Allamanis,Microsoft Research
ICLR,2018,Learning to Represent Programs with Graphs,Marc Brockschmidt,Microsoft Research
ICLR,2018,Learning to Represent Programs with Graphs,Mahmoud Khademi,Simon Fraser University
ICLR,2018,cGANs with Projection Discriminator,Takeru Miyato,"Preferred Networks, Inc."
ICLR,2018,cGANs with Projection Discriminator,Masanori Koyama,Ritsumeikan University
ICLR,2018,Generative Models of Visually Grounded Imagination,Rama Vedantam,Georgia Institute of Technology
ICLR,2018,Generative Models of Visually Grounded Imagination,Ian Fischer,Google
ICLR,2018,Generative Models of Visually Grounded Imagination,Jonathan Huang,None
ICLR,2018,Generative Models of Visually Grounded Imagination,Kevin P Murphy,Google Research
ICLR,2018,Emergent Translation in Multi-Agent Communication,Jason Lee,University of Southern California
ICLR,2018,Emergent Translation in Multi-Agent Communication,Kyunghyun Cho,New York University
ICLR,2018,Emergent Translation in Multi-Agent Communication,JASON Weston,Facebook AI Research
ICLR,2018,Emergent Translation in Multi-Agent Communication,Douwe Kiela,University of Cambridge
ICLR,2018,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation,Pietro Morerio,Italian Institute of Technology
ICLR,2018,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation,Jacopo Cavazza,Istituto Italiano di Tecnologia
ICLR,2018,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation,Vittorio Murino,Istituto Italiano di Tecnologia
ICLR,2018,An image representation based convolutional network for DNA classification,Bojian Yin,CWI
ICLR,2018,An image representation based convolutional network for DNA classification,Marleen Balvert,CWI
ICLR,2018,An image representation based convolutional network for DNA classification,Davide Zambrano,The BioRobotics Institute of Scuola Superiore Sant'Anna
ICLR,2018,An image representation based convolutional network for DNA classification,Alexander Schoenhuth,Centrum Wiskunde & Informatica
ICLR,2018,An image representation based convolutional network for DNA classification,Sander Bohte,CWI
ICLR,2018,Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation,Owen He,Jacobs University Bremen
ICLR,2018,Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation,Herbert Jaeger,None
ICLR,2018,Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks,Jinsung Yoon,"University of California, Los Angeles"
ICLR,2018,Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks,William R Zame,"University of California, Los Angeles"
ICLR,2018,Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks,Mihaela v Schaar,None
ICLR,2018,Non-Autoregressive Neural Machine Translation,Jiatao Gu,The University of Hong Kong
ICLR,2018,Non-Autoregressive Neural Machine Translation,James Bradbury,Salesforce Research
ICLR,2018,Non-Autoregressive Neural Machine Translation,Caiming Xiong,Salesforce Research
ICLR,2018,Non-Autoregressive Neural Machine Translation,Victor OK Li,University of hong Kong
ICLR,2018,Non-Autoregressive Neural Machine Translation,,None
ICLR,2018,Compressing Word Embeddings via Deep Compositional Code Learning,Raphael Shu,The University of Tokyo
ICLR,2018,Compressing Word Embeddings via Deep Compositional Code Learning,Hideki Nakayama,The University of Tokyo
ICLR,2018,Emergence of grid-like representations by training recurrent neural networks to perform spatial localization,Chris Cueva,Columbia University
ICLR,2018,Emergence of grid-like representations by training recurrent neural networks to perform spatial localization,Xue-Xin Wei,Columbia University
ICLR,2018,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,Hsin-Yuan Huang,National Taiwan University
ICLR,2018,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,Chenguang Zhu,Microsoft AI+Research
ICLR,2018,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,,None
ICLR,2018,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,Weizhu Chen,Microsoft
ICLR,2018,Depthwise Separable Convolutions for Neural Machine Translation,Lukasz Kaiser,Google
ICLR,2018,Depthwise Separable Convolutions for Neural Machine Translation,Aidan Gomez,"Department of Computer Science, University of Toronto"
ICLR,2018,Depthwise Separable Convolutions for Neural Machine Translation,Francois Chollet,Google
ICLR,2018,Parallelizing Linear Recurrent Neural Nets Over Sequence Length,Eric Martin,Jump Trading
ICLR,2018,Parallelizing Linear Recurrent Neural Nets Over Sequence Length,Chris Cundy,University of Oxford
ICLR,2018,Large scale distributed neural network training through online distillation,Rohan Anil,Google
ICLR,2018,Large scale distributed neural network training through online distillation,Gabriel Pereyra,None
ICLR,2018,Large scale distributed neural network training through online distillation,Alex Tachard Passos,Google Brain
ICLR,2018,Large scale distributed neural network training through online distillation,Robert Ormandi,University of Szeged
ICLR,2018,Large scale distributed neural network training through online distillation,George Dahl,Google Brain
ICLR,2018,Large scale distributed neural network training through online distillation,Geoffrey E Hinton,None
ICLR,2018,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,Dongsoo Lee,Samsung Research
ICLR,2018,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,Daehyun Ahn,POSTECH
ICLR,2018,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,Taesu Kim,POSTECH
ICLR,2018,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,Pierce I Chuang,University of Waterloo
ICLR,2018,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,Jae-Joon Kim,POSTECH
ICLR,2018,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering,Caiming Xiong,Salesforce Research
ICLR,2018,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering,richard socher,SalesForce.com
ICLR,2018,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering,Victor Zhong,Salesforce Research
ICLR,2018,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,Srikant Srikant,UIUC
ICLR,2018,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,Shiyu Liang,"University of Illinois, Urbana Champaign"
ICLR,2018,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,Yixuan Li,Facebook Research
ICLR,2018,Residual Connections Encourage Iterative Inference,Stanislaw Jastrzebski,Jagiellonian University
ICLR,2018,Residual Connections Encourage Iterative Inference,Devansh Arpit,MILA
ICLR,2018,Residual Connections Encourage Iterative Inference,Nicolas Ballas,Facebook AI Research
ICLR,2018,Residual Connections Encourage Iterative Inference,Vikas Verma,Aalto University
ICLR,2018,Residual Connections Encourage Iterative Inference,Tong Che,Montreal Institute of Learning Algorithms
ICLR,2018,Residual Connections Encourage Iterative Inference,Yoshua Bengio,University of Montreal
ICLR,2018,Towards Synthesizing Complex Programs From Input-Output Examples,Xinyun Chen,UC Berkeley
ICLR,2018,Towards Synthesizing Complex Programs From Input-Output Examples,Chang Liu,"Electrical Engineering & Computer Science Department, University of California Berkeley"
ICLR,2018,Towards Synthesizing Complex Programs From Input-Output Examples,dawn song,uc berkeley
ICLR,2018,"Don't Decay the Learning Rate, Increase the Batch Size",Samuel Smith,Google
ICLR,2018,"Don't Decay the Learning Rate, Increase the Batch Size",Pieter-Jan Kindermans,Google
ICLR,2018,"Don't Decay the Learning Rate, Increase the Batch Size",Chris Ying,Google AI
ICLR,2018,"Don't Decay the Learning Rate, Increase the Batch Size",Quoc V Le,Google
ICLR,2018,Minimax Curriculum Learning: Machine Teaching with Desirable   Difficulties and Scheduled Diversity,Tianyi Zhou,University of Washington
ICLR,2018,Minimax Curriculum Learning: Machine Teaching with Desirable   Difficulties and Scheduled Diversity,Jeff Bilmes,None
ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Gao Huang,Cornell University
ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Danlu Chen,Fudan University
ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Tianhong Li,Tsinghua University
ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Felix Wu,National Taiwan University
ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Laurens van der Maaten,Facebook AI Research
ICLR,2018,Multi-Scale Dense Networks for Resource Efficient Image Classification,Kilian Q Weinberger,Cornell University
ICLR,2018,A Deep Reinforced Model for Abstractive Summarization,Romain Paulus,Salesforce Research
ICLR,2018,A Deep Reinforced Model for Abstractive Summarization,Caiming Xiong,Salesforce Research
ICLR,2018,A Deep Reinforced Model for Abstractive Summarization,richard socher,SalesForce.com
ICLR,2018,Unbiased Online Recurrent Optimization,Corentin Tallec,INRIA
ICLR,2018,Unbiased Online Recurrent Optimization,Yann Ollivier,None
ICLR,2018,Kernel Implicit Variational Inference,Jiaxin Shi,Tsinghua University
ICLR,2018,Kernel Implicit Variational Inference,Shengyang Sun,University of Toronto
ICLR,2018,Kernel Implicit Variational Inference,Jun Zhu,Tsinghua University
ICLR,2018,Generative networks as inverse problems with Scattering transforms,Tomás Angles,"Ecole normale supérieure, CNRS, PSL Research University"
ICLR,2018,Generative networks as inverse problems with Scattering transforms,Stéphane Mallat,None
ICLR,2018,Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,Carlos Riquelme,Google Brain
ICLR,2018,Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,George Tucker,Google Brain
ICLR,2018,Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,Jasper Snoek,Google Brain
ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Vivien Seguy,Kyoto University
ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Bharath Bhushan Damodaran,"IRISA, University of South Brittany"
ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Rémi Flamary,Université Côte d'Azur
ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Nicolas Courty,None
ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Antoine Rolet,Kyoto University
ICLR,2018,Large Scale Optimal Transport and Mapping Estimation,Mathieu Blondel,None
ICLR,2018,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,Will Grathwohl,"Department of Computer Science, University of Toronto"
ICLR,2018,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,Dami Choi,"Department of Computer Science, University of Toronto"
ICLR,2018,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,Yuhuai Wu,"Department of Computer Science, University of Toronto"
ICLR,2018,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,Geoffrey Roeder,University of Toronto
ICLR,2018,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,David Duvenaud,University of Toronto
ICLR,2018,Activation Maximization Generative Adversarial Nets,Zhiming Zhou,Shanghai Jiao Tong University
ICLR,2018,Activation Maximization Generative Adversarial Nets,Han Cai,Shanghai Jiao Tong University
ICLR,2018,Activation Maximization Generative Adversarial Nets,Shu Rong,Yitu Tech
ICLR,2018,Activation Maximization Generative Adversarial Nets,Yuxuan Song,Shanghai Jiao Tong University
ICLR,2018,Activation Maximization Generative Adversarial Nets,Kan Ren,Shanghai Jiao Tong University
ICLR,2018,Activation Maximization Generative Adversarial Nets,Weinan Zhang Zhang,Shanghai Jiao Tong University
ICLR,2018,Activation Maximization Generative Adversarial Nets,Jun Wang,None
ICLR,2018,Activation Maximization Generative Adversarial Nets,Yong Yu,None
ICLR,2018,Parameter Space Noise for Exploration,Matthias Plappert,OpenAI
ICLR,2018,Parameter Space Noise for Exploration,Rein Houthooft,Ghent University
ICLR,2018,Parameter Space Noise for Exploration,Prafulla Dhariwal,Massachusetts Institute of Technology
ICLR,2018,Parameter Space Noise for Exploration,Szymon Sidor,None
ICLR,2018,Parameter Space Noise for Exploration,Richard Chen,OpenAI
ICLR,2018,Parameter Space Noise for Exploration,Xi Chen,University of California Berkeley
ICLR,2018,Parameter Space Noise for Exploration,Tamim Asfour,None
ICLR,2018,Parameter Space Noise for Exploration,Pieter Abbeel,UC Berkeley / Embodied Intelligence
ICLR,2018,Parameter Space Noise for Exploration,Marcin Andrychowicz,None
ICLR,2018,AmbientGAN: Generative models from lossy measurements,Ashish Bora,University of Texas at Austin
ICLR,2018,AmbientGAN: Generative models from lossy measurements,Eric Price,UT Austin
ICLR,2018,AmbientGAN: Generative models from lossy measurements,Alex Dimakis,UT Austin
ICLR,2018,RESIDUAL LOSS PREDICTION: REINFORCEMENT LEARNING WITH NO INCREMENTAL FEEDBACK,Hal Daumé III,None
ICLR,2018,RESIDUAL LOSS PREDICTION: REINFORCEMENT LEARNING WITH NO INCREMENTAL FEEDBACK,John Langford,None
ICLR,2018,RESIDUAL LOSS PREDICTION: REINFORCEMENT LEARNING WITH NO INCREMENTAL FEEDBACK,Paul Mineiro,None
ICLR,2018,RESIDUAL LOSS PREDICTION: REINFORCEMENT LEARNING WITH NO INCREMENTAL FEEDBACK,Amr Mohamed Nabil Aly Aly Sharaf,"Department of Computer Science, University of Maryland, College Park"
ICLR,2018,Mitigating Adversarial Effects Through Randomization,cihang xie,Johns Hopkins U
ICLR,2018,Mitigating Adversarial Effects Through Randomization,Jianyu Wang,Baidu Research USA
ICLR,2018,Mitigating Adversarial Effects Through Randomization,Zhishuai Zhang,Johns Hopkins University
ICLR,2018,Mitigating Adversarial Effects Through Randomization,Zhou Ren,Snap Inc.
ICLR,2018,Mitigating Adversarial Effects Through Randomization,Alan Yuille,None
ICLR,2018,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,Yuhuai Wu,"Department of Computer Science, University of Toronto"
ICLR,2018,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,Mengye Ren,University of Toronto
ICLR,2018,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,Renjie Liao,"Department of Computer Science, University of Toronto"
ICLR,2018,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,Roger Grosse,University of Toronto and Vector Institute
ICLR,2018,Towards Reverse-Engineering Black-Box Neural Networks,Seong Joon Oh,"PhD Student, MPI-INF, Germany         Intern at Google, MTV"
ICLR,2018,Towards Reverse-Engineering Black-Box Neural Networks,Max Augustin,Max Planck Institute for Informatics
ICLR,2018,Towards Reverse-Engineering Black-Box Neural Networks,Mario Fritz,Max Planck Institute for Informatics
ICLR,2018,Towards Reverse-Engineering Black-Box Neural Networks,Bernt Schiele,TU Darmstadt
ICLR,2018,The High-Dimensional Geometry of Binary Neural Networks,Alex Anderson,"University of California, Berkeley"
ICLR,2018,The High-Dimensional Geometry of Binary Neural Networks,Cory P Berg,"University of California, Berkeley"
ICLR,2018,On the Discrimination-Generalization Tradeoff in GANs,Pengchuan Zhang,Microsoft Research
ICLR,2018,On the Discrimination-Generalization Tradeoff in GANs,Qiang Liu,MIT
ICLR,2018,On the Discrimination-Generalization Tradeoff in GANs,Denny Zhou,Google
ICLR,2018,On the Discrimination-Generalization Tradeoff in GANs,Tao Xu,Lehigh University
ICLR,2018,On the Discrimination-Generalization Tradeoff in GANs,Xiaodong He,Microsoft
ICLR,2018,Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization,Ozsel Kilinc,University of Warwick
ICLR,2018,Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization,Ismail Uysal,University of South Florida
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Thomas Unterthiner,Johannes Kepler University Linz
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Bernhard Nessler,Johannes Kepler University Linz
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Calvin Seward,JKU Linz // Zalando Research
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Günter Klambauer,None
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Martin Heusel,Johannes Kepler Universität Linz
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Hubert Ramsauer,None
ICLR,2018,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,Sepp Hochreiter,None
ICLR,2018,Learning to Multi-Task by Active Sampling,Sahil Sharma,Google
ICLR,2018,Learning to Multi-Task by Active Sampling,Ashutosh Jha,Indian Institute of Technology Madras
ICLR,2018,Learning to Multi-Task by Active Sampling,Parikshit Hegde,Indian Institute of Technology Madras
ICLR,2018,Learning to Multi-Task by Active Sampling,Balaraman Ravindran,IIT Madras
ICLR,2018,Learning from Between-class Examples for Deep Sound Recognition,Yuji Tokozume,The University of Tokyo
ICLR,2018,Learning from Between-class Examples for Deep Sound Recognition,Yoshitaka Ushiku,University of Tokyo
ICLR,2018,Learning from Between-class Examples for Deep Sound Recognition,Tatsuya Harada,The Univ. of Tokyo
ICLR,2018,Emergent Complexity via Multi-Agent Competition,Trapit Bansal,University of Massachusetts Amherst
ICLR,2018,Emergent Complexity via Multi-Agent Competition,Jakub Pachocki,None
ICLR,2018,Emergent Complexity via Multi-Agent Competition,Szymon Sidor,None
ICLR,2018,Emergent Complexity via Multi-Agent Competition,Ilya Sutskever,OpenAI
ICLR,2018,Emergent Complexity via Multi-Agent Competition,Igor Mordatch,OpenAI
ICLR,2018,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,Lior Fox,The Hebrew University of Jerusalem
ICLR,2018,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,Leshem Choshen,HUJI (Hebrew University Jerusalem Israel)
ICLR,2018,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,Yonatan Loewenstein,The Hebrew University of Jerusalem
ICLR,2018,Polar Transformer Networks,Carlos Esteves,University of Pennsylvania
ICLR,2018,Polar Transformer Networks,Christine Allen-Blanchette,University of Pennsylvania
ICLR,2018,Polar Transformer Networks,Xiaowei Zhou,None
ICLR,2018,Polar Transformer Networks,Kostas Daniilidis,University of Pennsylvania
ICLR,2018,Compositional Obverter Communication Learning from Raw Visual Input,Edward Choi,Georgia Institute of Technology
ICLR,2018,Compositional Obverter Communication Learning from Raw Visual Input,Angeliki Lazaridou,DeepMind
ICLR,2018,Compositional Obverter Communication Learning from Raw Visual Input,Nando d Freitas,None
ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Yi Zhou,The Ohio State University
ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Zimo Li,University of Southern California
ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Shuangjiu Xiao,None
ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Chong He,None
ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Zeng Huang,None
ICLR,2018,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,Hao Li,Pinscreen / University of Southern California / USC Institute for Creative Technologies
ICLR,2018,Multi-Task Learning for Document Ranking and Query Suggestion,Wasi Ahmad,"University of California, Los Angeles"
ICLR,2018,Multi-Task Learning for Document Ranking and Query Suggestion,Kai-Wei Chang,UCLA
ICLR,2018,Multi-Task Learning for Document Ranking and Query Suggestion,Hongning Wang,None
ICLR,2018,Adaptive Quantization of Neural Networks,Soroosh Khoram,University of Wisconsin - Madison
ICLR,2018,Adaptive Quantization of Neural Networks,Jing Li,University of Wisconsin-Madison
ICLR,2018,Interactive Grounded Language Acquisition and Generalization in a 2D World,Haonan Yu,Baidu Research
ICLR,2018,Interactive Grounded Language Acquisition and Generalization in a 2D World,Haichao Zhang,Baidu USA
ICLR,2018,Interactive Grounded Language Acquisition and Generalization in a 2D World,Wei Xu,Baidu Research
ICLR,2018,Hyperparameter optimization: a spectral approach,Elad Hazan,Princeton University and Google Brain
ICLR,2018,Hyperparameter optimization: a spectral approach,Adam Klivans,None
ICLR,2018,Hyperparameter optimization: a spectral approach,Yang Yuan,Peking University
ICLR,2018,Deep Learning with Logged Bandit Feedback,Thorsten Joachims,Cornell University
ICLR,2018,Deep Learning with Logged Bandit Feedback,Adith Swaminathan,Microsoft Research
ICLR,2018,Deep Learning with Logged Bandit Feedback,Maarten de Rijke,University of Amsterdam
ICLR,2018,Generalizing Hamiltonian Monte Carlo with Neural Networks,Daniel Levy,Stanford University
ICLR,2018,Generalizing Hamiltonian Monte Carlo with Neural Networks,Matthew D Hoffman,Adobe
ICLR,2018,Generalizing Hamiltonian Monte Carlo with Neural Networks,Jascha Sohl-Dickstein,Google Brain
ICLR,2018,Detecting Statistical Interactions from Neural Network Weights,Michael Tsang,University of Southern California
ICLR,2018,Detecting Statistical Interactions from Neural Network Weights,Dehua Cheng,Facebook
ICLR,2018,Detecting Statistical Interactions from Neural Network Weights,Yan Liu,None
ICLR,2018,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,Seyed Moosavi Dezfooli,École polytechnique fédérale de Lausanne
ICLR,2018,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,Alhussein Fawzi,None
ICLR,2018,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,Omar Fawzi,None
ICLR,2018,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,Pascal Frossard,EPFL
ICLR,2018,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,,None
ICLR,2018,Adaptive Dropout with Rademacher Complexity Regularization,Ke Zhai,Microsoft AI & Research
ICLR,2018,Adaptive Dropout with Rademacher Complexity Regularization,Huan Wang,Salesforce Research
ICLR,2018,Mixed Precision Training,Paulius Micikevicius,None
ICLR,2018,Mixed Precision Training,SHARAN NARANG,Baidu Research
ICLR,2018,Mixed Precision Training,Jonah Alben,None
ICLR,2018,Mixed Precision Training,Gregory Diamos,None
ICLR,2018,Mixed Precision Training,Erich K Elsen,Stanford University
ICLR,2018,Mixed Precision Training,David Garcia,None
ICLR,2018,Mixed Precision Training,Boris Ginsburg,NVIDIA
ICLR,2018,Mixed Precision Training,Michael Houston,None
ICLR,2018,Mixed Precision Training,Oleksii Kuchaiev,NVIDIA
ICLR,2018,Mixed Precision Training,Ganesh Venkatesh,Intel
ICLR,2018,Mixed Precision Training,Hao Wu,None
ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Uri Shaham,"Yale University, Final Research"
ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Kelly Stanton,Yale University
ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Henry (Fangyi) Li,Yale University
ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Ronen Basri,Weizmann Institute of Science
ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Boaz Nadler,Weizmann Institute of Science
ICLR,2018,SpectralNet: Spectral Clustering using Deep Neural Networks,Yuval Kluger,None
ICLR,2018,Deep Rewiring: Training very sparse deep networks,Guillaume Bellec,TU Graz (IGI)
ICLR,2018,Deep Rewiring: Training very sparse deep networks,David Kappel,Graz University of Technology
ICLR,2018,Deep Rewiring: Training very sparse deep networks,Wolfgang Maass,None
ICLR,2018,Deep Rewiring: Training very sparse deep networks,Robert Legenstein,None
ICLR,2018,A Neural Representation of Sketch Drawings,David Ha,Google Brain
ICLR,2018,A Neural Representation of Sketch Drawings,Douglas Eck,Google Brain
ICLR,2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,Rudy Bunel,University of Oxford
ICLR,2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,Matthew Hausknecht,Microsoft Research
ICLR,2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,Jacob Devlin,None
ICLR,2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,Rishabh Singh,Google Brain
ICLR,2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,Pushmeet Kohli,Microsoft
ICLR,2018,All-but-the-Top: Simple and Effective Postprocessing for Word Representations,Jiaqi Mu,University of Illinois at Urbana Champaign
ICLR,2018,All-but-the-Top: Simple and Effective Postprocessing for Word Representations,Pramod Viswanath,None
ICLR,2018,Graph Attention Networks,Petar Veličković,University of Cambridge
ICLR,2018,Graph Attention Networks,Guillem Cucurull Preixens,Computer Vision Center (Barcelona)
ICLR,2018,Graph Attention Networks,Arantxa Casanova Paga,MILA - ElementAI
ICLR,2018,Graph Attention Networks,Adriana Romero,Facebook AI Research
ICLR,2018,Graph Attention Networks,Pietro Liò,None
ICLR,2018,Graph Attention Networks,Yoshua Bengio,University of Montreal
ICLR,2018,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,Marco Ancona,ETH Zurich
ICLR,2018,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,Enea Ceolini,"Institute of Neuroinformatics, UZH ETH"
ICLR,2018,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,Cengiz Öztireli,None
ICLR,2018,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,Markus Gross,None
ICLR,2018,Critical Percolation as a Framework to Analyze the Training of Deep Networks,Zohar Ringel,Hebrew University of Jerusalem
ICLR,2018,Critical Percolation as a Framework to Analyze the Training of Deep Networks,Rodrigo Andrade de Bem,University of Oxford
ICLR,2018,Learning to Count Objects in Natural Images for Visual Question Answering,Yan Zhang,University of Southampton
ICLR,2018,Learning to Count Objects in Natural Images for Visual Question Answering,Jonathon Hare,University of Southampton
ICLR,2018,Learning to Count Objects in Natural Images for Visual Question Answering,Adam Prugel-Bennett,University of Southampton
ICLR,2018,Variational image compression with a scale hyperprior,Johannes Ballé,RWTH Aachen University
ICLR,2018,Variational image compression with a scale hyperprior,David Minnen,Google
ICLR,2018,Variational image compression with a scale hyperprior,Saurabh Singh,"University of Illinois, Urbana Champaign"
ICLR,2018,Variational image compression with a scale hyperprior,Sung Jin Hwang,Google
ICLR,2018,Variational image compression with a scale hyperprior,Nick Johnston,Iowa State University
ICLR,2018,NerveNet: Learning Structured Policy with Graph Neural Networks,Tingwu Wang,University of Toronto; Vector Institute
ICLR,2018,NerveNet: Learning Structured Policy with Graph Neural Networks,Renjie Liao,"Department of Computer Science, University of Toronto"
ICLR,2018,NerveNet: Learning Structured Policy with Graph Neural Networks,Jimmy Ba,University of Toronto
ICLR,2018,NerveNet: Learning Structured Policy with Graph Neural Networks,Sanja Fidler,
ICLR,2018,Proximal Backpropagation,Thomas Frerix,Technical University of Munich
ICLR,2018,Proximal Backpropagation,Thomas Möllenhoff,TU Munich
ICLR,2018,Proximal Backpropagation,Michael Moeller,None
ICLR,2018,Proximal Backpropagation,Daniel Cremers,None
ICLR,2018,On the Expressive Power of Overlapping Architectures of Deep Learning,Or Sharir,Hebrew University of Jerusalem
ICLR,2018,On the Expressive Power of Overlapping Architectures of Deep Learning,Amnon Shashua,Hebrew University of Jerusalem
ICLR,2018,The Implicit Bias of Gradient Descent on Separable Data,Daniel Soudry,Technion
ICLR,2018,The Implicit Bias of Gradient Descent on Separable Data,Elad Hoffer,Technion
ICLR,2018,The Implicit Bias of Gradient Descent on Separable Data,Mor Shpigel Nacson,Technion
ICLR,2018,The Implicit Bias of Gradient Descent on Separable Data,Nati Srebro,TTIC
ICLR,2018,Multi-level Residual Networks from Dynamical Systems View,Bo Chang,University of British Columbia
ICLR,2018,Multi-level Residual Networks from Dynamical Systems View,Lili Meng,University of British Columbia
ICLR,2018,Multi-level Residual Networks from Dynamical Systems View,Eldad Haber,None
ICLR,2018,Multi-level Residual Networks from Dynamical Systems View,Frederick Tung,Simon Fraser University
ICLR,2018,Multi-level Residual Networks from Dynamical Systems View,David Begert,Xtract AI
ICLR,2018,Learning Deep Mean Field Games for Modeling Large Population Behavior,Jiachen Yang,Georgia Institute of Technology
ICLR,2018,Learning Deep Mean Field Games for Modeling Large Population Behavior,Xiaojing Ye,Georgia State University
ICLR,2018,Learning Deep Mean Field Games for Modeling Large Population Behavior,Rakshit Trivedi,Georgia Institute of Technology
ICLR,2018,Learning Deep Mean Field Games for Modeling Large Population Behavior,huan xu,Georgia Institute of Technology
ICLR,2018,Learning Deep Mean Field Games for Modeling Large Population Behavior,Hongyuan Zha,Georgia Institute of Technology
ICLR,2018,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN,Xu Chen,Northwestern University
ICLR,2018,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN,Jiang Wang,Google
ICLR,2018,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN,Hao Ge,None
ICLR,2018,Implicit Causal Models for Genome-wide Association Studies,Dustin Tran,None
ICLR,2018,Implicit Causal Models for Genome-wide Association Studies,David Blei,None
ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Aidan Gomez,"Department of Computer Science, University of Toronto"
ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Sheldon Huang,University of Toronto
ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Ivan Zhang,University of Toronto
ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Bryan M Li,"Department of Computer Science, University of Toronto"
ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Muhammad Osama,"Department of Computer Science, University of Toronto"
ICLR,2018,Unsupervised Cipher Cracking Using Discrete GANs,Lukasz Kaiser,Google
ICLR,2018,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,Chris Donahue,UC San Diego
ICLR,2018,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,Zachary Lipton,Carnegie Mellon University
ICLR,2018,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,Akshay Balsubramani,"University of California, San Diego"
ICLR,2018,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,Julian McAuley,UC San Diego
ICLR,2018,Not-So-Random Features,Brian Bullins,Princeton University
ICLR,2018,Not-So-Random Features,Cyril Zhang,Yale University
ICLR,2018,Not-So-Random Features,Yi Zhang,Princeton University
ICLR,2018,A Bayesian Perspective on Generalization and Stochastic Gradient Descent,Samuel Smith,Google
ICLR,2018,A Bayesian Perspective on Generalization and Stochastic Gradient Descent,Quoc V Le,Google
ICLR,2018,Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks,영진 Kim,Seoul National University
ICLR,2018,Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks,Minjung Kim,Seoul National University
ICLR,2018,Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks,Gunhee Kim,"Seoul National University, rippleAI"
ICLR,2018,Reinforcement Learning Algorithm Selection,Romain Laroche,Microsoft Research
ICLR,2018,Reinforcement Learning Algorithm Selection,Raphaël Féraud,Orange Labs
ICLR,2018,Improving GANs Using Optimal Transport,Tim Salimans,OpenAI
ICLR,2018,Improving GANs Using Optimal Transport,Han Zhang,"Rutgers, the state university of New Jersey"
ICLR,2018,Improving GANs Using Optimal Transport,Alec Radford,OpenAI
ICLR,2018,Improving GANs Using Optimal Transport,Dimitris Metaxas,None
ICLR,2018,Efficient Sparse-Winograd Convolutional Neural Networks,Xingyu Liu,Stanford University
ICLR,2018,Efficient Sparse-Winograd Convolutional Neural Networks,Jeff Pool,NVIDIA
ICLR,2018,Efficient Sparse-Winograd Convolutional Neural Networks,song han,Stanford University
ICLR,2018,Efficient Sparse-Winograd Convolutional Neural Networks,Bill Dally,NVIDIA & Stanford
ICLR,2018,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,Glen Berseth,University of British Columbia
ICLR,2018,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,Cheng Xie,University of British Columbia
ICLR,2018,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,Paul Cernek,University of British Columbia
ICLR,2018,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,Michiel van de Panne,University of British Columbia
ICLR,2018,An Online Learning Approach to Generative Adversarial Networks,Paulina Grnarova,ETH Zürich
ICLR,2018,An Online Learning Approach to Generative Adversarial Networks,Kfir Y Levy,Swiss Federal Institute of Technology
ICLR,2018,An Online Learning Approach to Generative Adversarial Networks,Aurelien Lucchi,Swiss Federal Institute of Technology
ICLR,2018,An Online Learning Approach to Generative Adversarial Networks,Thomas Hofmann,None
ICLR,2018,An Online Learning Approach to Generative Adversarial Networks,Andreas Krause,Swiss Federal Institute of Technology
ICLR,2018,Espresso: Efficient Forward Propagation for Binary Deep Neural Networks,Fabrizio Pedersoli,University of Victoria
ICLR,2018,Espresso: Efficient Forward Propagation for Binary Deep Neural Networks,George Tzanetakis,None
ICLR,2018,Espresso: Efficient Forward Propagation for Binary Deep Neural Networks,Andrea Tagliasacchi,University of Victoria
ICLR,2018,Learning Wasserstein Embeddings,Nicolas Courty,None
ICLR,2018,Learning Wasserstein Embeddings,Rémi Flamary,Université Côte d'Azur
ICLR,2018,Learning Wasserstein Embeddings,Mélanie Ducoffe,LABORATOIRE I3S UMR7271 CNRS
ICLR,2018,Towards Neural Phrase-based Machine Translation,Po-Sen Huang,Microsoft Research
ICLR,2018,Towards Neural Phrase-based Machine Translation,Chong Wang,Google
ICLR,2018,Towards Neural Phrase-based Machine Translation,Sitao Huang,University of Illinois at Urbana-Champaign
ICLR,2018,Towards Neural Phrase-based Machine Translation,Dengyong Zhou,None
ICLR,2018,Towards Neural Phrase-based Machine Translation,Li Deng,Citadel
ICLR,2018,Noisy Networks For Exploration,Meire Fortunato,DeepMind
ICLR,2018,Noisy Networks For Exploration,Mohammad Gheshlaghi Azar,DeepMind
ICLR,2018,Noisy Networks For Exploration,Bilal Piot,DeepMind
ICLR,2018,Noisy Networks For Exploration,Jacob Menick,None
ICLR,2018,Noisy Networks For Exploration,Matteo Hessel,DeepMind
ICLR,2018,Noisy Networks For Exploration,Ian Osband,Stanford University
ICLR,2018,Noisy Networks For Exploration,Alex Graves,None
ICLR,2018,Noisy Networks For Exploration,Volodymyr Mnih,None
ICLR,2018,Noisy Networks For Exploration,Remi Munos,DeepMind
ICLR,2018,Noisy Networks For Exploration,Demis Hassabis,None
ICLR,2018,Noisy Networks For Exploration,Olivier Pietquin,Université Lille 1
ICLR,2018,Noisy Networks For Exploration,Charles Blundell,None
ICLR,2018,Noisy Networks For Exploration,Shane Legg,DeepMind
ICLR,2018,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,Alexandre Péré,INRIA
ICLR,2018,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,Sébastien Forestier,Université de Bordeaux
ICLR,2018,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,Olivier Sigaud,Sorbonne University
ICLR,2018,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,Pierre-Yves Oudeyer,Inria
ICLR,2018,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,Yoav Levine,Hebrew University of Jerusalem
ICLR,2018,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,David Yakira,None
ICLR,2018,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,Nadav Cohen,Institute for Advanced Study
ICLR,2018,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,Amnon Shashua,Hebrew University of Jerusalem
ICLR,2018,Training wide residual networks for deployment using a single bit for each weight,Mark D. McDonnell,University of South Australia
ICLR,2018,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,Víctor Campos,Barcelona Supercomputing Center (BSC)
ICLR,2018,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,Brendan Jou,Google
ICLR,2018,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,Xavi Giro-i-Nieto,UPC Barcelona
ICLR,2018,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,Jordi Torres,Barcelona Supercomputing Center
ICLR,2018,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,Shih-Fu Chang,None
ICLR,2018,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,Erin Grant,UC Berkeley
ICLR,2018,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,Chelsea Finn,University of California Berkeley
ICLR,2018,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,Sergey Levine,UC Berkeley
ICLR,2018,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,Trevor Darrell,UC Berkeley
ICLR,2018,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,Thomas L Griffiths,Brown University
ICLR,2018,Learning Discrete Weights Using the Local Reparameterization Trick,Oran Shayer,Technion - Israel Institute of Technology
ICLR,2018,Learning Discrete Weights Using the Local Reparameterization Trick,Dan Levi,None
ICLR,2018,Learning Discrete Weights Using the Local Reparameterization Trick,Ethan Fetaya,University of Toronto
ICLR,2018,Regularizing and Optimizing LSTM Language Models,Stephen Merity,Salesforce Research
ICLR,2018,Regularizing and Optimizing LSTM Language Models,Nitish Keskar,Salesforce Research
ICLR,2018,Regularizing and Optimizing LSTM Language Models,richard socher,SalesForce.com
ICLR,2018,Active Neural Localization,Devendra Singh Chaplot,Carnegie Mellon University
ICLR,2018,Active Neural Localization,Emilio Parisotto,Carnegie Mellon University
ICLR,2018,Active Neural Localization,,None
ICLR,2018,Memory Augmented Control Networks,Arbaaz Khan,University of Pennsylvania
ICLR,2018,Memory Augmented Control Networks,Clark Zhang,University Of Pennsylvania
ICLR,2018,Memory Augmented Control Networks,Nikolay Atanasov,None
ICLR,2018,Memory Augmented Control Networks,Konstantinos Karydis,None
ICLR,2018,Memory Augmented Control Networks,Vijay Kumar,None
ICLR,2018,Memory Augmented Control Networks,Daniel D Lee,None
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Pieter-Jan Kindermans,Google
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Kristof T Schütt,Technische Universität Berlin
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Maximilian Alber,None
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Klaus R Muller,None
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Dumitru Erhan,Google Brain
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Been Kim,Google Brain
ICLR,2018,Learning how to explain neural networks: PatternNet and PatternAttribution,Sven Dähne,None
ICLR,2018,A New Method of Region Embedding for Text Classification,Chao Qiao,"Beijing Bytedance Network Technology Co., Ltd."
ICLR,2018,A New Method of Region Embedding for Text Classification,Bo Huang,Zhizhesihai (Beijing) Technology Limited
ICLR,2018,A New Method of Region Embedding for Text Classification,Guocheng Niu,"Beijing Baidu Netcom Science and Technology Co.,Ltd."
ICLR,2018,A New Method of Region Embedding for Text Classification,daren li,None
ICLR,2018,A New Method of Region Embedding for Text Classification,daxiang dong,None
ICLR,2018,A New Method of Region Embedding for Text Classification,wei he,None
ICLR,2018,A New Method of Region Embedding for Text Classification,Dianhai Yu,Baidu Inc.
ICLR,2018,A New Method of Region Embedding for Text Classification,hua wu,None
ICLR,2018,Distributed Fine-tuning of Language Models on Private Data,Vadim Popov,Samsung R&D Institute Russia
ICLR,2018,Distributed Fine-tuning of Language Models on Private Data,Mikhail Kudinov,Samsung R&D Center Russia
ICLR,2018,Distributed Fine-tuning of Language Models on Private Data,Irina Piontkovskaya,None
ICLR,2018,Distributed Fine-tuning of Language Models on Private Data,Petr Vytovtov,Samsung R&D Institute Russia
ICLR,2018,Distributed Fine-tuning of Language Models on Private Data,Alex Nevidomsky,Samsung R&D Institute Russia
ICLR,2018,Automatically Inferring Data Quality for Spatiotemporal Forecasting,Sungyong Seo,University of Southern California
ICLR,2018,Automatically Inferring Data Quality for Spatiotemporal Forecasting,Arash Mohegh,None
ICLR,2018,Automatically Inferring Data Quality for Spatiotemporal Forecasting,George Ban-Weiss,None
ICLR,2018,Automatically Inferring Data Quality for Spatiotemporal Forecasting,Yan Liu,None
ICLR,2018,Empirical Risk Landscape Analysis for Understanding Deep Neural Networks,Pan Zhou,National University of Singapore
ICLR,2018,Empirical Risk Landscape Analysis for Understanding Deep Neural Networks,Jiashi Feng,None
ICLR,2018,Empirical Risk Landscape Analysis for Understanding Deep Neural Networks,Pan Zhou,National University of Singapore
ICLR,2018,Decoupling the Layers in Residual Networks,Ricky Fok,York University
ICLR,2018,Decoupling the Layers in Residual Networks,Aijun An,York University
ICLR,2018,Decoupling the Layers in Residual Networks,Zana Rashidi,York University
ICLR,2018,Decoupling the Layers in Residual Networks,Xiaogang Wang,None
ICLR,2018,Learning to cluster in order to transfer across domains and tasks,Yen-Chang Hsu,Georgia Institute of Technology
ICLR,2018,Learning to cluster in order to transfer across domains and tasks,Zhaoyang Lv,Georgia Institute of Technology
ICLR,2018,Learning to cluster in order to transfer across domains and tasks,Zsolt Kira,Georgia Tech
ICLR,2018,Natural Language Inference over Interaction Space,Yichen Gong,New York University
ICLR,2018,Natural Language Inference over Interaction Space,Heng Luo,Horizon Robotics Inc.
ICLR,2018,Natural Language Inference over Interaction Space,Jian Zhang,"Horizon Robotics, Inc."
ICLR,2018,Consequentialist conditional cooperation in social dilemmas with imperfect information,Alex Peysakhovich,Yale University
ICLR,2018,Consequentialist conditional cooperation in social dilemmas with imperfect information,Adam Lerer,Facebook AI Research
ICLR,2018,SMASH: One-Shot Model Architecture Search through HyperNetworks,Andrew Brock,Edinburgh Centre for Robotics
ICLR,2018,SMASH: One-Shot Model Architecture Search through HyperNetworks,Theo Lim,None
ICLR,2018,SMASH: One-Shot Model Architecture Search through HyperNetworks,James Ritchie,None
ICLR,2018,SMASH: One-Shot Model Architecture Search through HyperNetworks,Nick Weston,Heriot-Watt University
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,Max Jaderberg,DeepMind
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,Wojciech Czarnecki,DeepMind
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,Simon Osindero,DeepMind
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,Oriol Vinyals,DeepMind
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,Alex Graves,DeepMind
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,David Silver,Google DeepMind
ICML,2017,Decoupled Neural Interfaces using Synthetic Gradients,koray kavukcuoglu,DeepMind
ICML,2017,PixelCNN Models with Auxiliary Variables for Natural Image Modeling,Alexander Kolesnikov,IST Austria
ICML,2017,PixelCNN Models with Auxiliary Variables for Natural Image Modeling,Christoph Lampert,IST Austria
ICML,2017,Tight Bounds for Approximate Carathéodory and Beyond,Vahab Mirrokni,Google Research
ICML,2017,Tight Bounds for Approximate Carathéodory and Beyond,Renato Leme,Google Research
ICML,2017,Tight Bounds for Approximate Carathéodory and Beyond,Adrian Vladu,MIT
ICML,2017,Tight Bounds for Approximate Carathéodory and Beyond,Sam Wong,UC Berkeley
ICML,2017,Robust Adversarial Reinforcement Learning,Lerrel Pinto,Carnegie Mellon University
ICML,2017,Robust Adversarial Reinforcement Learning,James Davidson,Google Brain
ICML,2017,Robust Adversarial Reinforcement Learning,RAHUL Sukthankar,Google Research
ICML,2017,Robust Adversarial Reinforcement Learning,Abhinav Gupta,Carnegie Mellon University
ICML,2017,Robust Probabilistic Modeling with Bayesian Data Reweighting,Yixin Wang,Columbia University
ICML,2017,Robust Probabilistic Modeling with Bayesian Data Reweighting,Alp Kucukelbir,Columbia University
ICML,2017,Robust Probabilistic Modeling with Bayesian Data Reweighting,David Blei,Columbia University
ICML,2017,Multi-objective Bandits: Optimizing the Generalized Gini Index,Robert Busa-Fekete,Yahoo! Research
ICML,2017,Multi-objective Bandits: Optimizing the Generalized Gini Index,Balazs Szorenyi,Technion
ICML,2017,Multi-objective Bandits: Optimizing the Generalized Gini Index,Paul Weng,SYSU-CMU JIE
ICML,2017,Multi-objective Bandits: Optimizing the Generalized Gini Index,Shie Mannor,Technion
ICML,2017,Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis,Dan Garber,TTIC
ICML,2017,Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis,Ohad Shamir,Weizmann Institute of Science
ICML,2017,Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis,Nati Srebro,Toyota Technological Institute at Chicago
ICML,2017,Enumerating Distinct Decision Trees,Salvatore Ruggieri,Università di Pisa
ICML,2017,Understanding Synthetic Gradients and Decoupled Neural Interfaces,Wojciech Czarnecki,DeepMind
ICML,2017,Understanding Synthetic Gradients and Decoupled Neural Interfaces,Grzegorz Świrszcz,DeepMind
ICML,2017,Understanding Synthetic Gradients and Decoupled Neural Interfaces,Max Jaderberg,DeepMind
ICML,2017,Understanding Synthetic Gradients and Decoupled Neural Interfaces,Simon Osindero,DeepMind
ICML,2017,Understanding Synthetic Gradients and Decoupled Neural Interfaces,Oriol Vinyals,DeepMind
ICML,2017,Understanding Synthetic Gradients and Decoupled Neural Interfaces,koray kavukcuoglu,DeepMind
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Scott Reed,Google Deepmind
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Aäron van den Oord,Google
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Nal Kalchbrenner,DeepMind
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Sergio Gómez Colmenarejo,Google DeepMind
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Ziyu Wang,Deep Mind
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Yutian Chen,DeepMind
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Dan Belov,Google
ICML,2017,Parallel Multiscale Autoregressive Density Estimation,Nando de Freitas,DeepMind
ICML,2017,Oracle Complexity of Second-Order Methods for Finite-Sum Problems,Yossi Arjevani,Weizmann Institute of Science
ICML,2017,Oracle Complexity of Second-Order Methods for Finite-Sum Problems,Ohad Shamir,Weizmann Institute of Science
ICML,2017,Minimax Regret Bounds for Reinforcement Learning,Mohammad Gheshlaghi Azar,Deepmind
ICML,2017,Minimax Regret Bounds for Reinforcement Learning,Ian Osband,Google DeepMind
ICML,2017,Minimax Regret Bounds for Reinforcement Learning,Remi Munos,DeepMind
ICML,2017,Post-Inference Prior Swapping,Willie Neiswanger,CMU
ICML,2017,Post-Inference Prior Swapping,Eric Xing,Carnegie Mellon University
ICML,2017,Online Learning with Local Permutations and Delayed Feedback,Liran Szlak,Weizmann Institute of Science
ICML,2017,Online Learning with Local Permutations and Delayed Feedback,Ohad Shamir,Weizmann Institute of Science
ICML,2017,SPLICE: Fully Tractable Hierarchical Extension of ICA with Pooling,Jun-ichiro Hirayama,RIKEN AIP / ATR
ICML,2017,SPLICE: Fully Tractable Hierarchical Extension of ICA with Pooling,Aapo Hyvärinen,UCL
ICML,2017,SPLICE: Fully Tractable Hierarchical Extension of ICA with Pooling,Motoaki Kawanabe,ATR / RIKEN
ICML,2017,Simultaneous Learning of Trees and Representations for Extreme Classification and Density Estimation,Yacine Jernite,New York University
ICML,2017,Simultaneous Learning of Trees and Representations for Extreme Classification and Density Estimation,Anna Choromanska,New York University
ICML,2017,Simultaneous Learning of Trees and Representations for Extreme Classification and Density Estimation,David Sontag,Massachusetts Institute of Technology
ICML,2017,meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting,Xu SUN,Peking University
ICML,2017,meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting,Xuancheng REN,Peking University
ICML,2017,meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting,Shuming Ma,Peking University
ICML,2017,meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting,Houfeng Wang,
ICML,2017,Video Pixel Networks,Nal Kalchbrenner,DeepMind
ICML,2017,Video Pixel Networks,Karen Simonyan,DeepMind
ICML,2017,Video Pixel Networks,Aäron van den Oord,Google
ICML,2017,Video Pixel Networks,Ivo Danihelka,Google DeepMind
ICML,2017,Video Pixel Networks,Oriol Vinyals,DeepMind
ICML,2017,Video Pixel Networks,Alex Graves,DeepMind
ICML,2017,Video Pixel Networks,koray kavukcuoglu,DeepMind
ICML,2017,Global optimization of Lipschitz functions,Cédric Malherbe,ENS Paris-Saclay
ICML,2017,Global optimization of Lipschitz functions,Nicolas Vayatis,ENS Cachan
ICML,2017,Fairness in Reinforcement Learning,Shahin Jabbari,University of Pennsylvania
ICML,2017,Fairness in Reinforcement Learning,Matthew Joseph,University of Pennsylvania
ICML,2017,Fairness in Reinforcement Learning,Michael Kearns,University of Pennsylvania
ICML,2017,Fairness in Reinforcement Learning,Jamie Morgenstern,University of Pennsylvania
ICML,2017,Fairness in Reinforcement Learning,Aaron Roth,University of Pennsylvania
ICML,2017,Evaluating Bayesian Models with Posterior Dispersion Indices,Alp Kucukelbir,Columbia University
ICML,2017,Evaluating Bayesian Models with Posterior Dispersion Indices,Yixin Wang,Columbia University
ICML,2017,Evaluating Bayesian Models with Posterior Dispersion Indices,David Blei,Columbia University
ICML,2017,Model-Independent Online Learning for Influence Maximization,Sharan Vaswani,University of British Columbia
ICML,2017,Model-Independent Online Learning for Influence Maximization,Branislav Kveton,Adobe Research
ICML,2017,Model-Independent Online Learning for Influence Maximization,Zheng Wen,Adobe Research
ICML,2017,Model-Independent Online Learning for Influence Maximization,Mohammad Ghavamzadeh,Adobe Research & INRIA
ICML,2017,Model-Independent Online Learning for Influence Maximization,Laks V.S Lakshmanan,University of British Columbia
ICML,2017,Model-Independent Online Learning for Influence Maximization,Mark Schmidt,University of British Columbia
ICML,2017,Latent Feature Lasso,Ian Yen,Carnegie Mellon University
ICML,2017,Latent Feature Lasso,Wei-Cheng Lee,National Taiwan University
ICML,2017,Latent Feature Lasso,Sung-En Chang,National Taiwan University
ICML,2017,Latent Feature Lasso,Arun Suggala,Carnegie Mellon University
ICML,2017,Latent Feature Lasso,Shou-De Lin,National Taiwan University
ICML,2017,Latent Feature Lasso,Pradeep Ravikumar,Carnegie Mellon University
ICML,2017,Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things,Ashish Kumar,Microsoft Research
ICML,2017,Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things,Saurabh Goyal,IBM India Pvt Ltd
ICML,2017,Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things,Manik Varma,Microsoft Research
ICML,2017,Learning Important Features Through Propagating Activation Differences,Avanti Shrikumar,Stanford University
ICML,2017,Learning Important Features Through Propagating Activation Differences,Peyton Greenside,Stanford University
ICML,2017,Learning Important Features Through Propagating Activation Differences,Anshul Kundaje,Stanford University
ICML,2017,Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks,Lars Mescheder,MPI Tübingen
ICML,2017,Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks,Sebastian Nowozin,Microsoft Research
ICML,2017,Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks,Andreas Geiger,MPI Tübingen
ICML,2017,Strong NP-Hardness for Sparse Optimization with Concave Penalty Functions,Yichen Chen,Princeton University
ICML,2017,Strong NP-Hardness for Sparse Optimization with Concave Penalty Functions,Dongdong Ge,Shanghai University of Finance and Economics
ICML,2017,Strong NP-Hardness for Sparse Optimization with Concave Penalty Functions,Mengdi Wang,Princeton University
ICML,2017,Strong NP-Hardness for Sparse Optimization with Concave Penalty Functions,Zizhuo Wang,University of Minnesota
ICML,2017,Strong NP-Hardness for Sparse Optimization with Concave Penalty Functions,Yinyu Ye,
ICML,2017,Strong NP-Hardness for Sparse Optimization with Concave Penalty Functions,Hao Yin,Stanford University
ICML,2017,Boosted Fitted Q-Iteration,Samuele Tosatto,Politecnico di Milano
ICML,2017,Boosted Fitted Q-Iteration,Matteo Pirotta,SequeL - Inria Lille - Nord Europe
ICML,2017,Boosted Fitted Q-Iteration,Carlo D'Eramo,Politecnico di Milano
ICML,2017,Boosted Fitted Q-Iteration,Marcello Restelli,Politecnico di Milano
ICML,2017,Automatic Discovery of the Statistical Types of Variables in a Dataset,Isabel Valera,University of Cambridge
ICML,2017,Automatic Discovery of the Statistical Types of Variables in a Dataset,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2017,Online Learning to Rank in Stochastic Click Models,Masrour Zoghi,Independent Researcher
ICML,2017,Online Learning to Rank in Stochastic Click Models,Tomas Tunys,Czech Technical University
ICML,2017,Online Learning to Rank in Stochastic Click Models,Mohammad Ghavamzadeh,Adobe Research & INRIA
ICML,2017,Online Learning to Rank in Stochastic Click Models,Branislav Kveton,Adobe Research
ICML,2017,Online Learning to Rank in Stochastic Click Models,Csaba Szepesvari,University of Alberta
ICML,2017,Online Learning to Rank in Stochastic Click Models,Zheng Wen,Adobe Research
ICML,2017,Online Partial Least Square Optimization: Dropping Convexity for Better Efficiency and Scalability,Zhehui Chen,Georgia Institute of Technology
ICML,2017,Online Partial Least Square Optimization: Dropping Convexity for Better Efficiency and Scalability,Lin Yang,Johns Hopkins
ICML,2017,Online Partial Least Square Optimization: Dropping Convexity for Better Efficiency and Scalability,Chris Junchi Li,Princeton University
ICML,2017,Online Partial Least Square Optimization: Dropping Convexity for Better Efficiency and Scalability,Tuo Zhao,Georgia Institute of Technology
ICML,2017,Multi-Class Optimal Margin Distribution Machine,Teng Zhang,Nanjing University
ICML,2017,Multi-Class Optimal Margin Distribution Machine,Zhi-Hua Zhou,Nanjing University
ICML,2017,Evaluating the Variance of Likelihood-Ratio Gradient Estimators,Seiya Tokui,Preferred Networks / The University of Tokyo
ICML,2017,Evaluating the Variance of Likelihood-Ratio Gradient Estimators,Issei Sato,University of Tokyo / RIKEN
ICML,2017,Learning Texture Manifolds with the Periodic Spatial GAN,Urs M Bergmann,Zalando Research
ICML,2017,Learning Texture Manifolds with the Periodic Spatial GAN,Nikolay Jetchev,Zalando Research
ICML,2017,Learning Texture Manifolds with the Periodic Spatial GAN,Roland Vollgraf,Zalando Research
ICML,2017,Stochastic Convex Optimization: Faster Local Growth Implies Faster Global Convergence,Yi Xu,The University of Iowa
ICML,2017,Stochastic Convex Optimization: Faster Local Growth Implies Faster Global Convergence,Qihang Lin,Univ Iowa
ICML,2017,Stochastic Convex Optimization: Faster Local Growth Implies Faster Global Convergence,Tianbao Yang,The University of Iowa
ICML,2017,Why is Posterior Sampling Better than Optimism for Reinforcement Learning?,Ian Osband,Google DeepMind
ICML,2017,Why is Posterior Sampling Better than Optimism for Reinforcement Learning?,Benjamin Van Roy,Stanford University
ICML,2017,Bayesian Models of Data Streams with Hierarchical Power Priors,Andres Masegosa,University of Almeria
ICML,2017,Bayesian Models of Data Streams with Hierarchical Power Priors,Thomas D. Nielsen,Aalborg University
ICML,2017,Bayesian Models of Data Streams with Hierarchical Power Priors,Helge Langseth,Norwegian University of Science and Technology
ICML,2017,Bayesian Models of Data Streams with Hierarchical Power Priors,Dario Ramos-Lopez,University of Almeria
ICML,2017,Bayesian Models of Data Streams with Hierarchical Power Priors,Antonio Salmeron,University of Almeria
ICML,2017,Bayesian Models of Data Streams with Hierarchical Power Priors,Anders Madsen,Hugin Expert A/S
ICML,2017,The Sample Complexity of Online One-Class Collaborative Filtering,Reinhard Heckel,UC Berkeley
ICML,2017,The Sample Complexity of Online One-Class Collaborative Filtering,Kannan Ramchandran,UC Berkeley
ICML,2017,Kernelized Support Tensor Machines,Lifang He,University of Illinios at Chicago/Shenzhen University
ICML,2017,Kernelized Support Tensor Machines,Chun-Ta Lu,University of Illinois at Chicago
ICML,2017,Kernelized Support Tensor Machines,Guixiang Ma,
ICML,2017,Kernelized Support Tensor Machines,Shen Wang,University of Illinios at Chicago
ICML,2017,Kernelized Support Tensor Machines,Linlin Shen,
ICML,2017,Kernelized Support Tensor Machines,Philip Yu,UIC
ICML,2017,Kernelized Support Tensor Machines,Ann Ragin,Northwestern University
ICML,2017,Equivariance Through Parameter-Sharing,Siamak Ravanbakhsh,Carnegie Mellon University
ICML,2017,Equivariance Through Parameter-Sharing,Jeff Schneider,CMU/Uber
ICML,2017,Equivariance Through Parameter-Sharing,Barnabás Póczos,CMU
ICML,2017,Generalization and Equilibrium in Generative Adversarial Nets (GANs),Sanjeev Arora,Princeton University
ICML,2017,Generalization and Equilibrium in Generative Adversarial Nets (GANs),Rong Ge,Duke University
ICML,2017,Generalization and Equilibrium in Generative Adversarial Nets (GANs),Yingyu Liang,Princeton University
ICML,2017,Generalization and Equilibrium in Generative Adversarial Nets (GANs),Tengyu Ma,Princeton University
ICML,2017,Generalization and Equilibrium in Generative Adversarial Nets (GANs),Yi Zhang,Princeton University
ICML,2017,GSOS: Gauss-Seidel Operator Splitting Algorithm for Multi-Term Nonsmooth Convex Composite Optimization,Li Shen,"School of Mathematics, South China University of Technology"
ICML,2017,GSOS: Gauss-Seidel Operator Splitting Algorithm for Multi-Term Nonsmooth Convex Composite Optimization,Wei Liu,Tencent AI Lab
ICML,2017,GSOS: Gauss-Seidel Operator Splitting Algorithm for Multi-Term Nonsmooth Convex Composite Optimization,Ganzhao Yuan,SYSU
ICML,2017,GSOS: Gauss-Seidel Operator Splitting Algorithm for Multi-Term Nonsmooth Convex Composite Optimization,Shiqian Ma,The Chinese University of Hong Kong
ICML,2017,Constrained Policy Optimization,Joshua Achiam,UC Berkeley
ICML,2017,Constrained Policy Optimization,Dave Held,UC Berkeley
ICML,2017,Constrained Policy Optimization,Aviv Tamar,UC Berkeley
ICML,2017,Constrained Policy Optimization,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2017,Ordinal Graphical Models: A Tale of Two Approaches,Arun SUGGALA,Carnegie Mellon University
ICML,2017,Ordinal Graphical Models: A Tale of Two Approaches,Eunho Yang,KAIST / AItrics
ICML,2017,Ordinal Graphical Models: A Tale of Two Approaches,Pradeep Ravikumar,Carnegie Mellon University
ICML,2017,Efficient Regret Minimization in Non-Convex Games,Elad Hazan,Princeton University
ICML,2017,Efficient Regret Minimization in Non-Convex Games,Karan Singh,Princeton University
ICML,2017,Efficient Regret Minimization in Non-Convex Games,Cyril Zhang,Princeton University
ICML,2017,Coresets for Vector Summarization with Applications to Network Graphs,Dan Feldman,
ICML,2017,Coresets for Vector Summarization with Applications to Network Graphs,Sedat Ozer,MIT
ICML,2017,Coresets for Vector Summarization with Applications to Network Graphs,Daniela Rus,
ICML,2017,Recovery Guarantees for One-hidden-layer Neural Networks,Kai Zhong,University of Texas at Austin
ICML,2017,Recovery Guarantees for One-hidden-layer Neural Networks,Zhao Song,UT-Austin
ICML,2017,Recovery Guarantees for One-hidden-layer Neural Networks,Prateek Jain,Microsoft Research
ICML,2017,Recovery Guarantees for One-hidden-layer Neural Networks,Peter Bartlett,UC Berkeley
ICML,2017,Recovery Guarantees for One-hidden-layer Neural Networks,Inderjit Dhillon,UT Austin & Amazon
ICML,2017,Dual Supervised Learning,Yingce Xia,University of Science and Technology of China
ICML,2017,Dual Supervised Learning,Tao Qin,Microsoft Research Asia
ICML,2017,Dual Supervised Learning,Wei Chen,Microsoft Research
ICML,2017,Dual Supervised Learning,Jiang Bian,Microsoft Research
ICML,2017,Dual Supervised Learning,Nenghai Yu,USTC
ICML,2017,Dual Supervised Learning,Tie-Yan Liu,Microsoft
ICML,2017,Warped Convolutions: Efficient Invariance to Spatial Transformations,Joao Henriques,University of Oxford
ICML,2017,Warped Convolutions: Efficient Invariance to Spatial Transformations,Andrea Vedaldi,University of Oxford
ICML,2017,McGan: Mean and Covariance Feature Matching GAN,Youssef Mroueh,IBM T.J Watson Research Center
ICML,2017,McGan: Mean and Covariance Feature Matching GAN,Tom Sercu,IBM Research
ICML,2017,McGan: Mean and Covariance Feature Matching GAN,Vaibhava Goel,IBM
ICML,2017,Breaking Locality Accelerates Block Gauss-Seidel,Stephen Tu,UC Berkeley
ICML,2017,Breaking Locality Accelerates Block Gauss-Seidel,Shivaram Venkataraman,UC Berkeley
ICML,2017,Breaking Locality Accelerates Block Gauss-Seidel,Ashia Wilson,UC Berkeley
ICML,2017,Breaking Locality Accelerates Block Gauss-Seidel,Alex Gittens,UC Berkeley
ICML,2017,Breaking Locality Accelerates Block Gauss-Seidel,Michael Jordan,UC Berkeley
ICML,2017,Breaking Locality Accelerates Block Gauss-Seidel,Benjamin Recht,Berkeley
ICML,2017,Reinforcement Learning with Deep Energy-Based Policies,Tuomas Haarnoja,UC Berkeley
ICML,2017,Reinforcement Learning with Deep Energy-Based Policies,Haoran Tang,UC Berkeley
ICML,2017,Reinforcement Learning with Deep Energy-Based Policies,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2017,Reinforcement Learning with Deep Energy-Based Policies,Sergey Levine,Berkeley
ICML,2017,Scalable Bayesian Rule Lists,Hongyu Yang,Massachusetts Institute of Technology
ICML,2017,Scalable Bayesian Rule Lists,Cynthia Rudin,Duke University
ICML,2017,Scalable Bayesian Rule Lists,Margo Seltzer,Harvard University
ICML,2017,Identify the Nash Equilibrium in Static Games with Random Payoffs,Yichi Zhou,Tsinghua University
ICML,2017,Identify the Nash Equilibrium in Static Games with Random Payoffs,Jialian Li,Tsinghua University
ICML,2017,Identify the Nash Equilibrium in Static Games with Random Payoffs,Jun Zhu,Tsinghua University
ICML,2017,Partitioned Tensor Factorizations for Learning Mixed Membership Models,Zilong Tan,Duke University
ICML,2017,Partitioned Tensor Factorizations for Learning Mixed Membership Models,Sayan Mukherjee,Duke University
ICML,2017,Failures of Gradient-Based Deep Learning,Shaked Shammah,"Hebrew University, Jerusalem"
ICML,2017,Failures of Gradient-Based Deep Learning,Shai Shalev-Shwartz,
ICML,2017,Failures of Gradient-Based Deep Learning,Ohad Shamir,Weizmann Institute of Science
ICML,2017,Learning Infinite Layer Networks without the Kernel Trick,ROI Livni,Princeton
ICML,2017,Learning Infinite Layer Networks without the Kernel Trick,Daniel Carmon,Tel-Aviv University
ICML,2017,Learning Infinite Layer Networks without the Kernel Trick,Amir Globerson,Tel Aviv University
ICML,2017,Graph-based Isometry Invariant Representation Learning,Renata Khasanova,Ecole Polytechnique Federale de Lausanne (EPFL)
ICML,2017,Graph-based Isometry Invariant Representation Learning,Pascal Frossard,EPFL
ICML,2017,Conditional Image Synthesis with Auxiliary Classifier GANs,Augustus Odena,Google Brain
ICML,2017,Conditional Image Synthesis with Auxiliary Classifier GANs,Christopher Olah,Google Brain
ICML,2017,Conditional Image Synthesis with Auxiliary Classifier GANs,Jon Shlens,Google Brain
ICML,2017,Stochastic DCA for the Large-sum of Non-convex Functions Problem and its Application to Group Variable Selection in Classification,Hoai An Le Thi,"Theoretical and Applied Computer Science Laboratory, University of Lorraine"
ICML,2017,Stochastic DCA for the Large-sum of Non-convex Functions Problem and its Application to Group Variable Selection in Classification,Hoai Minh Le,"Laboratory of Theoretical and Applied Computer Science, Univ. of Lorraine, Fr"
ICML,2017,Stochastic DCA for the Large-sum of Non-convex Functions Problem and its Application to Group Variable Selection in Classification,Duy Nhat Phan,Universite de Lorraine
ICML,2017,Stochastic DCA for the Large-sum of Non-convex Functions Problem and its Application to Group Variable Selection in Classification,Bach Tran,University of Lorraine
ICML,2017,Prediction and Control with Temporal Segment Models,Nikhil Mishra,UC Berkeley
ICML,2017,Prediction and Control with Temporal Segment Models,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2017,Prediction and Control with Temporal Segment Models,Igor Mordatch,OpenAI
ICML,2017,Learning Determinantal Point Processes with Moments and Cycles,John C Urschel,Massachusetts Institute of Technology
ICML,2017,Learning Determinantal Point Processes with Moments and Cycles,Ankur Moitra,
ICML,2017,Learning Determinantal Point Processes with Moments and Cycles,Philippe Rigollet,MIT
ICML,2017,Learning Determinantal Point Processes with Moments and Cycles,Victor-Emmanuel Brunel,Massachusetts Institute of Technology
ICML,2017,Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU,Zeyuan Allen-Zhu,Microsoft Research / Princeton / IAS
ICML,2017,Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU,Yuanzhi Li,Princeton University
ICML,2017,On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations,Xueyu Mao,University of Texas at Austin
ICML,2017,On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations,Purnamrita Sarkar,UT Austin
ICML,2017,On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations,Deepayan Chakrabarti,"University of Texas, Austin"
ICML,2017,Analytical Guarantees on Numerical Precision of Deep Neural Networks,Charbel Sakr,University of Illinois at Urbana-Champaign
ICML,2017,Analytical Guarantees on Numerical Precision of Deep Neural Networks,Yongjune Kim,UIUC
ICML,2017,Analytical Guarantees on Numerical Precision of Deep Neural Networks,Naresh Shanbhag,University of Illinois
ICML,2017,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,Haim Avron,Tel Aviv University
ICML,2017,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,Michael Kapralov,EPFL
ICML,2017,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,Cameron Musco,
ICML,2017,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,Christopher Musco,
ICML,2017,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,Ameya Velingker,
ICML,2017,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,Amir Zandieh,EPFL
ICML,2017,Deriving Neural Architectures from Sequence and Graph Kernels,Tao Lei,MIT CSAIL
ICML,2017,Deriving Neural Architectures from Sequence and Graph Kernels,Wengong Jin,MIT Computer Science and Artificial Intelligence Laboratory
ICML,2017,Deriving Neural Architectures from Sequence and Graph Kernels,Regina Barzilay,MIT CSAIL
ICML,2017,Deriving Neural Architectures from Sequence and Graph Kernels,Tommi Jaakkola,MIT
ICML,2017,Learning to Discover Cross-Domain Relations with Generative Adversarial Networks,Taeksoo Kim,SK T-Brain
ICML,2017,Learning to Discover Cross-Domain Relations with Generative Adversarial Networks,Moonsu Cha,SK T-Brain
ICML,2017,Learning to Discover Cross-Domain Relations with Generative Adversarial Networks,Hyunsoo Kim,SK T-Brain
ICML,2017,Learning to Discover Cross-Domain Relations with Generative Adversarial Networks,Jungkwon Lee,SK T-Brain
ICML,2017,Learning to Discover Cross-Domain Relations with Generative Adversarial Networks,Jiwon Kim,SK T-Brain
ICML,2017,Gradient Projection Iterative Sketch for Large-Scale Constrained Least-Squares,Junqi Tang,the University of Edinburgh
ICML,2017,Gradient Projection Iterative Sketch for Large-Scale Constrained Least-Squares,Mohammad Golbabaee,the University of Edinburgh
ICML,2017,Gradient Projection Iterative Sketch for Large-Scale Constrained Least-Squares,Mike E Davies,University of Edinburgh
ICML,2017,An Alternative Softmax Operator for Reinforcement Learning,Kavosh Asadi,Brown University
ICML,2017,An Alternative Softmax Operator for Reinforcement Learning,Michael L. Littman,Brown University
ICML,2017,Deep Bayesian Active Learning with Image Data,Yarin Gal,University of Cambridge
ICML,2017,Deep Bayesian Active Learning with Image Data,Riashat Islam,McGill University
ICML,2017,Deep Bayesian Active Learning with Image Data,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2017,On Kernelized Multi-armed Bandits,Sayak Ray Chowdhury,Indian Institute of Science
ICML,2017,On Kernelized Multi-armed Bandits,Aditya Gopalan,Indian Institute of Science
ICML,2017,Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates,Jiali Mei,EDF R&D & Université Paris-Sud
ICML,2017,Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates,Yohann De Castro,LMO
ICML,2017,Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates,Yannig Goude,EDF Lab Paris-Saclay
ICML,2017,Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates,Georges Hébrail,EDF Lab Paris-Saclay
ICML,2017,Follow the Moving Leader in Deep Learning,Shuai Zheng,Hong Kong University of Science and Technology
ICML,2017,Follow the Moving Leader in Deep Learning,James Kwok,Hong Kong University of Science and Technology
ICML,2017,Logarithmic Time One-Against-Some,Hal Daumé,University of Maryland
ICML,2017,Logarithmic Time One-Against-Some,NIKOS KARAMPATZIAKIS,Microsoft
ICML,2017,Logarithmic Time One-Against-Some,John Langford,Microsoft Research
ICML,2017,Logarithmic Time One-Against-Some,Paul Mineiro,Microsoft
ICML,2017,Unsupervised Learning by Predicting Noise,Piotr Bojanowski,Facebook
ICML,2017,Unsupervised Learning by Predicting Noise,Armand Joulin,Facebook
ICML,2017,Wasserstein Generative Adversarial Networks,Martin Arjovsky,New York University
ICML,2017,Wasserstein Generative Adversarial Networks,Soumith Chintala,Facebook
ICML,2017,Wasserstein Generative Adversarial Networks,Léon Bottou,Facebook
ICML,2017,Connected Subgraph Detection with Mirror Descent on SDPs,Cem Aksoylar,
ICML,2017,Connected Subgraph Detection with Mirror Descent on SDPs,Orecchia Lorenzo,Boston
ICML,2017,Connected Subgraph Detection with Mirror Descent on SDPs,Venkatesh Saligrama,Boston University
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Mehrdad Farajtabar,Georgia Tech
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Jiachen Yang,Georgia Institute of Technology
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Xiaojing Ye,Georgia State University
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Huan Xu,Georgia Tech
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Rakshit Trivedi,Georgia Institute of Technology
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Elias Khalil,Georgia Tech
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Shuang Li,
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Le Song,Georgia Institute of Technology
ICML,2017,Fake News Mitigation via Point Process Based Intervention,Hongyuan Zha,Georgia Institute of Technology
ICML,2017,Bayesian Boolean Matrix Factorisation,Tammo Rukat,University of Oxford
ICML,2017,Bayesian Boolean Matrix Factorisation,Christopher Holmes,University of Oxford
ICML,2017,Bayesian Boolean Matrix Factorisation,Michalis Titsias,Athens University of Economics and Business
ICML,2017,Bayesian Boolean Matrix Factorisation,Christopher Yau,University of Birmingham
ICML,2017,Second-Order Kernel Online Convex Optimization with Adaptive Sketching,Daniele Calandriello,INRIA Lille
ICML,2017,Second-Order Kernel Online Convex Optimization with Adaptive Sketching,Alessandro Lazaric,FACEBOOK
ICML,2017,Second-Order Kernel Online Convex Optimization with Adaptive Sketching,Michal Valko,Inria Lille - Nord Europe
ICML,2017,Frame-based Data Factorizations,Sebastian Mair,Leuphana University Lüneburg
ICML,2017,Frame-based Data Factorizations,Ahcène Boubekki,Leuphana University
ICML,2017,Frame-based Data Factorizations,Ulf Brefeld,Leuphana University
ICML,2017,Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank,Liang Zhao,The City University of New York
ICML,2017,Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank,Siyu Liao,
ICML,2017,Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank,Yanzhi Wang,
ICML,2017,Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank,Zhe Li,Syracuse University
ICML,2017,Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank,Jian Tang,Syracuse University
ICML,2017,Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank,Bo Yuan,"City College of New York, CUNY"
ICML,2017,Understanding Black-box Predictions via Influence Functions,Pang Wei Koh,Stanford University
ICML,2017,Understanding Black-box Predictions via Influence Functions,Percy Liang,Stanford University
ICML,2017,Deep Transfer Learning with Joint Adaptation Networks,Mingsheng Long,Tsinghua University
ICML,2017,Deep Transfer Learning with Joint Adaptation Networks,Han Zhu,Tsinghua University
ICML,2017,Deep Transfer Learning with Joint Adaptation Networks,Jianmin Wang,Tsinghua University
ICML,2017,Deep Transfer Learning with Joint Adaptation Networks,Michael Jordan,UC Berkeley
ICML,2017,Learning Hierarchical Features from Deep Generative Models,Shengjia Zhao,Stanford University
ICML,2017,Learning Hierarchical Features from Deep Generative Models,Jiaming Song,Stanford University
ICML,2017,Learning Hierarchical Features from Deep Generative Models,Stefano Ermon,Stanford University
ICML,2017,Prox-PDA: The Proximal Primal-Dual Algorithm for Fast Distributed Nonconvex Optimization and Learning Over Networks,Mingyi Hong,Iowa State University
ICML,2017,Prox-PDA: The Proximal Primal-Dual Algorithm for Fast Distributed Nonconvex Optimization and Learning Over Networks,Davood Hajinezhad,Iowa State University
ICML,2017,Prox-PDA: The Proximal Primal-Dual Algorithm for Fast Distributed Nonconvex Optimization and Learning Over Networks,Ming-Min Zhao,Zhejiang University
ICML,2017,Curiosity-driven Exploration by Self-supervised Prediction,Deepak Pathak,UC Berkeley
ICML,2017,Curiosity-driven Exploration by Self-supervised Prediction,Pulkit Agrawal,
ICML,2017,Curiosity-driven Exploration by Self-supervised Prediction,Alexei Efros,UC Berkeley
ICML,2017,Curiosity-driven Exploration by Self-supervised Prediction,Prof. Darrell,University of California at Berkeley
ICML,2017,Learning the Structure of Generative Models without Labeled Data,Stephen Bach,Stanford University
ICML,2017,Learning the Structure of Generative Models without Labeled Data,Bryan He,Stanford University
ICML,2017,Learning the Structure of Generative Models without Labeled Data,Alexander J Ratner,Stanford University
ICML,2017,Learning the Structure of Generative Models without Labeled Data,Christopher Re,Stanford
ICML,2017,Dueling Bandits with Weak Regret,Bangrui Chen,Cornell University
ICML,2017,Dueling Bandits with Weak Regret,Peter Frazier,Cornell University
ICML,2017,Nearly Optimal Robust Matrix Completion,Yeshwanth Cherapanamjeri,Microsoft Research
ICML,2017,Nearly Optimal Robust Matrix Completion,Prateek Jain,Microsoft Research
ICML,2017,Nearly Optimal Robust Matrix Completion,Kartik Gupta,Microsoft Research
ICML,2017,Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs,Alon Brutzkus,Tel Aviv University
ICML,2017,Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs,Amir Globerson,Tel Aviv University
ICML,2017,Re-revisiting Learning on Hypergraphs: Confidence Interval and Subgradient Method,Chenzi Zhang,HKU
ICML,2017,Re-revisiting Learning on Hypergraphs: Confidence Interval and Subgradient Method,Shuguang Hu,University of Hong Kong
ICML,2017,Re-revisiting Learning on Hypergraphs: Confidence Interval and Subgradient Method,Zhihao Gavin Tang,University of Hong Kong
ICML,2017,Re-revisiting Learning on Hypergraphs: Confidence Interval and Subgradient Method,Hubert Chan,University of Hong Kong
ICML,2017,Meta Networks,Tsendsuren Munkhdalai,University of Massachusetts
ICML,2017,Meta Networks,Hong Yu,University of Massachusetts
ICML,2017,Bottleneck Conditional Density Estimation,Rui Shu,Stanford University
ICML,2017,Bottleneck Conditional Density Estimation,Hung Bui,Adobe Research
ICML,2017,Bottleneck Conditional Density Estimation,Mohammad Ghavamzadeh,Adobe Research & INRIA
ICML,2017,Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms,Jialei Wang,University of Chicago
ICML,2017,Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms,Lin Xiao,Microsoft Research
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,James MacGlashan,Cogitai
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,Mark Ho,Brown University
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,Robert Loftin,North Carolina State University
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,Bei Peng,Washington State University
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,Guan Wang,Brown University
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,David L Roberts,North Carolina State University
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,Matthew E. Taylor,Washington State University
ICML,2017,Interactive Learning from Policy-Dependent Human Feedback,Michael L. Littman,Brown University
ICML,2017,Learning to Discover Sparse Graphical Models,Eugene Belilovsky,CentraleSupelec
ICML,2017,Learning to Discover Sparse Graphical Models,Kyle Kastner,
ICML,2017,Learning to Discover Sparse Graphical Models,Gael Varoquaux,Inria
ICML,2017,Learning to Discover Sparse Graphical Models,Matthew B Blaschko,KU Leuven
ICML,2017,On Context-Dependent Clustering of Bandits,Claudio Gentile,Universita dell'Insubria
ICML,2017,On Context-Dependent Clustering of Bandits,Shuai Li,University of Cambridge
ICML,2017,On Context-Dependent Clustering of Bandits,Puru Kar,Indian Institute of Technology Kanpur
ICML,2017,On Context-Dependent Clustering of Bandits,Alexandros Karatzoglou,Telefonica Research
ICML,2017,On Context-Dependent Clustering of Bandits,Giovanni Zappella,Amazon Dev Center Germany
ICML,2017,On Context-Dependent Clustering of Bandits,Evans Etrue Howard,University of Insubria
ICML,2017,Provable Alternating Gradient Descent for Non-negative Matrix Factorization with Strong Correlations,Yuanzhi Li,Princeton University
ICML,2017,Provable Alternating Gradient Descent for Non-negative Matrix Factorization with Strong Correlations,Yingyu Liang,Princeton University
ICML,2017,Convexified Convolutional Neural Networks,Yuchen Zhang,Stanford
ICML,2017,Convexified Convolutional Neural Networks,Percy Liang,Stanford University
ICML,2017,Convexified Convolutional Neural Networks,Martin Wainwright,University of California at Berkeley
ICML,2017,Self-Paced Co-training,Fan Ma,Xian Jiaotong University
ICML,2017,Self-Paced Co-training,Deyu Meng,
ICML,2017,Self-Paced Co-training,Qi Xie,
ICML,2017,Self-Paced Co-training,Zina Li,
ICML,2017,Self-Paced Co-training,Xuanyi Dong,University of Technology Sydney
ICML,2017,SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization,Juyong Kim,Seoul National University
ICML,2017,SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization,Yookoon Park,Seoul National University
ICML,2017,SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization,Gunhee Kim,Seoul National University
ICML,2017,SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization,Sung Ju Hwang,UNIST / AItrics
ICML,2017,Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo,Matthew Hoffman,DeepMind
ICML,2017,Doubly Greedy Primal-Dual Coordinate Descent for Sparse Empirical Risk Minimization,Qi Lei,University of Texas at Austin
ICML,2017,Doubly Greedy Primal-Dual Coordinate Descent for Sparse Empirical Risk Minimization,Ian Yen,Carnegie Mellon University
ICML,2017,Doubly Greedy Primal-Dual Coordinate Descent for Sparse Empirical Risk Minimization,Chao-Yuan Wu,UT Austin
ICML,2017,Doubly Greedy Primal-Dual Coordinate Descent for Sparse Empirical Risk Minimization,Inderjit Dhillon,UT Austin & Amazon
ICML,2017,Doubly Greedy Primal-Dual Coordinate Descent for Sparse Empirical Risk Minimization,Pradeep Ravikumar,Carnegie Mellon University
ICML,2017,End-to-End Differentiable Adversarial Imitation Learning,Nir Baram,Technion - Israel Institute of Technology
ICML,2017,End-to-End Differentiable Adversarial Imitation Learning,Oron Anschel,Technion
ICML,2017,End-to-End Differentiable Adversarial Imitation Learning,Itai Caspi,Technion
ICML,2017,End-to-End Differentiable Adversarial Imitation Learning,Shie Mannor,Technion
ICML,2017,Local-to-Global Bayesian Network Structure Learning,Tian Gao,IBM Research
ICML,2017,Local-to-Global Bayesian Network Structure Learning,Kshitij Fadnis,IBM
ICML,2017,Local-to-Global Bayesian Network Structure Learning,Murray Campbell,IBM
ICML,2017,Provably Optimal Algorithms for Generalized Linear Contextual Bandits,Lihong Li,Microsoft Research
ICML,2017,Provably Optimal Algorithms for Generalized Linear Contextual Bandits,Yu Lu,Yale University
ICML,2017,Provably Optimal Algorithms for Generalized Linear Contextual Bandits,Dengyong Zhou,Microsoft Research
ICML,2017,No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis,Rong Ge,Duke University
ICML,2017,No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis,Chi Jin,UC Berkeley
ICML,2017,No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis,Yi Zheng,Duke University
ICML,2017,On the Expressive Power of Deep Neural Networks,Maithra Raghu,Google Brain / Cornell University
ICML,2017,On the Expressive Power of Deep Neural Networks,Ben Poole,Stanford University
ICML,2017,On the Expressive Power of Deep Neural Networks,Surya Ganguli,Stanford
ICML,2017,On the Expressive Power of Deep Neural Networks,Jon Kleinberg,Cornell University
ICML,2017,On the Expressive Power of Deep Neural Networks,Jascha Sohl-Dickstein,Google Brain
ICML,2017,Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data,Tomoya Sakai,The University of Tokyo / RIKEN
ICML,2017,Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data,Marthinus C du Plessis,
ICML,2017,Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data,Gang Niu,University of Tokyo
ICML,2017,Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data,Masashi Sugiyama,RIKEN / The University of Tokyo
ICML,2017,Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks,Chelsea Finn,UC Berkeley
ICML,2017,Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2017,Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks,Sergey Levine,Berkeley
ICML,2017,Zero-Inflated Exponential Family Embeddings,Liping Liu,Columbia University
ICML,2017,Zero-Inflated Exponential Family Embeddings,David Blei,Columbia University
ICML,2017,A Richer Theory of Convex Constrained Optimization with Reduced Projections and Improved Rates,Tianbao Yang,The University of Iowa
ICML,2017,A Richer Theory of Convex Constrained Optimization with Reduced Projections and Improved Rates,Qihang Lin,Univ Iowa
ICML,2017,A Richer Theory of Convex Constrained Optimization with Reduced Projections and Improved Rates,Lijun Zhang,Nanjing University
ICML,2017,Learning in POMDPs with Monte Carlo Tree Search,Sammie Katt,Northeastern University
ICML,2017,Learning in POMDPs with Monte Carlo Tree Search,Frans A Oliehoek,University of Liverpool
ICML,2017,Learning in POMDPs with Monte Carlo Tree Search,Chris Amato,Northeastern University
ICML,2017,Composing Tree Graphical Models with Persistent Homology Features for Clustering Mixed-Type Data,XIUYAN NI,"THE GRADUATE CENTER, CUNY"
ICML,2017,Composing Tree Graphical Models with Persistent Homology Features for Clustering Mixed-Type Data,Novi Quadrianto,University of Sussex and National Research University Higher School of Economics
ICML,2017,Composing Tree Graphical Models with Persistent Homology Features for Clustering Mixed-Type Data,Yusu Wang,Ohio State University
ICML,2017,Composing Tree Graphical Models with Persistent Homology Features for Clustering Mixed-Type Data,Chao Chen,City University of New York (CUNY)
ICML,2017,Safety-Aware Algorithms for Adversarial Contextual Bandit,Wen Sun,Carnegie Mellon University
ICML,2017,Safety-Aware Algorithms for Adversarial Contextual Bandit,Debadeepta Dey,Microsoft
ICML,2017,Safety-Aware Algorithms for Adversarial Contextual Bandit,Ashish Kapoor,Microsoft Research
ICML,2017,"Coherence Pursuit: Fast, Simple, and Robust Subspace Recovery",Mostafa Rahmani,University of Central Florida
ICML,2017,"Coherence Pursuit: Fast, Simple, and Robust Subspace Recovery",George Atia,University of Central Florida
ICML,2017,Depth-Width Tradeoffs in Approximating Natural Functions With Neural Networks,Itay Safran,Weizmann Institute of Science
ICML,2017,Depth-Width Tradeoffs in Approximating Natural Functions With Neural Networks,Ohad Shamir,Weizmann Institute of Science
ICML,2017,Iterative Machine Teaching,Weiyang Liu,Georgia Tech
ICML,2017,Iterative Machine Teaching,Bo Dai,Georgia Tech
ICML,2017,Iterative Machine Teaching,Ahmad Humayun,Georgia Institute of Technology
ICML,2017,Iterative Machine Teaching,Charlene Tay,Indiana University
ICML,2017,Iterative Machine Teaching,Chen Yu,Indiana University
ICML,2017,Iterative Machine Teaching,Linda Smith,Indiana University
ICML,2017,Iterative Machine Teaching,Jim Rehg,Georgia Tech
ICML,2017,Iterative Machine Teaching,Le Song,Georgia Institute of Technology
ICML,2017,AdaNet: Adaptive Structural Learning of Artificial Neural Networks,Corinna Cortes,Google Research
ICML,2017,AdaNet: Adaptive Structural Learning of Artificial Neural Networks,Xavi Gonzalvo,
ICML,2017,AdaNet: Adaptive Structural Learning of Artificial Neural Networks,Vitaly Kuznetsov,Google
ICML,2017,AdaNet: Adaptive Structural Learning of Artificial Neural Networks,Mehryar Mohri,Courant Institute and Google Research
ICML,2017,AdaNet: Adaptive Structural Learning of Artificial Neural Networks,Scott Yang,Courant Institute
ICML,2017,Convex Phase Retrieval without Lifting via PhaseMax,Tom Goldstein,University of Maryland
ICML,2017,Convex Phase Retrieval without Lifting via PhaseMax,Christoph Studer,Cornell University
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Irina Higgins,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Arka Pal,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Andrei A Rusu,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Loic Matthey,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Christopher Burgess,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Alexander Pritzel,Deepmind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Matthew Botvinick,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Charles Blundell,DeepMind
ICML,2017,DARLA: Improving Zero-Shot Transfer in Reinforcement Learning,Alexander Lerchner,DeepMind
ICML,2017,On Relaxing Determinism in Arithmetic Circuits,Arthur Choi,UCLA
ICML,2017,On Relaxing Determinism in Arithmetic Circuits,Adnan Darwiche,UCLA
ICML,2017,Adaptive Multiple-Arm Identification,Jiecao (Jack) Chen,Indiana University Bloomington
ICML,2017,Adaptive Multiple-Arm Identification,Xi Chen,New York University
ICML,2017,Adaptive Multiple-Arm Identification,Qin Zhang,Indiana University Bloomington
ICML,2017,Adaptive Multiple-Arm Identification,Yuan Zhou,Indiana University Bloomington
ICML,2017,Tensor Decomposition with Smoothness,Masaaki Imaizumi,Institute of Statistical Mathematics
ICML,2017,Tensor Decomposition with Smoothness,Kohei Hayashi,AIST / RIKEN
ICML,2017,Automated Curriculum Learning for Neural Networks,Alex Graves,DeepMind
ICML,2017,Automated Curriculum Learning for Neural Networks,Marc Bellemare,DeepMind
ICML,2017,Automated Curriculum Learning for Neural Networks,Jacob Menick,DeepMind
ICML,2017,Automated Curriculum Learning for Neural Networks,Remi Munos,DeepMind
ICML,2017,Automated Curriculum Learning for Neural Networks,koray kavukcuoglu,DeepMind
ICML,2017,Attentive Recurrent Comparators,Pranav Shyam,R. V. College of Engineering & Indian Institute of Science
ICML,2017,Attentive Recurrent Comparators,Shubham Gupta,Indian Institute of Science
ICML,2017,Attentive Recurrent Comparators,Ambedkar Dukkipati,Indian Institute of Science
ICML,2017,An Infinite Hidden Markov Model With Similarity-Biased Transitions,Colin Dawson,Oberlin College
ICML,2017,An Infinite Hidden Markov Model With Similarity-Biased Transitions,Bill Huang,Oberlin College
ICML,2017,An Infinite Hidden Markov Model With Similarity-Biased Transitions,Clayton T. Morrison,University of Arizona
ICML,2017,Efficient Nonmyopic Active Search,Shali Jiang,Washington University in St. Louis
ICML,2017,Efficient Nonmyopic Active Search,Gustavo Malkomes,Washington University in St. Louis
ICML,2017,Efficient Nonmyopic Active Search,Geoff Converse,Simpson College
ICML,2017,Efficient Nonmyopic Active Search,Alyssa Shofner,University of South Carolina
ICML,2017,Efficient Nonmyopic Active Search,Benjamin Moseley,Washington University in St. Louis
ICML,2017,Efficient Nonmyopic Active Search,Roman Garnett,Washington University in St. Louis
ICML,2017,Asymmetric Tri-training for Unsupervised Domain Adaptation,Kuniaki Saito,The University of Tokyo
ICML,2017,Asymmetric Tri-training for Unsupervised Domain Adaptation,Yoshitaka Ushiku,The University of Tokyo
ICML,2017,Asymmetric Tri-training for Unsupervised Domain Adaptation,Tatsuya Harada,The Univ. of Tokyo / RIKEN
ICML,2017,State-Frequency Memory Recurrent Neural Networks,Hao Hu,University of Central Florida
ICML,2017,State-Frequency Memory Recurrent Neural Networks,Guo-Jun Qi,University of Central Florida
ICML,2017,Batched High-dimensional Bayesian Optimization via Structural Kernel Learning,Zi Wang,MIT
ICML,2017,Batched High-dimensional Bayesian Optimization via Structural Kernel Learning,Chengtao Li,MIT
ICML,2017,Batched High-dimensional Bayesian Optimization via Structural Kernel Learning,Stefanie Jegelka,MIT
ICML,2017,Batched High-dimensional Bayesian Optimization via Structural Kernel Learning,Pushmeet Kohli,Microsoft Research
ICML,2017,Leveraging Union of Subspace Structure to Improve Constrained Clustering,John Lipor,University of Michigan
ICML,2017,Leveraging Union of Subspace Structure to Improve Constrained Clustering,Laura Balzano,University of Michigan
ICML,2017,Source-Target Similarity Modelings for Multi-Source Transfer Gaussian Process Regression,PENGFEI WEI,"Nanyang Technological University, Singapore"
ICML,2017,Source-Target Similarity Modelings for Multi-Source Transfer Gaussian Process Regression,Ramon Sagarna,
ICML,2017,Source-Target Similarity Modelings for Multi-Source Transfer Gaussian Process Regression,Yiping Ke,Nanyang Technological University
ICML,2017,Source-Target Similarity Modelings for Multi-Source Transfer Gaussian Process Regression,Yew Soon ONG,Nanyang Technological University
ICML,2017,Source-Target Similarity Modelings for Multi-Source Transfer Gaussian Process Regression,CHI GOH,
ICML,2017,Delta Networks for Optimized Recurrent Network Computation,Daniel Neil,Institute of Neuroinformatics
ICML,2017,Delta Networks for Optimized Recurrent Network Computation,Jun Lee,Samsung Advanced Institute of Technology
ICML,2017,Delta Networks for Optimized Recurrent Network Computation,Tobi Delbruck,Institute of Neuroinformatics
ICML,2017,Delta Networks for Optimized Recurrent Network Computation,Shih-Chii Liu,Institute of Neuroinformatics
ICML,2017,From Patches to Images: A Nonparametric Generative Model,Geng Ji,Brown University
ICML,2017,From Patches to Images: A Nonparametric Generative Model,Michael C. Hughes,Harvard University
ICML,2017,From Patches to Images: A Nonparametric Generative Model,Erik Sudderth,"University of California, Irvine"
ICML,2017,Active Heteroscedastic Regression,Kamalika Chaudhuri,University of California at San Diego
ICML,2017,Active Heteroscedastic Regression,Prateek Jain,Microsoft Research
ICML,2017,Active Heteroscedastic Regression,Nagarajan Natarajan,Microsoft Research
ICML,2017,Multi-task Learning with Labeled and Unlabeled Tasks,Anastasia Pentina,IST Austria
ICML,2017,Multi-task Learning with Labeled and Unlabeled Tasks,Christoph Lampert,IST Austria
ICML,2017,Recurrent Highway Networks,Julian Zilly,ETH Zurich
ICML,2017,Recurrent Highway Networks,Rupesh Srivastava,IDSIA (University of Lugano)
ICML,2017,Recurrent Highway Networks,Jan Koutnik,NNAISSENSE
ICML,2017,Recurrent Highway Networks,Jürgen Schmidhuber,Swiss AI Lab
ICML,2017,Fast Bayesian Intensity Estimation for the Permanental Process,Christian Walder,CSIRO Data61
ICML,2017,Fast Bayesian Intensity Estimation for the Permanental Process,Adrian N Bishop,Data61/ANU/UTS
ICML,2017,Active Learning for Cost-Sensitive Classification,Akshay Krishnamurthy,UMass
ICML,2017,Active Learning for Cost-Sensitive Classification,Alekh Agarwal,Microsoft Research
ICML,2017,Active Learning for Cost-Sensitive Classification,Tzu-Kuo Huang,Uber
ICML,2017,Active Learning for Cost-Sensitive Classification,Hal Daumé III,University of Maryland
ICML,2017,Active Learning for Cost-Sensitive Classification,John Langford,Microsoft Research
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Ken Kansky,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Tom Silver,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,David A Mély,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Mo Eldawy,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Miguel Lazaro-Gredilla,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Xinghua Lou,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Nimrod Dorfman,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Szymon Sidor,OpenAI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Scott Phoenix,Vicarious AI
ICML,2017,Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,Dileep George,Vicarious AI
ICML,2017,A Birth-Death Process for Feature Allocation,Konstantina Palla,Oxford
ICML,2017,A Birth-Death Process for Feature Allocation,David Knowles,Stanford
ICML,2017,A Birth-Death Process for Feature Allocation,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2017,Diameter-Based Active Learning,Chris Tosh,"University of California, San Diego"
ICML,2017,Diameter-Based Active Learning,Sanjoy Dasgupta,UCSD
ICML,2017,Risk Bounds for Transferring Representations With and Without Fine-Tuning,Daniel McNamara,Australian National University and Data61
ICML,2017,Risk Bounds for Transferring Representations With and Without Fine-Tuning,Nina Balcan,Carnegie Mellon University
ICML,2017,The loss surface of deep and wide neural networks,Quynh Nguyen,Saarland University
ICML,2017,The loss surface of deep and wide neural networks,Matthias Hein,Saarland University
ICML,2017,Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks,David Balduzzi,Victoria University Wellington
ICML,2017,Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks,Brian McWilliams,Disney Research
ICML,2017,Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks,Tony Butler-Yeoman,Victoria University of Wellington
ICML,2017,Sharp Minima Can Generalize For Deep Nets,Laurent Dinh,University of Montreal
ICML,2017,Sharp Minima Can Generalize For Deep Nets,Razvan Pascanu,DeepMind
ICML,2017,Sharp Minima Can Generalize For Deep Nets,Samy Bengio,Google Brain
ICML,2017,Sharp Minima Can Generalize For Deep Nets,Yoshua Bengio,U. Montreal
ICML,2017,Geometry of Neural Network Loss Surfaces via Random Matrix Theory,Jeffrey Pennington,Google Brain
ICML,2017,Geometry of Neural Network Loss Surfaces via Random Matrix Theory,Yasaman Bahri,Google Brain
ICML,2017,"The Shattered Gradients Problem: If resnets are the answer, then what is the question?",David Balduzzi,Victoria University Wellington
ICML,2017,"The Shattered Gradients Problem: If resnets are the answer, then what is the question?",Marcus Frean,Victoria University Wellington
ICML,2017,"The Shattered Gradients Problem: If resnets are the answer, then what is the question?",Wan-Duo Ma,Victoria University of Wellington
ICML,2017,"The Shattered Gradients Problem: If resnets are the answer, then what is the question?",Brian McWilliams,Disney Research
ICML,2017,"The Shattered Gradients Problem: If resnets are the answer, then what is the question?",Lennox Leary,VUW
ICML,2017,"The Shattered Gradients Problem: If resnets are the answer, then what is the question?",J.P. Lewis,Frostbite Labs and Victoria University
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Yutian Chen,DeepMind
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Matthew Hoffman,DeepMind
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Sergio Gómez Colmenarejo,Google DeepMind
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Misha Denil,University of Oxford
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Tim Lillicrap,Google DeepMind
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Matthew Botvinick,DeepMind
ICML,2017,Learning to Learn without Gradient Descent by Gradient Descent,Nando de Freitas,DeepMind
ICML,2017,"A Semismooth Newton Method for Fast, Generic Convex Programming",Alnur Ali,Carnegie Mellon University
ICML,2017,"A Semismooth Newton Method for Fast, Generic Convex Programming",Eric Wong,Carnegie Mellon University
ICML,2017,"A Semismooth Newton Method for Fast, Generic Convex Programming",Zico Kolter,Carnegie Mellon University
ICML,2017,Unifying task specification in reinforcement learning,Martha White,University of Alberta/Indiana University
ICML,2017,Efficient Online Bandit Multiclass Learning with O(sqrt{T}) Regret,Alina Beygelzimer,Yahoo Research
ICML,2017,Efficient Online Bandit Multiclass Learning with O(sqrt{T}) Regret,Francesco Orabona,Stony Brook University
ICML,2017,Efficient Online Bandit Multiclass Learning with O(sqrt{T}) Regret,Chicheng Zhang,UCSD
ICML,2017,Orthogonalized ALS: A Theoretically Principled Tensor Decomposition Algorithm for Practical Use,Vatsal Sharan,Stanford University
ICML,2017,Orthogonalized ALS: A Theoretically Principled Tensor Decomposition Algorithm for Practical Use,Gregory Valiant,Stanford University
ICML,2017,Learned Optimizers that Scale and Generalize,Olga Wichrowska,Google Brain
ICML,2017,Learned Optimizers that Scale and Generalize,Niru Maheswaranathan,Stanford University
ICML,2017,Learned Optimizers that Scale and Generalize,Matthew Hoffman,DeepMind
ICML,2017,Learned Optimizers that Scale and Generalize,Sergio Gómez Colmenarejo,Google DeepMind
ICML,2017,Learned Optimizers that Scale and Generalize,Misha Denil,University of Oxford
ICML,2017,Learned Optimizers that Scale and Generalize,Nando de Freitas,DeepMind
ICML,2017,Learned Optimizers that Scale and Generalize,Jascha Sohl-Dickstein,Google Brain
ICML,2017,Approximate Newton Methods and Their Local Convergence,Haishan Ye,Shanghai Jiao Tong University
ICML,2017,Approximate Newton Methods and Their Local Convergence,Luo Luo,Shanghai Jiao Tong University
ICML,2017,Approximate Newton Methods and Their Local Convergence,Zhihua Zhang,Peking University
ICML,2017,A Distributional Perspective on Reinforcement Learning,Marc Bellemare,DeepMind
ICML,2017,A Distributional Perspective on Reinforcement Learning,Will Dabney,DeepMind
ICML,2017,A Distributional Perspective on Reinforcement Learning,Remi Munos,DeepMind
ICML,2017,Active Learning for Accurate Estimation of Linear Models,Carlos Riquelme Ruiz,Stanford University
ICML,2017,Active Learning for Accurate Estimation of Linear Models,Mohammad Ghavamzadeh,Adobe Research & INRIA
ICML,2017,Active Learning for Accurate Estimation of Linear Models,Alessandro Lazaric,FACEBOOK
ICML,2017,Tensor Decomposition via Simultaneous Power Iteration,Poan Wang,Academia sinica
ICML,2017,Tensor Decomposition via Simultaneous Power Iteration,Chi-Jen Lu,Academia Sinica
ICML,2017,Learning Gradient Descent: Better Generalization and Longer Horizons,Kaifeng Lv,Tsinghua University
ICML,2017,Learning Gradient Descent: Better Generalization and Longer Horizons,Shunhua Jiang,Tsinghua University
ICML,2017,Learning Gradient Descent: Better Generalization and Longer Horizons,Jian Li,IIIS
ICML,2017,Stochastic Adaptive Quasi-Newton Methods for Minimizing Expected Values,Chaoxu Zhou,Columbia University
ICML,2017,Stochastic Adaptive Quasi-Newton Methods for Minimizing Expected Values,Wenbo Gao,Columbia University
ICML,2017,Stochastic Adaptive Quasi-Newton Methods for Minimizing Expected Values,Donald Goldfarb,Columbia University
ICML,2017,Hierarchy Through Composition with Multitask LMDPs,Andrew Saxe,Harvard University
ICML,2017,Hierarchy Through Composition with Multitask LMDPs,Adam Earle,University of the Witwatersrand
ICML,2017,Hierarchy Through Composition with Multitask LMDPs,Benjamin Rosman,Council for Scientific and Industrial Research (CSIR)
ICML,2017,Adaptive Feature Selection: Computationally Efficient Online Sparse Linear Regression under RIP,Satyen Kale,Google Research
ICML,2017,Adaptive Feature Selection: Computationally Efficient Online Sparse Linear Regression under RIP,Zohar Karnin,yahoo
ICML,2017,Adaptive Feature Selection: Computationally Efficient Online Sparse Linear Regression under RIP,Tengyuan Liang,UPenn
ICML,2017,Adaptive Feature Selection: Computationally Efficient Online Sparse Linear Regression under RIP,David Pal,Yahoo
ICML,2017,A Unified Variance Reduction-Based Framework for Nonconvex Low-Rank Matrix Recovery,Lingxiao Wang,University of Virginia
ICML,2017,A Unified Variance Reduction-Based Framework for Nonconvex Low-Rank Matrix Recovery,Xiao Zhang,University of Virginia
ICML,2017,A Unified Variance Reduction-Based Framework for Nonconvex Low-Rank Matrix Recovery,Quanquan Gu,University of Virginia
ICML,2017,Learning Algorithms for Active Learning,Philip Bachman,Maluuba
ICML,2017,Learning Algorithms for Active Learning,Alessandro Sordoni,Microsoft Maluuba
ICML,2017,Learning Algorithms for Active Learning,Adam Trischler,Maluuba
ICML,2017,Practical Gauss-Newton Optimisation for Deep Learning,Alex Botev,University College London
ICML,2017,Practical Gauss-Newton Optimisation for Deep Learning,Hippolyt Ritter,University College London
ICML,2017,Practical Gauss-Newton Optimisation for Deep Learning,David Barber,University College London
ICML,2017,A Laplacian Framework for Option Discovery in Reinforcement Learning,Marlos C. Machado,University of Alberta
ICML,2017,A Laplacian Framework for Option Discovery in Reinforcement Learning,Marc Bellemare,DeepMind
ICML,2017,A Laplacian Framework for Option Discovery in Reinforcement Learning,Michael Bowling,University of Alberta
ICML,2017,Emulating the Expert: Inverse Optimization through Online Learning,Sebastian Pokutta,Georgia Tech
ICML,2017,Emulating the Expert: Inverse Optimization through Online Learning,Andreas Bärmann,FAU Erlangen-Nürnberg
ICML,2017,Emulating the Expert: Inverse Optimization through Online Learning,Oskar Schneider,
ICML,2017,"An Efficient, Sparsity-Preserving, Online Algorithm for Low-Rank Approximation",Dave Anderson,UC Berkeley
ICML,2017,"An Efficient, Sparsity-Preserving, Online Algorithm for Low-Rank Approximation",Ming Gu,University of California at Berkeley
ICML,2017,Tensor Balancing on Statistical Manifold,Mahito Sugiyama,National Institute of Informatics
ICML,2017,Tensor Balancing on Statistical Manifold,Hiroyuki Nakahara,RIKEN Brain Science Institute
ICML,2017,Tensor Balancing on Statistical Manifold,Koji Tsuda,University of Tokyo / RIKEN
ICML,2017,Modular Multitask Reinforcement Learning with Policy Sketches,Jacob Andreas,UC Berkeley
ICML,2017,Modular Multitask Reinforcement Learning with Policy Sketches,Dan Klein,UC Berkeley
ICML,2017,Modular Multitask Reinforcement Learning with Policy Sketches,Sergey Levine,Berkeley
ICML,2017,Variants of RMSProp and Adagrad with Logarithmic Regret Bounds,Mahesh Chandra Mukkamala,Saarland University
ICML,2017,Variants of RMSProp and Adagrad with Logarithmic Regret Bounds,Matthias Hein,Saarland University
ICML,2017,Algorithms for $\ell_p$ Low-Rank Approximation,Flavio Chierichetti,Sapienza University of Rome
ICML,2017,Algorithms for $\ell_p$ Low-Rank Approximation,Sreenivas Gollapudi,
ICML,2017,Algorithms for $\ell_p$ Low-Rank Approximation,Ravi Kumar,Google
ICML,2017,Algorithms for $\ell_p$ Low-Rank Approximation,Silvio Lattanzi,Google Zurich
ICML,2017,Algorithms for $\ell_p$ Low-Rank Approximation,Rina Panigrahy,Google
ICML,2017,Algorithms for $\ell_p$ Low-Rank Approximation,David Woodruff,
ICML,2017,Relative Fisher Information and Natural Gradient for Learning Large Modular Models,Ke Sun,KAUST
ICML,2017,Relative Fisher Information and Natural Gradient for Learning Large Modular Models,Frank Nielsen,"Sony CSL, Japan"
ICML,2017,Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using Householder Reflections,Zakaria mhammedi,The University of Melbourne
ICML,2017,Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using Householder Reflections,Andrew Hellicar,CSIRO
ICML,2017,Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using Householder Reflections,James Bailey,The University of Melbourne
ICML,2017,Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using Householder Reflections,Ashfaqur Rahman,CSIRO
ICML,2017,Lazifying Conditional Gradient Algorithms,Gábor Braun,
ICML,2017,Lazifying Conditional Gradient Algorithms,Sebastian Pokutta,Georgia Tech
ICML,2017,Lazifying Conditional Gradient Algorithms,Daniel Zink,
ICML,2017,Data-Efficient Policy Evaluation Through Behavior Policy Search,Josiah Hanna,University of Texas at Austin
ICML,2017,Data-Efficient Policy Evaluation Through Behavior Policy Search,Philip S. Thomas,CMU
ICML,2017,Data-Efficient Policy Evaluation Through Behavior Policy Search,Peter Stone,University of Texas at Austin
ICML,2017,Data-Efficient Policy Evaluation Through Behavior Policy Search,Scott Niekum,University of Texas at Austin
ICML,2017,Exact MAP Inference by Avoiding Fractional Vertices,Erik Lindgren,University of Texas at Austin
ICML,2017,Exact MAP Inference by Avoiding Fractional Vertices,Alex Dimakis,UT Austin
ICML,2017,Exact MAP Inference by Avoiding Fractional Vertices,Adam Klivans,University of Texas at Austin
ICML,2017,Leveraging Node Attributes for Incomplete Relational Data,He Zhao,"FIT, Monash University"
ICML,2017,Leveraging Node Attributes for Incomplete Relational Data,Lan Du,"Faculty of Information Technology, Monash University"
ICML,2017,Leveraging Node Attributes for Incomplete Relational Data,Wray Buntine,Monash University
ICML,2017,How Close Are the Eigenvectors of the Sample and Actual Covariance Matrices?,Andreas Loukas,EPFL
ICML,2017,Distributed and Provably Good Seedings for k-Means in Constant Rounds,Olivier Bachem,ETH Zurich
ICML,2017,Distributed and Provably Good Seedings for k-Means in Constant Rounds,Mario Lucic,ETH Zurich
ICML,2017,Distributed and Provably Good Seedings for k-Means in Constant Rounds,Andreas Krause,ETH Zurich
ICML,2017,Learning Deep Architectures via Generalized Whitened Neural Networks,Ping Luo,The Chinese University of Hong Kong
ICML,2017,On orthogonality and learning RNNs with long term dependencies,Eugene Vorontsov,MILA
ICML,2017,On orthogonality and learning RNNs with long term dependencies,Chiheb Trabelsi,Ecole Polytechnique de Montreal
ICML,2017,On orthogonality and learning RNNs with long term dependencies,Christopher Pal,École Polytechnique de Montréal
ICML,2017,On orthogonality and learning RNNs with long term dependencies,Samuel Kadoury,Ecole Polytechnique de Montreal
ICML,2017,Conditional Accelerated Lazy Stochastic Gradient Descent,Guanghui,George
ICML,2017,Conditional Accelerated Lazy Stochastic Gradient Descent,Sebastian Pokutta,Georgia Tech
ICML,2017,Conditional Accelerated Lazy Stochastic Gradient Descent,Yi Zhou,Georgia Institute of Technology
ICML,2017,Conditional Accelerated Lazy Stochastic Gradient Descent,Daniel Zink,
ICML,2017,Stochastic Variance Reduction Methods for Policy Evaluation,Simon Du,Carnegie Mellon University
ICML,2017,Stochastic Variance Reduction Methods for Policy Evaluation,Jianshu Chen,Microsoft Research
ICML,2017,Stochastic Variance Reduction Methods for Policy Evaluation,Lihong Li,Microsoft Research
ICML,2017,Stochastic Variance Reduction Methods for Policy Evaluation,Lin Xiao,Microsoft Research
ICML,2017,Stochastic Variance Reduction Methods for Policy Evaluation,Dengyong Zhou,Microsoft Research
ICML,2017,Exact Inference for Integer Latent-Variable Models,Kevin Winner,"University of Massachusetts, Amherst"
ICML,2017,Exact Inference for Integer Latent-Variable Models,Debora Sujono,University of Massachusetts Amherst
ICML,2017,Exact Inference for Integer Latent-Variable Models,Daniel Sheldon,University of Massachusetts Amherst
ICML,2017,Bayesian inference on random simple graphs with power law degree distributions,Juho Lee,POSTECH
ICML,2017,Bayesian inference on random simple graphs with power law degree distributions,Creighton Heaukulani,Cambridge University
ICML,2017,Bayesian inference on random simple graphs with power law degree distributions,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2017,Bayesian inference on random simple graphs with power law degree distributions,Lancelot F. James,Hong Kong University of Science and Technology
ICML,2017,Bayesian inference on random simple graphs with power law degree distributions,Seungjin Choi,POSTECH
ICML,2017,Faster Principal Component Regression and Stable Matrix Chebyshev Approximation,Zeyuan Allen-Zhu,Microsoft Research / Princeton / IAS
ICML,2017,Faster Principal Component Regression and Stable Matrix Chebyshev Approximation,Yuanzhi Li,Princeton University
ICML,2017,Consistent k-Clustering,Silvio Lattanzi,Google Zurich
ICML,2017,Consistent k-Clustering,Sergei Vassilvitskii,Google
ICML,2017,Continual Learning Through Synaptic Intelligence,Friedemann Zenke,Stanford
ICML,2017,Continual Learning Through Synaptic Intelligence,Ben Poole,Stanford University
ICML,2017,Continual Learning Through Synaptic Intelligence,Surya Ganguli,Stanford
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Li Jing,Massachusetts Institute of Technology
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Yichen Shen,MIT
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Tena Dubcek,MIT
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,John E Peurifoy,MIT
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Scott Skirlo,MIT
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Yann LeCun,New York University
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Max Tegmark,MIT
ICML,2017,Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,Marin Solja\v{c}i\'{c},MIT
ICML,2017,SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient,Lam Nguyen,Lehigh University
ICML,2017,SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient,Jie Liu,Lehigh University
ICML,2017,SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient,Katya Scheinberg,Lehigh University
ICML,2017,SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient,Martin Takac,Lehigh University
ICML,2017,Optimal and Adaptive Off-policy Evaluation in Contextual Bandits,Yu-Xiang Wang,Carnegie Mellon University / Amazon AWS
ICML,2017,Optimal and Adaptive Off-policy Evaluation in Contextual Bandits,Alekh Agarwal,Microsoft Research
ICML,2017,Optimal and Adaptive Off-policy Evaluation in Contextual Bandits,Miroslav Dudik,Microsoft Research
ICML,2017,Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms,Arturs Backurs,MIT
ICML,2017,Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms,Christos Tzamos,MIT
ICML,2017,Analogical Inference for Multi-relational Embeddings,Hanxiao Liu,CMU/Google DeepMind
ICML,2017,Analogical Inference for Multi-relational Embeddings,Yuexin Wu,Carnegie Mellon University
ICML,2017,Analogical Inference for Multi-relational Embeddings,Yiming Yang,Carnegie Mellon University
ICML,2017,Spectral Learning from a Single Trajectory under Finite-State Policies,Borja de Balle Pigem,Amazon Research Cambridge
ICML,2017,Spectral Learning from a Single Trajectory under Finite-State Policies,Odalric Maillard,
ICML,2017,Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering,Bo Yang,University of Minnesota
ICML,2017,Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering,Xiao Fu,University of Minnesota
ICML,2017,Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering,Nicholas Sidiropoulos,University of Minnesota
ICML,2017,Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering,Mingyi Hong,Iowa State University
ICML,2017,Adaptive Neural Networks for Efficient Inference,Tolga Bolukbasi,Boston University
ICML,2017,Adaptive Neural Networks for Efficient Inference,Joe Wang,Amazon
ICML,2017,Adaptive Neural Networks for Efficient Inference,Ofer Dekel,Microsoft
ICML,2017,Adaptive Neural Networks for Efficient Inference,Venkatesh Saligrama,Boston University
ICML,2017,The Statistical Recurrent Unit,Junier Oliva,Carnegie Mellon University
ICML,2017,The Statistical Recurrent Unit,Barnabás Póczos,CMU
ICML,2017,The Statistical Recurrent Unit,Jeff Schneider,CMU/Uber
ICML,2017,Approximate Steepest Coordinate Descent,Sebastian Stich,EPFL
ICML,2017,Approximate Steepest Coordinate Descent,Anant Raj,Max-Planck Institute for Intelligent Systems
ICML,2017,Approximate Steepest Coordinate Descent,Martin Jaggi,EPFL
ICML,2017,Consistent On-Line Off-Policy Evaluation,Assaf Hallak,Technion
ICML,2017,Consistent On-Line Off-Policy Evaluation,Shie Mannor,Technion
ICML,2017,Variational Inference for Sparse and Undirected Models,John Ingraham,Harvard University
ICML,2017,Variational Inference for Sparse and Undirected Models,Debora Marks,Harvard Medical School
ICML,2017,Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,Rakshit Trivedi,Georgia Institute of Technology
ICML,2017,Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,Hanjun Dai,Georgia Tech
ICML,2017,Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,Yichen Wang,Gatech
ICML,2017,Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,Le Song,Georgia Institute of Technology
ICML,2017,Capacity Releasing Diffusion for Speed and Locality.,Di Wang,UC Berkeley
ICML,2017,Capacity Releasing Diffusion for Speed and Locality.,Kimon Fountoulakis,University of California Berkeley and International Computer Science Institute
ICML,2017,Capacity Releasing Diffusion for Speed and Locality.,Monika Henzinger,
ICML,2017,Capacity Releasing Diffusion for Speed and Locality.,Michael Mahoney,UC Berkeley
ICML,2017,Capacity Releasing Diffusion for Speed and Locality.,Satish Rao,UC Berkeley
ICML,2017,Hyperplane Clustering Via Dual Principal Component Pursuit,Manolis Tsakiris,Johns Hopkins University
ICML,2017,Hyperplane Clustering Via Dual Principal Component Pursuit,Rene Vidal,Johns Hopkins University
ICML,2017,Combined Group and Exclusive Sparsity for Deep Neural Networks,jaehong yoon,UNIST
ICML,2017,Combined Group and Exclusive Sparsity for Deep Neural Networks,Sung Ju Hwang,UNIST / AItrics
ICML,2017,Input Switched Affine Networks: An RNN Architecture Designed for Interpretability,Jakob Foerster,University of Oxford
ICML,2017,Input Switched Affine Networks: An RNN Architecture Designed for Interpretability,Justin Gilmer,Google Brain
ICML,2017,Input Switched Affine Networks: An RNN Architecture Designed for Interpretability,Jan Chorowski,Google Brain
ICML,2017,Input Switched Affine Networks: An RNN Architecture Designed for Interpretability,Jascha Sohl-Dickstein,Google Brain
ICML,2017,Input Switched Affine Networks: An RNN Architecture Designed for Interpretability,David Sussillo,"Google Brain, Google Inc."
ICML,2017,StingyCD: Safely Avoiding Wasteful Updates in Coordinate Descent,Tyler Johnson,University of Washington
ICML,2017,StingyCD: Safely Avoiding Wasteful Updates in Coordinate Descent,Carlos Guestrin,
ICML,2017,Contextual Decision Processes with low Bellman rank are PAC-Learnable,Nan Jiang,Microsoft Research
ICML,2017,Contextual Decision Processes with low Bellman rank are PAC-Learnable,Akshay Krishnamurthy,UMass
ICML,2017,Contextual Decision Processes with low Bellman rank are PAC-Learnable,Alekh Agarwal,Microsoft Research
ICML,2017,Contextual Decision Processes with low Bellman rank are PAC-Learnable,John Langford,Microsoft Research
ICML,2017,Contextual Decision Processes with low Bellman rank are PAC-Learnable,Robert Schapire,Microsoft Research
ICML,2017,Tensor Belief Propagation,Andrew Wrigley,Australian National University
ICML,2017,Tensor Belief Propagation,Wee Sun Lee Lee,National University of Singapore
ICML,2017,Tensor Belief Propagation,Nan Ye,Queensland University of Technology
ICML,2017,Deep Generative Models for Relational Data with Side Information,Changwei Hu,Duke University
ICML,2017,Deep Generative Models for Relational Data with Side Information,Piyush Rai,IIT Kanpur
ICML,2017,Deep Generative Models for Relational Data with Side Information,Lawrence Carin,Duke
ICML,2017,Doubly Accelerated Methods for Faster CCA and Generalized Eigendecomposition,Zeyuan Allen-Zhu,Microsoft Research / Princeton / IAS
ICML,2017,Doubly Accelerated Methods for Faster CCA and Generalized Eigendecomposition,Yuanzhi Li,Princeton University
ICML,2017,Multilevel Clustering via Wasserstein Means,Nhat Ho,University of Michigan
ICML,2017,Multilevel Clustering via Wasserstein Means,Long Nguyen,University of Michigan
ICML,2017,Multilevel Clustering via Wasserstein Means,Mikhail Yurochkin,University of Michigan
ICML,2017,Multilevel Clustering via Wasserstein Means,Hung Bui,Adobe Research
ICML,2017,Multilevel Clustering via Wasserstein Means,Viet Huynh,Deakin University
ICML,2017,Multilevel Clustering via Wasserstein Means,Dinh Phung,Deakin University
ICML,2017,Online and Linear-Time Attention by Enforcing Monotonic Alignments,Colin Raffel,Google Brain
ICML,2017,Online and Linear-Time Attention by Enforcing Monotonic Alignments,Thang Luong,Google Brain
ICML,2017,Online and Linear-Time Attention by Enforcing Monotonic Alignments,Peter Liu,Google Brain
ICML,2017,Online and Linear-Time Attention by Enforcing Monotonic Alignments,Ron Weiss,Google Brain
ICML,2017,Online and Linear-Time Attention by Enforcing Monotonic Alignments,Douglas Eck,Google Brain
ICML,2017,Stochastic modified equations and adaptive stochastic gradient algorithms,Qianxiao Li,"Institute of High Performance Computing, A*STAR"
ICML,2017,Stochastic modified equations and adaptive stochastic gradient algorithms,Cheng Tai,Peking University
ICML,2017,Stochastic modified equations and adaptive stochastic gradient algorithms,Weinan E,Princeton University
ICML,2017,A Simple Multi-Class Boosting Framework with Theoretical Guarantees and Empirical Proficiency,Ron Appel,caltech.edu
ICML,2017,A Simple Multi-Class Boosting Framework with Theoretical Guarantees and Empirical Proficiency,Pietro Perona,caltech.edu
ICML,2017,Faster Greedy MAP Inference for Determinantal Point Processes,Insu Han,Korea Advanced Institute of Science and Technology
ICML,2017,Faster Greedy MAP Inference for Determinantal Point Processes,Prabhanjan Kambadur,Bloomberg
ICML,2017,Faster Greedy MAP Inference for Determinantal Point Processes,Kyoungsoo Park,KAIST
ICML,2017,Faster Greedy MAP Inference for Determinantal Point Processes,Jinwoo Shin,KAIST
ICML,2017,ChoiceRank: Identifying Preferences from Node Traffic in Networks,lum Maystre,EPFL
ICML,2017,ChoiceRank: Identifying Preferences from Node Traffic in Networks,Matt Grossglauser,EPFL
ICML,2017,On the Iteration Complexity of Support Recovery via Hard Thresholding Pursuit,Jie Shen,Rutgers University
ICML,2017,On the Iteration Complexity of Support Recovery via Hard Thresholding Pursuit,Ping Li,Rugters University
ICML,2017,Uniform Deviation Bounds for k-Means Clustering,Olivier Bachem,ETH Zurich
ICML,2017,Uniform Deviation Bounds for k-Means Clustering,Mario Lucic,ETH Zurich
ICML,2017,Uniform Deviation Bounds for k-Means Clustering,Hamed Hassani,ETH Zurich
ICML,2017,Uniform Deviation Bounds for k-Means Clustering,Andreas Krause,ETH Zurich
ICML,2017,Sequence Tutor: Conservative fine-tuning of sequence generation models with KL-control,Natasha Jaques,Massachusetts Institute of Technology
ICML,2017,Sequence Tutor: Conservative fine-tuning of sequence generation models with KL-control,Shixiang Gu,Cambridge
ICML,2017,Sequence Tutor: Conservative fine-tuning of sequence generation models with KL-control,Dzmitry Bahdanau,Université de Montréal
ICML,2017,Sequence Tutor: Conservative fine-tuning of sequence generation models with KL-control,Jose Hernandez-Lobato,University of Cambridge
ICML,2017,Sequence Tutor: Conservative fine-tuning of sequence generation models with KL-control,Richard E Turner,University of Cambridge
ICML,2017,Sequence Tutor: Conservative fine-tuning of sequence generation models with KL-control,Douglas Eck,Google Brain
ICML,2017,Dissipativity Theory for Nesterov's Accelerated Method,Bin Hu,University of Wisconsin
ICML,2017,Dissipativity Theory for Nesterov's Accelerated Method,Laurent Lessard,University of Wisconsin-Madison
ICML,2017,Gradient Boosted Decision Trees for High Dimensional Sparse Output,Si Si,Google Research
ICML,2017,Gradient Boosted Decision Trees for High Dimensional Sparse Output,Huan Zhang,UC Davis
ICML,2017,Gradient Boosted Decision Trees for High Dimensional Sparse Output,Sathiya Keerthi,Microsoft
ICML,2017,Gradient Boosted Decision Trees for High Dimensional Sparse Output,Dhruv Mahajan,Facebook
ICML,2017,Gradient Boosted Decision Trees for High Dimensional Sparse Output,Inderjit Dhillon,UT Austin & Amazon
ICML,2017,Gradient Boosted Decision Trees for High Dimensional Sparse Output,Cho-Jui Hsieh,"University of California, Davis"
ICML,2017,Zonotope hit-and-run for efficient sampling from projection DPPs,Guillaume Gautier,INRIA Lille
ICML,2017,Zonotope hit-and-run for efficient sampling from projection DPPs,Rémi Bardenet,CNRS and Univ. Lille
ICML,2017,Zonotope hit-and-run for efficient sampling from projection DPPs,Michal Valko,Inria Lille - Nord Europe
ICML,2017,Statistical Inference for Incomplete Ranking Data: The Case of Rank-Dependent Coarsening,Mohsen Ahmadi Fahandar,Paderborn University
ICML,2017,Statistical Inference for Incomplete Ranking Data: The Case of Rank-Dependent Coarsening,Eyke Hüllermeier,Paderborn University
ICML,2017,Statistical Inference for Incomplete Ranking Data: The Case of Rank-Dependent Coarsening,Ines Couso,University of Oviedo
ICML,2017,Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to Non-smooth Concave Maximization,Bo Liu,Rutgers
ICML,2017,Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to Non-smooth Concave Maximization,Xiaotong Yuan,Nanjing University of Information Science & Technology
ICML,2017,Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to Non-smooth Concave Maximization,Lezi Wang,Rutgers
ICML,2017,Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to Non-smooth Concave Maximization,Qingshan Liu,
ICML,2017,Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to Non-smooth Concave Maximization,Dimitris Metaxas,Rutgers
ICML,2017,Uniform Convergence Rates for Kernel Density Estimation,Heinrich Jiang,Google
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,agibiansky Gibiansky,Baidu Research Silicon Valley AI Lab
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Mike Chrzanowski,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Mohammad Shoeybi,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Shubho Sengupta,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Gregory Diamos,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Sercan Arik,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Jonathan Raiman,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,John Miller,Baidu Research
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Xian Li,Baidu
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Yongguo Kang,Baidu
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Adam Coates,Baidu SVAIL
ICML,2017,Deep Voice: Real-time Neural Text-to-Speech,Andrew Ng,Baidu
ICML,2017,An Analytical Formula of Population Gradient for two-layered ReLU network and its Applications in Convergence and Critical Point Analysis,Yuandong Tian,Facebook AI Research
ICML,2017,Globally Induced Forest: A Prepruning Compression Scheme,Jean-Michel Begon,University of Liege
ICML,2017,Globally Induced Forest: A Prepruning Compression Scheme,Arnaud Joly,University of Liege
ICML,2017,Globally Induced Forest: A Prepruning Compression Scheme,Pierre Geurts,University of Liege
ICML,2017,A Divergence Bound for Hybrids of MCMC and Variational Inference and an Application to Langevin Dynamics and SGVI,Justin Domke,"University of Massachusetts, Amherst"
ICML,2017,Just Sort It! A Simple and Effective Approach to Active Preference Learning,lum Maystre,EPFL
ICML,2017,Just Sort It! A Simple and Effective Approach to Active Preference Learning,Matt Grossglauser,EPFL
ICML,2017,On The Projection Operator to A Three-view Cardinality Constrained Set,Haichuan Yang,University of Rochester
ICML,2017,On The Projection Operator to A Three-view Cardinality Constrained Set,Shupeng Gui,University of Rochester
ICML,2017,On The Projection Operator to A Three-view Cardinality Constrained Set,Chuyang Ke,University of Rochester
ICML,2017,On The Projection Operator to A Three-view Cardinality Constrained Set,Daniel Stefankovic,University of Rochester
ICML,2017,On The Projection Operator to A Three-view Cardinality Constrained Set,Ryohei Fujimaki,-
ICML,2017,On The Projection Operator to A Three-view Cardinality Constrained Set,Ji Liu,University of Rochester
ICML,2017,Density Level Set Estimation on Manifolds with DBSCAN,Heinrich Jiang,Google
ICML,2017,DeepBach: a Steerable Model for Bach Chorales Generation,Gaëtan HADJERES,LIP6 / SONY CSL
ICML,2017,DeepBach: a Steerable Model for Bach Chorales Generation,François Pachet,Sony CSL / UPMC
ICML,2017,DeepBach: a Steerable Model for Bach Chorales Generation,Frank Nielsen,"Sony CSL, Japan"
ICML,2017,Forward and Reverse Gradient-Based Hyperparameter Optimization,Luca Franceschi,IIT and UCL
ICML,2017,Forward and Reverse Gradient-Based Hyperparameter Optimization,Michele Donini,IIT
ICML,2017,Forward and Reverse Gradient-Based Hyperparameter Optimization,Paolo Frasconi,University of Florence
ICML,2017,Forward and Reverse Gradient-Based Hyperparameter Optimization,Massimiliano Pontil,University College London
ICML,2017,Forest-type Regression with General Losses and Robust Forest,Hanbo Li,UC San Diego
ICML,2017,Forest-type Regression with General Losses and Robust Forest,Andy Martin,Zillow
ICML,2017,On the Sampling Problem for Kernel Quadrature,Francois-Xavier Briol,University of Warwick
ICML,2017,On the Sampling Problem for Kernel Quadrature,Chris J Oates,Newcastle University
ICML,2017,On the Sampling Problem for Kernel Quadrature,Jon Cockayne,University of Warwick
ICML,2017,On the Sampling Problem for Kernel Quadrature,Wilson Ye Chen,University of Technology Sydney
ICML,2017,On the Sampling Problem for Kernel Quadrature,Mark Girolami,Imperial College London
ICML,2017,Maximum Selection and Ranking under Noisy Comparisons,Moein Falahatgar,UCSD
ICML,2017,Maximum Selection and Ranking under Noisy Comparisons,Alon Orlitsky,UCSD
ICML,2017,Maximum Selection and Ranking under Noisy Comparisons,Venkatadheeraj Pichapati,University of California San Diego
ICML,2017,Maximum Selection and Ranking under Noisy Comparisons,Ananda Suresh,Google
ICML,2017,Sparse + Group-Sparse Dirty Models: Statistical Guarantees without Unreasonable Conditions and a Case for Non-Convexity,Eunho Yang,KAIST / AItrics
ICML,2017,Sparse + Group-Sparse Dirty Models: Statistical Guarantees without Unreasonable Conditions and a Case for Non-Convexity,Aurelie Lozano,IBM
ICML,2017,Algorithmic Stability and Hypothesis Complexity,Tongliang Liu,The University of Sydney
ICML,2017,Algorithmic Stability and Hypothesis Complexity,Gábor Lugosi,Universitat Pompeu Fabra
ICML,2017,Algorithmic Stability and Hypothesis Complexity,Gergely Neu,Universitat Pompeu Fabra / Google Brain Zürich
ICML,2017,Algorithmic Stability and Hypothesis Complexity,Dacheng Tao,
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,Cinjon Resnick,Google Brain
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,Adam Roberts,Google Brain
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,JesseEngel Engel,Google Brain
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,Douglas Eck,Google Brain
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,Sander Dieleman,DeepMind
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,Karen Simonyan,DeepMind
ICML,2017,Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders,Mohammad Norouzi,Google
ICML,2017,Adaptive Sampling Probabilities for Non-Smooth Optimization,Hongseok Namkoong,Stanford University
ICML,2017,Adaptive Sampling Probabilities for Non-Smooth Optimization,Aman Sinha,Stanford University
ICML,2017,Adaptive Sampling Probabilities for Non-Smooth Optimization,Steve Yadlowsky,Stanford University
ICML,2017,Adaptive Sampling Probabilities for Non-Smooth Optimization,John Duchi,Stanford University
ICML,2017,Confident Multiple Choice Learning,Kimin Lee,KAIST
ICML,2017,Confident Multiple Choice Learning,Changho Hwang,KAIST
ICML,2017,Confident Multiple Choice Learning,KyoungSoo Park,KAIST
ICML,2017,Confident Multiple Choice Learning,Jinwoo Shin,KAIST
ICML,2017,Measuring Sample Quality with Kernels,Jackson Gorham,STANFORD
ICML,2017,Measuring Sample Quality with Kernels,Lester Mackey,Microsoft Research
ICML,2017,Active Learning for Top-$K$ Rank Aggregation from Noisy Comparisons,Soheil Mohajer,University of Minnesota
ICML,2017,Active Learning for Top-$K$ Rank Aggregation from Noisy Comparisons,Changho Suh,KAIST
ICML,2017,Active Learning for Top-$K$ Rank Aggregation from Noisy Comparisons,Adel Elmahdy,University of Minnesota
ICML,2017,Compressed Sensing using Generative Models,Ashish Bora,University of Texas at Austin
ICML,2017,Compressed Sensing using Generative Models,Ajil Jalal,University of Texas at Austin
ICML,2017,Compressed Sensing using Generative Models,Eric Price,UT-Austin
ICML,2017,Compressed Sensing using Generative Models,Alex Dimakis,UT Austin
ICML,2017,Consistency Analysis for Binary Classification Revisited,Krzysztof Dembczynski,Poznan University of Technology
ICML,2017,Consistency Analysis for Binary Classification Revisited,Wojciech Kotlowski,Poznan University of Technology
ICML,2017,Consistency Analysis for Binary Classification Revisited,Sanmi Koyejo,University of Illinois at Urbana-Champaign
ICML,2017,Consistency Analysis for Binary Classification Revisited,Nagarajan Natarajan,Microsoft Research
ICML,2017,A Closer Look at Memorization in Deep Networks,David Krueger,MILA
ICML,2017,A Closer Look at Memorization in Deep Networks,Yoshua Bengio,U. Montreal
ICML,2017,A Closer Look at Memorization in Deep Networks,Stanislaw Jastrzebsk,Jagiellonian University
ICML,2017,A Closer Look at Memorization in Deep Networks,Maxinder S. Kanwal,UC Berkeley
ICML,2017,A Closer Look at Memorization in Deep Networks,Nicolas Ballas,Université de Montréal
ICML,2017,A Closer Look at Memorization in Deep Networks,Asja Fischer,"Computer Science Department, University of Bonn"
ICML,2017,A Closer Look at Memorization in Deep Networks,Emmanuel Bengio,McGill University
ICML,2017,A Closer Look at Memorization in Deep Networks,Devansh Arpit,
ICML,2017,A Closer Look at Memorization in Deep Networks,Tegan Maharaj,
ICML,2017,A Closer Look at Memorization in Deep Networks,Aaron Courville,University of Montreal
ICML,2017,A Closer Look at Memorization in Deep Networks,Simon Lacoste-Julien,University of Montreal
ICML,2017,Learning to Generate Long-term Future via Hierarchical Prediction,Ruben Villegas,University of Michigan
ICML,2017,Learning to Generate Long-term Future via Hierarchical Prediction,Jimei Yang,Adobe Research
ICML,2017,Learning to Generate Long-term Future via Hierarchical Prediction,Yuliang Zou,University of Michigan
ICML,2017,Learning to Generate Long-term Future via Hierarchical Prediction,Sungryull Sohn,University of Michigan
ICML,2017,Learning to Generate Long-term Future via Hierarchical Prediction,Xunyu Lin,
ICML,2017,Learning to Generate Long-term Future via Hierarchical Prediction,Honglak Lee,Google / U. Michigan
ICML,2017,Sub-sampled Cubic Regularization for Non-convex Optimization,Jonas Kohler,ETH Zurich
ICML,2017,Sub-sampled Cubic Regularization for Non-convex Optimization,Aurelien Lucchi,ETH
ICML,2017,Regret Minimization in Behaviorally-Constrained Zero-Sum Games,Gabriele Farina,Carnegie Mellon University
ICML,2017,Regret Minimization in Behaviorally-Constrained Zero-Sum Games,Christian Kroer,Carnegie Mellon University
ICML,2017,Regret Minimization in Behaviorally-Constrained Zero-Sum Games,Tuomas Sandholm,Carnegie Mellon University
ICML,2017,Variational Boosting: Iteratively Refining Posterior Approximations,Andrew Miller,Harvard
ICML,2017,Variational Boosting: Iteratively Refining Posterior Approximations,Nick J Foti,University of Washington
ICML,2017,Variational Boosting: Iteratively Refining Posterior Approximations,Ryan Adams,Google Brain and Princeton University
ICML,2017,Learning to Align the Source Code to the Compiled Object Code,Dor Levy,Tel Aviv University
ICML,2017,Learning to Align the Source Code to the Compiled Object Code,Lior Wolf,Facebook AI Research and Tel Aviv University
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Weizhong Zhang,Zhejiang University & Tencent AI Lab
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Bin Hong,Zhejiang University
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Wei Liu,Tencent AI Lab
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Jieping Ye,University of Michigan
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Deng Cai,Zhejiang University
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Xiaofei He,Zhejiang University
ICML,2017,Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Jie Wang,University of Michigan
ICML,2017,Distributed Mean Estimation with Limited Communication,Ananda Suresh,Google
ICML,2017,Distributed Mean Estimation with Limited Communication,Felix Xinnan Yu,Google Research
ICML,2017,Distributed Mean Estimation with Limited Communication,Sanjiv Kumar,"Google Research, NY"
ICML,2017,Distributed Mean Estimation with Limited Communication,Brendan McMahan,Google
ICML,2017,Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study,Sam Ritter,DeepMind
ICML,2017,Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study,David GT Barrett,DeepMind
ICML,2017,Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study,Adam Santoro,DeepMind
ICML,2017,Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study,Matthew Botvinick,DeepMind
ICML,2017,Sequence to Better Sequence: Continuous Revision of Combinatorial Structures,Jonas Mueller,MIT
ICML,2017,Sequence to Better Sequence: Continuous Revision of Combinatorial Structures,David Gifford,MIT
ICML,2017,Sequence to Better Sequence: Continuous Revision of Combinatorial Structures,Tommi Jaakkola,MIT
ICML,2017,Natasha: Faster Non-Convex Stochastic Optimization Via Strongly Non-Convex Parameter,Zeyuan Allen-Zhu,Microsoft Research / Princeton / IAS
ICML,2017,Reduced Space and Faster Convergence in Imperfect-Information Games via Pruning,Noam Brown,Carnegie Mellon University
ICML,2017,Reduced Space and Faster Convergence in Imperfect-Information Games via Pruning,Tuomas Sandholm,Carnegie Mellon University
ICML,2017,Lost Relatives of the Gumbel Trick,Matej Balog,University of Cambridge
ICML,2017,Lost Relatives of the Gumbel Trick,Nilesh Tripuraneni,UC Berkeley
ICML,2017,Lost Relatives of the Gumbel Trick,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2017,Lost Relatives of the Gumbel Trick,Adrian Weller,University of Cambridge
ICML,2017,RobustFill: Neural Program Learning under Noisy I/O,Jacob Devlin,Microsoft Research
ICML,2017,RobustFill: Neural Program Learning under Noisy I/O,Jonathan Uesato,MIT
ICML,2017,RobustFill: Neural Program Learning under Noisy I/O,Surya Bhupatiraju,MIT
ICML,2017,RobustFill: Neural Program Learning under Noisy I/O,Rishabh Singh,Microsoft Research
ICML,2017,RobustFill: Neural Program Learning under Noisy I/O,Abdelrahman Mohammad,Microsoft
ICML,2017,RobustFill: Neural Program Learning under Noisy I/O,Pushmeet Kohli,Microsoft Research
ICML,2017,Efficient Distributed Learning with Sparsity,Jialei Wang,University of Chicago
ICML,2017,Efficient Distributed Learning with Sparsity,Mladen Kolar,University of Chicago
ICML,2017,Efficient Distributed Learning with Sparsity,Nati Srebro,Toyota Technological Institute at Chicago
ICML,2017,Efficient Distributed Learning with Sparsity,Tong Zhang,Tecent AI Lab
ICML,2017,Nonparanormal Information Estimation,Shashank Singh,Carnegie Mellon University
ICML,2017,Nonparanormal Information Estimation,Barnabás Póczos,CMU
ICML,2017,Visualizing and Understanding Multilayer Perceptron Models: A Case Study in Speech Processing,Tasha Nagamine,Columbia University
ICML,2017,Visualizing and Understanding Multilayer Perceptron Models: A Case Study in Speech Processing,Nima Mesgarani,Columbia University
ICML,2017,Tensor-Train Recurrent Neural Networks for Video Classification,Yinchong Yang,"Ludwig-Maximilians-Universität München, Siemens AG"
ICML,2017,Tensor-Train Recurrent Neural Networks for Video Classification,Denis Krompass,Siemens AG
ICML,2017,Tensor-Train Recurrent Neural Networks for Video Classification,Volker Tresp,University of Munich
ICML,2017,“Convex Until Proven Guilty”: Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions,Yair Carmon,Stanford University
ICML,2017,“Convex Until Proven Guilty”: Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions,John Duchi,Stanford University
ICML,2017,“Convex Until Proven Guilty”: Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions,Oliver Hinder,Stanford
ICML,2017,“Convex Until Proven Guilty”: Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions,Aaron Sidford,Stanford
ICML,2017,Strongly-Typed Agents are Guaranteed to Interact Safely,David Balduzzi,Victoria University Wellington
ICML,2017,Learning to Aggregate Ordinal Labels by Maximizing Separating Width,Guangyong Chen,The Chinese University of Hong Kong
ICML,2017,Learning to Aggregate Ordinal Labels by Maximizing Separating Width,Shengyu Zhang,CUHK
ICML,2017,Learning to Aggregate Ordinal Labels by Maximizing Separating Width,Di Lin,Shenzhen University
ICML,2017,Learning to Aggregate Ordinal Labels by Maximizing Separating Width,HUI Huang,Shenzhen University
ICML,2017,Learning to Aggregate Ordinal Labels by Maximizing Separating Width,Pheng Ann Heng,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences"
ICML,2017,Programming with a Differentiable Forth Interpreter,Matko Bošnjak,University College London
ICML,2017,Programming with a Differentiable Forth Interpreter,Tim Rocktäschel,University of Oxford
ICML,2017,Programming with a Differentiable Forth Interpreter,Jason Naradowsky,University of Cambridge
ICML,2017,Programming with a Differentiable Forth Interpreter,Sebastian Riedel,UCL
ICML,2017,Innovation Pursuit: A New Approach to the Subspace Clustering Problem,Mostafa Rahmani,University of Central Florida
ICML,2017,Innovation Pursuit: A New Approach to the Subspace Clustering Problem,George Atia,University of Central Florida
ICML,2017,A Unified Maximum Likelihood Approach for Estimating Symmetric Properties of Discrete Distributions,Jayadev Acharya,Cornell University
ICML,2017,A Unified Maximum Likelihood Approach for Estimating Symmetric Properties of Discrete Distributions,Hirakendu Das,Yahoo!
ICML,2017,A Unified Maximum Likelihood Approach for Estimating Symmetric Properties of Discrete Distributions,Alon Orlitsky,UCSD
ICML,2017,A Unified Maximum Likelihood Approach for Estimating Symmetric Properties of Discrete Distributions,Ananda Suresh,Google
ICML,2017,Axiomatic Attribution for Deep Networks,Mukund Sundararajan,Google Inc.
ICML,2017,Axiomatic Attribution for Deep Networks,Ankur Taly,Google Inc.
ICML,2017,Axiomatic Attribution for Deep Networks,Qiqi Yan,Google Inc.
ICML,2017,Sequence Modeling via Segmentations,Chong Wang,Microsoft Research
ICML,2017,Sequence Modeling via Segmentations,Yining Wang,CMU
ICML,2017,Sequence Modeling via Segmentations,Po-Sen Huang,Microsoft Research
ICML,2017,Sequence Modeling via Segmentations,Abdelrahman Mohammad,Microsoft
ICML,2017,Sequence Modeling via Segmentations,Dengyong Zhou,Microsoft Research
ICML,2017,Sequence Modeling via Segmentations,Li Deng,Citadel
ICML,2017,Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization,Qunwei Li,Syracuse University
ICML,2017,Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization,Yi Zhou,Georgia Institute of Technology
ICML,2017,Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization,Yingbin Liang,
ICML,2017,Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization,Pramod K Varshney,Syracuse University
ICML,2017,Coordinated Multi-Agent Imitation Learning,Hoang M Le,Caltech
ICML,2017,Coordinated Multi-Agent Imitation Learning,Yisong Yue,Caltech
ICML,2017,Coordinated Multi-Agent Imitation Learning,Peter Carr,Disney Research
ICML,2017,Coordinated Multi-Agent Imitation Learning,Patrick Lucey,STATS LLC.
ICML,2017,Uncorrelation and Evenness: a New Diversity-Promoting Regularizer,Pengtao Xie,Carnegie Mellon University
ICML,2017,Uncorrelation and Evenness: a New Diversity-Promoting Regularizer,Aarti Singh,Carnegie Mellon University
ICML,2017,Uncorrelation and Evenness: a New Diversity-Promoting Regularizer,Eric Xing,Carnegie Mellon University
ICML,2017,Differentiable Programs with Neural Libraries,Alex Gaunt,Microsoft
ICML,2017,Differentiable Programs with Neural Libraries,Marc Brockschmidt,Microsoft Research
ICML,2017,Differentiable Programs with Neural Libraries,Nate Kushman,Microsoft Research
ICML,2017,Differentiable Programs with Neural Libraries,Daniel Tarlow,Google Brain
ICML,2017,Selective Inference for Sparse High-Order Interaction Models,Shinya Suzumura,Nagoya Institute of Technology
ICML,2017,Selective Inference for Sparse High-Order Interaction Models,Kazuya Nakagawa,Nagoya Institute of Technology
ICML,2017,Selective Inference for Sparse High-Order Interaction Models,Yuta Umezu,Nagoya Institute of Technology
ICML,2017,Selective Inference for Sparse High-Order Interaction Models,Koji Tsuda,University of Tokyo / RIKEN
ICML,2017,Selective Inference for Sparse High-Order Interaction Models,Ichiro Takeuchi,Nagoya Institute of Technology / RIKEN
ICML,2017,Gradient Coding: Avoiding Stragglers in Distributed Learning,Rashish Tandon,University of Texas at Austin
ICML,2017,Gradient Coding: Avoiding Stragglers in Distributed Learning,Qi Lei,University of Texas at Austin
ICML,2017,Gradient Coding: Avoiding Stragglers in Distributed Learning,Alex Dimakis,UT Austin
ICML,2017,Gradient Coding: Avoiding Stragglers in Distributed Learning,NIKOS KARAMPATZIAKIS,Microsoft
ICML,2017,On Calibration of Modern Neural Networks,Chuan Guo,Cornell University
ICML,2017,On Calibration of Modern Neural Networks,Geoff Pleiss,Cornell University
ICML,2017,On Calibration of Modern Neural Networks,Yu Sun,Cornell University
ICML,2017,On Calibration of Modern Neural Networks,Kilian Weinberger,Cornell University
ICML,2017,Latent LSTM Allocation: Joint clustering and non-linear dynamic modeling of sequence data,Manzil Zaheer,Carnegie Mellon University
ICML,2017,Latent LSTM Allocation: Joint clustering and non-linear dynamic modeling of sequence data,Amr Ahmed,Google
ICML,2017,Latent LSTM Allocation: Joint clustering and non-linear dynamic modeling of sequence data,Alex Smola,Amazon
ICML,2017,How to Escape Saddle Points Efficiently,Chi Jin,UC Berkeley
ICML,2017,How to Escape Saddle Points Efficiently,Rong Ge,Duke University
ICML,2017,How to Escape Saddle Points Efficiently,Praneeth Netrapalli,Microsoft Research
ICML,2017,How to Escape Saddle Points Efficiently,Sham Kakade,University of Washington
ICML,2017,How to Escape Saddle Points Efficiently,Michael Jordan,UC Berkeley
ICML,2017,Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability,Shayegan Omidshafiei,MIT
ICML,2017,Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability,Jason Pazis,Amazon
ICML,2017,Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability,Chris Amato,Northeastern University
ICML,2017,Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability,Jonathan How,MIT
ICML,2017,Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability,John L Vian,The Boeing Company
ICML,2017,Learning Latent Space Models with Angular Constraints,Pengtao Xie,Carnegie Mellon University
ICML,2017,Learning Latent Space Models with Angular Constraints,Yuntian Deng,Harvard University
ICML,2017,Learning Latent Space Models with Angular Constraints,Yi Zhou,Georgia Institute of Technology
ICML,2017,Learning Latent Space Models with Angular Constraints,Abhimanu Kumar,IMC Financial Markets
ICML,2017,Learning Latent Space Models with Angular Constraints,Yaoliang Yu,University of Waterloo
ICML,2017,Learning Latent Space Models with Angular Constraints,James Zou,Stanford
ICML,2017,Learning Latent Space Models with Angular Constraints,Eric Xing,Carnegie Mellon University
ICML,2017,Developing Bug-Free Machine Learning Systems With Formal Mathematics,Daniel Selsam,Stanford University
ICML,2017,Developing Bug-Free Machine Learning Systems With Formal Mathematics,Percy Liang,Stanford University
ICML,2017,Developing Bug-Free Machine Learning Systems With Formal Mathematics,David L Dill,Stanford University
ICML,2017,Dictionary Learning Based on Sparse Distribution Tomography,Pedram Pad,Ecole Polytechnique Federale de Lausanne (EPFL)
ICML,2017,Dictionary Learning Based on Sparse Distribution Tomography,Farnood Salehi,EPFL
ICML,2017,Dictionary Learning Based on Sparse Distribution Tomography,Elisa Celis,EPFL
ICML,2017,Dictionary Learning Based on Sparse Distribution Tomography,Patrick Thiran,EPFL
ICML,2017,Dictionary Learning Based on Sparse Distribution Tomography,Michael Unser,
ICML,2017,Learning Discrete Representations via Information Maximizing Self-Augmented Training,Weihua Hu,The University of Tokyo / RIKEN
ICML,2017,Learning Discrete Representations via Information Maximizing Self-Augmented Training,Takeru Miyato,"Preferred Networks, Inc., ATR"
ICML,2017,Learning Discrete Representations via Information Maximizing Self-Augmented Training,Seiya Tokui,Preferred Networks / The University of Tokyo
ICML,2017,Learning Discrete Representations via Information Maximizing Self-Augmented Training,Eiichi Matsumoto,Preferred Networks Inc.
ICML,2017,Learning Discrete Representations via Information Maximizing Self-Augmented Training,Masashi Sugiyama,RIKEN / The University of Tokyo
ICML,2017,"Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging",Shusen Wang,UC Berkeley
ICML,2017,"Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging",Alex Gittens,UC Berkeley
ICML,2017,"Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging",Michael Mahoney,UC Berkeley
ICML,2017,Estimating the unseen from multiple populations,Aditi Raghunathan,Stanford
ICML,2017,Estimating the unseen from multiple populations,Greg Valiant,
ICML,2017,Estimating the unseen from multiple populations,James Zou,Stanford
ICML,2017,Meritocratic Fairness for Cross-Population Selection,Michael Kearns,University of Pennsylvania
ICML,2017,Meritocratic Fairness for Cross-Population Selection,Aaron Roth,University of Pennsylvania
ICML,2017,Meritocratic Fairness for Cross-Population Selection,Steven Wu,UPenn
ICML,2017,Neural networks and rational functions,Matus Telgarsky,UIUC
ICML,2017,Input Convex Neural Networks,Brandon Amos,Carnegie Mellon University
ICML,2017,Input Convex Neural Networks,Lei Xu,Carnegie Mellon University
ICML,2017,Input Convex Neural Networks,Zico Kolter,Carnegie Mellon University
ICML,2017,Co-clustering through Optimal Transport,Charlotte Laclau,LIG
ICML,2017,Co-clustering through Optimal Transport,Ievgen Redko,Université Lyon 1 – INSA Lyon - Université Jean Monnet Saint-Etienne.
ICML,2017,Co-clustering through Optimal Transport,Basarab Matei,
ICML,2017,Co-clustering through Optimal Transport,Younès Bennani,
ICML,2017,Co-clustering through Optimal Transport,Vincent Brault,Univ. Grenoble Alpes
ICML,2017,OptNet: Differentiable Optimization as a Layer in Neural Networks,Brandon Amos,Carnegie Mellon University
ICML,2017,OptNet: Differentiable Optimization as a Layer in Neural Networks,Zico Kolter,Carnegie Mellon University
ICML,2017,Multiple Clustering Views from Multiple Uncertain Experts,Yale Chang,Northeastern University
ICML,2017,Multiple Clustering Views from Multiple Uncertain Experts,Junxiang Chen,Northeastern University
ICML,2017,Multiple Clustering Views from Multiple Uncertain Experts,Michael Cho,Harvard Medical School
ICML,2017,Multiple Clustering Views from Multiple Uncertain Experts,Peter Castaldi,Harvard Medical School
ICML,2017,Multiple Clustering Views from Multiple Uncertain Experts,Edwin Silverman,Harvard Medical School
ICML,2017,Multiple Clustering Views from Multiple Uncertain Experts,Jennifer G Dy,Northeastern University
ICML,2017,Parseval Networks: Improving Robustness to Adversarial Examples,Moustapha Cisse,
ICML,2017,Parseval Networks: Improving Robustness to Adversarial Examples,Piotr Bojanowski,Facebook
ICML,2017,Parseval Networks: Improving Robustness to Adversarial Examples,Edouard Grave,Facebook AI Research
ICML,2017,Parseval Networks: Improving Robustness to Adversarial Examples,Yann Dauphin,Facebook AI Research
ICML,2017,Parseval Networks: Improving Robustness to Adversarial Examples,Nicolas Usunier,Facebook AI Research
ICML,2017,"Clustering by Sum of Norms: Stochastic Incremental Algorithm, Convergence and Cluster Recovery",Ashkan Panahi,NC state university
ICML,2017,"Clustering by Sum of Norms: Stochastic Incremental Algorithm, Convergence and Cluster Recovery",Devdatt Dubhashi,Chalmers University
ICML,2017,"Clustering by Sum of Norms: Stochastic Incremental Algorithm, Convergence and Cluster Recovery",Fredrik D Johansson,MIT
ICML,2017,"Clustering by Sum of Norms: Stochastic Incremental Algorithm, Convergence and Cluster Recovery",Chiranjib Bhattacharya,
ICML,2017,Regularising Non-linear Models Using Feature Side-information,Amina Mollaysa,"University of Geneva, HES"
ICML,2017,Regularising Non-linear Models Using Feature Side-information,Pablo Strasser,HES-UNIGE
ICML,2017,Regularising Non-linear Models Using Feature Side-information,Alexandros Kalousis,HES-UNIGE
ICML,2017,Clustering High Dimensional Dynamic Data Streams,Lin Yang,Johns Hopkins
ICML,2017,Clustering High Dimensional Dynamic Data Streams,Harry Lang,Johns Hopkins University
ICML,2017,Clustering High Dimensional Dynamic Data Streams,Christian Sohler,TU Dortmund
ICML,2017,Clustering High Dimensional Dynamic Data Streams,Vladimir Braverman,Johns Hopkins University
ICML,2017,Clustering High Dimensional Dynamic Data Streams,Gereon Frahling,Linguee GmbH
ICML,2017,Fast k-Nearest Neighbour Search via Prioritized DCI,Ke Li,UC Berkeley
ICML,2017,Fast k-Nearest Neighbour Search via Prioritized DCI,Jitendra Malik,
ICML,2017,Deep Spectral Clustering Learning,Marc Law,University of Toronto
ICML,2017,Deep Spectral Clustering Learning,Raquel Urtasun,University of Toronto
ICML,2017,Deep Spectral Clustering Learning,Richard Zemel,University of Toronto
ICML,2017,Joint Dimensionality Reduction and Metric Learning: A Geometric Take,Mehrtash Harandi,Data61
ICML,2017,Joint Dimensionality Reduction and Metric Learning: A Geometric Take,Mathieu Salzmann,EPFL
ICML,2017,Joint Dimensionality Reduction and Metric Learning: A Geometric Take,Richard I Hartley,Australian National University
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Chirag Gupta,"Microsoft Research, India"
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,ARUN SUGGALA,Carnegie Mellon University
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Ankit Goyal,University of Michigan
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Saurabh Goyal,IBM India Pvt Ltd
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Ashish Kumar,Microsoft Research
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Bhargavi Paranjape,Microsoft Research
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Harsha Vardhan Simhadri,Microsoft Research
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Raghavendra Udupa,Microsoft Research
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Manik Varma,Microsoft Research
ICML,2017,ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,Prateek Jain,Microsoft Research
ICML,2017,Device Placement Optimization with Reinforcement Learning,Azalia Mirhoseini,Google
ICML,2017,Device Placement Optimization with Reinforcement Learning,Hieu Pham,Google
ICML,2017,Device Placement Optimization with Reinforcement Learning,Quoc Le,Google Brain
ICML,2017,Device Placement Optimization with Reinforcement Learning,benoit steiner,Google
ICML,2017,Device Placement Optimization with Reinforcement Learning,Mohammad Norouzi,Google
ICML,2017,Device Placement Optimization with Reinforcement Learning,Rasmus Larsen,Google
ICML,2017,Device Placement Optimization with Reinforcement Learning,Yuefeng Zhou,Google Brain
ICML,2017,Device Placement Optimization with Reinforcement Learning,Naveen Kumar,Google
ICML,2017,Device Placement Optimization with Reinforcement Learning,Samy Bengio,Google Brain
ICML,2017,Device Placement Optimization with Reinforcement Learning,Jeff Dean,Google Brain
ICML,2017,Dynamic Word Embeddings,Robert Bamler,Disney Research Pittsburgh
ICML,2017,Dynamic Word Embeddings,Stephan Mandt,Disney Research
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Shuxin Zheng,University of Science and Technology of China
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Qi Meng,Peking University
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Taifeng Wang,
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Wei Chen,Microsoft Research
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Nenghai Yu,USTC
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Zhiming Ma,
ICML,2017,Asynchronous Stochastic Gradient Descent with Delay Compensation,Tie-Yan Liu,Microsoft
ICML,2017,Improving Stochastic Policy Gradients in Continuous Control with Deep Reinforcement Learning using the Beta Distribution,Po-Wei Chou,Carnegie Mellon University
ICML,2017,Improving Stochastic Policy Gradients in Continuous Control with Deep Reinforcement Learning using the Beta Distribution,Daniel Maturana,Carnegie Mellon University
ICML,2017,Improving Stochastic Policy Gradients in Continuous Control with Deep Reinforcement Learning using the Beta Distribution,Sebastian Scherer,Carnegie Mellon University
ICML,2017,Fractional Langevin Monte Carlo: Exploring Levy Driven Stochastic Differential Equations for MCMC,Umut Simsekli,Telecom ParisTech
ICML,2017,Preferential Bayesian Optmization,Javier González,Amazon
ICML,2017,Preferential Bayesian Optmization,Zhenwen Dai,Amazon.com
ICML,2017,Preferential Bayesian Optmization,Andreas Damianou,Amazon.com
ICML,2017,Preferential Bayesian Optmization,Neil Lawrence,Amazon.com
ICML,2017,Being Robust (in High Dimensions) Can Be Practical,Ilias Diakonikolas,USC
ICML,2017,Being Robust (in High Dimensions) Can Be Practical,Gautam Kamath,MIT
ICML,2017,Being Robust (in High Dimensions) Can Be Practical,Daniel Kane,UCSD
ICML,2017,Being Robust (in High Dimensions) Can Be Practical,Jerry Li,MIT
ICML,2017,Being Robust (in High Dimensions) Can Be Practical,Ankur Moitra,
ICML,2017,Being Robust (in High Dimensions) Can Be Practical,Alistair Stewart,USC
ICML,2017,Differentially Private Ordinary Least Squares,Or Sheffet,University of Alberta
ICML,2017,"When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications",Hao Zhou,University of Wisconsin - Madison
ICML,2017,"When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications",Yilin Zhang,
ICML,2017,"When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications",Vamsi Ithapu,Univresity of Wisconsin Madiso
ICML,2017,"When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications",Sterling Johnson,UW Madison
ICML,2017,"When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications",Grace Wahba,University of Wisconsin-Madison
ICML,2017,"When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications",Vikas Singh,
ICML,2017,Deep Tensor Convolution on Multicores,David Budden,MIT / DeepMind
ICML,2017,Deep Tensor Convolution on Multicores,Alexander Matveev,MIT
ICML,2017,Deep Tensor Convolution on Multicores,Shibani Santurkar,MIT
ICML,2017,Deep Tensor Convolution on Multicores,Shraman Ray Chaudhuri,MIT
ICML,2017,Deep Tensor Convolution on Multicores,Nir Shavit,MIT
ICML,2017,Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling,Hairong Liu,Baidu Silicon Valley AI Lab
ICML,2017,Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling,Zhenyao Zhu,Baidu Silicon Valley AI Lab
ICML,2017,Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling,Xiangang Li,Baidu AI Lab
ICML,2017,Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling,Sanjeev Satheesh,Baidu SVAIL
ICML,2017,Adaptive Consensus ADMM for Distributed Optimization,Zheng Xu,University of Maryland
ICML,2017,Adaptive Consensus ADMM for Distributed Optimization,Gavin Taylor,US Naval Academy
ICML,2017,Adaptive Consensus ADMM for Distributed Optimization,Hao Li,University of Maryland at College Park
ICML,2017,Adaptive Consensus ADMM for Distributed Optimization,Mario Figueiredo,Instituto Superior Tecnico
ICML,2017,Adaptive Consensus ADMM for Distributed Optimization,Xiaoming Yuan,
ICML,2017,Adaptive Consensus ADMM for Distributed Optimization,Tom Goldstein,University of Maryland
ICML,2017,Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning,Yevgen Chebotar,University of Southern California
ICML,2017,Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning,Karol Hausman,University of Southern California
ICML,2017,Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning,Marvin Zhang,UC Berkeley
ICML,2017,Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning,Gaurav Sukhatme,University of Southern California
ICML,2017,Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning,Stefan Schaal,
ICML,2017,Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning,Sergey Levine,Berkeley
ICML,2017,Stochastic  Bouncy  Particle Sampler,Ari Pakman,Columbia University
ICML,2017,Stochastic  Bouncy  Particle Sampler,Dar Gilboa,Columbia University
ICML,2017,Stochastic  Bouncy  Particle Sampler,David Carlson,Duke University
ICML,2017,Stochastic  Bouncy  Particle Sampler,Liam Paninski,
ICML,2017,Max-value Entropy Search for Efficient Bayesian Optimization,Zi Wang,MIT
ICML,2017,Max-value Entropy Search for Efficient Bayesian Optimization,Stefanie Jegelka,MIT
ICML,2017,Multilabel Classification with Group Testing and Codes,Shashanka Ubaru,University of Minnesota
ICML,2017,Multilabel Classification with Group Testing and Codes,Arya Mazumdar,University of Massachusetts Amherst
ICML,2017,Priv’IT: Private and Sample Efficient Identity Testing,Bryan Cai,MIT
ICML,2017,Priv’IT: Private and Sample Efficient Identity Testing,Constantinos Daskalakis,MIT
ICML,2017,Priv’IT: Private and Sample Efficient Identity Testing,Gautam Kamath,MIT
ICML,2017,Learning from Clinical Judgments: Semi-Markov-Modulated Marked Hawkes Processes for Risk Prognosis,Ahmed M. Alaa Ibrahim,UCLA
ICML,2017,Learning from Clinical Judgments: Semi-Markov-Modulated Marked Hawkes Processes for Risk Prognosis,Scott B Hu,UCLA
ICML,2017,Learning from Clinical Judgments: Semi-Markov-Modulated Marked Hawkes Processes for Risk Prognosis,M van der Schaar,Oxford University and UCLA
ICML,2017,MEC: Memory-efficient Convolution for Deep Neural Network,Minsik Cho,IBM Research
ICML,2017,MEC: Memory-efficient Convolution for Deep Neural Network,Daniel Brand,IBM Research
ICML,2017,Coupling Distributed and Symbolic Execution for Natural Language Queries,Lili Mou,Peking University
ICML,2017,Coupling Distributed and Symbolic Execution for Natural Language Queries,Zhengdong Lu,DeeplyCurious.ai
ICML,2017,Coupling Distributed and Symbolic Execution for Natural Language Queries,Hang Li,Huawei
ICML,2017,Coupling Distributed and Symbolic Execution for Natural Language Queries,Zhi Jin,Peking University
ICML,2017,Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks,Kevin Scaman,MSR-INRIA Joint Center
ICML,2017,Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks,Francis Bach,INRIA
ICML,2017,Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks,Sebastien Bubeck,Microsoft Research
ICML,2017,Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks,Yin Tat Lee,Microsoft Research
ICML,2017,Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks,Laurent Massoulié,MSR-INRIA Joint Center
ICML,2017,Prediction under Uncertainty in Sparse Spectrum Gaussian Processes with Applications to Filtering and Control,Yunpeng Pan,Georgia Tech
ICML,2017,Prediction under Uncertainty in Sparse Spectrum Gaussian Processes with Applications to Filtering and Control,Xinyan Yan,Georgia Institute of Technology
ICML,2017,Prediction under Uncertainty in Sparse Spectrum Gaussian Processes with Applications to Filtering and Control,Evangelos Theodorou,Georgia Tech
ICML,2017,Prediction under Uncertainty in Sparse Spectrum Gaussian Processes with Applications to Filtering and Control,Byron Boots,Georgia Tech
ICML,2017,Canopy --- Fast Sampling with Cover Trees,Manzil Zaheer,Carnegie Mellon University
ICML,2017,Canopy --- Fast Sampling with Cover Trees,Satwik Kottur,Carnegie Mellon University
ICML,2017,Canopy --- Fast Sampling with Cover Trees,Amr Ahmed,Google
ICML,2017,Canopy --- Fast Sampling with Cover Trees,Jose Moura,CMU
ICML,2017,Canopy --- Fast Sampling with Cover Trees,Alex Smola,Amazon
ICML,2017,Bayesian Optimization with Tree-structured Dependencies,Rodolphe Jenatton,Amazon
ICML,2017,Bayesian Optimization with Tree-structured Dependencies,Cedric Archambeau,Amazon
ICML,2017,Bayesian Optimization with Tree-structured Dependencies,Javier González,Amazon
ICML,2017,Bayesian Optimization with Tree-structured Dependencies,Matthias Seeger,Amazon.com
ICML,2017,High-Dimensional Structured Quantile Regression,Vidyashankar Sivakumar,University of Minnesota
ICML,2017,High-Dimensional Structured Quantile Regression,Arindam Banerjee,University of Minnesota
ICML,2017,Differentially Private Submodular Maximization: Data Summarization in Disguise,Marko Mitrovic,Yale University
ICML,2017,Differentially Private Submodular Maximization: Data Summarization in Disguise,Mark Bun,Princeton University
ICML,2017,Differentially Private Submodular Maximization: Data Summarization in Disguise,Andreas Krause,ETH Zurich
ICML,2017,Differentially Private Submodular Maximization: Data Summarization in Disguise,Amin Karbasi,Yale
ICML,2017,Learning to Detect Sepsis with a Multitask Gaussian Process RNN Classifier,Joseph Futoma,Duke University
ICML,2017,Learning to Detect Sepsis with a Multitask Gaussian Process RNN Classifier,Sanjay Hariharan,Duke University
ICML,2017,Learning to Detect Sepsis with a Multitask Gaussian Process RNN Classifier,Katherine Heller,Duke University
ICML,2017,Beyond Filters: Compact Feature Map for Portable Deep Model,Yunhe Wang,Peking University
ICML,2017,Beyond Filters: Compact Feature Map for Portable Deep Model,Chang Xu,The University of Sydney
ICML,2017,Beyond Filters: Compact Feature Map for Portable Deep Model,Chao Xu,Peking University
ICML,2017,Beyond Filters: Compact Feature Map for Portable Deep Model,Dacheng Tao,
ICML,2017,Image-to-Markup Generation with Coarse-to-Fine Attention,Yuntian Deng,Harvard University
ICML,2017,Image-to-Markup Generation with Coarse-to-Fine Attention,Anssi Kanervisto,University of Eastern Finland
ICML,2017,Image-to-Markup Generation with Coarse-to-Fine Attention,Jeffrey Ling,Harvard University
ICML,2017,Image-to-Markup Generation with Coarse-to-Fine Attention,Alexander Rush,Harvard University
ICML,2017,Projection-free Distributed Online Learning in Networks,Wenpeng Zhang,Tsinghua University
ICML,2017,Projection-free Distributed Online Learning in Networks,Peilin Zhao,"Artificial Intelligence Department, Ant ​Financial"
ICML,2017,Projection-free Distributed Online Learning in Networks,wenwu zhu,
ICML,2017,Projection-free Distributed Online Learning in Networks,Steven Hoi,Singapore Management University
ICML,2017,Projection-free Distributed Online Learning in Networks,Tong Zhang,Tecent AI Lab
ICML,2017,Learning Stable Stochastic Nonlinear Dynamical Systems,Jonas Umlauft,Technical University of Munich
ICML,2017,Learning Stable Stochastic Nonlinear Dynamical Systems,Sandra Hirche,Technical University of Munich
ICML,2017,A Simulated Annealing Based Inexact Oracle for Wasserstein Loss Minimization,Jianbo Ye,Penn State University
ICML,2017,A Simulated Annealing Based Inexact Oracle for Wasserstein Loss Minimization,James Wang,Penn State University
ICML,2017,A Simulated Annealing Based Inexact Oracle for Wasserstein Loss Minimization,Jia Li,Penn State University
ICML,2017,Multi-fidelity Bayesian Optimisation with Continuous Approximations,kirthevasan kandasamy,CMU
ICML,2017,Multi-fidelity Bayesian Optimisation with Continuous Approximations,Gautam Dasarathy,Rice University
ICML,2017,Multi-fidelity Bayesian Optimisation with Continuous Approximations,Barnabás Póczos,CMU
ICML,2017,Multi-fidelity Bayesian Optimisation with Continuous Approximations,Jeff Schneider,CMU/Uber
ICML,2017,High-dimensional Non-Gaussian Single Index Models via Thresholded Score Function Estimation,Zhuoran Yang,Princeton University
ICML,2017,High-dimensional Non-Gaussian Single Index Models via Thresholded Score Function Estimation,Krishnakumar Balasubramanian,Princeton
ICML,2017,High-dimensional Non-Gaussian Single Index Models via Thresholded Score Function Estimation,Han Liu,Princeton University
ICML,2017,Differentially Private Learning of Graphical Models using CGMs,Garrett Bernstein,University of Massachusetts Amherst
ICML,2017,Differentially Private Learning of Graphical Models using CGMs,Ryan McKenna,UMass Amherst
ICML,2017,Differentially Private Learning of Graphical Models using CGMs,Tao Sun,University of Massachusetts Amherst
ICML,2017,Differentially Private Learning of Graphical Models using CGMs,Daniel Sheldon,University of Massachusetts Amherst
ICML,2017,Differentially Private Learning of Graphical Models using CGMs,Michael Hay,Colgate University
ICML,2017,Differentially Private Learning of Graphical Models using CGMs,Gerome Miklau,"University of Massachusetts, Amherst"
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",Walter Dempsey,University of Michigan
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",Alexander Moreno,Georgia Institute of Technology
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",Jim Rehg,Georgia Tech
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",Susan Murphy,University of Michigan
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",Chris Scott,Chestnut Health Systems
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",Michael Dennis,Lighthouse Institute
ICML,2017,"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",David Gustafson,University of Wisconsin-Madison
ICML,2017,Efficient softmax approximation for GPUs,Edouard Grave,Facebook AI Research
ICML,2017,Efficient softmax approximation for GPUs,Armand Joulin,Facebook
ICML,2017,Efficient softmax approximation for GPUs,Moustapha Cisse,
ICML,2017,Efficient softmax approximation for GPUs,David Grangier,Facebook
ICML,2017,Efficient softmax approximation for GPUs,Herve Jegou,Facebook AI Research
ICML,2017,Multichannel End-to-end Speech Recognition,Tsubasa Ochiai,Doshisha University
ICML,2017,Multichannel End-to-end Speech Recognition,Shinji Watanabe,MITSUBISHI ELECTRIC RESEARCH LABORATORIES
ICML,2017,Multichannel End-to-end Speech Recognition,Takaaki Hori,MITSUBISHI ELECTRIC RESEARCH LABORATORIES
ICML,2017,Multichannel End-to-end Speech Recognition,John Hershey,MITSUBISHI ELECTRIC RESEARCH LABORATORIES
ICML,2017,Local Bayesian Optimization of Motor Skills,Riad Akrour,TU Darmstadt
ICML,2017,Local Bayesian Optimization of Motor Skills,Dmitry Sorokin,
ICML,2017,Local Bayesian Optimization of Motor Skills,Jan Peters,TU Darmstadt
ICML,2017,Local Bayesian Optimization of Motor Skills,Gerhard Neumann,University of Lincoln
ICML,2017,Improving Gibbs Sampler Scan Quality with DoGS,Ioannis Mitliagkas,Stanford University
ICML,2017,Improving Gibbs Sampler Scan Quality with DoGS,Lester Mackey,Microsoft Research
ICML,2017,Parallel and Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space,Jose Hernandez-Lobato,University of Cambridge
ICML,2017,Parallel and Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space,James Requeima,University of Cambridge
ICML,2017,Parallel and Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space,Edward Pyzer-Knapp,IBM
ICML,2017,Parallel and Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space,alan Aspuru-Guzik,
ICML,2017,Robust Structured Estimation with Single-Index Models,Sheng Chen,University of Minnesota
ICML,2017,Robust Structured Estimation with Single-Index Models,Arindam Banerjee,University of Minnesota
ICML,2017,Minimizing Trust Leaks for Robust Sybil Detection,János Höner,TU Berlin / MathPlan
ICML,2017,Minimizing Trust Leaks for Robust Sybil Detection,Shinichi Nakajima,TU Berlin
ICML,2017,Minimizing Trust Leaks for Robust Sybil Detection,Alexander Bauer,TU Berlin
ICML,2017,Minimizing Trust Leaks for Robust Sybil Detection,Klaus-robert Mueller,
ICML,2017,Minimizing Trust Leaks for Robust Sybil Detection,Nico Görnitz,TU Berlin
ICML,2017,Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture,Mingmin Zhao,MIT
ICML,2017,Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture,Shichao Yue,MIT
ICML,2017,Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture,Dina Katabi,MIT
ICML,2017,Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture,Tommi Jaakkola,MIT
ICML,2017,Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture,Matt Bianchi,Massachusetts General Hospital
ICML,2017,Dropout Inference in Bayesian Neural Networks with Alpha-divergences,Yingzhen Li,University of Cambridge
ICML,2017,Dropout Inference in Bayesian Neural Networks with Alpha-divergences,Yarin Gal,University of Cambridge
ICML,2017,Latent Intention Dialogue Models,Tsung-Hsien Wen,University of Cambridge
ICML,2017,Latent Intention Dialogue Models,Yishu Miao,University of Oxford
ICML,2017,Latent Intention Dialogue Models,Philip Blunsom,Oxford University and DeepMind
ICML,2017,Latent Intention Dialogue Models,Steve Young J Young,University of Cambridge
ICML,2017,Robust Guarantees of Stochastic Greedy Algorithms,Yaron Singer,Harvard
ICML,2017,Robust Guarantees of Stochastic Greedy Algorithms,Avinatan Hassidim,Bar Ilan University
ICML,2017,Count-Based Exploration with Neural Density Models,Georg Ostrovski,Google DeepMind
ICML,2017,Count-Based Exploration with Neural Density Models,Marc Bellemare,DeepMind
ICML,2017,Count-Based Exploration with Neural Density Models,Aäron van den Oord,Google
ICML,2017,Count-Based Exploration with Neural Density Models,Remi Munos,DeepMind
ICML,2017,Magnetic Hamiltonian Monte Carlo,Nilesh Tripuraneni,UC Berkeley
ICML,2017,Magnetic Hamiltonian Monte Carlo,Mark Rowland,University of Cambridge
ICML,2017,Magnetic Hamiltonian Monte Carlo,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2017,Magnetic Hamiltonian Monte Carlo,Richard E Turner,University of Cambridge
ICML,2017,Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference,Aditya Chaudhry,University of Virginia
ICML,2017,Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference,Pan Xu,University of Virginia
ICML,2017,Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference,Quanquan Gu,University of Virginia
ICML,2017,Toward Efficient and Accurate Covariance Matrix Estimation on Compressed Data,Xixian Chen,The Chinese University of Hong Kong
ICML,2017,Toward Efficient and Accurate Covariance Matrix Estimation on Compressed Data,Michael Lyu,The Chinese University of Hong Kong
ICML,2017,Toward Efficient and Accurate Covariance Matrix Estimation on Compressed Data,Irwin King,CUHK
ICML,2017,The Price of Differential Privacy For Online Learning,Naman Agarwal,Princeton University
ICML,2017,The Price of Differential Privacy For Online Learning,Karan Singh,Princeton University
ICML,2017,Bidirectional learning for time-series models with hidden units,Takayuki Osogami,IBM Research - Tokyo
ICML,2017,Bidirectional learning for time-series models with hidden units,Hiroshi Kajino,IBM Research - Tokyo
ICML,2017,Bidirectional learning for time-series models with hidden units,Taro Sekiyama,IBM Research - Tokyo
ICML,2017,Multiplicative Normalizing Flows for Variational Bayesian Neural Networks,Christos Louizos,University of Amsterdam
ICML,2017,Multiplicative Normalizing Flows for Variational Bayesian Neural Networks,Max Welling,University of Amsterdam
ICML,2017,Discovering Discrete Latent Topics with Neural Variational Inference,Yishu Miao,University of Oxford
ICML,2017,Discovering Discrete Latent Topics with Neural Variational Inference,Edward Grefenstette,Deepmind
ICML,2017,Discovering Discrete Latent Topics with Neural Variational Inference,Philip Blunsom,Oxford University and DeepMind
ICML,2017,Guarantees for Greedy Maximization of Non-submodular Functions with Applications,An Bian,ETH Zurich
ICML,2017,Guarantees for Greedy Maximization of Non-submodular Functions with Applications,Joachim Buhmann,
ICML,2017,Guarantees for Greedy Maximization of Non-submodular Functions with Applications,Andreas Krause,ETH Zurich
ICML,2017,Guarantees for Greedy Maximization of Non-submodular Functions with Applications,Sebastian Tschiatschek,ETH
ICML,2017,Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning,Junhyuk Oh,University of Michigan
ICML,2017,Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning,Satinder Singh,University of Michigan
ICML,2017,Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning,Honglak Lee,Google / U. Michigan
ICML,2017,Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning,Pushmeet Kohli,Microsoft Research
ICML,2017,Probabilistic Path Hamiltonian Monte Carlo,Vu Dinh,Fred Hutchinson Cancer Center
ICML,2017,Probabilistic Path Hamiltonian Monte Carlo,Arman Bilge,University of Washington
ICML,2017,Probabilistic Path Hamiltonian Monte Carlo,Cheng Zhang,Fred Hutchinson Cancer Center
ICML,2017,Probabilistic Path Hamiltonian Monte Carlo,Erick Matsen,Fred Hutchinson Cancer Center
ICML,2017,Uncovering Causality from Multivariate Hawkes Integrated Cumulants,Massil Achab,Ecole Polytechnique
ICML,2017,Uncovering Causality from Multivariate Hawkes Integrated Cumulants,Emmanuel Bacry,Ecole Polytechnique
ICML,2017,Uncovering Causality from Multivariate Hawkes Integrated Cumulants,Stéphane Gaïffas,CMAP CNRS UMR 7641
ICML,2017,Uncovering Causality from Multivariate Hawkes Integrated Cumulants,Iacopo Mastromatteo,Capital Fund Management
ICML,2017,Uncovering Causality from Multivariate Hawkes Integrated Cumulants,Jean-François Muzy,Université de Corse
ICML,2017,Robust Gaussian Graphical Model Estimation with Arbitrary Corruption,Lingxiao Wang,University of Virginia
ICML,2017,Robust Gaussian Graphical Model Estimation with Arbitrary Corruption,Quanquan Gu,University of Virginia
ICML,2017,Pain-Free Random Differential Privacy with Sensitivity Sampling,Ben Rubinstein,University​ of Melbourne
ICML,2017,Pain-Free Random Differential Privacy with Sensitivity Sampling,Francesco Aldà,Ruhr-Universität Bochum
ICML,2017,Learning Hawkes Processes from Short Doubly-Censored Event Sequences,Hongteng Xu,Georgia Institute of Technology
ICML,2017,Learning Hawkes Processes from Short Doubly-Censored Event Sequences,Dixin Luo,University of Toronto
ICML,2017,Learning Hawkes Processes from Short Doubly-Censored Event Sequences,Hongyuan Zha,Georgia Institute of Technology
ICML,2017,Variational Dropout Sparsifies Deep Neural Networks,Dmitry Molchanov,Skoltech
ICML,2017,Variational Dropout Sparsifies Deep Neural Networks,Arsenii Ashukha,"HSE, MIPT"
ICML,2017,Variational Dropout Sparsifies Deep Neural Networks,Dmitry Vetrov,HSE
ICML,2017,Toward Controlled Generation of Text,Zhiting Hu,Carnegie Mellon University
ICML,2017,Toward Controlled Generation of Text,Zichao Yang,Carnegie Mellon University
ICML,2017,Toward Controlled Generation of Text,Xiaodan Liang,Carnegie Mellon University
ICML,2017,Toward Controlled Generation of Text,Russ Salakhutdinov,Carnegie Mellen University
ICML,2017,Toward Controlled Generation of Text,Eric Xing,Carnegie Mellon University
ICML,2017,Robust Submodular Maximization: A Non-Uniform Partitioning Approach,Ilija Bogunovic,EPFL
ICML,2017,Robust Submodular Maximization: A Non-Uniform Partitioning Approach,Boba Mitrovic,EPFL
ICML,2017,Robust Submodular Maximization: A Non-Uniform Partitioning Approach,Jonathan Scarlett,EPFL
ICML,2017,Robust Submodular Maximization: A Non-Uniform Partitioning Approach,Volkan Cevher,EPFL
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Jakob Foerster,University of Oxford
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Nantas Nardelli,University of Oxford
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Greg Farquhar,University of Oxford
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Triantafyllos Afouras,University of Oxford
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Phil Torr,Oxford
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Pushmeet Kohli,Microsoft Research
ICML,2017,Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning,Shimon Whiteson,University of Oxford
ICML,2017,Stochastic Gradient Monomial Gamma Sampler,Yizhe Zhang,Duke university
ICML,2017,Stochastic Gradient Monomial Gamma Sampler,Changyou Chen,Duke
ICML,2017,Stochastic Gradient Monomial Gamma Sampler,Zhe Gan,Duke University
ICML,2017,Stochastic Gradient Monomial Gamma Sampler,Ricardo Henao,Duke University
ICML,2017,Stochastic Gradient Monomial Gamma Sampler,Lawrence Carin,Duke
ICML,2017,Cost-Optimal Learning of Causal Graphs,Murat Kocaoglu,University of Texas at Austin
ICML,2017,Cost-Optimal Learning of Causal Graphs,Alex Dimakis,UT Austin
ICML,2017,Cost-Optimal Learning of Causal Graphs,Sriram Vishwanath,
ICML,2017,Algebraic Variety Models for High-Rank Matrix Completion,Greg Ongie,University of Michigan
ICML,2017,Algebraic Variety Models for High-Rank Matrix Completion,Laura Balzano,University of Michigan
ICML,2017,Algebraic Variety Models for High-Rank Matrix Completion,Rebecca Willett,UW Madison
ICML,2017,Algebraic Variety Models for High-Rank Matrix Completion,Robert Nowak,University of Wisconsion-Madison
ICML,2017,Differentially Private Clustering in High-Dimensional Euclidean Spaces,Nina Balcan,Carnegie Mellon University
ICML,2017,Differentially Private Clustering in High-Dimensional Euclidean Spaces,Travis Dick,CMU
ICML,2017,Differentially Private Clustering in High-Dimensional Euclidean Spaces,Yingyu Liang,Princeton University
ICML,2017,Differentially Private Clustering in High-Dimensional Euclidean Spaces,Wenlong Mou,Peking University
ICML,2017,Differentially Private Clustering in High-Dimensional Euclidean Spaces,Hongyang Zhang,Carnegie Mellon University
ICML,2017,Coherent probabilistic forecasts for hierarchical time series,Souhaib Ben Taieb,Monash University
ICML,2017,Coherent probabilistic forecasts for hierarchical time series,James Taylor,University of Oxford
ICML,2017,Coherent probabilistic forecasts for hierarchical time series,Rob Hyndman,Monash University
ICML,2017,Unimodal Probability Distributions for Deep Ordinal Classification,Christopher Beckham,MILA
ICML,2017,Unimodal Probability Distributions for Deep Ordinal Classification,Christopher Pal,École Polytechnique de Montréal
ICML,2017,Adversarial Feature Matching for Text Generation,Yizhe Zhang,Duke university
ICML,2017,Adversarial Feature Matching for Text Generation,Zhe Gan,Duke University
ICML,2017,Adversarial Feature Matching for Text Generation,Kai Fan,
ICML,2017,Adversarial Feature Matching for Text Generation,Zhi Chen,Nanjing University
ICML,2017,Adversarial Feature Matching for Text Generation,Ricardo Henao,Duke University
ICML,2017,Adversarial Feature Matching for Text Generation,Dinghan Shen,Duke University
ICML,2017,Adversarial Feature Matching for Text Generation,Lawrence Carin,Duke
ICML,2017,Probabilistic Submodular Maximization in Sub-Linear Time,Serban A Stan,Yale
ICML,2017,Probabilistic Submodular Maximization in Sub-Linear Time,Morteza Zadimoghaddam,Google
ICML,2017,Probabilistic Submodular Maximization in Sub-Linear Time,Andreas Krause,ETH Zurich
ICML,2017,Probabilistic Submodular Maximization in Sub-Linear Time,Amin Karbasi,Yale
ICML,2017,The Predictron:  End-To-End Learning and Planning,David Silver,Google DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Hado van Hasselt,DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Matteo Hessel,Deep Mind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Tom Schaul,DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Arthur Guez,Google DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Tim Harley,DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Gabriel Dulac-Arnold,Google DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,David Reichert,DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Neil Rabinowitz,DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Andre Barreto,Google DeepMind
ICML,2017,The Predictron:  End-To-End Learning and Planning,Thomas Degris,DeepMind
ICML,2017,Stochastic Gradient MCMC Methods for Hidden Markov Models,Yi-An Ma,University of Washington
ICML,2017,Stochastic Gradient MCMC Methods for Hidden Markov Models,Nick J Foti,University of Washington
ICML,2017,Stochastic Gradient MCMC Methods for Hidden Markov Models,Emily Fox,University of Washington
ICML,2017,Identification and Model Testing in Linear Structural Equation Models using Auxiliary Variables,Bryant Chen,IBM Research
ICML,2017,Identification and Model Testing in Linear Structural Equation Models using Auxiliary Variables,Daniel Kumor,Purdue University
ICML,2017,Identification and Model Testing in Linear Structural Equation Models using Auxiliary Variables,Elias Bareinboim,Purdue
ICML,2017,High-Dimensional Variance-Reduced Stochastic Gradient Expectation-Maximization Algorithm,Rongda Zhu,Facebook
ICML,2017,High-Dimensional Variance-Reduced Stochastic Gradient Expectation-Maximization Algorithm,Lingxiao Wang,University of Virginia
ICML,2017,High-Dimensional Variance-Reduced Stochastic Gradient Expectation-Maximization Algorithm,Chengxiang Zhai,University of Illinois at Urbana-Champaign
ICML,2017,High-Dimensional Variance-Reduced Stochastic Gradient Expectation-Maximization Algorithm,Quanquan Gu,University of Virginia
ICML,2017,Differentially Private Chi-squared Test by Unit Circle Mechanism,Kazuya Kakizaki,University of Tsukuba / NEC
ICML,2017,Differentially Private Chi-squared Test by Unit Circle Mechanism,Kazuto Fukuchi,University of Tsukuba
ICML,2017,Differentially Private Chi-squared Test by Unit Circle Mechanism,Jun Sakuma,University of Tsukuba / RIKEN AIP
ICML,2017,Soft-DTW: a Differentiable Loss Function for Time-Series,Marco Cuturi,ENSAE / CREST
ICML,2017,Soft-DTW: a Differentiable Loss Function for Time-Series,Mathieu Blondel,NTT
ICML,2017,Learning Continuous Semantic Representations of Symbolic Expressions,Miltos Allamanis,Microsoft Research
ICML,2017,Learning Continuous Semantic Representations of Symbolic Expressions,pankajan Chanthirasegaran,
ICML,2017,Learning Continuous Semantic Representations of Symbolic Expressions,Pushmeet Kohli,Microsoft Research
ICML,2017,Learning Continuous Semantic Representations of Symbolic Expressions,Charles Sutton,University of Edinburgh
ICML,2017,On Approximation Guarantees for Greedy Low Rank Optimization,RAJIV KHANNA,UT Austin
ICML,2017,On Approximation Guarantees for Greedy Low Rank Optimization,Ethan Elenberg,The University of Texas at Austin
ICML,2017,On Approximation Guarantees for Greedy Low Rank Optimization,Alex Dimakis,UT Austin
ICML,2017,On Approximation Guarantees for Greedy Low Rank Optimization,Joydeep Ghosh,The University of Texas at Austin
ICML,2017,On Approximation Guarantees for Greedy Low Rank Optimization,Sahand Negahban,YALE
ICML,2017,Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning,Oron Anschel,Technion
ICML,2017,Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning,Nir Baram,Technion - Israel Institute of Technology
ICML,2017,Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning,Nahum Shimkin,Technion
ICML,2017,Deep Latent Dirichlet Allocation with Topic-Layer-Adaptive Stochastic Gradient Riemannian MCMC,Yulai Cong,Xidian University
ICML,2017,Deep Latent Dirichlet Allocation with Topic-Layer-Adaptive Stochastic Gradient Riemannian MCMC,Bo Chen,"National Lab of Radar Signal Processing, School of Electronic Engineering, Xidian University"
ICML,2017,Deep Latent Dirichlet Allocation with Topic-Layer-Adaptive Stochastic Gradient Riemannian MCMC,Hongwei Liu,Xidian University
ICML,2017,Deep Latent Dirichlet Allocation with Topic-Layer-Adaptive Stochastic Gradient Riemannian MCMC,Mingyuan Zhou,University of Texas at Austin
ICML,2017,Estimating individual treatment effect: generalization bounds and algorithms,Uri Shalit,NYU
ICML,2017,Estimating individual treatment effect: generalization bounds and algorithms,Fredrik D Johansson,MIT
ICML,2017,Estimating individual treatment effect: generalization bounds and algorithms,David Sontag,Massachusetts Institute of Technology
ICML,2017,"Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible",Kai Zheng,Peking University
ICML,2017,"Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible",Wenlong Mou,Peking University
ICML,2017,"Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible",Liwei Wang,Peking University
ICML,2017,Variational Policy for Guiding Point Processes,Yichen Wang,Gatech
ICML,2017,Variational Policy for Guiding Point Processes,Grady Williams,Georgia Tech
ICML,2017,Variational Policy for Guiding Point Processes,Evangelos Theodorou,Georgia Tech
ICML,2017,Variational Policy for Guiding Point Processes,Le Song,Georgia Institute of Technology
ICML,2017,Dance Dance Convolution,Chris Donahue,"University of California, San Diego"
ICML,2017,Dance Dance Convolution,Zachary Lipton,UCSD
ICML,2017,Dance Dance Convolution,Julian McAuley,UCSD
ICML,2017,Language Modeling with Gated Convolutional Networks,Yann Dauphin,Facebook AI Research
ICML,2017,Language Modeling with Gated Convolutional Networks,Angela Fan,Facebook AI Research
ICML,2017,Language Modeling with Gated Convolutional Networks,Michael Auli,Facebook
ICML,2017,Language Modeling with Gated Convolutional Networks,David Grangier,Facebook
ICML,2017,"Deletion-Robust Submodular Maximization: Data Summarization with ""the Right to be Forgotten""",Baharan Mirzasoleiman,ETH Zurich
ICML,2017,"Deletion-Robust Submodular Maximization: Data Summarization with ""the Right to be Forgotten""",Amin Karbasi,Yale
ICML,2017,"Deletion-Robust Submodular Maximization: Data Summarization with ""the Right to be Forgotten""",Andreas Krause,ETH Zurich
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,Sasha Vezhnevets,DeepMind
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,Simon Osindero,DeepMind
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,Tom Schaul,DeepMind
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,Nicolas Heess,Google DeepMind
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,Max Jaderberg,DeepMind
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,David Silver,Google DeepMind
ICML,2017,FeUdal Networks for Hierarchical Reinforcement Learning,koray kavukcuoglu,DeepMind
ICML,2017,Distributed Batch Gaussian Process Optimization,Erik Daxberger,Ludwig-Maximilians-Universität München
ICML,2017,Distributed Batch Gaussian Process Optimization,Bryan Kian Hsiang Low,National University of Singapore
ICML,2017,Recursive Partitioning for Personalization using Observational Data,Nathan Kallus,Cornell University
ICML,2017,Optimal Densification for Fast and Accurate Minwise Hashing,Anshumali Shrivastava,Rice University
ICML,2017,An Adaptive Test of Independence with Analytic Kernel Embeddings,Wittawat Jitkrittum,UCL
ICML,2017,An Adaptive Test of Independence with Analytic Kernel Embeddings,Zoltan Szabo,École Polytechnique
ICML,2017,An Adaptive Test of Independence with Analytic Kernel Embeddings,Arthur Gretton,Gatsby Computational Neuroscience Unit
ICML,2017,Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs,Gygli Gygli,Gifs.com
ICML,2017,Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs,Mohammad Norouzi,Google
ICML,2017,Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs,Anelia Angelova,Google Brain
ICML,2017,World of Bits: An Open-Domain Platform for Web-Based Agents,Tim Shi,Stanford University
ICML,2017,World of Bits: An Open-Domain Platform for Web-Based Agents,Andrej Karpathy,OpenAI
ICML,2017,World of Bits: An Open-Domain Platform for Web-Based Agents,Jim Fan Fan,Stanford University
ICML,2017,World of Bits: An Open-Domain Platform for Web-Based Agents,Jonathan Hernandez,
ICML,2017,World of Bits: An Open-Domain Platform for Web-Based Agents,Percy Liang,Stanford University
ICML,2017,Convolutional Sequence to Sequence Learning,Jonas Gehring,Facebook AI Research
ICML,2017,Convolutional Sequence to Sequence Learning,Michael Auli,Facebook
ICML,2017,Convolutional Sequence to Sequence Learning,David Grangier,Facebook
ICML,2017,Convolutional Sequence to Sequence Learning,Denis Yarats,Facebook AI Research
ICML,2017,Convolutional Sequence to Sequence Learning,Yann Dauphin,Facebook AI Research
ICML,2017,Analysis and Optimization of Graph Decompositions by Lifted Multicuts,Andrea Hornakova,Max Planck Institute for Informatics
ICML,2017,Analysis and Optimization of Graph Decompositions by Lifted Multicuts,Jan-Hendrik Lange,MPI for Informatics
ICML,2017,Analysis and Optimization of Graph Decompositions by Lifted Multicuts,Bjoern Andres,MPI for Informatics
ICML,2017,Deciding How to Decide: Dynamic Routing in Artificial Neural Networks,Mason McGill,California Institute of Technology
ICML,2017,Deciding How to Decide: Dynamic Routing in Artificial Neural Networks,Pietro Perona,caltech.edu
ICML,2017,Scalable Multi-Class Gaussian Process Classification using Expectation Propagation,Carlos Villacampa-Calvo,Universidad Autónoma de Madrid
ICML,2017,Scalable Multi-Class Gaussian Process Classification using Expectation Propagation,Daniel Hernandez-Lobato,Universidad Autonoma de Madrid
ICML,2017,Identifying Best Interventions through Online Importance Sampling,Rajat Sen,University of Texas at Austin
ICML,2017,Identifying Best Interventions through Online Importance Sampling,Karthikeyan Shanmugam,"IBM Research, T. J. Watson Research Center"
ICML,2017,Identifying Best Interventions through Online Importance Sampling,Alex Dimakis,UT Austin
ICML,2017,Identifying Best Interventions through Online Importance Sampling,Sanjay Shakkottai,University of Texas at Austin
ICML,2017,Stochastic Generative Hashing,Bo Dai,Georgia Tech
ICML,2017,Stochastic Generative Hashing,Ruiqi Guo,Google Research
ICML,2017,Stochastic Generative Hashing,Sanjiv Kumar,"Google Research, NY"
ICML,2017,Stochastic Generative Hashing,Niao He,UIUC
ICML,2017,Stochastic Generative Hashing,Le Song,Georgia Institute of Technology
ICML,2017,Sliced Wasserstein Kernel for Persistence Diagrams,Mathieu Carrière,Inria Saclay
ICML,2017,Sliced Wasserstein Kernel for Persistence Diagrams,Marco Cuturi,ENSAE / CREST
ICML,2017,Sliced Wasserstein Kernel for Persistence Diagrams,Steve Oudot,
ICML,2017,Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,Wen Sun,Carnegie Mellon University
ICML,2017,Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,Arun Venkatraman,Carnegie Mellon University
ICML,2017,Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,Geoff Gordon,Carnegie Mellon University
ICML,2017,Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,Byron Boots,Georgia Tech
ICML,2017,Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,Drew Bagnell,Carnegie Mellon University
ICML,2017,Real-Time Adaptive Image Compression,Oren Rippel,"WaveOne, Inc."
ICML,2017,Real-Time Adaptive Image Compression,Lubomir Bourdev,"WaveOne, Inc."
ICML,2017,Improved Variational Autoencoders for Text Modeling using Dilated Convolutions,Zichao Yang,Carnegie Mellon University
ICML,2017,Improved Variational Autoencoders for Text Modeling using Dilated Convolutions,Zhiting Hu,Carnegie Mellon University
ICML,2017,Improved Variational Autoencoders for Text Modeling using Dilated Convolutions,Russ Salakhutdinov,Carnegie Mellen University
ICML,2017,Improved Variational Autoencoders for Text Modeling using Dilated Convolutions,Taylor Berg-Kirkpatrick,
ICML,2017,Near-Optimal Design of Experiments via Regret Minimization,Zeyuan Allen-Zhu,Microsoft Research / Princeton / IAS
ICML,2017,Near-Optimal Design of Experiments via Regret Minimization,Yuanzhi Li,Princeton University
ICML,2017,Near-Optimal Design of Experiments via Regret Minimization,Aarti Singh,Carnegie Mellon University
ICML,2017,Near-Optimal Design of Experiments via Regret Minimization,Yining Wang,CMU
ICML,2017,Neural Episodic Control,Alexander Pritzel,Deepmind
ICML,2017,Neural Episodic Control,Benigno Uria,Deepmind
ICML,2017,Neural Episodic Control,Raam Sriram,DeepMind
ICML,2017,Neural Episodic Control,Adrià Puigdomenech Badia,Deepmind
ICML,2017,Neural Episodic Control,Oriol Vinyals,DeepMind
ICML,2017,Neural Episodic Control,Demis Hassabis,Deepmind
ICML,2017,Neural Episodic Control,Daan Wierstra,Google DeepMind
ICML,2017,Neural Episodic Control,Charles Blundell,DeepMind
ICML,2017,Random Feature Expansions for Deep Gaussian Processes,Kurt Cutajar,EURECOM
ICML,2017,Random Feature Expansions for Deep Gaussian Processes,Edwin Bonilla,UNSW
ICML,2017,Random Feature Expansions for Deep Gaussian Processes,Pietro Michiardi,EURECOM
ICML,2017,Random Feature Expansions for Deep Gaussian Processes,Maurizio Filippone,Eurecom
ICML,2017,Deep IV: A Flexible Approach for Counterfactual Prediction,Jason Hartford,University of British Columbia
ICML,2017,Deep IV: A Flexible Approach for Counterfactual Prediction,Greg Lewis,Microsoft Research
ICML,2017,Deep IV: A Flexible Approach for Counterfactual Prediction,Kevin Leyton-Brown,
ICML,2017,Deep IV: A Flexible Approach for Counterfactual Prediction,Matt Taddy,MICROSOFT
ICML,2017,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning",Hantian Zhang,ETH Zurich
ICML,2017,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning",Jerry Li,MIT
ICML,2017,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning",Kaan Kara,ETH Zurich
ICML,2017,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning",Dan Alistarh,IST Austria & ETH Zurich
ICML,2017,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning",Ji Liu,University of Rochester
ICML,2017,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning",Ce Zhang,ETH Zurich
ICML,2017,Adapting Kernel Representations Online Using Submodular Maximization,Matthew Schlegel,Indiana University
ICML,2017,Adapting Kernel Representations Online Using Submodular Maximization,Yangchen Pan,Indiana University
ICML,2017,Adapting Kernel Representations Online Using Submodular Maximization,Jiecao (Jack) Chen,Indiana University Bloomington
ICML,2017,Adapting Kernel Representations Online Using Submodular Maximization,Martha White,University of Alberta/Indiana University
ICML,2017,End-to-End Learning for Structured Prediction Energy Networks,David Belanger,Google Brain
ICML,2017,End-to-End Learning for Structured Prediction Energy Networks,Bishan Yang,Carnegie Mellon University
ICML,2017,End-to-End Learning for Structured Prediction Energy Networks,Andrew McCallum,UMass Amherst
ICML,2017,Neural Message Passing for Quantum Chemistry,Justin Gilmer,Google Brain
ICML,2017,Neural Message Passing for Quantum Chemistry,Samuel Schoenholz,Google Brain
ICML,2017,Neural Message Passing for Quantum Chemistry,Patrick F Riley,Google
ICML,2017,Neural Message Passing for Quantum Chemistry,Oriol Vinyals,DeepMind
ICML,2017,Neural Message Passing for Quantum Chemistry,George Dahl,Google Brain
ICML,2017,Grammar Variational Autoencoder,Matt J. Kusner,Alan Turing Institute
ICML,2017,Grammar Variational Autoencoder,Brooks Paige,Alan Turing Institute
ICML,2017,Grammar Variational Autoencoder,Jose Hernandez-Lobato,University of Cambridge
ICML,2017,Robust Budget Allocation via Continuous Submodular Functions,Matthew J Staib,MIT
ICML,2017,Robust Budget Allocation via Continuous Submodular Functions,Stefanie Jegelka,MIT
ICML,2017,Neural Optimizer Search using Reinforcement Learning,Irwan Bello,Google Brain
ICML,2017,Neural Optimizer Search using Reinforcement Learning,Barret Zoph,Google
ICML,2017,Neural Optimizer Search using Reinforcement Learning,Vijay Vasudevan,Google
ICML,2017,Neural Optimizer Search using Reinforcement Learning,Quoc Le,Google Brain
ICML,2017,Counterfactual Data-Fusion for Online Reinforcement Learners,Andrew Forney,UCLA
ICML,2017,Counterfactual Data-Fusion for Online Reinforcement Learners,Judea Pearl,UCLA
ICML,2017,Counterfactual Data-Fusion for Online Reinforcement Learners,Elias Bareinboim,Purdue
ICML,2017,Large-Scale Evolution of Image Classifiers,Esteban Real,Google Inc.
ICML,2017,Large-Scale Evolution of Image Classifiers,Sherry Moore,Google Inc.
ICML,2017,Large-Scale Evolution of Image Classifiers,Andrew Selle,Google Inc.
ICML,2017,Large-Scale Evolution of Image Classifiers,Saurabh Saxena,Google Inc.
ICML,2017,Large-Scale Evolution of Image Classifiers,Yutaka Leon Suematsu,Google Inc.
ICML,2017,Large-Scale Evolution of Image Classifiers,Jie Tan,Google Inc.
ICML,2017,Large-Scale Evolution of Image Classifiers,Quoc Le,Google Brain
ICML,2017,Large-Scale Evolution of Image Classifiers,Alex Kurakin,Google Brain
ICML,2017,Spherical Structured Feature Maps for Kernel Approximation,Yueming LYU,city university of hong kong
ICML,2017,A Unified View of Multi-Label Performance Measures,Xi-Zhu Wu,Nanjing University
ICML,2017,A Unified View of Multi-Label Performance Measures,Zhi-Hua Zhou,Nanjing University
ICML,2017,Accelerating Eulerian Fluid Simulation With Convolutional Networks,Jonathan Tompson,Google Brain
ICML,2017,Accelerating Eulerian Fluid Simulation With Convolutional Networks,Kristofer D Schlachter,New York University
ICML,2017,Accelerating Eulerian Fluid Simulation With Convolutional Networks,Pablo Sprechmann,NYU
ICML,2017,Accelerating Eulerian Fluid Simulation With Convolutional Networks,Ken Perlin,New York University
ICML,2017,Rule-Enhanced Penalized Regression by Column Generation using Rectangular Maximum Agreement,Jonathan Eckstein,Rutgers University
ICML,2017,Rule-Enhanced Penalized Regression by Column Generation using Rectangular Maximum Agreement,Noam Goldberg,Bar-Ilan University
ICML,2017,Rule-Enhanced Penalized Regression by Column Generation using Rectangular Maximum Agreement,Ai Kagawa,Rutgers Univeristy
ICML,2017,High Dimensional Bayesian Optimization with Elastic Gaussian Process,Santu Rana,Deakin University
ICML,2017,High Dimensional Bayesian Optimization with Elastic Gaussian Process,Cheng Li,Deakin University
ICML,2017,High Dimensional Bayesian Optimization with Elastic Gaussian Process,Sunil Gupta,Deakin University
ICML,2017,High Dimensional Bayesian Optimization with Elastic Gaussian Process,Vu Nguyen,Deakin University
ICML,2017,High Dimensional Bayesian Optimization with Elastic Gaussian Process,Svetha Venkatesh,Deakin University
ICML,2017,Nyström Method with Kernel K-means++ Samples as Landmarks,Dino Oglic,University of Bonn
ICML,2017,Nyström Method with Kernel K-means++ Samples as Landmarks,Thomas Gaertner,The University of Nottingham
ICML,2017,Scalable Generative Models for Multi-label Learning with Missing Labels,Vikas Jain,Indian Institute of Technology Kanpur
ICML,2017,Scalable Generative Models for Multi-label Learning with Missing Labels,Nirbhay Modhe,Indian Institute of Technology Kanpur
ICML,2017,Scalable Generative Models for Multi-label Learning with Missing Labels,Piyush Rai,IIT Kanpur
ICML,2018,Spline Filters For End-to-End Deep Learning,Randall Balestriero,Rice University
ICML,2018,Spline Filters For End-to-End Deep Learning,Romain Cosentino,Rice University
ICML,2018,Spline Filters For End-to-End Deep Learning,Herve Glotin,Universite de Toulon
ICML,2018,Spline Filters For End-to-End Deep Learning,Richard Baraniuk,OpenStax / Rice University
ICML,2018,Non-linear motor control by local learning in spiking neural networks,Aditya Gilra,University of Bonn
ICML,2018,Non-linear motor control by local learning in spiking neural networks,Wulfram Gerstner,EPFL
ICML,2018,Implicit Quantile Networks for Distributional Reinforcement Learning,Will Dabney,DeepMind
ICML,2018,Implicit Quantile Networks for Distributional Reinforcement Learning,Georg Ostrovski,DeepMind
ICML,2018,Implicit Quantile Networks for Distributional Reinforcement Learning,David Silver,Google DeepMind
ICML,2018,Implicit Quantile Networks for Distributional Reinforcement Learning,Remi Munos,DeepMind
ICML,2018,An Inference-Based Policy Gradient Method for Learning Options,Matthew Smith,McGill University
ICML,2018,An Inference-Based Policy Gradient Method for Learning Options,Herke van Hoof,McGill University
ICML,2018,An Inference-Based Policy Gradient Method for Learning Options,Joelle Pineau,McGill University / Facebook
ICML,2018,Predict and Constrain: Modeling Cardinality in Deep Structured Prediction,Nataly Brukhim,Tel Aviv University
ICML,2018,Predict and Constrain: Modeling Cardinality in Deep Structured Prediction,Amir Globerson,"Tel Aviv University, Google"
ICML,2018,Differentially Private Matrix Completion Revisited,Prateek Jain,Microsoft Research
ICML,2018,Differentially Private Matrix Completion Revisited,Om Thakkar,Boston University
ICML,2018,Differentially Private Matrix Completion Revisited,Abhradeep Thakurta,UCSC
ICML,2018,Differentiable plasticity: training plastic neural networks with backpropagation,Thomas Miconi,Uber AI Labs
ICML,2018,Differentiable plasticity: training plastic neural networks with backpropagation,Ken Stanley,Uber AI Labs & University of Central Florida
ICML,2018,Differentiable plasticity: training plastic neural networks with backpropagation,Jeff Clune,Uber AI Labs
ICML,2018,Model-Level Dual Learning,Yingce Xia,University of Science and Technology of China
ICML,2018,Model-Level Dual Learning,Xu Tan,Microsoft Research
ICML,2018,Model-Level Dual Learning,Fei Tian,Microsoft Research
ICML,2018,Model-Level Dual Learning,Tao Qin,Microsoft Research Asia
ICML,2018,Model-Level Dual Learning,Nenghai Yu,USTC
ICML,2018,Model-Level Dual Learning,Tie-Yan Liu,Microsoft
ICML,2018,CoVeR: Learning Covariate-Specific Vector Representations with Tensor Decompositions,Kevin Tian,Stanford University
ICML,2018,CoVeR: Learning Covariate-Specific Vector Representations with Tensor Decompositions,Teng Zhang,Stanford University
ICML,2018,CoVeR: Learning Covariate-Specific Vector Representations with Tensor Decompositions,James Zou,Stanford University
ICML,2018,Tree Edit Distance Learning via Adaptive Symbol Embeddings,Benjamin Paaßen,Bielefeld University
ICML,2018,Tree Edit Distance Learning via Adaptive Symbol Embeddings,Claudio Gallicchio,University of Pisa
ICML,2018,Tree Edit Distance Learning via Adaptive Symbol Embeddings,Alessio Micheli,Universita di Pisa
ICML,2018,Tree Edit Distance Learning via Adaptive Symbol Embeddings,CITEC Barbara Hammer,"CITEC, Bielefeld University"
ICML,2018,Gradually Updated Neural Networks for Large-Scale Image Recognition,Siyuan Qiao,Johns Hopkins University
ICML,2018,Gradually Updated Neural Networks for Large-Scale Image Recognition,Zhishuai Zhang,Johns Hopkins University
ICML,2018,Gradually Updated Neural Networks for Large-Scale Image Recognition,Wei Shen,Shanghai University
ICML,2018,Gradually Updated Neural Networks for Large-Scale Image Recognition,Bo Wang,Hikvision Research Institue
ICML,2018,Gradually Updated Neural Networks for Large-Scale Image Recognition,Alan Yuille,Johns Hopkins University
ICML,2018,One-Shot Segmentation in Clutter,Claudio Michaelis,Universty of Tübingen
ICML,2018,One-Shot Segmentation in Clutter,Matthias Bethge,University of Tübingen
ICML,2018,One-Shot Segmentation in Clutter,Alexander Ecker,University of Tübingen
ICML,2018,Active Testing: An Efficient and Robust Framework for Estimating Accuracy,Phuc Nguyen,UC Irvine
ICML,2018,Active Testing: An Efficient and Robust Framework for Estimating Accuracy,Deva Ramanan,Carnegie Mellon University
ICML,2018,Active Testing: An Efficient and Robust Framework for Estimating Accuracy,Charless Fowlkes,UC Irvine
ICML,2018,Learning Deep ResNet Blocks Sequentially using Boosting Theory,Furong Huang,University of Maryland College Park
ICML,2018,Learning Deep ResNet Blocks Sequentially using Boosting Theory,Jordan Ash,Princeton University
ICML,2018,Learning Deep ResNet Blocks Sequentially using Boosting Theory,John Langford,Microsoft Research
ICML,2018,Learning Deep ResNet Blocks Sequentially using Boosting Theory,Robert Schapire,Microsoft Research
ICML,2018,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,JD Co-Reyes,UC Berkeley
ICML,2018,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,Yu Xuan Liu,"University of California, Berkeley"
ICML,2018,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,Abhishek Gupta,UC Berkeley
ICML,2018,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,Benjamin Eysenbach,Google
ICML,2018,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2018,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,Sergey Levine,Berkeley
ICML,2018,Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs,Andrea Zanette,Stanford University
ICML,2018,Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs,Emma Brunskill,Stanford University
ICML,2018,Stochastic PCA with $\ell_2$ and $\ell_1$ Regularization,Poorya Mianjy,Johns Hopkins University
ICML,2018,Stochastic PCA with $\ell_2$ and $\ell_1$ Regularization,Raman Arora,Johns Hopkins University
ICML,2018,Subspace Embedding and Linear Regression with Orlicz Norm,Alexandr Andoni,
ICML,2018,Subspace Embedding and Linear Regression with Orlicz Norm,Chengyu Lin,Columbia University
ICML,2018,Subspace Embedding and Linear Regression with Orlicz Norm,Ying Sheng,
ICML,2018,Subspace Embedding and Linear Regression with Orlicz Norm,Peilin Zhong,Columbia University
ICML,2018,Subspace Embedding and Linear Regression with Orlicz Norm,Ruiqi Zhong,Columbia University in the City of New York
ICML,2018,Signal and  Noise Statistics Oblivious Orthogonal Matching Pursuit,Sreejith Kallummil,Qualcomm India Private Limited
ICML,2018,Signal and  Noise Statistics Oblivious Orthogonal Matching Pursuit,Sheetal Kalyani,IIT Madras
ICML,2018,Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope,Eric Wong,Carnegie Mellon University
ICML,2018,Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope,Zico Kolter,Carnegie Mellon University
ICML,2018,Learning the Reward Function for a Misspecified Model,Erik Talvitie,Franklin & Marshall College
ICML,2018,Deep Reinforcement Learning in Continuous Action Spaces: a Case Study in the Game of Simulated Curling,kyowoon Lee,UNIST
ICML,2018,Deep Reinforcement Learning in Continuous Action Spaces: a Case Study in the Game of Simulated Curling,Sol-A Kim,UNIST
ICML,2018,Deep Reinforcement Learning in Continuous Action Spaces: a Case Study in the Game of Simulated Curling,Jaesik Choi,Ulsan National Institute of Science and Technology
ICML,2018,Deep Reinforcement Learning in Continuous Action Spaces: a Case Study in the Game of Simulated Curling,Seong-Whan Lee,Korea University
ICML,2018,Do Outliers Ruin Collaboration?,Mingda Qiao,"IIIS, Tsinghua University"
ICML,2018,"Dropout Training, Data-dependent Regularization, and Generalization Bounds",Wenlong Mou,UC Berkeley
ICML,2018,"Dropout Training, Data-dependent Regularization, and Generalization Bounds",Yuchen Zhou,"University of Wisconsin, Madison"
ICML,2018,"Dropout Training, Data-dependent Regularization, and Generalization Bounds",Jun Gao,Peking University
ICML,2018,"Dropout Training, Data-dependent Regularization, and Generalization Bounds",Liwei Wang,Peking University
ICML,2018,Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations,IEMS Xingyu Wang,"IEMS, Northwestern University"
ICML,2018,Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations,Diego Klabjan,Northwestern University
ICML,2018,Continual Reinforcement Learning with Complex Synapses,Christos Kaplanis,Imperial College London
ICML,2018,Continual Reinforcement Learning with Complex Synapses,Murray Shanahan,Imperial College London
ICML,2018,Continual Reinforcement Learning with Complex Synapses,Claudia Clopath,Imperial College London
ICML,2018,Equivalence of Multicategory SVM and Simplex Cone SVM: Fast Computations and Statistical Theory,Guillaume Pouliot,University of Chicago
ICML,2018,Quickshift++: Provably Good Initializations for Sample-Based Mean Shift,Heinrich Jiang,Google
ICML,2018,Quickshift++: Provably Good Initializations for Sample-Based Mean Shift,Jennifer Jang,Uber
ICML,2018,Quickshift++: Provably Good Initializations for Sample-Based Mean Shift,Samory Kpotufe,Princeton University
ICML,2018,Learning Diffusion using Hyperparameters,Dimitris Kalimeris,Harvard University
ICML,2018,Learning Diffusion using Hyperparameters,Yaron Singer,Harvard
ICML,2018,Learning Diffusion using Hyperparameters,Karthik Subbian,Facebook
ICML,2018,Learning Diffusion using Hyperparameters,Udi Weinsberg,Facebook
ICML,2018,Learning a Mixture of Two Multinomial Logits,Flavio Chierichetti,Sapienza University
ICML,2018,Learning a Mixture of Two Multinomial Logits,Ravi Kumar,Google
ICML,2018,Learning a Mixture of Two Multinomial Logits,Andrew Tomkins,Google
ICML,2018,Crowdsourcing with Arbitrary Adversaries,Matthäus Kleindessner,Rutgers University
ICML,2018,Crowdsourcing with Arbitrary Adversaries,Pranjal Awasthi,Rutgers University
ICML,2018,Deep Density Destructors,David Inouye,Carnegie Mellon University
ICML,2018,Deep Density Destructors,Pradeep Ravikumar,Carnegie Mellon University
ICML,2018,Programmatically Interpretable Reinforcement Learning,Abhinav Verma,Rice University
ICML,2018,Programmatically Interpretable Reinforcement Learning,Vijayaraghavan Murali,Rice University
ICML,2018,Programmatically Interpretable Reinforcement Learning,Rishabh Singh,Google Brain
ICML,2018,Programmatically Interpretable Reinforcement Learning,Pushmeet Kohli,DeepMind
ICML,2018,Programmatically Interpretable Reinforcement Learning,Swarat Chaudhuri,Rice University
ICML,2018,Structured Evolution with Compact Architectures for Scalable Policy Optimization,Krzysztof Choromanski,Google Brain Robotics
ICML,2018,Structured Evolution with Compact Architectures for Scalable Policy Optimization,Mark Rowland,University of Cambridge
ICML,2018,Structured Evolution with Compact Architectures for Scalable Policy Optimization,Vikas Sindhwani,Google
ICML,2018,Structured Evolution with Compact Architectures for Scalable Policy Optimization,Richard E Turner,University of Cambridge
ICML,2018,Structured Evolution with Compact Architectures for Scalable Policy Optimization,Adrian Weller,"University of Cambridge, Alan Turing Institute"
ICML,2018,The Weighted Kendall and High-order Kernels for Permutations,Yunlong Jiao,University of Oxford
ICML,2018,The Weighted Kendall and High-order Kernels for Permutations,JP Vert,ENS Paris
ICML,2018,"The Limits of Maxing, Ranking, and Preference Learning",Moein Falahatgar,UC San Diego
ICML,2018,"The Limits of Maxing, Ranking, and Preference Learning",Ayush Jain,UC San Diego
ICML,2018,"The Limits of Maxing, Ranking, and Preference Learning",Alon Orlitsky,UCSD
ICML,2018,"The Limits of Maxing, Ranking, and Preference Learning",Venkatadheeraj Pichapati,University of California San Diego
ICML,2018,"The Limits of Maxing, Ranking, and Preference Learning",Vaishakh Ravindrakumar,UC San Diego
ICML,2018,Black Box FDR,Wesley Tansey,Columbia University
ICML,2018,Black Box FDR,Yixin Wang,Columbia University
ICML,2018,Black Box FDR,David Blei,Columbia University
ICML,2018,Black Box FDR,Raul Rabadan,Columbia University Medical Center
ICML,2018,Variable Selection via Penalized Neural Network: a Drop-Out-One Loss Approach,Mao Ye,PURDUE UNIVERSITY
ICML,2018,Variable Selection via Penalized Neural Network: a Drop-Out-One Loss Approach,Yan Sun,Purdue University
ICML,2018,Clustering Semi-Random Mixtures of Gaussians,Aravindan Vijayaraghavan,
ICML,2018,Clustering Semi-Random Mixtures of Gaussians,Pranjal Awasthi,Rutgers University
ICML,2018,Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski $p$-Norms,Charlie Dickens,Alan Turing Institute & University of Warwick
ICML,2018,Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski $p$-Norms,Graham Cormode,University of Warwick
ICML,2018,Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski $p$-Norms,David Woodruff,Carnegie Mellon University
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Martin Riedmiller,DeepMind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Roland Hafner,DeepMind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Thomas Lampe,DeepMind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Michael Neunert,Google DeepMind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Jonas Degrave,Google
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Tom Van de Wiele,DeepMind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Vlad Mnih,Google Deepmind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Nicolas Heess,Google DeepMind
ICML,2018,Learning by Playing - Solving Sparse Reward Tasks from Scratch,Jost Springenberg,DeepMind
ICML,2018,Structured Control Nets for Deep Reinforcement Learning,Mario Srouji,Carnegie Mellon University
ICML,2018,Structured Control Nets for Deep Reinforcement Learning,Jian Zhang,Apple Inc.
ICML,2018,Structured Control Nets for Deep Reinforcement Learning,Russ Salakhutdinov,Carnegie Mellen University
ICML,2018,Stagewise Safe Bayesian Optimization with Gaussian Processes,Yanan Sui,Caltech / Stanford
ICML,2018,Stagewise Safe Bayesian Optimization with Gaussian Processes,Vincent Zhuang,Caltech
ICML,2018,Stagewise Safe Bayesian Optimization with Gaussian Processes,Joel Burdick,Caltech
ICML,2018,Stagewise Safe Bayesian Optimization with Gaussian Processes,Yisong Yue,Caltech
ICML,2018,Bayesian Optimization of Combinatorial Structures,Ricardo Baptista,Massachusetts Institute of Technology
ICML,2018,Bayesian Optimization of Combinatorial Structures,Matthias Poloczek,University of Arizona
ICML,2018,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,Jiaxuan You,Stanford University
ICML,2018,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,Zhitao Ying,Stanford University
ICML,2018,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,Xiang Ren,University of Southern California
ICML,2018,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,Will Hamilton,Stanford University
ICML,2018,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,Jure Leskovec,Stanford University
ICML,2018,Dependent Relational Gamma Process Models for Longitudinal Networks,Sikun Yang,TU Darmstadt
ICML,2018,Dependent Relational Gamma Process Models for Longitudinal Networks,Heinz Koeppl,TU Darmstadt
ICML,2018,K-means clustering using random matrix sparsification,Kaushik Sinha,Wichita State University
ICML,2018,Hierarchical Clustering with Structural Constraints,Vaggos Chatziafratis,Stanford University
ICML,2018,Hierarchical Clustering with Structural Constraints,Niazadeh Niazadeh,Stanford University
ICML,2018,Hierarchical Clustering with Structural Constraints,Moses Charikar,Stanford University
ICML,2018,Kronecker Recurrent Units,Cijo Jose,Idiap Research Institute
ICML,2018,Kronecker Recurrent Units,Moustapha Cisse,Google
ICML,2018,Kronecker Recurrent Units,Francois Fleuret,Idiap research institute
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Konstantinos Kamnitsas,Imperial College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Daniel C. Castro,Imperial College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Loic Le Folgoc,Imperial College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Ian Walker,Imperial College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Ryutaro Tanno,University College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Daniel Rueckert,Imperial College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Ben Glocker,Imperial College London
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Antonio Criminisi,Microsoft
ICML,2018,Semi-Supervised Learning via Compact Latent Space Clustering,Aditya Nori,Microsoft Research Cambridge
ICML,2018,Dynamic Evaluation of Neural Sequence Models,Ben Krause,University of Edinburgh
ICML,2018,Dynamic Evaluation of Neural Sequence Models,Emmanuel Kahembwe,Edinburgh University
ICML,2018,Dynamic Evaluation of Neural Sequence Models,Iain Murray,University of Edinburgh
ICML,2018,Dynamic Evaluation of Neural Sequence Models,Steve Renals,University of Edinburgh
ICML,2018,TACO: Learning Task Decomposition via Temporal Alignment for Control,Kyriacos Shiarlis,University of Amsterdam
ICML,2018,TACO: Learning Task Decomposition via Temporal Alignment for Control,Markus Wulfmeier,University of Oxford
ICML,2018,TACO: Learning Task Decomposition via Temporal Alignment for Control,Sasha Salter,University of Oxford
ICML,2018,TACO: Learning Task Decomposition via Temporal Alignment for Control,Shimon Whiteson,University of Oxford
ICML,2018,TACO: Learning Task Decomposition via Temporal Alignment for Control,Ingmar Posner,University of Oxford
ICML,2018,A Spectral Approach to Gradient Estimation for Implicit Distributions,Jiaxin Shi,Tsinghua University
ICML,2018,A Spectral Approach to Gradient Estimation for Implicit Distributions,Shengyang Sun,University of Toronto
ICML,2018,A Spectral Approach to Gradient Estimation for Implicit Distributions,Jun Zhu,Tsinghua University
ICML,2018,Quasi-Monte Carlo Variational Inference,Alexander Buchholz,ENSAE-CREST Paris
ICML,2018,Quasi-Monte Carlo Variational Inference,Florian Wenzel,University of Kaiserslautern
ICML,2018,Quasi-Monte Carlo Variational Inference,Stephan Mandt,Disney Research
ICML,2018,Learning to Optimize Combinatorial Functions,Nir Rosenfeld,Harvard University
ICML,2018,Learning to Optimize Combinatorial Functions,Eric Balkanski,Harvard
ICML,2018,Learning to Optimize Combinatorial Functions,Amir Globerson,"Tel Aviv University, Google"
ICML,2018,Learning to Optimize Combinatorial Functions,Yaron Singer,Harvard
ICML,2018,"Proportional Allocation: Simple, Distributed, and Diverse Matching with High Entropy",Shipra Agarwal,Columbia
ICML,2018,"Proportional Allocation: Simple, Distributed, and Diverse Matching with High Entropy",Morteza Zadimoghaddam,Google
ICML,2018,"Proportional Allocation: Simple, Distributed, and Diverse Matching with High Entropy",Vahab Mirrokni,Google Research
ICML,2018,Representation Learning on Graphs with Jumping Knowledge Networks,Keyulu Xu,MIT
ICML,2018,Representation Learning on Graphs with Jumping Knowledge Networks,Chengtao Li,MIT
ICML,2018,Representation Learning on Graphs with Jumping Knowledge Networks,Yonglong Tian,MIT
ICML,2018,Representation Learning on Graphs with Jumping Knowledge Networks,Tomohiro Sonobe,National Institute of Informatics
ICML,2018,Representation Learning on Graphs with Jumping Knowledge Networks,Ken-ichi Kawarabayashi,National Institute of Informatics
ICML,2018,Representation Learning on Graphs with Jumping Knowledge Networks,Stefanie Jegelka,MIT
ICML,2018,NetGAN: Generating Graphs via Random Walks,Aleksandar Bojchevski,Technical University of Munich
ICML,2018,NetGAN: Generating Graphs via Random Walks,Oleksandr Shchur,Technical University of Munich
ICML,2018,NetGAN: Generating Graphs via Random Walks,Daniel Zügner,Technical University of Munich
ICML,2018,NetGAN: Generating Graphs via Random Walks,Stephan Günnemann,Technical University of Munich
ICML,2018,INSPECTRE: Privately Estimating the Unseen,Jayadev Acharya,Cornell University
ICML,2018,INSPECTRE: Privately Estimating the Unseen,Gautam Kamath,MIT
ICML,2018,INSPECTRE: Privately Estimating the Unseen,Ziteng Sun,Cornell University
ICML,2018,INSPECTRE: Privately Estimating the Unseen,Huanyu Zhang,Cornell University
ICML,2018,Locally Private Hypothesis Testing,Or Sheffet,University of Alberta
ICML,2018,Latent Space Policies for Hierarchical Reinforcement Learning,Tuomas Haarnoja,UC Berkeley
ICML,2018,Latent Space Policies for Hierarchical Reinforcement Learning,Kristian Hartikainen,UC Berkeley
ICML,2018,Latent Space Policies for Hierarchical Reinforcement Learning,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2018,Latent Space Policies for Hierarchical Reinforcement Learning,Sergey Levine,Berkeley
ICML,2018,More Robust Doubly Robust Off-policy Evaluation,Mehrdad Farajtabar,Georgia Tech
ICML,2018,More Robust Doubly Robust Off-policy Evaluation,Yinlam Chow,DeepMind
ICML,2018,More Robust Doubly Robust Off-policy Evaluation,Mohammad Ghavamzadeh,Google DeepMind and INRIA
ICML,2018,Learning to Explain: An Information-Theoretic Perspective on Model Interpretation,Jianbo Chen,"University of California, Berkeley"
ICML,2018,Learning to Explain: An Information-Theoretic Perspective on Model Interpretation,Le Song,Georgia Institute of Technology
ICML,2018,Learning to Explain: An Information-Theoretic Perspective on Model Interpretation,Martin Wainwright,University of California at Berkeley
ICML,2018,Learning to Explain: An Information-Theoretic Perspective on Model Interpretation,Michael Jordan,UC Berkeley
ICML,2018,End-to-end Active Object Tracking via Reinforcement Learning,Wenhan Luo,Tencent AI Lab
ICML,2018,End-to-end Active Object Tracking via Reinforcement Learning,Peng Sun,Tencent AI Lab
ICML,2018,End-to-end Active Object Tracking via Reinforcement Learning,Fangwei Zhong,Peking University
ICML,2018,End-to-end Active Object Tracking via Reinforcement Learning,Wei Liu,Tencent AI Lab
ICML,2018,End-to-end Active Object Tracking via Reinforcement Learning,Tong Zhang,Tecent AI Lab
ICML,2018,End-to-end Active Object Tracking via Reinforcement Learning,Yizhou Wang,Peking University
ICML,2018,Efficient and Consistent Adversarial Bipartite Matching,Rizal Fathony,University of Illinois at Chicago
ICML,2018,Efficient and Consistent Adversarial Bipartite Matching,Sima Behpour,University of Illinois at Chicago
ICML,2018,Efficient and Consistent Adversarial Bipartite Matching,Xinhua Zhang,University of Illinois at Chicago
ICML,2018,Efficient and Consistent Adversarial Bipartite Matching,Brian Ziebart,University of Illinois at Chicago
ICML,2018,SparseMAP: Differentiable Sparse Structured Inference,Vlad Niculae,Cornell University
ICML,2018,SparseMAP: Differentiable Sparse Structured Inference,Andre Filipe Torres Martins,Instituto de Telecomunicacoes
ICML,2018,SparseMAP: Differentiable Sparse Structured Inference,Mathieu Blondel,NTT
ICML,2018,SparseMAP: Differentiable Sparse Structured Inference,Claire Cardie,Cornell University
ICML,2018,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,Luca Franceschi,Istituto Italiano di Tecnologia - University College London
ICML,2018,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,Paolo Frasconi,University of Florence
ICML,2018,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,Saverio Salzo,Istituto Italiano di Tecnologia
ICML,2018,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,Riccardo Grazzi,Istituto Italiano di Tecnologia
ICML,2018,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,Massimiliano Pontil,University College London
ICML,2018,Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory,Ron Amit,Technion – Israel Institute of Technology
ICML,2018,Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory,Ron Meir,Technion Israeli Institute of Technology
ICML,2018,Parameterized Algorithms for the Matrix Completion Problem,Robert Ganian,TU Wien
ICML,2018,Parameterized Algorithms for the Matrix Completion Problem,DePaul Iyad Kanj,"DePaul University, Chicago"
ICML,2018,Parameterized Algorithms for the Matrix Completion Problem,Sebastian Ordyniak,University of Sheffield
ICML,2018,Parameterized Algorithms for the Matrix Completion Problem,Stefan Szeider,TU Wien
ICML,2018,Nearly Optimal Robust Subspace Tracking,Praneeth Narayanamurthy,Iowa State University
ICML,2018,Nearly Optimal Robust Subspace Tracking,Namrata Vaswani,Iowa State University
ICML,2018,Katyusha X: Simple Momentum Method for Stochastic Sum-of-Nonconvex Optimization,Zeyuan Allen-Zhu,Microsoft Research AI
ICML,2018,signSGD: Compressed Optimisation for Non-Convex Problems,Jeremy Bernstein,Caltech
ICML,2018,signSGD: Compressed Optimisation for Non-Convex Problems,Yu-Xiang Wang,Amazon / UCSB
ICML,2018,signSGD: Compressed Optimisation for Non-Convex Problems,Kamyar Azizzadenesheli,UC Irvine/ Stanford
ICML,2018,signSGD: Compressed Optimisation for Non-Convex Problems,Anima Anandkumar,Amazon
ICML,2018,Synthesizing Robust Adversarial Examples,Anish Athalye,MIT CSAIL
ICML,2018,Synthesizing Robust Adversarial Examples,Logan Engstrom,MIT
ICML,2018,Synthesizing Robust Adversarial Examples,Andrew Ilyas,Massachusetts Institute of Technology
ICML,2018,Synthesizing Robust Adversarial Examples,Kevin Kwok,LabSix
ICML,2018,Differentiable Abstract Interpretation for Provably Robust Neural Networks,Matthew Mirman,ETH Zürich
ICML,2018,Differentiable Abstract Interpretation for Provably Robust Neural Networks,Timon Gehr,ETH Zurich
ICML,2018,Differentiable Abstract Interpretation for Provably Robust Neural Networks,Martin Vechev,ETH Zurich
ICML,2018,Stochastic Training of Graph Convolutional Networks with Variance Reduction,Jianfei Chen,Tsinghua University
ICML,2018,Stochastic Training of Graph Convolutional Networks with Variance Reduction,Jun Zhu,Tsinghua University
ICML,2018,Stochastic Training of Graph Convolutional Networks with Variance Reduction,Le Song,Georgia Institute of Technology
ICML,2018,Neural Relational Inference for Interacting Systems,Thomas Kipf,University of Amsterdam
ICML,2018,Neural Relational Inference for Interacting Systems,Ethan Fetaya,University of Toronto
ICML,2018,Neural Relational Inference for Interacting Systems,Jackson Wang,Univeristy of Toronto
ICML,2018,Neural Relational Inference for Interacting Systems,Max Welling,University of Amsterdam
ICML,2018,Neural Relational Inference for Interacting Systems,Richard Zemel,Vector Institute
ICML,2018,Which Training Methods for GANs do actually Converge?,Lars Mescheder,MPI Tübingen
ICML,2018,Which Training Methods for GANs do actually Converge?,Andreas Geiger,MPI-IS and University of Tuebingen
ICML,2018,Which Training Methods for GANs do actually Converge?,Sebastian Nowozin,Microsoft Research
ICML,2018,Learning Independent Causal Mechanisms,Giambattista Parascandolo,Max Planck Institute for Intelligent Systems and ETH Zurich
ICML,2018,Learning Independent Causal Mechanisms,Niki Kilbertus,MPI Tübingen & Cambridge
ICML,2018,Learning Independent Causal Mechanisms,Mateo Rojas-Carulla,Cambridge/MPI
ICML,2018,Learning Independent Causal Mechanisms,Bernhard Schölkopf,"MPI for Intelligent Systems Tübingen, Germany"
ICML,2018,Nonconvex Optimization for Regression with Fairness Constraints,Junpei Komiyama,U-Tokyo
ICML,2018,Nonconvex Optimization for Regression with Fairness Constraints,Akiko Takeda,The Institute of Statistical Mathematics
ICML,2018,Nonconvex Optimization for Regression with Fairness Constraints,Junya Honda,University of Tokyo / RIKEN
ICML,2018,Nonconvex Optimization for Regression with Fairness Constraints,Hajime Shimao,Purdue University
ICML,2018,Fairness Without Demographics in Repeated Loss Minimization,Tatsunori Hashimoto,Stanford
ICML,2018,Fairness Without Demographics in Repeated Loss Minimization,Megha Srivastava,Stanford University
ICML,2018,Fairness Without Demographics in Repeated Loss Minimization,Hongseok Namkoong,Stanford University
ICML,2018,Fairness Without Demographics in Repeated Loss Minimization,Percy Liang,Stanford University
ICML,2018,MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,Bo Zhao,Peking University
ICML,2018,MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,Xinwei Sun,Peking University
ICML,2018,MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,Yanwei Fu,Fudan university
ICML,2018,MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,Yuan Yao,Hong Kong Science Tech
ICML,2018,MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,Yizhou Wang,Peking University
ICML,2018,Nonoverlap-Promoting Variable Selection,Pengtao Xie,Carnegie Mellon University
ICML,2018,Nonoverlap-Promoting Variable Selection,Hongbao Zhang,Petuum Inc
ICML,2018,Nonoverlap-Promoting Variable Selection,Yichen Zhu,Peking University
ICML,2018,Nonoverlap-Promoting Variable Selection,Eric Xing,Carnegie Mellon University
ICML,2018,Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication,Zebang Shen,Zhejiang University
ICML,2018,Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication,Aryan Mokhtari,MIT
ICML,2018,Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication,Tengfei Zhou,Zhejiang University
ICML,2018,Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication,Peilin Zhao,"Artificial Intelligence Department, Ant ​Financial"
ICML,2018,Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication,Hui Qian,Zhejiang University
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Alvaro Sanchez,DeepMind
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Nicolas Heess,Google DeepMind
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Jost Springenberg,DeepMind
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Josh Merel,DeepMind
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Martin Riedmiller,DeepMind
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Raia Hadsell,DeepMind
ICML,2018,Graph Networks as Learnable Physics Engines for Inference and Control,Peter Battaglia,DeepMind
ICML,2018,An Alternative View: When Does SGD Escape Local Minima?,Bobby Kleinberg,Cornell
ICML,2018,An Alternative View: When Does SGD Escape Local Minima?,Yuanzhi Li,Princeton University
ICML,2018,An Alternative View: When Does SGD Escape Local Minima?,Yang Yuan,Cornell University
ICML,2018,Asynchronous Decentralized Parallel Stochastic Gradient Descent,Xiangru Lian,University of Rochester
ICML,2018,Asynchronous Decentralized Parallel Stochastic Gradient Descent,Wei Zhang,IBM Research
ICML,2018,Asynchronous Decentralized Parallel Stochastic Gradient Descent,Ce Zhang,ETH Zurich
ICML,2018,Asynchronous Decentralized Parallel Stochastic Gradient Descent,Ji Liu,University of Rochester
ICML,2018,An Estimation and Analysis Framework for the Rasch Model,Andrew Lan,Princeton University
ICML,2018,An Estimation and Analysis Framework for the Rasch Model,Mung Chiang,Purdue University
ICML,2018,An Estimation and Analysis Framework for the Rasch Model,Christoph Studer,Cornell University
ICML,2018,Mitigating Bias in Adaptive Data Gathering via Differential Privacy,Seth V Neel,University of Pennsylvania
ICML,2018,Mitigating Bias in Adaptive Data Gathering via Differential Privacy,Aaron Roth,University of Pennsylvania
ICML,2018,Local Private Hypothesis Testing: Chi-Square Tests,Marco Gaboardi,Univeristy at Buffalo
ICML,2018,Local Private Hypothesis Testing: Chi-Square Tests,Ryan Rogers,Apple
ICML,2018,Disentangling by Factorising,Hyunjik Kim,"DeepMind, University of Oxford"
ICML,2018,Disentangling by Factorising,Andriy Mnih,DeepMind
ICML,2018,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning,Ronan Fruit,Inria Lille Nord-Europe
ICML,2018,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning,Matteo Pirotta,SequeL - Inria Lille - Nord Europe
ICML,2018,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning,Alessandro Lazaric,Facebook AI Research
ICML,2018,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning,Ronald Ortner,Montanuniversitaet Leoben
ICML,2018,Learning to search with MCTSnets,Arthur Guez,Google DeepMind
ICML,2018,Learning to search with MCTSnets,Theo Weber,DeepMind
ICML,2018,Learning to search with MCTSnets,Ioannis Antonoglou,Deepmind
ICML,2018,Learning to search with MCTSnets,Karen Simonyan,DeepMind
ICML,2018,Learning to search with MCTSnets,Oriol Vinyals,DeepMind
ICML,2018,Learning to search with MCTSnets,Daan Wierstra,Google DeepMind
ICML,2018,Learning to search with MCTSnets,Remi Munos,DeepMind
ICML,2018,Learning to search with MCTSnets,David Silver,Google DeepMind
ICML,2018,Decoupled Parallel Backpropagation with Convergence Guarantee,Zhouyuan Huo,University of Pittsburgh
ICML,2018,Decoupled Parallel Backpropagation with Convergence Guarantee,Bin Gu,University of Pittsburgh
ICML,2018,Decoupled Parallel Backpropagation with Convergence Guarantee,Qian Yang,University of Pittsburgh
ICML,2018,Decoupled Parallel Backpropagation with Convergence Guarantee,Heng Huang,University of Pittsburgh
ICML,2018,On Learning Sparsely Used Dictionaries from Incomplete Samples,Thanh Nguyen,Iowa State University
ICML,2018,On Learning Sparsely Used Dictionaries from Incomplete Samples,Akshay Soni,Yahoo Research
ICML,2018,On Learning Sparsely Used Dictionaries from Incomplete Samples,Chinmay Hegde,Iowa State University
ICML,2018,Variational Network Inference: Strong and Stable with Concrete Support,Amir Dezfouli,UNSW
ICML,2018,Variational Network Inference: Strong and Stable with Concrete Support,Edwin Bonilla,UNSW
ICML,2018,Variational Network Inference: Strong and Stable with Concrete Support,Richard Nock,"Data61, The Australian National University and the University of Sydney"
ICML,2018,Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?,Lin Chen,Yale University
ICML,2018,Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?,Moran Feldman,The Open University of Israel
ICML,2018,Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?,Amin Karbasi,Yale
ICML,2018,Data Summarization at Scale: A Two-Stage Submodular Approach,Marko Mitrovic,Yale University
ICML,2018,Data Summarization at Scale: A Two-Stage Submodular Approach,Ehsan Kazemi,Yale
ICML,2018,Data Summarization at Scale: A Two-Stage Submodular Approach,Morteza Zadimoghaddam,Google
ICML,2018,Data Summarization at Scale: A Two-Stage Submodular Approach,Amin Karbasi,Yale
ICML,2018,Best Arm Identification in Linear Bandits with Linear Dimension Dependency,Chao Tao,Indiana University Bloomington
ICML,2018,Best Arm Identification in Linear Bandits with Linear Dimension Dependency,Saúl A. Blanco,Indiana University
ICML,2018,Best Arm Identification in Linear Bandits with Linear Dimension Dependency,Yuan Zhou,Indiana University Bloomington
ICML,2018,Learning with Abandonment,Sven Schmit,Stanford University
ICML,2018,Learning with Abandonment,Ramesh Johari,Stanford University
ICML,2018,Hyperbolic Entailment Cones for Learning Hierarchical Embeddings,Octavian-Eugen Ganea,ETH Zurich
ICML,2018,Hyperbolic Entailment Cones for Learning Hierarchical Embeddings,Gary Becigneul,ETHZ
ICML,2018,Hyperbolic Entailment Cones for Learning Hierarchical Embeddings,Thomas Hofmann,ETH Zurich
ICML,2018,Generative Temporal Models with Spatial Memory for Partially Observed Environments,Marco Fraccaro,Technical University of Denmark
ICML,2018,Generative Temporal Models with Spatial Memory for Partially Observed Environments,Danilo J. Rezende,DeepMind
ICML,2018,Generative Temporal Models with Spatial Memory for Partially Observed Environments,Yori Zwols,DeepMind
ICML,2018,Generative Temporal Models with Spatial Memory for Partially Observed Environments,Alexander Pritzel,Deepmind
ICML,2018,Generative Temporal Models with Spatial Memory for Partially Observed Environments,S. M. Ali Eslami,DeepMind
ICML,2018,Generative Temporal Models with Spatial Memory for Partially Observed Environments,Fabio Viola,DeepMind
ICML,2018,DiCE: The Infinitely Differentiable Monte Carlo Estimator,Jakob Foerster,University of Oxford
ICML,2018,DiCE: The Infinitely Differentiable Monte Carlo Estimator,Gregory Farquhar,University of Oxford
ICML,2018,DiCE: The Infinitely Differentiable Monte Carlo Estimator,Maruan Al-Shedivat,Carnegie Mellon University
ICML,2018,DiCE: The Infinitely Differentiable Monte Carlo Estimator,Tim Rocktäschel,University of Oxford
ICML,2018,DiCE: The Infinitely Differentiable Monte Carlo Estimator,Eric Xing,Carnegie Mellon University
ICML,2018,DiCE: The Infinitely Differentiable Monte Carlo Estimator,Shimon Whiteson,University of Oxford
ICML,2018,Orthogonal Recurrent Neural Networks with Scaled Cayley Transform,Kyle Helfrich,University of Kentucky
ICML,2018,Orthogonal Recurrent Neural Networks with Scaled Cayley Transform,Devin Willmott,University of Kentucky
ICML,2018,Orthogonal Recurrent Neural Networks with Scaled Cayley Transform,Qiang Ye,University of Kentucky
ICML,2018,Least-Squares Temporal Difference Learning for the Linear Quadratic Regulator,Stephen Tu,UC Berkeley
ICML,2018,Least-Squares Temporal Difference Learning for the Linear Quadratic Regulator,Benjamin Recht,Berkeley
ICML,2018,Spotlight: Optimizing Device Placement for Training Deep Neural Networks,Yuanxiang Gao,University of Toronto
ICML,2018,Spotlight: Optimizing Device Placement for Training Deep Neural Networks,Li Chen,"Department of Electrical and Computer Engineering, University of Toronto"
ICML,2018,Spotlight: Optimizing Device Placement for Training Deep Neural Networks,Baochun Li,University of Toronto
ICML,2018,Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control,Aravind Srinivas,UC Berkeley
ICML,2018,Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control,Allan Jabri,UC Berkeley
ICML,2018,Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2018,Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control,Sergey Levine,Berkeley
ICML,2018,Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control,Chelsea Finn,UC Berkeley
ICML,2018,Coordinated Exploration in Concurrent Reinforcement Learning,Maria Dimakopoulou,Stanford
ICML,2018,Coordinated Exploration in Concurrent Reinforcement Learning,Benjamin Van Roy,Stanford University
ICML,2018,A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks,Akifumi Okuno,Kyoto University / RIKEN AIP
ICML,2018,A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks,Tetsuya Hada,Recruit Technologies Co. Ltd.
ICML,2018,A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks,Hidetoshi Shimodaira,Kyoto University / RIKEN AIP
ICML,2018,Learning Steady-States of Iterative Algorithms over Graphs,Hanjun Dai,Georgia Tech
ICML,2018,Learning Steady-States of Iterative Algorithms over Graphs,Zornitsa Kozareva,
ICML,2018,Learning Steady-States of Iterative Algorithms over Graphs,Bo Dai,Georgia Institute of Technology
ICML,2018,Learning Steady-States of Iterative Algorithms over Graphs,Alex Smola,Amazon
ICML,2018,Learning Steady-States of Iterative Algorithms over Graphs,Le Song,Georgia Institute of Technology
ICML,2018,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,Anish Athalye,MIT CSAIL
ICML,2018,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,Nicholas Carlini,"University of California, Berkeley"
ICML,2018,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,David Wagner,UC Berkeley
ICML,2018,Fair and Diverse DPP-Based Data Summarization,Elisa Celis,EPFL
ICML,2018,Fair and Diverse DPP-Based Data Summarization,Vijay Keswani,EPFL
ICML,2018,Fair and Diverse DPP-Based Data Summarization,Damian Straszak,EPFL
ICML,2018,Fair and Diverse DPP-Based Data Summarization,Amit Jayant Deshpande,Microsoft Research
ICML,2018,Fair and Diverse DPP-Based Data Summarization,Tarun Kathuria,UC Berkeley
ICML,2018,Fair and Diverse DPP-Based Data Summarization,Nisheeth Vishnoi,EPFL
ICML,2018,Learning Implicit Generative Models with the Method of Learned Moments,Suman Ravuri,DeepMind
ICML,2018,Learning Implicit Generative Models with the Method of Learned Moments,Shakir Mohamed,DeepMind
ICML,2018,Learning Implicit Generative Models with the Method of Learned Moments,Mihaela Rosca,DeepMind
ICML,2018,Learning Implicit Generative Models with the Method of Learned Moments,Oriol Vinyals,DeepMind
ICML,2018,Chi-square Generative Adversarial Network,Chenyang Tao,Duke University
ICML,2018,Chi-square Generative Adversarial Network,Liqun Chen,Duke University
ICML,2018,Chi-square Generative Adversarial Network,Ricardo Henao,Duke University
ICML,2018,Chi-square Generative Adversarial Network,Jianfeng Feng,Fudan University
ICML,2018,Chi-square Generative Adversarial Network,Lawrence Carin,Duke
ICML,2018,Streaming Principal Component Analysis in Noisy Setting,Teodor Vanislavov Marinov,Johns Hopkins University
ICML,2018,Streaming Principal Component Analysis in Noisy Setting,Poorya Mianjy,Johns Hopkins University
ICML,2018,Streaming Principal Component Analysis in Noisy Setting,Raman Arora,Johns Hopkins University
ICML,2018,Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering,Jan-Hendrik Lange,Max Planck Institute for Informatics
ICML,2018,Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering,Andreas Karrenbauer,Max Planck Institute for Informatics
ICML,2018,Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering,Bjoern Andres,MPI for Informatics
ICML,2018,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,Lam Nguyen,Lehigh University & IBM T.J. Watson Research Center
ICML,2018,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,PHUONG HA NGUYEN,University of Connecticut
ICML,2018,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,Marten van Dijk,University of Connecticut
ICML,2018,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,Peter Richtarik,"King Abdullah University of Science and Technology (KAUST) - University of Edinburgh, Scotland"
ICML,2018,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,Katya Scheinberg,Lehigh University
ICML,2018,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,Martin Takac,Lehigh University
ICML,2018,Computational Optimal Transport: Complexity by Accelerated Gradient Descent Is Better Than by Sinkhorn's Algorithm,Pavel Dvurechenskii,Weierstrass Institute for Applied Analysis and Stochastics
ICML,2018,Computational Optimal Transport: Complexity by Accelerated Gradient Descent Is Better Than by Sinkhorn's Algorithm,Alexander Gasnikov,Moscow Institute of Physics and Technology
ICML,2018,Computational Optimal Transport: Complexity by Accelerated Gradient Descent Is Better Than by Sinkhorn's Algorithm,Alexey Kroshnin,Institute for Information Transmission Problems
ICML,2018,Stability and Generalization of Learning Algorithms that Converge to Global Optima,Zachary Charles,University of Wisconsin-Madison
ICML,2018,Stability and Generalization of Learning Algorithms that Converge to Global Optima,Dimitris Papailiopoulos,ECE at University of Wisconsin-Madison
ICML,2018,Optimal Rates of Sketched-regularized Algorithms for Least-Squares Regression over Hilbert Spaces,Junhong Lin,EPFL
ICML,2018,Optimal Rates of Sketched-regularized Algorithms for Least-Squares Regression over Hilbert Spaces,Volkan Cevher,EPFL
ICML,2018,Adafactor: Adaptive Learning Rates with Sublinear Memory Cost,Noam Shazeer,Google
ICML,2018,Adafactor: Adaptive Learning Rates with Sublinear Memory Cost,Mitchell Stern,UC Berkeley
ICML,2018,Fast Parametric Learning with Activation Memorization,Jack Rae,DeepMind
ICML,2018,Fast Parametric Learning with Activation Memorization,Chris Dyer,DeepMind
ICML,2018,Fast Parametric Learning with Activation Memorization,Peter Dayan,UCL
ICML,2018,Fast Parametric Learning with Activation Memorization,Tim Lillicrap,Google DeepMind
ICML,2018,Essentially No Barriers in Neural Network Energy Landscape,Felix Draxler,Heidelberg University
ICML,2018,Essentially No Barriers in Neural Network Energy Landscape,Kambis Veschgini,University of Heidelberg
ICML,2018,Essentially No Barriers in Neural Network Energy Landscape,Manfred Salmhofer,Heidelberg University
ICML,2018,Essentially No Barriers in Neural Network Energy Landscape,Fred Hamprecht,Heidelberg Collaboratory for Image Processing
ICML,2018,Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global,Thomas Laurent,Loyola Marymount University
ICML,2018,Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global,James von Brecht,CSULB
ICML,2018,Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression,Haitao Liu,Rolls-Royce@NTU Corp Lab
ICML,2018,Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression,Jianfei Cai,Nanyang Technological University
ICML,2018,Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression,Yi Wang,Rolls-Royce Singapore
ICML,2018,Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression,Yew Soon ONG,Nanyang Technological University
ICML,2018,Bayesian Quadrature for Multiple Related Integrals,Xiaoyue Xi,Imperial College London
ICML,2018,Bayesian Quadrature for Multiple Related Integrals,Francois-Xavier Briol,University of Warwick
ICML,2018,Bayesian Quadrature for Multiple Related Integrals,Mark Girolami,Imperial College London
ICML,2018,Deep Predictive Coding Network for Object Recognition,Haiguang Wen,Purdue University
ICML,2018,Deep Predictive Coding Network for Object Recognition,Kuan Han,Purdue University
ICML,2018,Deep Predictive Coding Network for Object Recognition,Junxing Shi,Purdue University
ICML,2018,Deep Predictive Coding Network for Object Recognition,Yizhen Zhang,
ICML,2018,Deep Predictive Coding Network for Object Recognition,Eugenio Culurciello,Nil
ICML,2018,Deep Predictive Coding Network for Object Recognition,Zhongming Liu,Purdue University
ICML,2018,Neural Inverse Rendering for General Reflectance Photometric Stereo,Tatsunori Taniai,RIKEN AIP
ICML,2018,Neural Inverse Rendering for General Reflectance Photometric Stereo,Takanori Maehara,RIKEN AIP
ICML,2018,On the Relationship between Data Efficiency and Error for Uncertainty Sampling,Steve Mussmann,Stanford University
ICML,2018,On the Relationship between Data Efficiency and Error for Uncertainty Sampling,Percy Liang,Stanford University
ICML,2018,Selecting Representative Examples for Program Synthesis,Yewen Pu,MIT
ICML,2018,Selecting Representative Examples for Program Synthesis,Zachery Miranda,MIT
ICML,2018,Selecting Representative Examples for Program Synthesis,Armando Solar-Lezama,MIT
ICML,2018,Selecting Representative Examples for Program Synthesis,Leslie Kaelbling,(organization)
ICML,2018,Conditional Neural Processes,Marta Garnelo,DeepMind
ICML,2018,Conditional Neural Processes,Dan Rosenbaum,DeepMind
ICML,2018,Conditional Neural Processes,Chris Maddison,"Oxford, DeepMind"
ICML,2018,Conditional Neural Processes,Tiago Ramalho,DeepMind
ICML,2018,Conditional Neural Processes,David Saxton,DeepMind
ICML,2018,Conditional Neural Processes,Murray Shanahan,Imperial College London
ICML,2018,Conditional Neural Processes,Yee Teh,DeepMind
ICML,2018,Conditional Neural Processes,Danilo J. Rezende,DeepMind
ICML,2018,Conditional Neural Processes,S. M. Ali Eslami,DeepMind
ICML,2018,Hierarchical Long-term Video Prediction without Supervision,Nevan Wichers,Google
ICML,2018,Hierarchical Long-term Video Prediction without Supervision,Ruben Villegas,University of Michigan
ICML,2018,Hierarchical Long-term Video Prediction without Supervision,Dumitru Erhan,Google Brain
ICML,2018,Hierarchical Long-term Video Prediction without Supervision,Honglak Lee,Google / U. Michigan
ICML,2018,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,Jonathan Uesato,DeepMind
ICML,2018,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,Brendan O'Donoghue,DeepMind
ICML,2018,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,Pushmeet Kohli,DeepMind
ICML,2018,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,Aäron van den Oord,Google Deepmind
ICML,2018,A Classification-Based Study of Covariate Shift in GAN Distributions,Shibani Santurkar,MIT
ICML,2018,A Classification-Based Study of Covariate Shift in GAN Distributions,Ludwig Schmidt,UC Berkeley
ICML,2018,A Classification-Based Study of Covariate Shift in GAN Distributions,Aleksander Madry,MIT
ICML,2018,Gated Path Planning Networks,Lisa Lee,Carnegie Mellon University
ICML,2018,Gated Path Planning Networks,Emilio Parisotto,Carnegie Mellon University
ICML,2018,Gated Path Planning Networks,Devendra Singh Chaplot,Carnegie Mellon University
ICML,2018,Gated Path Planning Networks,Eric Xing,Carnegie Mellon University
ICML,2018,Gated Path Planning Networks,Russ Salakhutdinov,Carnegie Mellen University
ICML,2018,Automatic Goal Generation for Reinforcement Learning Agents,Carlos Florensa,UC Berkeley
ICML,2018,Automatic Goal Generation for Reinforcement Learning Agents,David Held,Carnegie Mellon University
ICML,2018,Automatic Goal Generation for Reinforcement Learning Agents,Xinyang Geng,UC Berkeley
ICML,2018,Automatic Goal Generation for Reinforcement Learning Agents,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2018,ADMM and Accelerated ADMM as Continuous Dynamical Systems,Guilherme Franca,Johns Hopkins University
ICML,2018,ADMM and Accelerated ADMM as Continuous Dynamical Systems,Daniel Robinson,Johns Hopkins University
ICML,2018,ADMM and Accelerated ADMM as Continuous Dynamical Systems,Rene Vidal,Johns Hopkins University
ICML,2018,Dissipativity Theory for Accelerating Stochastic Variance Reduction: A Unified Analysis of SVRG and Katyusha Using Semidefinite Programs,Bin Hu,University of Wisconsin-Madison
ICML,2018,Dissipativity Theory for Accelerating Stochastic Variance Reduction: A Unified Analysis of SVRG and Katyusha Using Semidefinite Programs,Stephen Wright,University of Wisconsin-Madison
ICML,2018,Dissipativity Theory for Accelerating Stochastic Variance Reduction: A Unified Analysis of SVRG and Katyusha Using Semidefinite Programs,Laurent Lessard,University of Wisconsin-Madison
ICML,2018,Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing,Davide Bacciu,University of Pisa
ICML,2018,Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing,Federico Errica,University of Pisa
ICML,2018,Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing,Alessio Micheli,Universita di Pisa
ICML,2018,Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry,Maximillian Nickel,Facebook AI Research
ICML,2018,Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry,Douwe Kiela,Facebook AI Research
ICML,2018,Fast Variance Reduction Method with Stochastic Batch Size,University of California Xuanqing Liu,"University of California, Davis"
ICML,2018,Fast Variance Reduction Method with Stochastic Batch Size,Cho-Jui Hsieh,"University of California, Davis"
ICML,2018,Lyapunov Functions for First-Order Methods: Tight Automated Convergence Guarantees,Adrien Taylor,INRIA/ENS
ICML,2018,Lyapunov Functions for First-Order Methods: Tight Automated Convergence Guarantees,Bryan Van Scoy,University of Wisconsin--Madison
ICML,2018,Lyapunov Functions for First-Order Methods: Tight Automated Convergence Guarantees,Laurent Lessard,University of Wisconsin-Madison
ICML,2018,Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information,Yichong Xu,Carnegie Mellon University
ICML,2018,Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information,Hariank Muthakana,Carnegie Mellon University
ICML,2018,Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information,Sivaraman Balakrishnan,Carnegie Mellon University
ICML,2018,Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information,Aarti Singh,Carnegie Mellon University
ICML,2018,Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information,Artur Dubrawski,CMU
ICML,2018,The Well-Tempered Lasso,Yuanzhi Li,Princeton University
ICML,2018,The Well-Tempered Lasso,Yoram Singer,Google
ICML,2018,Transfer Learning via Learning to Transfer,Ying WEI,Tencent AI Lab
ICML,2018,Transfer Learning via Learning to Transfer,Yu Zhang,Hong Kong UST
ICML,2018,Transfer Learning via Learning to Transfer,Junzhou Huang,University of Texas at Arlington / Tencent AI Lab
ICML,2018,Transfer Learning via Learning to Transfer,Qiang Yang,Hong Kong UST
ICML,2018,Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing—and Back,Elliot Meyerson,UT Austin - Sentient Technologies
ICML,2018,Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing—and Back,Risto Miikkulainen,UT Austin - Sentient Technologies
ICML,2018,Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model,Hideaki Imamura,The University of Tokyo
ICML,2018,Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model,Issei Sato,University of Tokyo / RIKEN
ICML,2018,Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model,Masashi Sugiyama,RIKEN / The University of Tokyo
ICML,2018,Deep One-Class Classification,Lukas Ruff,Hasso Plattner Institute
ICML,2018,Deep One-Class Classification,Nico Görnitz,TU Berlin
ICML,2018,Deep One-Class Classification,Lucas Deecke,University of Edinburgh
ICML,2018,Deep One-Class Classification,Shoaib Ahmed Siddiqui,German Research Center for Artificial Intelligence
ICML,2018,Deep One-Class Classification,Rob Vandermeulen,TU Kaiserslautern
ICML,2018,Deep One-Class Classification,Alexander Binder,Singapore University of Technology and Design
ICML,2018,Deep One-Class Classification,Emmanuel Müller,Hasso Plattner Institute
ICML,2018,Deep One-Class Classification,Marius Kloft,TU Kaiserslautern
ICML,2018,Binary Partitions with Approximate  Minimum Impurity,Eduardo Laber,PUC-RIO
ICML,2018,Binary Partitions with Approximate  Minimum Impurity,Marco Molinaro,PUC-RIO
ICML,2018,Binary Partitions with Approximate  Minimum Impurity,Felipe de A. Mello Pereira,PUC-Rio
ICML,2018,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,Ashkan Norouzi-Fard,EPFL
ICML,2018,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,Jakub Tarnawski,EPFL
ICML,2018,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,Boba Mitrovic,EPFL
ICML,2018,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,Amir Zandieh,EPFL
ICML,2018,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,Aida Mousavifar,EPFL
ICML,2018,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,Ola Svensson,EPFL
ICML,2018,"Yes, but Did It Work?: Evaluating Variational Inference",Yuling Yao,Columbia University
ICML,2018,"Yes, but Did It Work?: Evaluating Variational Inference",Aki Vehtari,Aalto University
ICML,2018,"Yes, but Did It Work?: Evaluating Variational Inference",Daniel Simpson,University of Toronto
ICML,2018,"Yes, but Did It Work?: Evaluating Variational Inference",Andrew Gelman,Columbia University
ICML,2018,Black-Box Variational Inference for Stochastic Differential Equations,Tom Ryder,Newcastle University
ICML,2018,Black-Box Variational Inference for Stochastic Differential Equations,Andrew Golightly,Newcastle University
ICML,2018,Black-Box Variational Inference for Stochastic Differential Equations,Stephen McGough,Newcastle University
ICML,2018,Black-Box Variational Inference for Stochastic Differential Equations,Dennis Prangle,Newcastle University
ICML,2018,Online Convolutional Sparse Coding with Sample-Dependent Dictionary,Yaqing WANG,Hong Kong University of Science and Technology
ICML,2018,Online Convolutional Sparse Coding with Sample-Dependent Dictionary,Quanming Yao,4Paradigm
ICML,2018,Online Convolutional Sparse Coding with Sample-Dependent Dictionary,James Kwok,Hong Kong University of Science and Technology
ICML,2018,Online Convolutional Sparse Coding with Sample-Dependent Dictionary,Lionel NI,University of Macau
ICML,2018,Learning to Speed Up Structured Output Prediction,Xingyuan Pan,University of Utah
ICML,2018,Learning to Speed Up Structured Output Prediction,Vivek Srikumar,University of Utah
ICML,2018,Differentially Private Identity and Equivalence Testing of Discrete Distributions,Maryam Aliakbarpour,MIT
ICML,2018,Differentially Private Identity and Equivalence Testing of Discrete Distributions,Ilias Diakonikolas,USC
ICML,2018,Differentially Private Identity and Equivalence Testing of Discrete Distributions,MIT Ronitt Rubinfeld,"MIT, TAU"
ICML,2018,Information Theoretic Guarantees for Empirical Risk Minimization with Applications to Model Selection and Large-Scale Optimization,Ibrahim Alabdulmohsin,Saudi Aramco
ICML,2018,BOCK : Bayesian Optimization with Cylindrical Kernels,ChangYong Oh,University of Amsterdam
ICML,2018,BOCK : Bayesian Optimization with Cylindrical Kernels,Stratis Gavves,University of Amsterdam
ICML,2018,BOCK : Bayesian Optimization with Cylindrical Kernels,Max Welling,University of Amsterdam
ICML,2018,BOHB: Robust and Efficient Hyperparameter Optimization at Scale,Stefan Falkner,University of Freiburg
ICML,2018,BOHB: Robust and Efficient Hyperparameter Optimization at Scale,Aaron Klein,University of Freiburg
ICML,2018,BOHB: Robust and Efficient Hyperparameter Optimization at Scale,Frank Hutter,University of Freiburg
ICML,2018,Distributed Nonparametric Regression under Communication Constraints,Yuancheng Zhu,University of Pennsylvania
ICML,2018,Distributed Nonparametric Regression under Communication Constraints,John Lafferty,Yale University
ICML,2018,Optimal Tuning for Divide-and-conquer Kernel Ridge Regression with Massive Data,Ganggang Xu,SUNY-Binghamton University
ICML,2018,Optimal Tuning for Divide-and-conquer Kernel Ridge Regression with Massive Data,Zuofeng Shang,Indiana University–Purdue University Indianapolis
ICML,2018,Optimal Tuning for Divide-and-conquer Kernel Ridge Regression with Massive Data,Guang Cheng,Purdue University
ICML,2018,WHInter: A Working set algorithm for High-dimensional sparse second order Interaction models,Marine LE MORVAN,Mines Paristech
ICML,2018,WHInter: A Working set algorithm for High-dimensional sparse second order Interaction models,JP Vert,ENS Paris
ICML,2018,Safe Element Screening for Submodular Function Minimization,Weizhong Zhang,Tencent AI Lab
ICML,2018,Safe Element Screening for Submodular Function Minimization,Bin Hong,Zhejiang University
ICML,2018,Safe Element Screening for Submodular Function Minimization,Lin Ma,Tencent AI Lab
ICML,2018,Safe Element Screening for Submodular Function Minimization,Wei Liu,Tencent AI Lab
ICML,2018,Safe Element Screening for Submodular Function Minimization,Tong Zhang,Tecent AI Lab
ICML,2018,Feedback-Based Tree Search for Reinforcement Learning,Daniel Jiang,University of Pittsburgh
ICML,2018,Feedback-Based Tree Search for Reinforcement Learning,Emmanuel Ekwedike,Princeton University
ICML,2018,Feedback-Based Tree Search for Reinforcement Learning,Han Liu,Northwestern
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Andre Barreto,DeepMind
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Diana Borsa,DeepMind
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,John Quan,DeepMind
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Tom Schaul,DeepMind
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,David Silver,Google DeepMind
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Matteo Hessel,Deep Mind
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Daniel J. Mankowitz,Technion
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Augustin Zidek,
ICML,2018,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,Remi Munos,DeepMind
ICML,2018,Data-Dependent Stability of Stochastic Gradient Descent,Ilja Kuzborskij,University of Milan
ICML,2018,Data-Dependent Stability of Stochastic Gradient Descent,Christoph Lampert,IST Austria
ICML,2018,LeapsAndBounds: A Method for Approximately Optimal Algorithm Configuration,Gellért Weisz,DeepMind
ICML,2018,LeapsAndBounds: A Method for Approximately Optimal Algorithm Configuration,Andras Gyorgy,DeepMind
ICML,2018,LeapsAndBounds: A Method for Approximately Optimal Algorithm Configuration,Csaba Szepesvari,Deepmind/University of Alberta
ICML,2018,Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints,Ehsan Kazemi,Yale
ICML,2018,Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints,Morteza Zadimoghaddam,Google
ICML,2018,Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints,Amin Karbasi,Yale
ICML,2018,Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization,Jinghui Chen,University of Virginia
ICML,2018,Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization,Pan Xu,"University of California, Los Angeles"
ICML,2018,Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization,Lingxiao Wang,UCLA
ICML,2018,Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization,Jian Ma,Carnegie Mellon University
ICML,2018,Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization,Quanquan Gu,UCLA
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Marco Baity-Jesi,Columbia University
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Levent Sagun,ENS/CEA
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Mario Geiger,EPFL
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Stefano Spigler,
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Gerard Arous,
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Chiara Cammarota,King's College London
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Yann LeCun,New York University
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Matthieu Wyart,
ICML,2018,Comparing Dynamics: Deep Neural Networks versus Glassy Systems,Giulio Biroli,
ICML,2018,An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks,Qianxiao Li,"Institute of High Performance Computing, A*STAR, Singapore"
ICML,2018,An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks,IHPC Shuji Hao,"IHPC, A*STAR"
ICML,2018,Not All Samples Are Created Equal: Deep Learning with Importance Sampling,Angelos Katharopoulos,Idiap
ICML,2018,Not All Samples Are Created Equal: Deep Learning with Importance Sampling,Francois Fleuret,Idiap research institute
ICML,2018,"Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",Lechao Xiao,Google Brain
ICML,2018,"Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",Yasaman Bahri,Google Brain
ICML,2018,"Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",Jascha Sohl-Dickstein,Google Brain
ICML,2018,"Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",Samuel Schoenholz,Google Brain
ICML,2018,"Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",Jeffrey Pennington,Google Brain
ICML,2018,Path Consistency Learning in Tsallis Entropy Regularized MDPs,Yinlam Chow,DeepMind
ICML,2018,Path Consistency Learning in Tsallis Entropy Regularized MDPs,Ofir Nachum,Google Brain
ICML,2018,Path Consistency Learning in Tsallis Entropy Regularized MDPs,Mohammad Ghavamzadeh,Google DeepMind and INRIA
ICML,2018,Lipschitz Continuity in Model-based Reinforcement Learning,Kavosh Asadi,Brown University
ICML,2018,Lipschitz Continuity in Model-based Reinforcement Learning,Dipendra Misra,Cornell University
ICML,2018,Lipschitz Continuity in Model-based Reinforcement Learning,Michael L. Littman,Brown University
ICML,2018,Bounds on the Approximation Power of Feedforward Neural Networks,Mohammad Mehrabi,Sharif University of Technology
ICML,2018,Bounds on the Approximation Power of Feedforward Neural Networks,Aslan Tchamkerten,Telecom ParisTech
ICML,2018,Bounds on the Approximation Power of Feedforward Neural Networks,MANSOOR I YOUSEFI,Telecom ParisTech
ICML,2018,Linear Spectral Estimators and an Application to Phase Retrieval,Ramina Ghods,Cornell University
ICML,2018,Linear Spectral Estimators and an Application to Phase Retrieval,Andrew Lan,Princeton University
ICML,2018,Linear Spectral Estimators and an Application to Phase Retrieval,Tom Goldstein,University of Maryland
ICML,2018,Linear Spectral Estimators and an Application to Phase Retrieval,Christoph Studer,Cornell University
ICML,2018,Testing Sparsity over Known and Unknown Bases,Siddharth Barman,Indian Institute of Science
ICML,2018,Testing Sparsity over Known and Unknown Bases,Arnab Bhattacharyya,Indian Institute of Science
ICML,2018,Testing Sparsity over Known and Unknown Bases,Suprovat Ghoshal,Indian Institute of Science
ICML,2018,Inference Suboptimality in Variational Autoencoders,Chris Cremer,University of Toronto
ICML,2018,Inference Suboptimality in Variational Autoencoders,Xuechen Li,University of Toronto
ICML,2018,Inference Suboptimality in Variational Autoencoders,David Duvenaud,University of Toronto
ICML,2018,Semi-Implicit Variational Inference,Mingzhang Yin,University of Texas at Austin
ICML,2018,Semi-Implicit Variational Inference,Mingyuan Zhou,University of Texas at Austin
ICML,2018,Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization,Hang Wu,Georgia Institute of Technology
ICML,2018,Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization,May Wang,Georgia Institute of Technology
ICML,2018,Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design,Ahmed M. Alaa Ibrahim,UCLA
ICML,2018,Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design,M van der Schaar,UCLA
ICML,2018,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,Jingyi Xu,"University of California, Los Angeles"
ICML,2018,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,Zilu Zhang,Peking University
ICML,2018,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,Tal Friedman,UCLA
ICML,2018,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,Yitao Liang,UCLA
ICML,2018,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,Guy Van den Broeck,"University of California, Los Angeles"
ICML,2018,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization,Jiong Zhang,University of Texas at Austin
ICML,2018,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization,Qi Lei,University of Texas at Austin
ICML,2018,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization,Inderjit Dhillon,UT Austin & Amazon
ICML,2018,An Efficient Semismooth Newton based Algorithm for Convex Clustering,Yancheng Yuan,National University of Singapore
ICML,2018,An Efficient Semismooth Newton based Algorithm for Convex Clustering,Defeng Sun,The Hong Kong Polytechnic University
ICML,2018,An Efficient Semismooth Newton based Algorithm for Convex Clustering,Kim-Chuan Toh,National University of Singapre
ICML,2018,Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data,Shuai Zheng,Hong Kong University of Science and Technology
ICML,2018,Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data,James Kwok,Hong Kong University of Science and Technology
ICML,2018,Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search,Masanori SUGANUMA,RIKEN AIP / Tohoku University
ICML,2018,Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search,Mete Ozay,Tohoku University
ICML,2018,Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search,Takayuki Okatani,Tohoku University/RIKEN AIP
ICML,2018,Efficient Neural Architecture Search via Parameters Sharing,Hieu Pham,Carnegie Mellon University
ICML,2018,Efficient Neural Architecture Search via Parameters Sharing,Melody Guan,Stanford University
ICML,2018,Efficient Neural Architecture Search via Parameters Sharing,Barret Zoph,Google
ICML,2018,Efficient Neural Architecture Search via Parameters Sharing,Quoc Le,Google Brain
ICML,2018,Efficient Neural Architecture Search via Parameters Sharing,Jeff Dean,Google Brain
ICML,2018,Non-convex Conditional Gradient Sliding,chao qu,technion
ICML,2018,Non-convex Conditional Gradient Sliding,Yan Li,Georgia Institute of Technology
ICML,2018,Non-convex Conditional Gradient Sliding,Huan Xu,Georgia Tech
ICML,2018,Stochastic Variance-Reduced Cubic Regularized Newton Method,Dongruo Zhou,"University of California, Los Angeles"
ICML,2018,Stochastic Variance-Reduced Cubic Regularized Newton Method,Pan Xu,"University of California, Los Angeles"
ICML,2018,Stochastic Variance-Reduced Cubic Regularized Newton Method,Quanquan Gu,UCLA
ICML,2018,On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization,Sanjeev Arora,Princeton University and Institute for Advanced Study
ICML,2018,On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization,Nadav Cohen,Institute for Advanced Study
ICML,2018,On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization,Elad Hazan,Google Brain and Princeton University
ICML,2018,The Dynamics of Learning: A Random Matrix Approach,Zhenyu Liao,"L2S, CentraleSupelec"
ICML,2018,The Dynamics of Learning: A Random Matrix Approach,Romain Couillet,CentralSupélec
ICML,2018,Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations,Ting Chen,UCLA
ICML,2018,Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations,Martin Reqiang Min,NEC Laboratories America
ICML,2018,Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations,Yizhou Sun,UCLA
ICML,2018,Discovering Interpretable Representations for Both Deep Generative and Discriminative Models,Tameem Adel,University of Cambridge
ICML,2018,Discovering Interpretable Representations for Both Deep Generative and Discriminative Models,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2018,Discovering Interpretable Representations for Both Deep Generative and Discriminative Models,Adrian Weller,"University of Cambridge, Alan Turing Institute"
ICML,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Changyou Chen,SUNY at Buffalo
ICML,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Chunyuan Li,Duke University
ICML,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Liquan Chen,Duke University
ICML,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Wenlin Wang,Duke University
ICML,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Yunchen Pu,Duke
ICML,2018,Continuous-Time Flows for Efficient Inference and Density Estimation,Lawrence Carin,Duke
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Tom Rainforth,University of Oxford
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Adam Kosiorek,University of Oxford
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Tuan Anh Le,University of Oxford
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Chris Maddison,"Oxford, DeepMind"
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Max Igl,University of Oxford
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Frank Wood,University of Oxford
ICML,2018,Tighter Variational Bounds are Not Necessarily Better,Yee Whye Teh,Oxford and DeepMind
ICML,2018,PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,Yunbo Wang,Tsinghua University
ICML,2018,PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,Zhifeng Gao,Tsinghua University
ICML,2018,PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,Mingsheng Long,Tsinghua University
ICML,2018,PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,Jianmin Wang,Tsinghua University
ICML,2018,PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,Philip Yu,UIC
ICML,2018,RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks,Jinsung Yoon,"University of California, Los Angeles"
ICML,2018,RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks,James Jordon,University of Oxford
ICML,2018,RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks,Mihaela van der Schaar,University of Oxford
ICML,2018,Differentiable Compositional Kernel Learning for Gaussian Processes,Shengyang Sun,University of Toronto
ICML,2018,Differentiable Compositional Kernel Learning for Gaussian Processes,Guodong Zhang,University of Toronto
ICML,2018,Differentiable Compositional Kernel Learning for Gaussian Processes,Chaoqi Wang,University of Toronto
ICML,2018,Differentiable Compositional Kernel Learning for Gaussian Processes,Wenyuan Zeng,"University of Toronto, Uber ATG"
ICML,2018,Differentiable Compositional Kernel Learning for Gaussian Processes,Jiaman Li,University of Toronto
ICML,2018,Differentiable Compositional Kernel Learning for Gaussian Processes,Roger Grosse,University of Toronto and Vector Institute
ICML,2018,Markov Modulated Gaussian Cox Processes for Semi-Stationary Intensity Modeling of Events Data,Minyoung Kim,"SeoulTech, Rutgers University"
ICML,2018,Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems,Marc Abeille,Criteo
ICML,2018,Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems,Alessandro Lazaric,Facebook AI Research
ICML,2018,Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches,Simon Olofsson,Imperial College London
ICML,2018,Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches,Marc P Deisenroth,Imperial College London and PROWLER.io
ICML,2018,Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches,Ruth Misener,Imperial College London
ICML,2018,Anonymous Walk Embeddings,Sergey Ivanov,Skoltech & Criteo
ICML,2018,Anonymous Walk Embeddings,Evgeny Burnaev,Skoltech
ICML,2018,Improving Optimization in Models With Continuous Symmetry Breaking,Robert Bamler,Disney Research
ICML,2018,Improving Optimization in Models With Continuous Symmetry Breaking,Stephan Mandt,Disney Research
ICML,2018,Conditional Noise-Contrastive Estimation of Unnormalised Models,Ciwan Ceylan,RWTH
ICML,2018,Conditional Noise-Contrastive Estimation of Unnormalised Models,Michael Gutmann,University of Edinburgh
ICML,2018,Canonical Tensor Decomposition for Knowledge Base Completion,Timothee Lacroix,Facebook
ICML,2018,Canonical Tensor Decomposition for Knowledge Base Completion,Nicolas Usunier,Facebook AI Research
ICML,2018,Canonical Tensor Decomposition for Knowledge Base Completion,Guillaume R Obozinski,Ecole des Ponts - ParisTech
ICML,2018,The Power of Interpolation:  Understanding the Effectiveness of SGD in Modern Over-parametrized Learning,Siyuan Ma,The Ohio State University
ICML,2018,The Power of Interpolation:  Understanding the Effectiveness of SGD in Modern Over-parametrized Learning,Raef Bassily,
ICML,2018,The Power of Interpolation:  Understanding the Effectiveness of SGD in Modern Over-parametrized Learning,Mikhail Belkin,Ohio State University
ICML,2018,A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates,Kaiwen Zhou,The Chinese University of Hong Kong
ICML,2018,A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates,Fanhua Shang,The Chinese University of Hong Kong
ICML,2018,A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates,James Cheng,CUHK
ICML,2018,Escaping Saddles with Stochastic Gradients,Hadi Daneshmand,ETH Zurich
ICML,2018,Escaping Saddles with Stochastic Gradients,Jonas Kohler,ETH Zurich
ICML,2018,Escaping Saddles with Stochastic Gradients,Aurelien Lucchi,ETH Zurich
ICML,2018,Escaping Saddles with Stochastic Gradients,Thomas Hofmann,ETH Zurich
ICML,2018,$D^2$: Decentralized Training over Decentralized Data,Hanlin Tang,University of Rochester
ICML,2018,$D^2$: Decentralized Training over Decentralized Data,Xiangru Lian,University of Rochester
ICML,2018,$D^2$: Decentralized Training over Decentralized Data,Ming Yan,Michigan State University
ICML,2018,$D^2$: Decentralized Training over Decentralized Data,Ce Zhang,ETH Zurich
ICML,2018,$D^2$: Decentralized Training over Decentralized Data,Ji Liu,University of Rochester
ICML,2018,Machine Theory of Mind,Neil Rabinowitz,DeepMind
ICML,2018,Machine Theory of Mind,Frank Perbet,DeepMind
ICML,2018,Machine Theory of Mind,Francis Song,DeepMind
ICML,2018,Machine Theory of Mind,Chiyuan Zhang,Google
ICML,2018,Machine Theory of Mind,S. M. Ali Eslami,DeepMind
ICML,2018,Machine Theory of Mind,Matthew Botvinick,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Sam Ritter,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Jane Wang,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Zeb Kurth-Nelson,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Siddhant Jayakumar,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Charles Blundell,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Razvan Pascanu,DeepMind
ICML,2018,"Been There, Done That: Meta-Learning with Episodic Recall",Matthew Botvinick,DeepMind
ICML,2018,Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines,Bin Gu,University of Pittsburgh
ICML,2018,Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines,Zhouyuan Huo,University of Pittsburgh
ICML,2018,Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines,Cheng Deng,Xidian University
ICML,2018,Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines,Heng Huang,University of Pittsburgh
ICML,2018,Coded Sparse Matrix Multiplication,Sinong Wang,The Ohio State University
ICML,2018,Coded Sparse Matrix Multiplication,Jiashang Liu,The Ohio State University
ICML,2018,Coded Sparse Matrix Multiplication,Ness Shroff,The Ohio State University
ICML,2018,Augment and Reduce: Stochastic Inference for Large Categorical Distributions,Francisco Ruiz,Columbia University
ICML,2018,Augment and Reduce: Stochastic Inference for Large Categorical Distributions,Michalis Titsias,Athens University of Economics and Business
ICML,2018,Augment and Reduce: Stochastic Inference for Large Categorical Distributions,Adji Bousso Dieng,Columbia University
ICML,2018,Augment and Reduce: Stochastic Inference for Large Categorical Distributions,David Blei,Columbia University
ICML,2018,Efficient Gradient-Free Variational Inference using Policy Search,Oleg Arenz,TU Darmstadt
ICML,2018,Efficient Gradient-Free Variational Inference using Policy Search,Gerhard Neumann,University of Lincoln
ICML,2018,Efficient Gradient-Free Variational Inference using Policy Search,Mingjun Zhong,University of Lincoln
ICML,2018,Fixing a Broken ELBO,Alex Alemi,Google
ICML,2018,Fixing a Broken ELBO,Ben Poole,Stanford University
ICML,2018,Fixing a Broken ELBO,Ian Fischer,Google
ICML,2018,Fixing a Broken ELBO,Josh V Dillon,Google
ICML,2018,Fixing a Broken ELBO,Rif Saurous,
ICML,2018,Fixing a Broken ELBO,Kevin Murphy,Google
ICML,2018,Variational Inference and Model Selection with Generalized Evidence Bounds,Liqun Chen,Duke University
ICML,2018,Variational Inference and Model Selection with Generalized Evidence Bounds,Chenyang Tao,Duke University
ICML,2018,Variational Inference and Model Selection with Generalized Evidence Bounds,RUIYI ZHANG,Duke University
ICML,2018,Variational Inference and Model Selection with Generalized Evidence Bounds,Ricardo Henao,Duke University
ICML,2018,Variational Inference and Model Selection with Generalized Evidence Bounds,Lawrence Carin,Duke
ICML,2018,The Generalization Error of Dictionary Learning with Moreau Envelopes,ALEXANDROS GEORGOGIANNIS,TECHNICAL UNIVERSITY OF CRETE
ICML,2018,Network Global Testing by Counting Graphlets,Jiashun Jin,Carnegie Mellon University
ICML,2018,Network Global Testing by Counting Graphlets,Zheng Ke,University of Chicago
ICML,2018,Network Global Testing by Counting Graphlets,Shengming Luo,CMU
ICML,2018,Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion,Richard Zhang,"University of California, Berkeley"
ICML,2018,Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion,Salar Fattahi,UC Berkeley
ICML,2018,Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion,Somayeh Sojoudi,"University of California, Berkeley"
ICML,2018,Robust and Scalable Models of Microbiome Dynamics,Travis Gibson,Harvard Medical School
ICML,2018,Robust and Scalable Models of Microbiome Dynamics,Georg Gerber,Harvard Medical School
ICML,2018,Explicit Inductive Bias for Transfer Learning with Convolutional Networks,Xuhong LI,CNRS/UTC Heudiasyc
ICML,2018,Explicit Inductive Bias for Transfer Learning with Convolutional Networks,Yves Grandvalet,CNRS/UTC
ICML,2018,Explicit Inductive Bias for Transfer Learning with Convolutional Networks,Franck Davoine,"CNRS, Université de technologie de Compiègne"
ICML,2018,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,Zhao Chen,"Magic Leap, Inc"
ICML,2018,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,Vijay Badrinarayanan,Magic Leap Inc.
ICML,2018,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,Chen-Yu Lee,
ICML,2018,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,Andrew Rabinovich,"Magic Leap, Inc."
ICML,2018,Optimizing the Latent Space of Generative Networks,Piotr Bojanowski,Facebook
ICML,2018,Optimizing the Latent Space of Generative Networks,Armand Joulin,Facebook
ICML,2018,Optimizing the Latent Space of Generative Networks,David Lopez-Paz,Facebook AI Research
ICML,2018,Optimizing the Latent Space of Generative Networks,Arthur Szlam,Facebook
ICML,2018,Theoretical Analysis of Image-to-Image Translation with Adversarial Learning,Morino Pan,Fudan University
ICML,2018,Theoretical Analysis of Image-to-Image Translation with Adversarial Learning,Mi Zhang,Fudan University
ICML,2018,Theoretical Analysis of Image-to-Image Translation with Adversarial Learning,Daizong Ding,Fudan University
ICML,2018,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,Tuomas Haarnoja,UC Berkeley
ICML,2018,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,Aurick Zhou,UC Berkeley
ICML,2018,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2018,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,Sergey Levine,Berkeley
ICML,2018,PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos,Paavo Parmas,Okinawa Institute of Science and Technology Graduate University
ICML,2018,PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos,Carl E Rasmussen,Cambridge University
ICML,2018,PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos,Jan Peters,TU Darmstadt + Max Planck Institute for Intelligent Systems
ICML,2018,PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos,Kenji Doya,Okinawa Institute of Science and Technology
ICML,2018,Probabilistic Recurrent State-Space Models,Andreas Doerr,"Bosch Center for Artificial Intelligence, Max Planck Institute for Intelligent Systems"
ICML,2018,Probabilistic Recurrent State-Space Models,Christian Daniel,TU Darmstadt
ICML,2018,Probabilistic Recurrent State-Space Models,Martin Schiegg,Bosch Center for AI (BCAI)
ICML,2018,Probabilistic Recurrent State-Space Models,Duy Nguyen-Tuong,Bosch Center for AI
ICML,2018,Probabilistic Recurrent State-Space Models,Stefan Schaal,University of Southern California
ICML,2018,Probabilistic Recurrent State-Space Models,Marc Toussaint,(organization)
ICML,2018,Probabilistic Recurrent State-Space Models,Sebastian Trimpe,Max Planck Institute for Intelligent Systems
ICML,2018,Structured Variationally Auto-encoded Optimization,Xiaoyu Lu,University of Oxford
ICML,2018,Structured Variationally Auto-encoded Optimization,Javier González,Amazon
ICML,2018,Structured Variationally Auto-encoded Optimization,Zhenwen Dai,Amazon.com
ICML,2018,Structured Variationally Auto-encoded Optimization,Neil Lawrence,Amazon
ICML,2018,A Robust Approach to Sequential Information Theoretic Planning,Sue Zheng,MIT
ICML,2018,A Robust Approach to Sequential Information Theoretic Planning,Jason Pacheco,Brown University
ICML,2018,A Robust Approach to Sequential Information Theoretic Planning,John Fisher,MIT
ICML,2018,Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap,Miles Lopes,"University of California, Davis"
ICML,2018,Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap,Shusen Wang,UC Berkeley
ICML,2018,Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap,Michael Mahoney,UC Berkeley
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Zhengyuan Zhou,Stanford University
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Panayotis Mertikopoulos,CNRS
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Nicholas Bambos,
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Peter Glynn,Stanford University
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Yinyu Ye,
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Li-Jia Li,Google
ICML,2018,Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?,Li Fei-Fei,Stanford University & Google
ICML,2018,Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization,Jiaxiang Wu,Tencent AI Lab
ICML,2018,Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization,Weidong Huang,Tencent
ICML,2018,Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization,Junzhou Huang,University of Texas at Arlington / Tencent AI Lab
ICML,2018,Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization,Tong Zhang,Tecent AI Lab
ICML,2018,Low-Rank Riemannian Optimization on Positive Semidefinite Stochastic Matrices with Applications to Graph Clustering,Ahmed Douik,California Institute of technology
ICML,2018,Low-Rank Riemannian Optimization on Positive Semidefinite Stochastic Matrices with Applications to Graph Clustering,Babak Hassibi,Caltech
ICML,2018,"Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",Lukas Balles,Max Planck Institute for Intelligent Systems
ICML,2018,"Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",Philipp Hennig,University of Tübingen
ICML,2018,Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning,Thomas Dietterich,(organization)
ICML,2018,Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning,George Trimponias,Huawei Noah's Ark Lab
ICML,2018,Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning,Zhitang Chen,Huawei Noah’s Ark Lab
ICML,2018,Differentially Private Database Release via Kernel Mean Embeddings,Matej Balog,University of Cambridge and MPI Tübingen
ICML,2018,Differentially Private Database Release via Kernel Mean Embeddings,Ilya Tolstikhin,"Max Planck Institute for Intelligent Systems, Tübingen"
ICML,2018,Differentially Private Database Release via Kernel Mean Embeddings,Bernhard Schölkopf,"MPI for Intelligent Systems Tübingen, Germany"
ICML,2018,Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples,Gail Weiss,Technion
ICML,2018,Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples,Yoav Goldberg,Bar Ilan University
ICML,2018,Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples,Eran Yahav,Technion
ICML,2018,Neural Dynamic Programming for Musical Self Similarity,Christian Walder,"Data61, the Australian National University"
ICML,2018,Neural Dynamic Programming for Musical Self Similarity,Dongwoo Kim,The Australian National University
ICML,2018,Learning long term dependencies via Fourier recurrent units,Jiong Zhang,University of Texas at Austin
ICML,2018,Learning long term dependencies via Fourier recurrent units,Yibo Lin,UT-Austin
ICML,2018,Learning long term dependencies via Fourier recurrent units,Zhao Song,UT-Austin
ICML,2018,Learning long term dependencies via Fourier recurrent units,Inderjit Dhillon,UT Austin & Amazon
ICML,2018,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,Mikolaj Binkowski,Imperial College London
ICML,2018,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,Gautier Marti,Ecole Polytechnique AXA IM Chorus
ICML,2018,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,Philippe Donnat,Hellebore Capital Limited
ICML,2018,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation,Dane Corneil,EPFL
ICML,2018,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation,Wulfram Gerstner,EPFL
ICML,2018,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation,Johanni Brea,EPFL
ICML,2018,Regret Minimization for Partially Observable Deep Reinforcement Learning,Peter Jin,UC Berkeley
ICML,2018,Regret Minimization for Partially Observable Deep Reinforcement Learning,EECS Kurt Keutzer,"EECS, UC Berkeley"
ICML,2018,Regret Minimization for Partially Observable Deep Reinforcement Learning,Sergey Levine,Berkeley
ICML,2018,Goodness-of-fit Testing for Discrete Distributions via Stein Discrepancy,Jiasen Yang,Purdue University
ICML,2018,Goodness-of-fit Testing for Discrete Distributions via Stein Discrepancy,Qiang Liu,UT Austin
ICML,2018,Goodness-of-fit Testing for Discrete Distributions via Stein Discrepancy,Vinayak A Rao,Purdue University
ICML,2018,Goodness-of-fit Testing for Discrete Distributions via Stein Discrepancy,Jennifer Neville,Purdue University
ICML,2018,Unbiased Objective Estimation in Predictive Optimization,Shinji Ito,NEC Corporation
ICML,2018,Unbiased Objective Estimation in Predictive Optimization,Akihiro Yabe,NEC Corporation
ICML,2018,Unbiased Objective Estimation in Predictive Optimization,Ryohei Fujimaki,-
ICML,2018,Ultra Large-Scale Feature Selection using Count-Sketches,Amirali Aghazadeh,Stanford University
ICML,2018,Ultra Large-Scale Feature Selection using Count-Sketches,Ryan Spring,Rice University
ICML,2018,Ultra Large-Scale Feature Selection using Count-Sketches,Daniel LeJeune,Rice University
ICML,2018,Ultra Large-Scale Feature Selection using Count-Sketches,Gautam Dasarathy,Rice University
ICML,2018,Ultra Large-Scale Feature Selection using Count-Sketches,Anshumali Shrivastava,Rice University
ICML,2018,Ultra Large-Scale Feature Selection using Count-Sketches,Richard Baraniuk,OpenStax / Rice University
ICML,2018,"Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",Vladimir Braverman,Johns Hopkins University
ICML,2018,"Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",Stephen Chestnut,ETH Zurich
ICML,2018,"Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",Robert Krauthgamer,Weizmann Institute of Science
ICML,2018,"Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",Yi Li,Nanyang Technological University
ICML,2018,"Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",David Woodruff,Carnegie Mellon University
ICML,2018,"Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",Lin Yang,Princeton
ICML,2018,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?,Maithra Raghu,Google Brain / Cornell University
ICML,2018,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?,Alex Irpan,Google
ICML,2018,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?,Jacob Andreas,UC Berkeley
ICML,2018,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?,Bobby Kleinberg,Cornell
ICML,2018,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?,Quoc Le,Google Brain
ICML,2018,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?,Jon Kleinberg,Cornell University
ICML,2018,The Mirage of Action-Dependent Baselines in Reinforcement Learning,George Tucker,Google Brain
ICML,2018,The Mirage of Action-Dependent Baselines in Reinforcement Learning,Surya Bhupatiraju,Google Brain
ICML,2018,The Mirage of Action-Dependent Baselines in Reinforcement Learning,Shixiang Gu,Cambridge
ICML,2018,The Mirage of Action-Dependent Baselines in Reinforcement Learning,Richard E Turner,University of Cambridge
ICML,2018,The Mirage of Action-Dependent Baselines in Reinforcement Learning,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2018,The Mirage of Action-Dependent Baselines in Reinforcement Learning,Sergey Levine,Berkeley
ICML,2018,Composite Marginal Likelihood Methods for Random Utility Models,Zhibing Zhao,Rensselaer Polytechnic Institute
ICML,2018,Composite Marginal Likelihood Methods for Random Utility Models,Lirong Xia,RPI
ICML,2018,Ranking Distributions based on Noisy Sorting,Adil El Mesaoudi-Paul,University of Paderborn
ICML,2018,Ranking Distributions based on Noisy Sorting,Eyke Hüllermeier,Paderborn University
ICML,2018,Ranking Distributions based on Noisy Sorting,Robert Busa-Fekete,Yahoo Research
ICML,2018,DICOD: Distributed Convolutional Coordinate Descent for Convolutional Sparse Coding,Thomas Moreau,"CMLA, ENS Paris-Saclay"
ICML,2018,DICOD: Distributed Convolutional Coordinate Descent for Convolutional Sparse Coding,Laurent Oudre,Universite Paris 13
ICML,2018,DICOD: Distributed Convolutional Coordinate Descent for Convolutional Sparse Coding,Nicolas Vayatis,"CMLA, ENS Paris Saclay"
ICML,2018,Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks,Zhihao Jia,Stanford University
ICML,2018,Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks,Sina Lin,Microsoft
ICML,2018,Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks,Charles Qi,Stanford University
ICML,2018,Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks,Alex Aiken,Stanford University
ICML,2018,Deep Models of Interactions Across Sets,Jason Hartford,University of British Columbia
ICML,2018,Deep Models of Interactions Across Sets,Devon Graham,University of British Columbia
ICML,2018,Deep Models of Interactions Across Sets,Kevin Leyton-Brown,University of British Columbia
ICML,2018,Deep Models of Interactions Across Sets,Siamak Ravanbakhsh,University of British Columbia
ICML,2018,ContextNet: Deep learning for Star Galaxy Classification,Noble Kennamer,"University of California, Irvine"
ICML,2018,ContextNet: Deep learning for Star Galaxy Classification,University of California David Kirkby,"University of California, Irvine"
ICML,2018,ContextNet: Deep learning for Star Galaxy Classification,Alex Ihler,UC Irvine
ICML,2018,ContextNet: Deep learning for Star Galaxy Classification,University of California Francisco Javier Sanchez-Lopez,"University of California, Irvine"
ICML,2018,First Order Generative Adversarial Networks,Calvin Seward,Zalando Research
ICML,2018,First Order Generative Adversarial Networks,Thomas Unterthiner,Johannes Kepler University Linz
ICML,2018,First Order Generative Adversarial Networks,Urs M Bergmann,Zalando Research
ICML,2018,First Order Generative Adversarial Networks,Nikolay Jetchev,Zalando Research
ICML,2018,First Order Generative Adversarial Networks,Sepp Hochreiter,Johannes Kepler University Linz
ICML,2018,Max-Mahalanobis Linear Discriminant Analysis Networks,Tianyu Pang,Tsinghua University
ICML,2018,Max-Mahalanobis Linear Discriminant Analysis Networks,Chao Du,Tsinghua University
ICML,2018,Max-Mahalanobis Linear Discriminant Analysis Networks,Jun Zhu,Tsinghua University
ICML,2018,Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time,Asish Ghoshal,Purdue University
ICML,2018,Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time,Jean Honorio,Purdue University
ICML,2018,Structured Output Learning with Abstention: Application to Accurate Opinion Prediction,Alexandre Garcia,Telecom Paristech
ICML,2018,Structured Output Learning with Abstention: Application to Accurate Opinion Prediction,Telecom-ParisTech Chloé Clavel,"LTCI, Telecom-ParisTech, Paris, France"
ICML,2018,Structured Output Learning with Abstention: Application to Accurate Opinion Prediction,Slim Essid,Telecom ParisTech
ICML,2018,Structured Output Learning with Abstention: Application to Accurate Opinion Prediction,Florence d'Alche-Buc,"Télécom ParisTech, Université Paris-Saclay,Paris, France"
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Bo Dai,Georgia Institute of Technology
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Albert Shaw,Georgia Tech
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Lihong Li,Google Inc.
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Lin Xiao,Microsoft Research
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Niao He,UIUC
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Zhen Liu,Georgia Tech
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Jianshu Chen,Microsoft Research
ICML,2018,SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation,Le Song,Georgia Institute of Technology
ICML,2018,Smoothed Action Value Functions for Learning Gaussian Policies,Ofir Nachum,Google Brain
ICML,2018,Smoothed Action Value Functions for Learning Gaussian Policies,Mohammad Norouzi,Google Brain
ICML,2018,Smoothed Action Value Functions for Learning Gaussian Policies,George Tucker,Google Brain
ICML,2018,Smoothed Action Value Functions for Learning Gaussian Policies,Dale Schuurmans,University of Alberta
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,RJ Skerry-Ryan,"Google, Inc."
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Eric Battenberg,
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Ying Xiao,Google Inc
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Yuxuan Wang,Google
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Daisy Stanton,
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Joel Shor,Google
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Ron Weiss,Google Brain
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Rob Clark,Google UK
ICML,2018,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,Rif Saurous,
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Yuxuan Wang,Google
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Daisy Stanton,
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Yu Zhang,Hong Kong UST
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",RJ-Skerry Ryan,
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Eric Battenberg,
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Joel Shor,Google
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Ying Xiao,Google Inc
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Ye Jia,Google
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Fei Ren,Google
ICML,2018,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",Rif Saurous,
ICML,2018,AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning,Ahmed M. Alaa Ibrahim,UCLA
ICML,2018,AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning,M van der Schaar,UCLA
ICML,2018,TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service,Amartya Sanyal,University of Oxford
ICML,2018,TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service,Matt Kusner,Alan Turing Institute
ICML,2018,TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service,Adria Gascon,The Alan Turing Institute / Warwick University
ICML,2018,TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service,Varun Kanade,University of Oxford
ICML,2018,End-to-End Learning for the Deep Multivariate Probit Model,Di Chen,Cornell University
ICML,2018,End-to-End Learning for the Deep Multivariate Probit Model,Yexiang Xue,Purdue University
ICML,2018,End-to-End Learning for the Deep Multivariate Probit Model,Carla Gomes,Cornell University
ICML,2018,Differentiable Dynamic Programming for Structured Prediction and Attention,Arthur Mensch,Inria Parietal
ICML,2018,Differentiable Dynamic Programming for Structured Prediction and Attention,Mathieu Blondel,NTT
ICML,2018,Optimal Distributed Learning with Multi-pass Stochastic Gradient Methods,Junhong Lin,EPFL
ICML,2018,Optimal Distributed Learning with Multi-pass Stochastic Gradient Methods,Volkan Cevher,EPFL
ICML,2018,Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,Dong Yin,UC Berkeley
ICML,2018,Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,Yudong Chen,Cornell University
ICML,2018,Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,Kannan Ramchandran,UC Berkeley
ICML,2018,Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,Peter Bartlett,UC Berkeley
ICML,2018,SQL-Rank: A Listwise Approach to Collaborative Ranking,LIWEI WU,"University of California, Davis"
ICML,2018,SQL-Rank: A Listwise Approach to Collaborative Ranking,Cho-Jui Hsieh,"University of California, Davis"
ICML,2018,SQL-Rank: A Listwise Approach to Collaborative Ranking,University of California James Sharpnack,"University of California, Davis"
ICML,2018,Extreme Learning to Rank via Low Rank Assumption,Minhao Cheng,UC Davis
ICML,2018,Extreme Learning to Rank via Low Rank Assumption,Ian Davidson,UC Davis
ICML,2018,Extreme Learning to Rank via Low Rank Assumption,Cho-Jui Hsieh,"University of California, Davis"
ICML,2018,Adversarial Attack on Graph Structured Data,Hanjun Dai,Georgia Tech
ICML,2018,Adversarial Attack on Graph Structured Data,Hui Li,Ant Financial Services Group
ICML,2018,Adversarial Attack on Graph Structured Data,Tian Tian,Tsinghua University
ICML,2018,Adversarial Attack on Graph Structured Data,huangxin Huang,Ant Financial
ICML,2018,Adversarial Attack on Graph Structured Data,Lin Wang,
ICML,2018,Adversarial Attack on Graph Structured Data,Jun Zhu,Tsinghua University
ICML,2018,Adversarial Attack on Graph Structured Data,Le Song,Georgia Institute of Technology
ICML,2018,Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training,Xi Wu,Google
ICML,2018,Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training,Uyeong Jang,University of Wisconsin - Madison
ICML,2018,Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training,Jiefeng Chen,University of Wisconsin-Madison
ICML,2018,Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training,Lingjiao Chen,University of Wisconsin-Madison
ICML,2018,Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training,Somesh Jha,"University of Wisconsin, Madison"
ICML,2018,Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization,Louis Filstroff,"CNRS, Toulouse"
ICML,2018,Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization,Alberto Lumbreras,CNRS - IRIT
ICML,2018,Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization,Cedric Fevotte,CNRS
ICML,2018,Learning Binary Latent Variable Models: A Tensor Eigenpair Approach,Ariel Jaffe,Weizmann Institute of Science
ICML,2018,Learning Binary Latent Variable Models: A Tensor Eigenpair Approach,Roi Weiss,WeizmannInstitute
ICML,2018,Learning Binary Latent Variable Models: A Tensor Eigenpair Approach,Boaz Nadler,Weizmann Institute of Science
ICML,2018,Learning Binary Latent Variable Models: A Tensor Eigenpair Approach,Shai Carmi,The Hebrew University of Jerusalem
ICML,2018,Learning Binary Latent Variable Models: A Tensor Eigenpair Approach,Yuval Kluger,Yale School of Medicine
ICML,2018,Thompson Sampling for Combinatorial Semi-Bandits,Siwei Wang,Tsinghua University
ICML,2018,Thompson Sampling for Combinatorial Semi-Bandits,Wei Chen,Microsoft
ICML,2018,Let’s be Honest: An Optimal No-Regret Framework for Zero-Sum Games,Ehsan Asadi Kangarshahi,University of Cambridge
ICML,2018,Let’s be Honest: An Optimal No-Regret Framework for Zero-Sum Games,Ya-Ping Hsieh,École Polytechnique Fédérale d
ICML,2018,Let’s be Honest: An Optimal No-Regret Framework for Zero-Sum Games,Mehmet Fatih Sahin,Ecole Polytechnique Fédérale de Lausanne
ICML,2018,Let’s be Honest: An Optimal No-Regret Framework for Zero-Sum Games,Volkan Cevher,EPFL
ICML,2018,Deep Asymmetric Multi-task Feature Learning,Hae Beom Lee,UNIST
ICML,2018,Deep Asymmetric Multi-task Feature Learning,Eunho Yang,KAIST / AItrics
ICML,2018,Deep Asymmetric Multi-task Feature Learning,Sung Ju Hwang,KAIST
ICML,2018,Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations,Ashwin Kalyan,Georgia Tech
ICML,2018,Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations,Stefan Lee,Georgia Institute of Technology
ICML,2018,Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations,Anitha Kannan,Curai
ICML,2018,Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations,Dhruv Batra,Georgia Institute of Technology / Facebook AI Research
ICML,2018,Stein Variational Message Passing for Continuous Graphical Models,Dilin Wang,UT Austin
ICML,2018,Stein Variational Message Passing for Continuous Graphical Models,Zhe Zeng,Zhejiang University
ICML,2018,Stein Variational Message Passing for Continuous Graphical Models,Qiang Liu,UT Austin
ICML,2018,Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms,Yi Wu,UC Berkeley
ICML,2018,Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms,Siddharth Srivastava,Arizona State University
ICML,2018,Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms,Nicholas Hay,
ICML,2018,Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms,Simon Du,Carnegie Mellon University
ICML,2018,Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms,Stuart Russell,UC Berkeley
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Zhuohan Li,Peking University
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Di He,Peking University
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Fei Tian,Microsoft Research
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Wei Chen,Microsoft
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Tao Qin,Microsoft Research Asia
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Liwei Wang,Peking University
ICML,2018,Towards Binary-Valued Gates for Robust LSTM Training,Tie-Yan Liu,Microsoft
ICML,2018,Fitting New Speakers Based on a Short Untranscribed Sample,Eliya Nachmani,Facebook AI Research and Tel Aviv University
ICML,2018,Fitting New Speakers Based on a Short Untranscribed Sample,Adam Polyak,Facebook AI Research and Tel Aviv University
ICML,2018,Fitting New Speakers Based on a Short Untranscribed Sample,Yaniv Taigman,Facebook
ICML,2018,Fitting New Speakers Based on a Short Untranscribed Sample,Lior Wolf,Facebook AI Research and Tel Aviv University
ICML,2018,Stochastic Variance-Reduced Policy Gradient,Matteo Papini,Politecnico di Milano
ICML,2018,Stochastic Variance-Reduced Policy Gradient,Damiano Binaghi,Politecnico di Milano
ICML,2018,Stochastic Variance-Reduced Policy Gradient,Giuseppe Canonaco,Politecnico di Milano
ICML,2018,Stochastic Variance-Reduced Policy Gradient,Matteo Pirotta,SequeL - Inria Lille - Nord Europe
ICML,2018,Stochastic Variance-Reduced Policy Gradient,Marcello Restelli,Politecnico di Milano
ICML,2018,Convergent Tree Backup and Retrace with Function Approximation,Ahmed Touati,MILA
ICML,2018,Convergent Tree Backup and Retrace with Function Approximation,Pierre-Luc Bacon,McGill
ICML,2018,Convergent Tree Backup and Retrace with Function Approximation,Doina Precup,McGill University / DeepMind
ICML,2018,Convergent Tree Backup and Retrace with Function Approximation,Pascal Vincent,U Montreal
ICML,2018,Alternating Randomized Block Coordinate Descent,Jelena Diakonikolas,Boston University
ICML,2018,Alternating Randomized Block Coordinate Descent,Orecchia Lorenzo,Boston
ICML,2018,Shampoo: Preconditioned Stochastic Tensor Optimization,Vineet Gupta,Google
ICML,2018,Shampoo: Preconditioned Stochastic Tensor Optimization,Tomer Koren,Google Brain
ICML,2018,Shampoo: Preconditioned Stochastic Tensor Optimization,Yoram Singer,Google
ICML,2018,Stochastic Wasserstein Barycenters,Sebastian Claici,MIT
ICML,2018,Stochastic Wasserstein Barycenters,Edward Chien,Massachusetts Institute of Technology
ICML,2018,Stochastic Wasserstein Barycenters,Justin Solomon,MIT
ICML,2018,Accelerating Natural Gradient with Higher-Order Invariance,Yang Song,Stanford University
ICML,2018,Accelerating Natural Gradient with Higher-Order Invariance,Jiaming Song,Stanford
ICML,2018,Accelerating Natural Gradient with Higher-Order Invariance,Stefano Ermon,Stanford University
ICML,2018,Learning unknown ODE models with Gaussian processes,Markus Heinonen,Aalto University
ICML,2018,Learning unknown ODE models with Gaussian processes,Cagatay Yildiz,Aalto University
ICML,2018,Learning unknown ODE models with Gaussian processes,Henrik Mannerström,Aalto University
ICML,2018,Learning unknown ODE models with Gaussian processes,Jukka Intosalmi,Aalto University
ICML,2018,Learning unknown ODE models with Gaussian processes,Harri Lähdesmäki,Aalto University
ICML,2018,Constraining the Dynamics of Deep Probabilistic Models,Marco Lorenzi,Inria Sophia Antipolis
ICML,2018,Constraining the Dynamics of Deep Probabilistic Models,Maurizio Filippone,Eurecom
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Lukasz Kaiser,Google
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Samy Bengio,Google Brain
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Aurko Roy,Google Brain
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Ashish Vaswani,Google Brain
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Niki Parmar,Google
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Jakob Uszkoreit,
ICML,2018,Fast Decoding in Sequence Models Using Discrete Latent Variables,Noam Shazeer,Google
ICML,2018,High Performance Zero-Memory Overhead Direct Convolutions,Jiyuan Zhang,Cargenie Mellon University
ICML,2018,High Performance Zero-Memory Overhead Direct Convolutions,Franz Franchetti,Carnegie Mellon University
ICML,2018,High Performance Zero-Memory Overhead Direct Convolutions,Tze Meng Low,Carnegie Mellon University
ICML,2018,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,Shuaiwen Wang,Columbia University
ICML,2018,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,Wenda Zhou,Columbia University
ICML,2018,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,Haihao Lu,MIT
ICML,2018,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,Arian Maleki,Columbia
ICML,2018,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,Vahab Mirrokni,Google Research
ICML,2018,Improved large-scale graph learning through ridge spectral sparsification,Daniele Calandriello,INRIA Lille
ICML,2018,Improved large-scale graph learning through ridge spectral sparsification,Alessandro Lazaric,Facebook AI Research
ICML,2018,Improved large-scale graph learning through ridge spectral sparsification,Ioannis Koutis,
ICML,2018,Improved large-scale graph learning through ridge spectral sparsification,Michal Valko,Inria Lille - Nord Europe
ICML,2018,Distilling the Posterior in Bayesian Neural Networks,Jackson Wang,Univeristy of Toronto
ICML,2018,Distilling the Posterior in Bayesian Neural Networks,Paul Vicol,University of Toronto
ICML,2018,Distilling the Posterior in Bayesian Neural Networks,James Lucas,University of Toronto
ICML,2018,Distilling the Posterior in Bayesian Neural Networks,Li Gu,University of Toronto
ICML,2018,Distilling the Posterior in Bayesian Neural Networks,Roger Grosse,University of Toronto and Vector Institute
ICML,2018,Distilling the Posterior in Bayesian Neural Networks,Richard Zemel,Vector Institute
ICML,2018,Scalable approximate Bayesian inference for particle tracking data,Ruoxi Sun,Columbia University
ICML,2018,Scalable approximate Bayesian inference for particle tracking data,Department of Statistics Liam Paninski,"Department of Statistics, Columbia University"
ICML,2018,Weakly Consistent Optimal Pricing Algorithms in Repeated Posted-Price Auctions with Strategic Buyer,Alexey Drutsa,Yandex; MSU
ICML,2018,Practical Contextual Bandits with Regression Oracles,Dylan Foster,Cornell University
ICML,2018,Practical Contextual Bandits with Regression Oracles,Alekh Agarwal,Microsoft Research
ICML,2018,Practical Contextual Bandits with Regression Oracles,Miroslav Dudik,Microsoft Research
ICML,2018,Practical Contextual Bandits with Regression Oracles,Haipeng Luo,University of Southern California
ICML,2018,Practical Contextual Bandits with Regression Oracles,Robert Schapire,Microsoft Research
ICML,2018,Stochastic Variance-Reduced Hamilton Monte Carlo Methods,Difan Zou,University of Virginia
ICML,2018,Stochastic Variance-Reduced Hamilton Monte Carlo Methods,Pan Xu,"University of California, Los Angeles"
ICML,2018,Stochastic Variance-Reduced Hamilton Monte Carlo Methods,Quanquan Gu,UCLA
ICML,2018,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,Umut Simsekli,Telecom ParisTech
ICML,2018,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,Cagatay Yildiz,Aalto University
ICML,2018,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,Thanh Huy Nguyen,Telecom ParisTech
ICML,2018,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,Ali Taylan Cemgil,Bogazici University
ICML,2018,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,Gaël RICHARD,Télécom ParisTech
ICML,2018,GAIN: Missing Data Imputation using Generative Adversarial Nets,Jinsung Yoon,"University of California, Los Angeles"
ICML,2018,GAIN: Missing Data Imputation using Generative Adversarial Nets,James Jordon,University of Oxford
ICML,2018,GAIN: Missing Data Imputation using Generative Adversarial Nets,Mihaela van der Schaar,University of Oxford
ICML,2018,Synthesizing Programs for Images using Reinforced Adversarial Learning,Yaroslav Ganin,Montreal Institute for Learning Algorithms
ICML,2018,Synthesizing Programs for Images using Reinforced Adversarial Learning,Tejas Kulkarni,DeepMind
ICML,2018,Synthesizing Programs for Images using Reinforced Adversarial Learning,Igor Babuschkin,DeepMind
ICML,2018,Synthesizing Programs for Images using Reinforced Adversarial Learning,S. M. Ali Eslami,DeepMind
ICML,2018,Synthesizing Programs for Images using Reinforced Adversarial Learning,Oriol Vinyals,DeepMind
ICML,2018,Geometry Score: A Method For Comparing Generative Adversarial Networks,Valentin Khrulkov,Skolkovo Institute Of Science And Technology
ICML,2018,Geometry Score: A Method For Comparing Generative Adversarial Networks,Ivan Oseledets,Skoltech
ICML,2018,Addressing Function Approximation Error in Actor-Critic Methods,Scott Fujimoto,McGill University
ICML,2018,Addressing Function Approximation Error in Actor-Critic Methods,Herke van Hoof,McGill University
ICML,2018,Addressing Function Approximation Error in Actor-Critic Methods,David Meger,McGill University
ICML,2018,Fast Bellman Updates for Robust MDPs,Clint Ho,Imperial College London
ICML,2018,Fast Bellman Updates for Robust MDPs,Marek Petrik,University of New Hamoshire
ICML,2018,Fast Bellman Updates for Robust MDPs,Wolfram Wiesemann,Imperial College
ICML,2018,Configurable Markov Decision Processes,Alberto Maria Metelli,Politecnico di Milano
ICML,2018,Configurable Markov Decision Processes,Mirco Mutti,Politecnico di Milano
ICML,2018,Configurable Markov Decision Processes,Marcello Restelli,Politecnico di Milano
ICML,2018,Prediction Rule Reshaping,Matt Bonakdarpour,University of Chicago
ICML,2018,Prediction Rule Reshaping,Sabyasachi Chatterjee,Sabyasachi Chatterjee
ICML,2018,Prediction Rule Reshaping,Rina Barber,
ICML,2018,Prediction Rule Reshaping,John Lafferty,Yale University
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Daniel Ma,The University of Melbourne
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Yisen Wang,Tsinghua University
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Michael E. Houle,National Institute of Informatics
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Shuo Zhou,The University of Melbourne
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Sarah Erfani,University of Melbourne
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Shutao Xia,Tsinghua University
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,Sudanthi Wijewickrema,University of Melbourne
ICML,2018,Dimensionality-Driven Learning with Noisy Labels,James Bailey,The University of Melbourne
ICML,2018,Learning Memory Access Patterns,Milad Hashemi,Google
ICML,2018,Learning Memory Access Patterns,Kevin Swersky,Google Brain
ICML,2018,Learning Memory Access Patterns,Jamie Smith,Google
ICML,2018,Learning Memory Access Patterns,Grant Ayers,Stanford
ICML,2018,Learning Memory Access Patterns,Heiner Litz,UC Santa Cruz
ICML,2018,Learning Memory Access Patterns,Jichuan Chang,Google
ICML,2018,Learning Memory Access Patterns,Christos Kozyrakis,Stanford University
ICML,2018,Learning Memory Access Patterns,Partha Ranganathan,"Google, USA"
ICML,2018,Geodesic Convolutional Shape Optimization,Pierre Baque,EPFL
ICML,2018,Geodesic Convolutional Shape Optimization,Edoardo Remelli,epfl
ICML,2018,Geodesic Convolutional Shape Optimization,Francois Fleuret,Idiap research institute
ICML,2018,Geodesic Convolutional Shape Optimization,EPFL Pascal Fua,"EPFL, Switzerland"
ICML,2018,Visualizing and Understanding Atari Agents,Samuel Greydanus,Oregon State University
ICML,2018,Visualizing and Understanding Atari Agents,Anurag Koul,Oregon State University
ICML,2018,Visualizing and Understanding Atari Agents,Jonathan Dodge,Oregon State University
ICML,2018,Visualizing and Understanding Atari Agents,Alan Fern,Oregon State University
ICML,2018,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",Dhruv Malik,UC Berkeley
ICML,2018,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",Andy Palaniappan,UC Berkeley
ICML,2018,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",Jaime Fisac,UC Berkeley
ICML,2018,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",Dylan Hadfield-Menell,UC Berkeley
ICML,2018,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",Stuart Russell,UC Berkeley
ICML,2018,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",EECS Anca Dragan,"EECS Department, University of California, Berkeley"
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Augustus Odena,Google Brain
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Jacob Buckman,Google
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Catherine Olsson,Google Brain
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Tom B Brown,Google Brain
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Christopher Olah,Google Brain
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Colin Raffel,Google
ICML,2018,Is Generator Conditioning Causally Related to GAN Performance?,Ian Goodfellow,Google Brain
ICML,2018,K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning,Jihun Hamm,The Ohio State University
ICML,2018,K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning,Yung-Kyun Noh,Seoul National University
ICML,2018,Inductive Two-Layer Modeling with Parametric Bregman Transfer,Vignesh Ganapathiraman,University of Illinois at Chicago
ICML,2018,Inductive Two-Layer Modeling with Parametric Bregman Transfer,Zhan Shi,University of Illinois at Chicago
ICML,2018,Inductive Two-Layer Modeling with Parametric Bregman Transfer,Xinhua Zhang,University of Illinois at Chicago
ICML,2018,Inductive Two-Layer Modeling with Parametric Bregman Transfer,Yaoliang Yu,University of Waterloo
ICML,2018,Does Distributionally Robust Supervised Learning Give Robust Classifiers?,Weihua Hu,The University of Tokyo
ICML,2018,Does Distributionally Robust Supervised Learning Give Robust Classifiers?,Gang Niu,RIKEN
ICML,2018,Does Distributionally Robust Supervised Learning Give Robust Classifiers?,Issei Sato,University of Tokyo / RIKEN
ICML,2018,Does Distributionally Robust Supervised Learning Give Robust Classifiers?,Masashi Sugiyama,RIKEN / The University of Tokyo
ICML,2018,Understanding Generalization and Optimization Performance of Deep CNNs,Pan Zhou,National University of Singapore
ICML,2018,Understanding Generalization and Optimization Performance of Deep CNNs,Jiashi Feng,National University of Singapore
ICML,2018,The Multilinear Structure of ReLU Networks,Thomas Laurent,Loyola Marymount University
ICML,2018,The Multilinear Structure of ReLU Networks,James von Brecht,CSULB
ICML,2018,Parallel and Streaming Algorithms for K-Core Decomposition,Hossein Esfandiari,Harvard University
ICML,2018,Parallel and Streaming Algorithms for K-Core Decomposition,Silvio Lattanzi,Google Zurich
ICML,2018,Parallel and Streaming Algorithms for K-Core Decomposition,Vahab Mirrokni,Google Research
ICML,2018,Fast Approximate Spectral Clustering for Dynamic Networks,Lionel Martin,EPFL
ICML,2018,Fast Approximate Spectral Clustering for Dynamic Networks,Andreas Loukas,EPFL
ICML,2018,Fast Approximate Spectral Clustering for Dynamic Networks,Pierre Vandergheynst,École polytechnique fédérale de Lausanne
ICML,2018,Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima,Simon Du,Carnegie Mellon University
ICML,2018,Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima,Jason Lee,University of Southern California
ICML,2018,Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima,Yuandong Tian,Facebook AI Research
ICML,2018,Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima,Aarti Singh,Carnegie Mellon University
ICML,2018,Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima,Barnabás Póczos,CMU
ICML,2018,Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions,Quynh Nguyen,Saarland University
ICML,2018,Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions,Mahesh Mukkamala,Saarland University
ICML,2018,Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions,Matthias Hein,University of Tuebingen
ICML,2018,Greed is Still Good: Maximizing Monotone Submodular+Supermodular (BP) Functions,Wenruo Bai,University of Washington
ICML,2018,Greed is Still Good: Maximizing Monotone Submodular+Supermodular (BP) Functions,Jeff Bilmes,UW
ICML,2018,Black-box Adversarial Attacks with Limited Queries and Information,Andrew Ilyas,Massachusetts Institute of Technology
ICML,2018,Black-box Adversarial Attacks with Limited Queries and Information,Logan Engstrom,MIT
ICML,2018,Black-box Adversarial Attacks with Limited Queries and Information,Anish Athalye,MIT CSAIL
ICML,2018,Black-box Adversarial Attacks with Limited Queries and Information,Jessy Lin,MIT
ICML,2018,Using Inherent Structures to design Lean 2-layer RBMs,Abhishek Bansal,IBM Research
ICML,2018,Using Inherent Structures to design Lean 2-layer RBMs,Abhinav Anand,Indian Institute of Science
ICML,2018,Using Inherent Structures to design Lean 2-layer RBMs,Chiru Bhattacharyya,Indian Institute of Science
ICML,2018,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,Patrick Schwab,ETH Zurich
ICML,2018,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,Emanuela Keller,University Hospital Zurich
ICML,2018,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,Carl Muroi,University Hospital Zurich
ICML,2018,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,David J. Mack,University Hospital Zurich
ICML,2018,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,Christian Strässle,University Hospital Zurich
ICML,2018,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,Walter Karlen,ETH Zurich
ICML,2018,Composable Planning with Attributes,Amy Zhang,Facebook AI Research
ICML,2018,Composable Planning with Attributes,Sainbayar Sukhbaatar,NYU
ICML,2018,Composable Planning with Attributes,Adam Lerer,Facebook AI Research
ICML,2018,Composable Planning with Attributes,Arthur Szlam,Facebook
ICML,2018,Composable Planning with Attributes,Facebook Rob Fergus,"Facebook AI Research, NYU"
ICML,2018,Measuring abstract reasoning in neural networks,Adam Santoro,DeepMind
ICML,2018,Measuring abstract reasoning in neural networks,Feilx Hill,Deepmind
ICML,2018,Measuring abstract reasoning in neural networks,David GT Barrett,DeepMind
ICML,2018,Measuring abstract reasoning in neural networks,Ari S Morcos,DeepMind
ICML,2018,Measuring abstract reasoning in neural networks,Tim Lillicrap,Google DeepMind
ICML,2018,Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity,Lin Chen,Yale University
ICML,2018,Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity,Chris Harshaw,Yale University
ICML,2018,Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity,Hamed Hassani,University of Pennsylvania
ICML,2018,Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity,Amin Karbasi,Yale
ICML,2018,Self-Bounded Prediction Suffix Tree via Approximate String Matching,Dongwoo Kim,The Australian National University
ICML,2018,Self-Bounded Prediction Suffix Tree via Approximate String Matching,Christian Walder,"Data61, the Australian National University"
ICML,2018,MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,Lu Jiang,Google
ICML,2018,MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,Zhengyuan Zhou,Stanford University
ICML,2018,MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,Thomas Leung,Google Inc
ICML,2018,MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,Li-Jia Li,Google
ICML,2018,MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,Li Fei-Fei,Stanford University & Google
ICML,2018,Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks,Daphna Weinshall,"Hebrew University of Jerusalem, Israel"
ICML,2018,Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks,Gad A Cohen,Hebrew University
ICML,2018,Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks,Dan Amir,Hebrew University of Jerusalem
ICML,2018,Composite Functional Gradient Learning of Generative  Adversarial Models,Rie Johnson,RJ Research Consulting
ICML,2018,Composite Functional Gradient Learning of Generative  Adversarial Models,Tong Zhang,Tecent AI Lab
ICML,2018,LaVAN: Localized and Visible Adversarial Noise,Danny Karmon,Bar Ilan University
ICML,2018,LaVAN: Localized and Visible Adversarial Noise,Daniel Zoran,DeepMind
ICML,2018,LaVAN: Localized and Visible Adversarial Noise,Yoav Goldberg,Bar Ilan University
ICML,2018,Approximation Guarantees for Adaptive Sampling,Eric Balkanski,Harvard
ICML,2018,Approximation Guarantees for Adaptive Sampling,Yaron Singer,Harvard
ICML,2018,Constrained Interacting Submodular Groupings,Andrew Cotter,Google
ICML,2018,Constrained Interacting Submodular Groupings,Mahdi Milani Fard,Google
ICML,2018,Constrained Interacting Submodular Groupings,Seungil You,Google
ICML,2018,Constrained Interacting Submodular Groupings,Maya Gupta,Google
ICML,2018,Constrained Interacting Submodular Groupings,Jeff Bilmes,UW
ICML,2018,Residual Unfairness in Fair Machine Learning from Prejudiced Data,Nathan Kallus,Cornell University
ICML,2018,Residual Unfairness in Fair Machine Learning from Prejudiced Data,Angela Zhou,Cornell University
ICML,2018,Adversarial Regression with Multiple Learners,Liang Tong,Vanderbilt University
ICML,2018,Adversarial Regression with Multiple Learners,Sixie Yu,Vanderbilt University
ICML,2018,Adversarial Regression with Multiple Learners,Scott Alfeld,Amherst College
ICML,2018,Adversarial Regression with Multiple Learners,Yevgeniy Vorobeychik,Vanderbilt University
ICML,2018,Representation Tradeoffs for Hyperbolic Embeddings,Frederic Sala,Stanford
ICML,2018,Representation Tradeoffs for Hyperbolic Embeddings,Chris De Sa,Cornell
ICML,2018,Representation Tradeoffs for Hyperbolic Embeddings,Albert Gu,Stanford University
ICML,2018,Representation Tradeoffs for Hyperbolic Embeddings,Christopher Re,Stanford
ICML,2018,Improving Sign Random Projections With Additional Information,Keegan Kang,Singapore University Of Technology And Design
ICML,2018,Improving Sign Random Projections With Additional Information,Wei Pin Wong,Singapore University of Technology and Design
ICML,2018,"Bandits with Delayed, Aggregated Anonymous Feedback",Ciara Pike-Burke,Lancaster University
ICML,2018,"Bandits with Delayed, Aggregated Anonymous Feedback",Shipra Agrawal,Columbia University
ICML,2018,"Bandits with Delayed, Aggregated Anonymous Feedback",Csaba Szepesvari,Deepmind/University of Alberta
ICML,2018,"Bandits with Delayed, Aggregated Anonymous Feedback",Steffen Grünewälder,Lancaster University
ICML,2018,Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits,Zeyuan Allen-Zhu,Microsoft Research AI
ICML,2018,Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits,Sebastien Bubeck,Microsoft Research
ICML,2018,Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits,Yuanzhi Li,Princeton University
ICML,2018,Learning Policy Representations in Multiagent Systems,Aditya Grover,Stanford University
ICML,2018,Learning Policy Representations in Multiagent Systems,Maruan Al-Shedivat,Carnegie Mellon University
ICML,2018,Learning Policy Representations in Multiagent Systems,Jayesh Gupta,Stanford University
ICML,2018,Learning Policy Representations in Multiagent Systems,Yura Burda,OpenAI
ICML,2018,Learning Policy Representations in Multiagent Systems,Harrison Edwards,OpenAI / University of Edinburgh
ICML,2018,Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems,Eugenio Bargiacchi,Vrije Universiteit Brussel
ICML,2018,Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems,Timothy Verstraeten,Vrije Universiteit Brussel
ICML,2018,Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems,Diederik Roijers,VUB
ICML,2018,Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems,Ann Nowé,Vrije Universiteit Brussel
ICML,2018,Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems,Hado van Hasselt,DeepMind
ICML,2018,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,Yiping Lu,Peking University
ICML,2018,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,Aoxiao Zhong,Zhejiang University
ICML,2018,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,Quanzheng Li,"Mass General Hospital, Harvard Medical School"
ICML,2018,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,Bin Dong,Peking University
ICML,2018,Compressing Neural Networks using the Variational Information Bottelneck,Bin Dai,Tsinghua University
ICML,2018,Compressing Neural Networks using the Variational Information Bottelneck,Chen Zhu,University of Maryland
ICML,2018,Compressing Neural Networks using the Variational Information Bottelneck,Baining Guo,MSR Asia
ICML,2018,Compressing Neural Networks using the Variational Information Bottelneck,David Wipf,Microsoft Research
ICML,2018,Scalable Bilinear Pi Learning Using State and Action Features,Yichen Chen,Princeton University
ICML,2018,Scalable Bilinear Pi Learning Using State and Action Features,Lihong Li,Google Inc.
ICML,2018,Scalable Bilinear Pi Learning Using State and Action Features,Mengdi Wang,Princeton University
ICML,2018,Time Limits in Reinforcement Learning,Fabio Pardo,Imperial College London
ICML,2018,Time Limits in Reinforcement Learning,Arash Tavakoli,Imperial College London
ICML,2018,Time Limits in Reinforcement Learning,Vitaly Levdik,Imperial College London
ICML,2018,Time Limits in Reinforcement Learning,Petar Kormushev,Imperial College London
ICML,2018,Semi-Supervised Learning on Data Streams via Temporal Label Propagation,Tal Wagner,MIT
ICML,2018,Semi-Supervised Learning on Data Streams via Temporal Label Propagation,Sudipto Guha,Amazon
ICML,2018,Semi-Supervised Learning on Data Streams via Temporal Label Propagation,Shiva Kasiviswanathan,Amazon
ICML,2018,Semi-Supervised Learning on Data Streams via Temporal Label Propagation,Nina Mishra,Amazon
ICML,2018,Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion,Cong Ma,Princeton University
ICML,2018,Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion,Kaizheng Wang,Princeton University
ICML,2018,Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion,Yuejie Chi,CMU
ICML,2018,Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion,Yuxin Chen,Princeton University
ICML,2018,A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models,Beilun Wang,University of Virginia
ICML,2018,A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models,Arshdeep Sekhon,University of Virginia
ICML,2018,A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models,Yanjun Qi,University of Virginia
ICML,2018,Bucket Renormalization for Approximate Inference,Sungsoo Ahn,KAIST
ICML,2018,Bucket Renormalization for Approximate Inference,Misha Chertkov,Los Alamos National Laboratory
ICML,2018,Bucket Renormalization for Approximate Inference,Adrian Weller,"University of Cambridge, Alan Turing Institute"
ICML,2018,Bucket Renormalization for Approximate Inference,Jinwoo Shin,KAIST
ICML,2018,Kernel Recursive ABC: Point Estimation with Intractable Likelihood,Takafumi Kajihara,NEC
ICML,2018,Kernel Recursive ABC: Point Estimation with Intractable Likelihood,Motonobu Kanagawa,Max Planck Institute for Intelligent Systems
ICML,2018,Kernel Recursive ABC: Point Estimation with Intractable Likelihood,Keisuke Yamazaki,National Institute of Advanced Industrial Science and Technology
ICML,2018,Kernel Recursive ABC: Point Estimation with Intractable Likelihood,Kenji Fukumizu,Institute of Statistical Mathematics
ICML,2018,Modeling Others using Oneself in Multi-Agent Reinforcement Learning,Roberta Raileanu,NYU
ICML,2018,Modeling Others using Oneself in Multi-Agent Reinforcement Learning,Emily Denton,New York University
ICML,2018,Modeling Others using Oneself in Multi-Agent Reinforcement Learning,Arthur Szlam,Facebook
ICML,2018,Modeling Others using Oneself in Multi-Agent Reinforcement Learning,Facebook Rob Fergus,"Facebook AI Research, NYU"
ICML,2018,Tropical Geometry of Deep Neural Networks,Liwen Zhang,University of Chicago
ICML,2018,Tropical Geometry of Deep Neural Networks,Gregory Naisat,The University of Chicago
ICML,2018,Tropical Geometry of Deep Neural Networks,Lek-Heng Lim,University of Chicago
ICML,2018,Learning Dynamics of Linear Denoising Autoencoders,Arnu Pretorius,Stellenbosch University
ICML,2018,Learning Dynamics of Linear Denoising Autoencoders,Steve Kroon,Stellenbosch University
ICML,2018,Learning Dynamics of Linear Denoising Autoencoders,Herman Kamper,Stellenbosch University
ICML,2018,Nonparametric variable importance using an augmented neural network with multi-task learning,Jean Feng,University of Washington
ICML,2018,Nonparametric variable importance using an augmented neural network with multi-task learning,Brian Williamson,University of Washington
ICML,2018,Nonparametric variable importance using an augmented neural network with multi-task learning,Noah Simon,University of Washington
ICML,2018,Nonparametric variable importance using an augmented neural network with multi-task learning,Marco Carone,University of Washington
ICML,2018,Training Neural Machines with Trace-Based Supervision,Matthew Mirman,ETH Zürich
ICML,2018,Training Neural Machines with Trace-Based Supervision,Dimitar Dimitrov,ETH Zurich
ICML,2018,Training Neural Machines with Trace-Based Supervision,Pavle Djordjevic,ETH
ICML,2018,Training Neural Machines with Trace-Based Supervision,Timon Gehr,ETH Zurich
ICML,2018,Training Neural Machines with Trace-Based Supervision,Martin Vechev,ETH Zurich
ICML,2018,Open Category Detection with PAC Guarantees,Si Liu,Oregon State University
ICML,2018,Open Category Detection with PAC Guarantees,Risheek Garrepalli,Oregon State University
ICML,2018,Open Category Detection with PAC Guarantees,Thomas Dietterich,(organization)
ICML,2018,Open Category Detection with PAC Guarantees,Alan Fern,Oregon State University
ICML,2018,Open Category Detection with PAC Guarantees,Dan Hendrycks,UC Berkeley
ICML,2018,SAFFRON: an Adaptive Algorithm for Online Control of the False Discovery Rate,Aaditya Ramdas,UC Berkeley
ICML,2018,SAFFRON: an Adaptive Algorithm for Online Control of the False Discovery Rate,Tijana Zrnic,"University of California, Berkeley"
ICML,2018,SAFFRON: an Adaptive Algorithm for Online Control of the False Discovery Rate,Martin Wainwright,University of California at Berkeley
ICML,2018,SAFFRON: an Adaptive Algorithm for Online Control of the False Discovery Rate,Michael Jordan,UC Berkeley
ICML,2018,Learning Localized Spatio-Temporal Models From Streaming Data,Muhammad Osama,Uppsala University
ICML,2018,Learning Localized Spatio-Temporal Models From Streaming Data,Dave Zachariah,Uppsala University
ICML,2018,Learning Localized Spatio-Temporal Models From Streaming Data,Thomas Schön,Uppsala University
ICML,2018,Feasible Arm Identification,Julian Katz-Samuels,University of Michigan
ICML,2018,Feasible Arm Identification,Clay Scott,University of Michigan
ICML,2018,"Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice",Alan Kuhnle,University of Florida
ICML,2018,"Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice",J. Smith,University of Florida
ICML,2018,"Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice",Victoria Crawford,University of Florida
ICML,2018,"Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice",My Thai,University of Florida
ICML,2018,Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings,Aryan Mokhtari,MIT
ICML,2018,Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings,Hamed Hassani,University of Pennsylvania
ICML,2018,Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings,Amin Karbasi,Yale
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Lily Weng,MIT
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Huan Zhang,UC Davis
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Hongge Chen,MIT
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Zhao Song,UT-Austin
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Cho-Jui Hsieh,"University of California, Davis"
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Luca Daniel,MIT
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Duane Boning,MIT
ICML,2018,Towards Fast Computation of Certified Robustness for ReLU Networks,Inderjit Dhillon,UT Austin & Amazon
ICML,2018,A Two-Step Computation of the Exact GAN Wasserstein Distance,Huidong Liu,Stony Brook University
ICML,2018,A Two-Step Computation of the Exact GAN Wasserstein Distance,Xianfeng GU,Stony Brook University
ICML,2018,A Two-Step Computation of the Exact GAN Wasserstein Distance,Samaras Dimitris,Stony Brook University
ICML,2018,Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection,Jeremias Knoblauch,Warwick University
ICML,2018,Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection,Theo Damoulas,University of Warwick
ICML,2018,Fast Stochastic AUC Maximization with $O(1/n)$-Convergence Rate,Mingrui Liu,The University of Iowa
ICML,2018,Fast Stochastic AUC Maximization with $O(1/n)$-Convergence Rate,Xiaoxuan Zhang,University of Iowa
ICML,2018,Fast Stochastic AUC Maximization with $O(1/n)$-Convergence Rate,Zaiyi Chen,University of Science and Technology of China
ICML,2018,Fast Stochastic AUC Maximization with $O(1/n)$-Convergence Rate,Xiaoyu Wang,-
ICML,2018,Fast Stochastic AUC Maximization with $O(1/n)$-Convergence Rate,Tianbao Yang,The University of Iowa
ICML,2018,Accurate Uncertainties for Deep Learning Using Calibrated Regression,Volodymyr Kuleshov,Stanford University
ICML,2018,Accurate Uncertainties for Deep Learning Using Calibrated Regression,Nathan Fenner,Afresh Technologies
ICML,2018,Accurate Uncertainties for Deep Learning Using Calibrated Regression,Stefano Ermon,Stanford University
ICML,2018,Neural Autoregressive Flows,Chin-Wei Huang,MILA
ICML,2018,Neural Autoregressive Flows,David Krueger,Universit? de Montr?al
ICML,2018,Neural Autoregressive Flows,Alexandre Lacoste,Element AI
ICML,2018,Neural Autoregressive Flows,Aaron Courville,University of Montreal
ICML,2018,Probabilistic Boolean Tensor Decomposition,Tammo Rukat,University of Oxford
ICML,2018,Probabilistic Boolean Tensor Decomposition,Christopher Holmes,University of Oxford
ICML,2018,Probabilistic Boolean Tensor Decomposition,Christopher Yau,University of Birmingham
ICML,2018,A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery,Xiao Zhang,University of Virginia
ICML,2018,A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery,Lingxiao Wang,UCLA
ICML,2018,A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery,Yaodong Yu,University of Virginia
ICML,2018,A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery,Quanquan Gu,UCLA
ICML,2018,A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning,Konstantin Mishchenko,King Abdullah University of Science & Technology (KAUST)
ICML,2018,A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning,Franck Iutzeler,Univ. Grenoble Alpes
ICML,2018,A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning,Jérôme Malick,CNRS
ICML,2018,A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning,Massih-Reza Amini,Univ. Grenoble Alpes
ICML,2018,Randomized Block Cubic Newton Method,Nikita Doikov,National Research University Higher School of Economics
ICML,2018,Randomized Block Cubic Newton Method,Peter Richtarik,"King Abdullah University of Science and Technology (KAUST) - University of Edinburgh, Scotland"
ICML,2018,Massively Parallel Algorithms and Hardness for Single-Linkage Clustering under $\ell_p$ Distances,Grigory Yaroslavtsev,Indiana University
ICML,2018,Massively Parallel Algorithms and Hardness for Single-Linkage Clustering under $\ell_p$ Distances,Adithya Vadapalli,INDIANA UNIVERSITY
ICML,2018,Local Density Estimation in High Dimensions,Xian Wu,Stanford University
ICML,2018,Local Density Estimation in High Dimensions,Moses Charikar,Stanford University
ICML,2018,Local Density Estimation in High Dimensions,Vishnu Natchu,
ICML,2018,To Understand Deep Learning We Need to Understand Kernel Learning,Mikhail Belkin,Ohio State University
ICML,2018,To Understand Deep Learning We Need to Understand Kernel Learning,Siyuan Ma,The Ohio State University
ICML,2018,To Understand Deep Learning We Need to Understand Kernel Learning,Soumik Mandal,
ICML,2018,Learning in Reproducing Kernel Kreı̆n Spaces,Dino Oglic,University of Bonn
ICML,2018,Learning in Reproducing Kernel Kreı̆n Spaces,Thomas Gaertner,The University of Nottingham
ICML,2018,Functional Gradient Boosting based on Residual Network Perception,Atsushi Nitanda,The University of Tokyo / RIKEN
ICML,2018,Functional Gradient Boosting based on Residual Network Perception,Taiji Suzuki,The University of Tokyo / RIKEN
ICML,2018,"Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",Bowei Yan,University of Texas at Austin
ICML,2018,"Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",Sanmi Koyejo,University of Illinois at Urbana-Champaign
ICML,2018,"Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",Kai Zhong,University of Texas at Austin
ICML,2018,"Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",Pradeep Ravikumar,Carnegie Mellon University
ICML,2018,Characterizing Implicit Bias in Terms of Optimization Geometry,Suriya Gunasekar,Toyota Technological Institute at Chicago
ICML,2018,Characterizing Implicit Bias in Terms of Optimization Geometry,Jason Lee,University of Southern California
ICML,2018,Characterizing Implicit Bias in Terms of Optimization Geometry,Daniel Soudry,Technion
ICML,2018,Characterizing Implicit Bias in Terms of Optimization Geometry,Nati Srebro,Toyota Technological Institute at Chicago
ICML,2018,prDeep: Robust Phase Retrieval with a Flexible Deep Network,Christopher Metzler,Rice University
ICML,2018,prDeep: Robust Phase Retrieval with a Flexible Deep Network,Phil Schniter,Ohio State
ICML,2018,prDeep: Robust Phase Retrieval with a Flexible Deep Network,Ashok Veeraraghavan,Rice University
ICML,2018,prDeep: Robust Phase Retrieval with a Flexible Deep Network,Richard Baraniuk,OpenStax / Rice University
ICML,2018,Adversarial Time-to-Event Modeling,Paidamoyo Chapfuwa,Duke University
ICML,2018,Adversarial Time-to-Event Modeling,Chenyang Tao,Duke University
ICML,2018,Adversarial Time-to-Event Modeling,Chunyuan Li,Duke University
ICML,2018,Adversarial Time-to-Event Modeling,Courtney Page,Duke University
ICML,2018,Adversarial Time-to-Event Modeling,Benjamin Goldstein,
ICML,2018,Adversarial Time-to-Event Modeling,Lawrence Carin,Duke
ICML,2018,Adversarial Time-to-Event Modeling,Ricardo Henao,Duke University
ICML,2018,MAGAN: Aligning Biological Manifolds,Matt Amodio,Yale University
ICML,2018,MAGAN: Aligning Biological Manifolds,Smita Krishnaswamy,Yale University
ICML,2018,Multicalibration: Calibration for the (Computationally-Identifiable) Masses,Ursula Hebert-Johnson,Stanford University
ICML,2018,Multicalibration: Calibration for the (Computationally-Identifiable) Masses,Michael Kim,Stanford University
ICML,2018,Multicalibration: Calibration for the (Computationally-Identifiable) Masses,Omer Reingold,Stanford University
ICML,2018,Multicalibration: Calibration for the (Computationally-Identifiable) Masses,Guy Rothblum,Weizmann Institute of Science
ICML,2018,Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms,Xueru Zhang,University of Michigan
ICML,2018,Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms,Mohammad Khalili,University of Michigan
ICML,2018,Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms,Mingyan Liu,"University of Michigan, Ann Arbor"
ICML,2018,PixelSNAIL: An Improved Autoregressive Generative Model,Xi Chen,covariant.ai
ICML,2018,PixelSNAIL: An Improved Autoregressive Generative Model,Nikhil Mishra,
ICML,2018,PixelSNAIL: An Improved Autoregressive Generative Model,Mostafa Rohaninejad,
ICML,2018,PixelSNAIL: An Improved Autoregressive Generative Model,Pieter Abbeel,OpenAI / UC Berkeley
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Rosemary Nan Ke,"MILA, University of Montreal"
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Konrad Zolna,"Universite de Montreal, Jagiellonian University"
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Alessandro Sordoni,Microsoft Research
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,MILA Zhouhan Lin,"MILA, University of Montreal"
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Adam Trischler,Microsoft Research
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Yoshua Bengio,U. Montreal
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Joelle Pineau,McGill University / Facebook
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Laurent Charlin,McGill University
ICML,2018,Focused Hierarchical RNNs for Conditional Sequence Processing,Christopher Pal,École Polytechnique de Montréal
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Jaakko Lehtinen,Aalto University & NVIDIA
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Jacob Munkberg,NVIDIA
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Jon Hasselgren,NVIDIA
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Samuli Laine,NVIDIA Research
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Tero Karras,NVIDIA
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Miika Aittala,MIT
ICML,2018,Noise2Noise: Learning Image Restoration without Clean Data,Timo Aila,NVIDIA
ICML,2018,Learning to Reweight Examples for Robust Deep Learning,Mengye Ren,Uber ATG / University of Toronto
ICML,2018,Learning to Reweight Examples for Robust Deep Learning,Wenyuan Zeng,"University of Toronto, Uber ATG"
ICML,2018,Learning to Reweight Examples for Robust Deep Learning,Bin Yang,Uber ATG / University of Toronto
ICML,2018,Learning to Reweight Examples for Robust Deep Learning,Raquel Urtasun,University of Toronto
ICML,2018,Policy and Value Transfer in Lifelong Reinforcement Learning,David Abel,Brown University
ICML,2018,Policy and Value Transfer in Lifelong Reinforcement Learning,Yuu Jinnai,Brown University
ICML,2018,Policy and Value Transfer in Lifelong Reinforcement Learning,Sophie Guo,Guo
ICML,2018,Policy and Value Transfer in Lifelong Reinforcement Learning,George Konidaris,Brown
ICML,2018,Policy and Value Transfer in Lifelong Reinforcement Learning,Michael L. Littman,Brown University
ICML,2018,GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms,Cédric Colas,Inria
ICML,2018,GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms,Olivier Sigaud,Sorbonne University
ICML,2018,GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms,Pierre-Yves Oudeyer,Inria
ICML,2018,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,Adam Roberts,Google Brain
ICML,2018,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,JesseEngel Engel,Google Brain
ICML,2018,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,Colin Raffel,Google
ICML,2018,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,"Curtis ""Fjord"" Hawthorne",Google Brain
ICML,2018,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,Douglas Eck,Google Brain
ICML,2018,Understanding the Loss Surface of Neural Networks for Binary Classification,SHIYU LIANG,UIUC
ICML,2018,Understanding the Loss Surface of Neural Networks for Binary Classification,Ruoyu Sun,University of Illinois at Urbana-Champaign
ICML,2018,Understanding the Loss Surface of Neural Networks for Binary Classification,Yixuan Li,Facebook Inc
ICML,2018,Understanding the Loss Surface of Neural Networks for Binary Classification,R Srikant,UIUC
ICML,2018,Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks,Minmin Chen,Google research
ICML,2018,Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks,Jeffrey Pennington,Google Brain
ICML,2018,Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks,Samuel Schoenholz,Google Brain
ICML,2018,Reviving and Improving Recurrent Back-Propagation,Renjie Liao,University of Toronto
ICML,2018,Reviving and Improving Recurrent Back-Propagation,Yuwen Xiong,Uber ATG / University of Toronto
ICML,2018,Reviving and Improving Recurrent Back-Propagation,Ethan Fetaya,University of Toronto
ICML,2018,Reviving and Improving Recurrent Back-Propagation,Lisa Zhang,University of Toronto
ICML,2018,Reviving and Improving Recurrent Back-Propagation,KiJung Yoon,Rice University
ICML,2018,Reviving and Improving Recurrent Back-Propagation,xaq S Pitkow,Baylor College of Medicine / Rice University
ICML,2018,Reviving and Improving Recurrent Back-Propagation,Raquel Urtasun,University of Toronto
ICML,2018,Reviving and Improving Recurrent Back-Propagation,Richard Zemel,Vector Institute
ICML,2018,Riemannian Stochastic Recursive Gradient Algorithm with Retraction and Vector Transport and Its Convergence Analysis,Hiroyuki Kasai,The University of Electro-Communications
ICML,2018,Riemannian Stochastic Recursive Gradient Algorithm with Retraction and Vector Transport and Its Convergence Analysis,Hiroyuki Sato,Kyoto University
ICML,2018,Riemannian Stochastic Recursive Gradient Algorithm with Retraction and Vector Transport and Its Convergence Analysis,Bamdev Mishra,Microsoft
ICML,2018,Learning Compact Neural Networks with Regularization,Samet Oymak,"University of California, Riverside"
ICML,2018,Investigating Human Priors for Playing Video Games,Rachit Dubey,"University of California, Berkeley"
ICML,2018,Investigating Human Priors for Playing Video Games,Pulkit Agrawal,UC Berkeley
ICML,2018,Investigating Human Priors for Playing Video Games,Deepak Pathak,UC Berkeley
ICML,2018,Investigating Human Priors for Playing Video Games,Tom Griffiths,UC Berkeley
ICML,2018,Investigating Human Priors for Playing Video Games,Alexei Efros,UC Berkeley
ICML,2018,Decoupling Gradient-Like Learning Rules from Representations,Philip Thomas,University of Massachusetts Amherst
ICML,2018,Decoupling Gradient-Like Learning Rules from Representations,Christoph Dann,Carnegie Mellon University
ICML,2018,Decoupling Gradient-Like Learning Rules from Representations,Emma Brunskill,Stanford University
ICML,2018,Invariance of Weight Distributions in Rectified MLPs,Russell Tsuchida,The University of Queensland
ICML,2018,Invariance of Weight Distributions in Rectified MLPs,Fred Roosta,University of Queensland
ICML,2018,Invariance of Weight Distributions in Rectified MLPs,Marcus Gallagher,University of Queensland
ICML,2018,Stronger Generalization Bounds for Deep Nets via a Compression Approach,Sanjeev Arora,Princeton University and Institute for Advanced Study
ICML,2018,Stronger Generalization Bounds for Deep Nets via a Compression Approach,Rong Ge,Duke University
ICML,2018,Stronger Generalization Bounds for Deep Nets via a Compression Approach,Behnam Neyshabur,New York University
ICML,2018,Stronger Generalization Bounds for Deep Nets via a Compression Approach,Yi Zhang,Princeton University
ICML,2018,Near Optimal Frequent Directions for Sketching Dense and Sparse Matrices,Zengfeng Huang,Fudan University
ICML,2018,Loss Decomposition for Fast Learning in Large Output Spaces,Ian Yen,Carnegie Mellon University
ICML,2018,Loss Decomposition for Fast Learning in Large Output Spaces,Satyen Kale,Google Research
ICML,2018,Loss Decomposition for Fast Learning in Large Output Spaces,Felix Xinnan Yu,Google AI
ICML,2018,Loss Decomposition for Fast Learning in Large Output Spaces,Daniel Holtmann-Rice,Google Inc
ICML,2018,Loss Decomposition for Fast Learning in Large Output Spaces,Sanjiv Kumar,"Google Research, NY"
ICML,2018,Loss Decomposition for Fast Learning in Large Output Spaces,Pradeep Ravikumar,Carnegie Mellon University
ICML,2018,Stochastic Proximal Algorithms for AUC Maximization,Michael Natole Jr,University at Albany
ICML,2018,Stochastic Proximal Algorithms for AUC Maximization,Yiming Ying,SUNY Albany
ICML,2018,Stochastic Proximal Algorithms for AUC Maximization,Siwei Lyu,"University at Albany, State University of New York"
ICML,2018,Accelerated Spectral Ranking,Arpit Agarwal,University of Pennsylvania
ICML,2018,Accelerated Spectral Ranking,Prathamesh Patil,University of Pennsylvania
ICML,2018,Accelerated Spectral Ranking,Shivani Agarwal,University of Pennsylvania
ICML,2018,Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning,Stefan Depeweg,TU Munich
ICML,2018,Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning,Jose Hernandez-Lobato,University of Cambridge
ICML,2018,Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning,Finale Doshi-Velez,Harvard University
ICML,2018,Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning,Steffen Udluft,Siemens AG
ICML,2018,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,Emti Khan,RIKEN
ICML,2018,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,Didrik Nielsen,RIKEN
ICML,2018,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,Voot Tangkaratt,RIKEN AIP
ICML,2018,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,Wu Lin,University of British Columbia
ICML,2018,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,Yarin Gal,University of OXford
ICML,2018,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,Akash Srivastava,University of Edinburgh
ICML,2018,Learning One Convolutional Layer with Overlapping Patches,Surbhi Goel,University of Texas at Austin
ICML,2018,Learning One Convolutional Layer with Overlapping Patches,Adam Klivans,University of Texas at Austin
ICML,2018,Learning One Convolutional Layer with Overlapping Patches,Raghu Meka,UCLA
ICML,2018,A Spline Theory of Deep Learning,Randall Balestriero,Rice University
ICML,2018,A Spline Theory of Deep Learning,Richard Baraniuk,OpenStax / Rice University
ICML,2018,Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors,Soumya Ghosh,IBM Research
ICML,2018,Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors,Jiayu Yao,Harvard University
ICML,2018,Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors,Finale Doshi-Velez,Harvard University
ICML,2018,Variational Bayesian dropout: pitfalls and fixes,Jiri Hron,University of Cambridge
ICML,2018,Variational Bayesian dropout: pitfalls and fixes,Alex Matthews,University of Cambridge
ICML,2018,Variational Bayesian dropout: pitfalls and fixes,Zoubin Ghahramani,University of Cambridge & Uber
ICML,2018,Adversarial Learning with Local Coordinate Coding,Jiezhang Cao,South China University of Technology
ICML,2018,Adversarial Learning with Local Coordinate Coding,Yong Guo,South China University of Technology
ICML,2018,Adversarial Learning with Local Coordinate Coding,Qingyao Wu,South China University of Technology
ICML,2018,Adversarial Learning with Local Coordinate Coding,Chunhua Shen,University of Adelaide
ICML,2018,Adversarial Learning with Local Coordinate Coding,Junzhou Huang,University of Texas at Arlington / Tencent AI Lab
ICML,2018,Adversarial Learning with Local Coordinate Coding,Mingkui Tan,South China University of Technology
ICML,2018,Learning Representations and Generative Models for 3D Point Clouds,Panos Achlioptas,Stanford
ICML,2018,Learning Representations and Generative Models for 3D Point Clouds,Olga Diamanti,Autodesk
ICML,2018,Learning Representations and Generative Models for 3D Point Clouds,Ioannis Mitliagkas,"MILA, UdeM"
ICML,2018,Learning Representations and Generative Models for 3D Point Clouds,Leonidas Guibas,Stanford University
ICML,2018,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,Mattias Teye,KTH / EA SEED
ICML,2018,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,Hossein Azizpour,KTH
ICML,2018,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,Kevin Smith,KTH Royal Institute of Technology
ICML,2018,Noisy Natural Gradient as Variational Inference,Guodong Zhang,University of Toronto
ICML,2018,Noisy Natural Gradient as Variational Inference,Shengyang Sun,University of Toronto
ICML,2018,Noisy Natural Gradient as Variational Inference,David Duvenaud,University of Toronto
ICML,2018,Noisy Natural Gradient as Variational Inference,Roger Grosse,University of Toronto and Vector Institute
ICML,2018,Deep Variational Reinforcement Learning for POMDPs,Maximilian Igl,University of Oxford
ICML,2018,Deep Variational Reinforcement Learning for POMDPs,Luisa Zintgraf,University of Oxford
ICML,2018,Deep Variational Reinforcement Learning for POMDPs,Tuan Anh Le,University of Oxford
ICML,2018,Deep Variational Reinforcement Learning for POMDPs,Frank Wood,University of Oxford
ICML,2018,Deep Variational Reinforcement Learning for POMDPs,Shimon Whiteson,University of Oxford
ICML,2018,Recurrent Predictive State Policy Networks,Ahmed Hefny,Carnegie Mellon University
ICML,2018,Recurrent Predictive State Policy Networks,Zita Marinho,Carnegie Mellon University
ICML,2018,Recurrent Predictive State Policy Networks,Wen Sun,Carnegie Mellon University
ICML,2018,Recurrent Predictive State Policy Networks,Siddhartha Srinivasa,University of Washington
ICML,2018,Recurrent Predictive State Policy Networks,Geoff Gordon,Carnegie Mellon University
ICML,2018,The Mechanics of n-Player Differentiable Games,David Balduzzi,DeepMind
ICML,2018,The Mechanics of n-Player Differentiable Games,Sebastien Racaniere,DeepMind
ICML,2018,The Mechanics of n-Player Differentiable Games,James Martens,DeepMind
ICML,2018,The Mechanics of n-Player Differentiable Games,Jakob Foerster,University of Oxford
ICML,2018,The Mechanics of n-Player Differentiable Games,Karl Tuyls,DeepMind
ICML,2018,The Mechanics of n-Player Differentiable Games,Thore Graepel,DeepMind
ICML,2018,Improved Training of Generative Adversarial Networks Using Representative Features,Duhyeon Bang,Yonsei univ.
ICML,2018,Improved Training of Generative Adversarial Networks Using Representative Features,Hyunjung Shim,Yonsei University
ICML,2018,Hierarchical Multi-Label Classification Networks,Jonatas Wehrmann,Pontifícia Universidade Catolica do Rio Grande do Sul - PUCRS
ICML,2018,Hierarchical Multi-Label Classification Networks,Ricardo Cerri,UFSCAR
ICML,2018,Hierarchical Multi-Label Classification Networks,Rodrigo Barros,PUCRS
ICML,2018,Knowledge Transfer with Jacobian Matching,Suraj Srinivas,Idiap
ICML,2018,Knowledge Transfer with Jacobian Matching,Francois Fleuret,Idiap research institute
ICML,2018,Towards Black-box Iterative Machine Teaching,Weiyang Liu,Georgia Tech
ICML,2018,Towards Black-box Iterative Machine Teaching,Bo Dai,Georgia Institute of Technology
ICML,2018,Towards Black-box Iterative Machine Teaching,Xingguo Li,University of Minnesota
ICML,2018,Towards Black-box Iterative Machine Teaching,Zhen Liu,Georgia Tech
ICML,2018,Towards Black-box Iterative Machine Teaching,Jim Rehg,Georgia Tech
ICML,2018,Towards Black-box Iterative Machine Teaching,Le Song,Georgia Institute of Technology
ICML,2018,Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising,Borja de Balle Pigem,Amazon Research
ICML,2018,Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising,Yu-Xiang Wang,Amazon / UCSB
ICML,2018,Importance Weighted Transfer of Samples in Reinforcement Learning,Andrea Tirinzoni,Politecnico di Milano
ICML,2018,Importance Weighted Transfer of Samples in Reinforcement Learning,Andrea Sessa,Politecnico di Milano
ICML,2018,Importance Weighted Transfer of Samples in Reinforcement Learning,Matteo Pirotta,SequeL - Inria Lille - Nord Europe
ICML,2018,Importance Weighted Transfer of Samples in Reinforcement Learning,Marcello Restelli,Politecnico di Milano
ICML,2018,Beyond the One-Step Greedy Approach in Reinforcement Learning,Yonathan Efroni,Technion
ICML,2018,Beyond the One-Step Greedy Approach in Reinforcement Learning,Gal Dalal,
ICML,2018,Beyond the One-Step Greedy Approach in Reinforcement Learning,Bruno Scherrer,INRIA
ICML,2018,Beyond the One-Step Greedy Approach in Reinforcement Learning,Shie Mannor,Technion
ICML,2018,"Optimization, fast and slow: optimally switching between local and Bayesian optimization",Mark McLeod,University of Oxford
ICML,2018,"Optimization, fast and slow: optimally switching between local and Bayesian optimization",Stephen Roberts,University of Oxford
ICML,2018,"Optimization, fast and slow: optimally switching between local and Bayesian optimization",Michael A Osborne,U Oxford
ICML,2018,Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design,Wenlong Lyu,Fudan University
ICML,2018,Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design,Fan Yang,Fudan University
ICML,2018,Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design,Changhao Yan,
ICML,2018,Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design,Dian Zhou,Department of Electrical Engineering The University of Texas at Dallas Richardso
ICML,2018,Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design,Xuan Zeng,Fudan University
ICML,2018,Graphical Nonconvex Optimization via an Adaptive Convex Relaxation,Qiang Sun,University of Toronto
ICML,2018,Graphical Nonconvex Optimization via an Adaptive Convex Relaxation,Kean Ming Tan,University of Minnesota Twin Cities
ICML,2018,Graphical Nonconvex Optimization via an Adaptive Convex Relaxation,Han Liu,Northwestern
ICML,2018,Graphical Nonconvex Optimization via an Adaptive Convex Relaxation,Tong Zhang,Tecent AI Lab
ICML,2018,Approximate message passing for amplitude based optimization,Junjie Ma,Columbia University
ICML,2018,Approximate message passing for amplitude based optimization,Ji Xu,Columbia University
ICML,2018,Approximate message passing for amplitude based optimization,Arian Maleki,Columbia
ICML,2018,Tempered Adversarial Networks,Mehdi S. M. Sajjadi,Max Planck Institute for Intelligent Systems
ICML,2018,Tempered Adversarial Networks,Giambattista Parascandolo,Max Planck Institute for Intelligent Systems and ETH Zurich
ICML,2018,Tempered Adversarial Networks,Arash Mehrjou,Max Planck Institute for Intelligent Systems
ICML,2018,Tempered Adversarial Networks,Bernhard Schölkopf,"MPI for Intelligent Systems Tübingen, Germany"
ICML,2018,Delayed Impact of Fair Machine Learning,Lydia T. Liu,University of California Berkeley
ICML,2018,Delayed Impact of Fair Machine Learning,Sarah Dean,UC Berkeley
ICML,2018,Delayed Impact of Fair Machine Learning,Esther Rolf,UC Berkeley
ICML,2018,Delayed Impact of Fair Machine Learning,Max Simchowitz,UC Berkeley
ICML,2018,Delayed Impact of Fair Machine Learning,University of California Moritz Hardt,"University of California, Berkeley"
ICML,2018,Fast Information-theoretic Bayesian Optimisation,Robin Ru,University of Oxford
ICML,2018,Fast Information-theoretic Bayesian Optimisation,Michael A Osborne,U Oxford
ICML,2018,Fast Information-theoretic Bayesian Optimisation,Mark Mcleod,University of Oxford
ICML,2018,Fast Information-theoretic Bayesian Optimisation,Diego Granziol,Oxford
ICML,2018,Tight Regret Bounds for Bayesian Optimization in One Dimension,Jonathan Scarlett,National University of Singapore
ICML,2018,Image Transformer,Niki Parmar,Google
ICML,2018,Image Transformer,Ashish Vaswani,Google Brain
ICML,2018,Image Transformer,Jakob Uszkoreit,
ICML,2018,Image Transformer,Lukasz Kaiser,Google
ICML,2018,Image Transformer,Noam Shazeer,Google
ICML,2018,Image Transformer,Alexander Ku,UC Berkeley
ICML,2018,Image Transformer,Dustin Tran,Google
ICML,2018,Kernelized Synaptic Weight Matrices,Lorenz Müller,ETH Zurich and University of Zurich
ICML,2018,Kernelized Synaptic Weight Matrices,Julien Martel,ETH Zurich
ICML,2018,Kernelized Synaptic Weight Matrices,Giacomo Indiveri,University of Zurich
ICML,2018,A Distributed Second-Order Algorithm You Can Trust,Celestine Dünner,IBM Research
ICML,2018,A Distributed Second-Order Algorithm You Can Trust,Aurelien Lucchi,ETH Zurich
ICML,2018,A Distributed Second-Order Algorithm You Can Trust,Matilde Gargiani,University of Freiburg
ICML,2018,A Distributed Second-Order Algorithm You Can Trust,An Bian,ETH Zurich
ICML,2018,A Distributed Second-Order Algorithm You Can Trust,Thomas Hofmann,ETH Zurich
ICML,2018,A Distributed Second-Order Algorithm You Can Trust,Martin Jaggi,EPFL
ICML,2018,On Acceleration with Noise-Corrupted Gradients,Michael Cohen,
ICML,2018,On Acceleration with Noise-Corrupted Gradients,Jelena Diakonikolas,Boston University
ICML,2018,On Acceleration with Noise-Corrupted Gradients,Orecchia Lorenzo,Boston
ICML,2018,Gradient Coding from Cyclic MDS Codes and Expander Graphs,Netanel Raviv,California Institute of Technology
ICML,2018,Gradient Coding from Cyclic MDS Codes and Expander Graphs,Rashish Tandon,Apple
ICML,2018,Gradient Coding from Cyclic MDS Codes and Expander Graphs,Alex Dimakis,UT Austin
ICML,2018,Gradient Coding from Cyclic MDS Codes and Expander Graphs,Itzhak Tamo,Tel-Aviv University
ICML,2018,Accelerating Greedy Coordinate Descent Methods,Haihao Lu,MIT
ICML,2018,Accelerating Greedy Coordinate Descent Methods,Robert Freund,MIT
ICML,2018,Accelerating Greedy Coordinate Descent Methods,Vahab Mirrokni,Google Research
ICML,2018,Finding Influential Training Samples for Gradient Boosted Decision Trees,Boris Sharchilev,Yandex
ICML,2018,Finding Influential Training Samples for Gradient Boosted Decision Trees,Yury Ustinovskiy,Princeton University
ICML,2018,Finding Influential Training Samples for Gradient Boosted Decision Trees,Pavel Serdyukov,Yandex
ICML,2018,Finding Influential Training Samples for Gradient Boosted Decision Trees,Maarten de Rijke,University of Amsterdam
ICML,2018,Improving Regression Performance with Distributional Losses,Ehsan Imani,University of Alberta
ICML,2018,Improving Regression Performance with Distributional Losses,Martha White,University of Alberta
ICML,2018,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Tabish Rashid,University of Oxford
ICML,2018,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Mikayel Samvelyan,Russian-Armenian University
ICML,2018,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Christian Schroeder,University of Oxford
ICML,2018,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Gregory Farquhar,University of Oxford
ICML,2018,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Jakob Foerster,University of Oxford
ICML,2018,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Shimon Whiteson,University of Oxford
ICML,2018,Learning to Act in Decentralized Partially Observable MDPs,Jilles Dibangoye,INRIA
ICML,2018,Learning to Act in Decentralized Partially Observable MDPs,Olivier Buffet,INRIA
ICML,2018,Local Convergence Properties of SAGA/Prox-SVRG and Acceleration,Clarice Poon,University of Cambridge
ICML,2018,Local Convergence Properties of SAGA/Prox-SVRG and Acceleration,Jingwei Liang,University of Cambridge
ICML,2018,Local Convergence Properties of SAGA/Prox-SVRG and Acceleration,Carola-Bibiane Schönlieb,University of Cambridge
ICML,2018,Stein Points,Wilson Ye Chen,University of Technology Sydney
ICML,2018,Stein Points,Lester Mackey,Microsoft Research
ICML,2018,Stein Points,Jackson Gorham,STANFORD
ICML,2018,Stein Points,Francois-Xavier Briol,University of Warwick
ICML,2018,Stein Points,Chris J Oates,Newcastle University
ICML,2018,Large-Scale Cox Process Inference using Variational Fourier Features,Ti John,PROWLER.io
ICML,2018,Large-Scale Cox Process Inference using Variational Fourier Features,James Hensman,PROWLER.io
ICML,2018,SADAGRAD: Strongly Adaptive Stochastic Gradient Methods,Zaiyi Chen,University of Science and Technology of China
ICML,2018,SADAGRAD: Strongly Adaptive Stochastic Gradient Methods,Yi Xu,The University of Iowa
ICML,2018,SADAGRAD: Strongly Adaptive Stochastic Gradient Methods,Enhong Chen,University of Science and Technology of China
ICML,2018,SADAGRAD: Strongly Adaptive Stochastic Gradient Methods,Tianbao Yang,The University of Iowa
ICML,2018,Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solution for  Nonconvex Distributed Optimization Over Networks,Mingyi Hong,University of Minnesota
ICML,2018,Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solution for  Nonconvex Distributed Optimization Over Networks,Meisam Razaviyayn,University of southern California
ICML,2018,Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solution for  Nonconvex Distributed Optimization Over Networks,Jason Lee,University of Southern California
ICML,2018,A Progressive Batching L-BFGS Method for Machine Learning,Raghu Bollapragada,Northwestern University
ICML,2018,A Progressive Batching L-BFGS Method for Machine Learning,Jorge Nocedal,Northwestern University
ICML,2018,A Progressive Batching L-BFGS Method for Machine Learning,Dheevatsa Mudigere,Intel Labs
ICML,2018,A Progressive Batching L-BFGS Method for Machine Learning,Hao-Jun M Shi,Northwestern University
ICML,2018,A Progressive Batching L-BFGS Method for Machine Learning,Ping Tak Tang,Intel Corporation
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Xiaojie Jin,National University of Singapore
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Yingzhen Yang,University of Illinois at Urbana-Champaign
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Ning Xu,Snap
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Jianchao Yang,Bytedance Inc.
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Nebojsa Jojic,Microsoft Research
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Jiashi Feng,National University of Singapore
ICML,2018,WSNet: Compact and Efficient Networks Through Weight Sampling,Shuicheng Yan,Qihoo/360
ICML,2018,Entropy-SGD optimizes the prior of a PAC-Bayes bound: Generalization properties of Entropy-SGD and data-dependent priors,Gintare Karolina Dziugaite,University of Cambridge
ICML,2018,Entropy-SGD optimizes the prior of a PAC-Bayes bound: Generalization properties of Entropy-SGD and data-dependent priors,Dan Roy,Univ of Toronto | Toronto
ICML,2018,"High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach",Tim Pearce,University of Cambridge / The Alan Turing Institute
ICML,2018,"High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach",Alexandra Brintrup,
ICML,2018,"High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach",Mohamed Zaki,University of Cambridge
ICML,2018,"High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach",Andy Neely,
ICML,2018,Competitive Caching with Machine Learned Advice,Thodoris Lykouris,Cornell University
ICML,2018,Competitive Caching with Machine Learned Advice,Sergei Vassilvitskii,Google
ICML,2018,Approximation Algorithms for Cascading Prediction Models,Matthew Streeter,Google
ICML,2018,Orthogonal Machine Learning: Power and Limitations,Ilias Zadik,MIT
ICML,2018,Orthogonal Machine Learning: Power and Limitations,Lester Mackey,Microsoft Research
ICML,2018,Orthogonal Machine Learning: Power and Limitations,Vasilis Syrgkanis,Microsoft Research
ICML,2018,Causal Bandits with Propagating Inference,Akihiro Yabe,NEC Corporation
ICML,2018,Causal Bandits with Propagating Inference,Daisuke Hatano,RIKEN AIP
ICML,2018,Causal Bandits with Propagating Inference,Hanna Sumita,National Institute of Informatics
ICML,2018,Causal Bandits with Propagating Inference,Shinji Ito,NEC Corporation
ICML,2018,Causal Bandits with Propagating Inference,Naonori Kakimura,Keio University
ICML,2018,Causal Bandits with Propagating Inference,Takuro Fukunaga,RIKEN AIP
ICML,2018,Causal Bandits with Propagating Inference,Ken-ichi Kawarabayashi,National Institute of Informatics
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Wojciech Czarnecki,DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Siddhant Jayakumar,DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Max Jaderberg,DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Leonard Hasenclever,DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Yee Teh,DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Nicolas Heess,Google DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Simon Osindero,DeepMind
ICML,2018,Mix & Match - Agent Curricula for Reinforcement Learning,Razvan Pascanu,DeepMind
ICML,2018,The Uncertainty Bellman Equation and Exploration,Brendan O'Donoghue,DeepMind
ICML,2018,The Uncertainty Bellman Equation and Exploration,Ian Osband,Google DeepMind
ICML,2018,The Uncertainty Bellman Equation and Exploration,Remi Munos,DeepMind
ICML,2018,The Uncertainty Bellman Equation and Exploration,Vlad Mnih,Google Deepmind
ICML,2018,Hierarchical Imitation and Reinforcement Learning,Hoang M Le,Caltech
ICML,2018,Hierarchical Imitation and Reinforcement Learning,Nan Jiang,Microsoft Research
ICML,2018,Hierarchical Imitation and Reinforcement Learning,Alekh Agarwal,Microsoft Research
ICML,2018,Hierarchical Imitation and Reinforcement Learning,Miroslav Dudik,Microsoft Research
ICML,2018,Hierarchical Imitation and Reinforcement Learning,Yisong Yue,Caltech
ICML,2018,Hierarchical Imitation and Reinforcement Learning,Hal Daume,Microsoft Research
ICML,2018,Policy Optimization with Demonstrations,Bingyi Kang,National University of Singapore
ICML,2018,Policy Optimization with Demonstrations,Zequn Jie,Tencent AI Lab
ICML,2018,Policy Optimization with Demonstrations,Jiashi Feng,National University of Singapore
ICML,2018,Fast Gradient-Based Methods with Exponential Rate: A Hybrid Control Framework,Arman Sharifi Kolarijani,Delft University of Technology
ICML,2018,Fast Gradient-Based Methods with Exponential Rate: A Hybrid Control Framework,Peyman Mohajerin Esfahani,Delft University of Technology
ICML,2018,Fast Gradient-Based Methods with Exponential Rate: A Hybrid Control Framework,Tamas Keviczky,Delft University of Technology
ICML,2018,Level-Set Methods for Finite-Sum Constrained Convex Optimization,Qihang Lin,Univ Iowa
ICML,2018,Level-Set Methods for Finite-Sum Constrained Convex Optimization,Runchao Ma,University of Iowa
ICML,2018,Level-Set Methods for Finite-Sum Constrained Convex Optimization,Tianbao Yang,The University of Iowa
ICML,2018,A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations,Weili Nie,Rice University
ICML,2018,A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations,Yang Zhang,Rice University
ICML,2018,A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations,Ankit Patel,"Rice University, Baylor College of Medicine"
ICML,2018,A Boo(n) for Evaluating Architecture Performance,Ondrej Bajgar,IBM Watson
ICML,2018,A Boo(n) for Evaluating Architecture Performance,Rudolf Kadlec,IBM Watson
ICML,2018,A Boo(n) for Evaluating Architecture Performance,Jan Kleindienst,IBM Watson
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Eric Liang,"University of California, Berkeley"
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Richard Liaw,UC Berkeley
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Robert Nishihara,Unknown
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Philipp Moritz,UC Berkeley
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Roy Fox,UC Berkeley
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Ken Goldberg,UC Berkeley
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Joseph Gonzalez,UC Berkeley
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Michael Jordan,UC Berkeley
ICML,2018,RLlib: Abstractions for Distributed Reinforcement Learning,Ion Stoica,UC Berkeley
ICML,2018,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator,Maryam Fazel,University of Washington
ICML,2018,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator,Rong Ge,Duke University
ICML,2018,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator,Sham Kakade,University of Washington
ICML,2018,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator,Mehran Mesbahi,
ICML,2018,The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference,Hao Lu,Princeton University
ICML,2018,The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference,Yuan Cao,Princeton University
ICML,2018,The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference,Junwei Lu,
ICML,2018,The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference,Han Liu,Northwestern
ICML,2018,The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference,Zhaoran Wang,Northwestern U
ICML,2018,Sound Abstraction and Decomposition of Probabilistic Programs,Steven Holtzen,"University of California, Los Angeles"
ICML,2018,Sound Abstraction and Decomposition of Probabilistic Programs,Guy Van den Broeck,"University of California, Los Angeles"
ICML,2018,Sound Abstraction and Decomposition of Probabilistic Programs,Todd Millstein,"University of California, Los Angeles"
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Aäron van den Oord,Google Deepmind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Yazhe Li,Deepmind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Igor Babuschkin,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Karen Simonyan,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Oriol Vinyals,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,koray kavukcuoglu,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,George van den Driessche,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Edward Lockhart,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Luis C Cobo,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Florian Stimberg,
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Norman Casagrande,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Dominik Grewe,
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Seb Noury,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Sander Dieleman,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Erich Elsen,
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Nal Kalchbrenner,Google Brain Amsterdam
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Heiga Zen,
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Alex Graves,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Helen King,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Tom Walters,DeepMind
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Dan Belov,Google
ICML,2018,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Demis Hassabis,Deepmind
ICML,2018,Modeling Sparse Deviations for Compressed Sensing using Generative Models,Manik Dhar,Stanford University
ICML,2018,Modeling Sparse Deviations for Compressed Sensing using Generative Models,Aditya Grover,Stanford University
ICML,2018,Modeling Sparse Deviations for Compressed Sensing using Generative Models,Stefano Ermon,Stanford University
ICML,2018,Revealing Common Statistical Behaviors in Heterogeneous Populations,Andrey Zhitnikov,Technion
ICML,2018,Revealing Common Statistical Behaviors in Heterogeneous Populations,Rotem Mulayoff,Technion
ICML,2018,Revealing Common Statistical Behaviors in Heterogeneous Populations,Tomer Michaeli,Technion
ICML,2018,Improved nearest neighbor search using auxiliary information and priority functions,Omid Keivani,Wichita State University
ICML,2018,Improved nearest neighbor search using auxiliary information and priority functions,Kaushik Sinha,Wichita State University
ICML,2018,Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings,Aviral Kumar,IIT Bombay
ICML,2018,Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings,Sunita Sarawagi,IIT Bombay
ICML,2018,Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings,Ujjwal Jain,IIT Bombay
ICML,2018,QuantTree: Histograms for Change Detection in Multivariate Data Streams,Giacomo Boracchi,Politecnico di Milano
ICML,2018,QuantTree: Histograms for Change Detection in Multivariate Data Streams,Diego Carrera,Politecnico di Milano
ICML,2018,QuantTree: Histograms for Change Detection in Multivariate Data Streams,Cristiano Cervellera,National Research Council
ICML,2018,QuantTree: Histograms for Change Detection in Multivariate Data Streams,Danilo Macciò,
ICML,2018,"An Iterative, Sketching-based Framework for Ridge Regression",Agniva Chowdhury,Purdue University
ICML,2018,"An Iterative, Sketching-based Framework for Ridge Regression",Jiasen Yang,Purdue University
ICML,2018,"An Iterative, Sketching-based Framework for Ridge Regression",Petros Drineas,Purdue University
ICML,2018,Learning Low-Dimensional Temporal Representations,Bing Su,Institute of Software Chinese Academy of Sciences
ICML,2018,Learning Low-Dimensional Temporal Representations,Ying Wu,Northwestern University
ICML,2018,Rapid Adaptation with Conditionally Shifted Neurons,Tsendsuren Munkhdalai,Microsoft Research
ICML,2018,Rapid Adaptation with Conditionally Shifted Neurons,Xingdi Yuan,Microsoft Maluuba
ICML,2018,Rapid Adaptation with Conditionally Shifted Neurons,Soroush Mehri,Microsoft Research
ICML,2018,Rapid Adaptation with Conditionally Shifted Neurons,Adam Trischler,Microsoft Research
ICML,2018,PDE-Net: Learning PDEs from Data,Zichao Long,Peking University
ICML,2018,PDE-Net: Learning PDEs from Data,Yiping Lu,Peking University
ICML,2018,PDE-Net: Learning PDEs from Data,Xianzhong Ma,Peking University
ICML,2018,PDE-Net: Learning PDEs from Data,Bin Dong,Peking University
ICML,2018,Theoretical Analysis of Sparse Subspace Clustering with Missing Entries,Manolis Tsakiris,Johns Hopkins University
ICML,2018,Theoretical Analysis of Sparse Subspace Clustering with Missing Entries,Rene Vidal,Johns Hopkins University
ICML,2018,Topological mixture estimation,Steve Huntsman,BAE Systems FAST Labs
ICML,2018,On Matching Pursuit and Coordinate Descent,Francesco Locatello,ETH Zurich - Max Planck Institute
ICML,2018,On Matching Pursuit and Coordinate Descent,Anant Raj,Max-Planck Institute for Intelligent Systems
ICML,2018,On Matching Pursuit and Coordinate Descent,Praneeth Karimireddy,EPFL
ICML,2018,On Matching Pursuit and Coordinate Descent,Gunnar Raetsch,ETH Zurich
ICML,2018,On Matching Pursuit and Coordinate Descent,Bernhard Schölkopf,"MPI for Intelligent Systems Tübingen, Germany"
ICML,2018,On Matching Pursuit and Coordinate Descent,Sebastian Stich,EPFL
ICML,2018,On Matching Pursuit and Coordinate Descent,Martin Jaggi,EPFL
ICML,2018,Frank-Wolfe with Subsampling Oracle,Thomas Kerdreux,INRIA
ICML,2018,Frank-Wolfe with Subsampling Oracle,Fabian Pedregosa,UC Berkeley
ICML,2018,Frank-Wolfe with Subsampling Oracle,Alex d'Aspremont,"CNRS, Ecole Normale Superieure"
ICML,2018,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,Yangchen Pan,University of Alberta
ICML,2018,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,Amir-massoud Farahmand,Vector Institute
ICML,2018,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,Martha White,University of Alberta
ICML,2018,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,Saleh Nabi,
ICML,2018,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,Piyush Grover,Mitsubishi Electric Research Labs
ICML,2018,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,Daniel Nikovski,Mitsubishi Electric Research Labs
ICML,2018,Fourier Policy Gradients,Matthew Fellows,University of Oxford
ICML,2018,Fourier Policy Gradients,Kamil Ciosek,Oxford
ICML,2018,Fourier Policy Gradients,Shimon Whiteson,University of Oxford
ICML,2018,Adaptive Three Operator Splitting,Fabian Pedregosa,UC Berkeley
ICML,2018,Adaptive Three Operator Splitting,Gauthier Gidel,MILA
ICML,2018,A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming,Alp Yurtsever,EPFL
ICML,2018,A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming,Olivier Fercoq,
ICML,2018,A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming,Francesco Locatello,ETH Zurich - Max Planck Institute
ICML,2018,A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming,Volkan Cevher,EPFL
ICML,2018,Learning Semantic Representations for Unsupervised Domain Adaptation,Shaoan Xie,Sun Yat-sen University
ICML,2018,Learning Semantic Representations for Unsupervised Domain Adaptation,Zibin Zheng,
ICML,2018,Learning Semantic Representations for Unsupervised Domain Adaptation,Liang Chen,Sun Yat-sen University
ICML,2018,Learning Semantic Representations for Unsupervised Domain Adaptation,Chuan Chen,Sun Yat-sen University
ICML,2018,Learning Adversarially Fair and Transferable Representations,David Madras,University of Toronto
ICML,2018,Learning Adversarially Fair and Transferable Representations,Elliot Creager,University of Toronto
ICML,2018,Learning Adversarially Fair and Transferable Representations,Toniann Pitassi,University of Toronto
ICML,2018,Learning Adversarially Fair and Transferable Representations,Richard Zemel,Vector Institute
ICML,2018,Spurious Local Minima are Common in Two-Layer ReLU Neural Networks,Itay Safran,Weizmann Institute of Science
ICML,2018,Spurious Local Minima are Common in Two-Layer ReLU Neural Networks,Ohad Shamir,Weizmann Institute of Science
ICML,2018,Efficient end-to-end learning for quantizable representations,Yeonwoo Jeong,Seoul National University
ICML,2018,Efficient end-to-end learning for quantizable representations,Hyun Oh Song,Seoul National University
ICML,2018,Solving Partial Assignment Problems using Random Clique Complexes,Charu Sharma,Indian Institute of Technology Hyderabad
ICML,2018,Solving Partial Assignment Problems using Random Clique Complexes,Deepak Nathani,IIT Hyderabad
ICML,2018,Solving Partial Assignment Problems using Random Clique Complexes,Manu Kaul,IIT Hyderabad
ICML,2018,Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction,Siyuan Qi,UCLA
ICML,2018,Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction,Baoxiong Jia,Peking University
ICML,2018,Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction,Song-Chun Zhu,UCLA
ICML,2018,Convergence guarantees for a class of non-convex and   non-smooth optimization problems,Koulik Khamaru,University Of California Berkeley
ICML,2018,Convergence guarantees for a class of non-convex and   non-smooth optimization problems,Martin Wainwright,University of California at Berkeley
ICML,2018,Estimation of Markov Chain via Rank-constrained Likelihood,XUDONG LI,Princeton Univerisity
ICML,2018,Estimation of Markov Chain via Rank-constrained Likelihood,Mengdi Wang,Princeton University
ICML,2018,Estimation of Markov Chain via Rank-constrained Likelihood,Anru Zhang,University of Wisconsin-Madison
ICML,2018,Efficient First-Order Algorithms for Adaptive Signal Denoising,Dmitrii Ostrovskii,INRIA
ICML,2018,Efficient First-Order Algorithms for Adaptive Signal Denoising,Zaid Harchaoui,University of Washington
ICML,2018,Continuous and Discrete-time Accelerated Stochastic Mirror Descent for Strongly Convex Functions,Pan Xu,"University of California, Los Angeles"
ICML,2018,Continuous and Discrete-time Accelerated Stochastic Mirror Descent for Strongly Convex Functions,Tianhao Wang,University of Science and Technology of China
ICML,2018,Continuous and Discrete-time Accelerated Stochastic Mirror Descent for Strongly Convex Functions,Quanquan Gu,UCLA
ICML,2018,Noisin: Unbiased Regularization for Recurrent Neural Networks,Adji Bousso Dieng,Columbia University
ICML,2018,Noisin: Unbiased Regularization for Recurrent Neural Networks,Rajesh Ranganath,New York University
ICML,2018,Noisin: Unbiased Regularization for Recurrent Neural Networks,Jaan Altosaar,Princeton University
ICML,2018,Noisin: Unbiased Regularization for Recurrent Neural Networks,David Blei,Columbia University
ICML,2018,Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series,Zhengping Che,University of Southern California
ICML,2018,Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series,Sanjay Purushotham,University of Southern California
ICML,2018,Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series,Max Guangyu Li,University of Southern California
ICML,2018,Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series,Bo Jiang,University of Southern California
ICML,2018,Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series,Yan Liu,University of Southern California
ICML,2018,Disentangled Sequential Autoencoder,Yingzhen Li,University of Cambridge
ICML,2018,Disentangled Sequential Autoencoder,Stephan Mandt,Disney Research
ICML,2018,Stochastic Video Generation with a Learned Prior,Emily Denton,New York University
ICML,2018,Stochastic Video Generation with a Learned Prior,Rob Fergus,Facebook / NYU
ICML,2018,Mutual Information Neural Estimation,Mohamed Ishmael Belghazi,MILA
ICML,2018,Mutual Information Neural Estimation,Aristide Baratin,University of Montreal
ICML,2018,Mutual Information Neural Estimation,Sai Rajeswar,University of Montreal
ICML,2018,Mutual Information Neural Estimation,Sherjil Ozair,University of Montreal
ICML,2018,Mutual Information Neural Estimation,Yoshua Bengio,U. Montreal
ICML,2018,Mutual Information Neural Estimation,R Devon Hjelm,MILA
ICML,2018,Mutual Information Neural Estimation,Aaron Courville,University of Montreal
ICML,2018,Adversarially Regularized Autoencoders,Jake Zhao,NYU / Facebook AI Research
ICML,2018,Adversarially Regularized Autoencoders,Yoon Kim,Harvard University
ICML,2018,Adversarially Regularized Autoencoders,Kelly Zhang,New York University
ICML,2018,Adversarially Regularized Autoencoders,Alexander Rush,Harvard University
ICML,2018,Adversarially Regularized Autoencoders,Yann LeCun,New York University
ICML,2018,Policy Optimization as Wasserstein Gradient Flows,RUIYI ZHANG,Duke University
ICML,2018,Policy Optimization as Wasserstein Gradient Flows,Changyou Chen,SUNY at Buffalo
ICML,2018,Policy Optimization as Wasserstein Gradient Flows,Chunyuan Li,Duke University
ICML,2018,Policy Optimization as Wasserstein Gradient Flows,Lawrence Carin,Duke
ICML,2018,Self-Imitation Learning,Junhyuk Oh,University of Michigan
ICML,2018,Self-Imitation Learning,Yijie Guo,University of Michigan
ICML,2018,Self-Imitation Learning,Satinder Singh,University of Michigan
ICML,2018,Self-Imitation Learning,Honglak Lee,Google / U. Michigan
ICML,2018,Spectrally Approximating Large Graphs with Smaller Graphs,Andreas Loukas,EPFL
ICML,2018,Spectrally Approximating Large Graphs with Smaller Graphs,Pierre Vandergheynst,École polytechnique fédérale de Lausanne
ICML,2018,On the Spectrum of Random Features Maps of High Dimensional Data,Zhenyu Liao,"L2S, CentraleSupelec"
ICML,2018,On the Spectrum of Random Features Maps of High Dimensional Data,Romain Couillet,CentralSupélec
ICML,2018,Learning Registered Point Processes from Idiosyncratic Observations,Hongteng Xu,"InfiniaML, Inc."
ICML,2018,Learning Registered Point Processes from Idiosyncratic Observations,Lawrence Carin,Duke
ICML,2018,Learning Registered Point Processes from Idiosyncratic Observations,Hongyuan Zha,Georgia Institute of Technology
ICML,2018,Deep Bayesian Nonparametric Tracking,Aonan Zhang,Columbia University
ICML,2018,Deep Bayesian Nonparametric Tracking,John Paisley,Columbia University
ICML,2018,Learning and Memorization,Sat Chatterjee,Two Sigma Investments
ICML,2018,Attention-based Deep Multiple Instance Learning,Maximilian Ilse,University of Amsterdam
ICML,2018,Attention-based Deep Multiple Instance Learning,Jakub Tomczak,University of Amsterdam
ICML,2018,Attention-based Deep Multiple Instance Learning,Max Welling,University of Amsterdam
ICML,2018,Classification from Pairwise Similarity and Unlabeled Data,Han Bao,The University of Tokyo
ICML,2018,Classification from Pairwise Similarity and Unlabeled Data,Gang Niu,RIKEN
ICML,2018,Classification from Pairwise Similarity and Unlabeled Data,Masashi Sugiyama,RIKEN / The University of Tokyo
ICML,2018,Analyzing the Robustness of Nearest Neighbors to Adversarial Examples,Yizhen Wang,UCSD
ICML,2018,Analyzing the Robustness of Nearest Neighbors to Adversarial Examples,Somesh Jha,"University of Wisconsin, Madison"
ICML,2018,Analyzing the Robustness of Nearest Neighbors to Adversarial Examples,Kamalika Chaudhuri,University of California at San Diego
ICML,2018,On the Implicit Bias of Dropout,Poorya Mianjy,Johns Hopkins University
ICML,2018,On the Implicit Bias of Dropout,Raman Arora,Johns Hopkins University
ICML,2018,On the Implicit Bias of Dropout,Rene Vidal,Johns Hopkins University
ICML,2018,Convolutional Imputation of Matrix Networks,Qingyun Sun,Stanford University
ICML,2018,Convolutional Imputation of Matrix Networks,Mengyuan Yan,Stanford University
ICML,2018,Convolutional Imputation of Matrix Networks,David Donoho,Stanford University
ICML,2018,Convolutional Imputation of Matrix Networks,stephen boyd,stanford university
ICML,2018,Detecting and Correcting for Label Shift with Black Box Predictors,Zachary Lipton,Carnegie Mellon University
ICML,2018,Detecting and Correcting for Label Shift with Black Box Predictors,Yu-Xiang Wang,Amazon / UCSB
ICML,2018,Detecting and Correcting for Label Shift with Black Box Predictors,Alexander Smola,Amazon
ICML,2018,Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis,Pengtao Xie,Carnegie Mellon University
ICML,2018,Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis,Wei Wu,Carnegie Mellon University
ICML,2018,Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis,Yichen Zhu,Peking University
ICML,2018,Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis,Eric Xing,Carnegie Mellon University
ICML,2018,Comparison-Based Random Forests,Siavash Haghiri,University of Tübingen
ICML,2018,Comparison-Based Random Forests,Damien Garreau,Max Planck Institute
ICML,2018,Comparison-Based Random Forests,Ulrike von Luxburg,University of Tübingen
ICML,2018,A Probabilistic Theory of Supervised Similarity Learning for Pointwise ROC Curve Optimization,Robin Vogel,Télécom ParisTech
ICML,2018,A Probabilistic Theory of Supervised Similarity Learning for Pointwise ROC Curve Optimization,Aurélien Bellet,INRIA
ICML,2018,A Probabilistic Theory of Supervised Similarity Learning for Pointwise ROC Curve Optimization,Stéphan Clémençon,Télécom ParisTech
ICML,2018,Provable Variable Selection for Streaming Features,Jing Wang,Cornell University
ICML,2018,Provable Variable Selection for Streaming Features,Jie Shen,Rutgers University
ICML,2018,Provable Variable Selection for Streaming Features,Ping Li,Rugters University
ICML,2018,Out-of-sample extension of graph adjacency spectral embedding,Keith Levin,University of Michigan
ICML,2018,Out-of-sample extension of graph adjacency spectral embedding,Fred Roosta,University of Queensland
ICML,2018,Out-of-sample extension of graph adjacency spectral embedding,Michael Mahoney,UC Berkeley
ICML,2018,Out-of-sample extension of graph adjacency spectral embedding,Carey Priebe,Johns Hopkins University
ICML,2018,Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers,Yao Ma,Boston University
ICML,2018,Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers,Alexander Olshevsky,
ICML,2018,Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers,Csaba Szepesvari,Deepmind/University of Alberta
ICML,2018,Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers,Venkatesh Saligrama,Boston University
ICML,2018,Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase Procrustes Flow,Xiao Zhang,University of Virginia
ICML,2018,Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase Procrustes Flow,Simon Du,Carnegie Mellon University
ICML,2018,Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase Procrustes Flow,Quanquan Gu,UCLA
ICML,2018,DCFNet: Deep Neural Network with Decomposed Convolutional Filters,Qiang Qiu,Duke University
ICML,2018,DCFNet: Deep Neural Network with Decomposed Convolutional Filters,Xiuyuan Cheng,Duke University
ICML,2018,DCFNet: Deep Neural Network with Decomposed Convolutional Filters,robert Calderbank,Duke University
ICML,2018,DCFNet: Deep Neural Network with Decomposed Convolutional Filters,Guillermo Sapiro,Duke University
ICML,2018,Optimization Landscape and Expressivity of Deep CNNs,Quynh Nguyen,Saarland University
ICML,2018,Optimization Landscape and Expressivity of Deep CNNs,Matthias Hein,University of Tuebingen
ICML,2018,Scalable Gaussian Processes with Grid-Structured Eigenfunctions (GP-GRIEF),Trefor Evans,University of Toronto
ICML,2018,Scalable Gaussian Processes with Grid-Structured Eigenfunctions (GP-GRIEF),Prasanth B Nair,University of Toronto
ICML,2018,Learning in Integer Latent Variable Models with Nested Automatic Differentiation,Daniel Sheldon,University of Massachusetts Amherst
ICML,2018,Learning in Integer Latent Variable Models with Nested Automatic Differentiation,Kevin Winner,"University of Massachusetts, Amherst"
ICML,2018,Learning in Integer Latent Variable Models with Nested Automatic Differentiation,Debora Sujono,University of Massachusetts Amherst
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Judy Hoffman,UC Berkeley and Georgia Tech
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Eric Tzeng,UC Berkeley
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Taesung Park,UC Berkeley
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Jun-Yan Zhu,MIT
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Philip Isola,UC Berkeley
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Kate Saenko,Boston University
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Alexei Efros,UC Berkeley
ICML,2018,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,Prof. Darrell,University of California at Berkeley
ICML,2018,Rectify Heterogeneous Models with Semantic Mapping,Han-Jia Ye,Nanjing University
ICML,2018,Rectify Heterogeneous Models with Semantic Mapping,De-Chuan Zhan,Nanjing University
ICML,2018,Rectify Heterogeneous Models with Semantic Mapping,Yuan Jiang,Nanjing University
ICML,2018,Rectify Heterogeneous Models with Semantic Mapping,Zhi-Hua Zhou,Nanjing University
ICML,2018,DVAE++: Discrete Variational Autoencoders with Overlapping Transformations,Arash Vahdat,"Quadrant.ai, D-Wave"
ICML,2018,DVAE++: Discrete Variational Autoencoders with Overlapping Transformations,William Macready,D-Wave
ICML,2018,DVAE++: Discrete Variational Autoencoders with Overlapping Transformations,Zhengbing Bian,"Quadrant.ai, D-Wave Systems Inc."
ICML,2018,DVAE++: Discrete Variational Autoencoders with Overlapping Transformations,Amir Khoshaman,D-Wave systems Inc
ICML,2018,DVAE++: Discrete Variational Autoencoders with Overlapping Transformations,Evgeny Andriyash,D-Wave
ICML,2018,Iterative Amortized Inference,Joe Marino,Caltech
ICML,2018,Iterative Amortized Inference,Yisong Yue,Caltech
ICML,2018,Iterative Amortized Inference,Stephan Mandt,Disney Research
ICML,2018,Blind Justice: Fairness with Encrypted Sensitive Attributes,Niki Kilbertus,MPI Tübingen & Cambridge
ICML,2018,Blind Justice: Fairness with Encrypted Sensitive Attributes,Adria Gascon,The Alan Turing Institute / Warwick University
ICML,2018,Blind Justice: Fairness with Encrypted Sensitive Attributes,Matt Kusner,Alan Turing Institute
ICML,2018,Blind Justice: Fairness with Encrypted Sensitive Attributes,Michael Veale,UCL
ICML,2018,Blind Justice: Fairness with Encrypted Sensitive Attributes,Krishna Gummadi,MPI-SWS
ICML,2018,Blind Justice: Fairness with Encrypted Sensitive Attributes,Adrian Weller,"University of Cambridge, Alan Turing Institute"
ICML,2018,Active Learning with Logged Data,Songbai Yan,University of California San Diego
ICML,2018,Active Learning with Logged Data,Kamalika Chaudhuri,University of California at San Diego
ICML,2018,Active Learning with Logged Data,Tara Javidi,University of California San Diego
ICML,2018,A Reductions Approach to Fair Classification,Alekh Agarwal,Microsoft Research
ICML,2018,A Reductions Approach to Fair Classification,Alina Beygelzimer,Yahoo Research
ICML,2018,A Reductions Approach to Fair Classification,Miroslav Dudik,Microsoft Research
ICML,2018,A Reductions Approach to Fair Classification,John Langford,Microsoft Research
ICML,2018,A Reductions Approach to Fair Classification,Hanna Wallach,Microsoft Research
ICML,2018,Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness,Michael Kearns,University of Pennsylvania
ICML,2018,Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness,Seth V Neel,University of Pennsylvania
ICML,2018,Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness,Aaron Roth,University of Pennsylvania
ICML,2018,Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness,Zhiwei Wu,Microsoft Research
ICML,2018,Bayesian Model Selection for Change Point Detection and Clustering,othmane mazhar,KTH Royal Institute of Technology
ICML,2018,Bayesian Model Selection for Change Point Detection and Clustering,Cristian R. Rojas,KTH Royal Institute of Technology
ICML,2018,Bayesian Model Selection for Change Point Detection and Clustering,Inst. of Technology Carlo Fischione,"Royal Inst. of Technology, KTH"
ICML,2018,Bayesian Model Selection for Change Point Detection and Clustering,Mohammad Reza Hesamzadeh,KTH Royal Institute of Technology
ICML,2018,A Unified Framework for Structured Low-rank Matrix Learning,Pratik Kumar Jawanpuria,Microsoft
ICML,2018,A Unified Framework for Structured Low-rank Matrix Learning,Bamdev Mishra,Microsoft
ICML,2018,Firing Bandits: Optimizing Crowdfunding,Lalit Jain,University of Washington
ICML,2018,Firing Bandits: Optimizing Crowdfunding,Kevin Jamieson,University of Washington
ICML,2018,Multi-Fidelity Black-Box Optimization with Hierarchical Partitions,Rajat Sen,University of Texas at Austin
ICML,2018,Multi-Fidelity Black-Box Optimization with Hierarchical Partitions,kirthevasan kandasamy,CMU
ICML,2018,Multi-Fidelity Black-Box Optimization with Hierarchical Partitions,Sanjay Shakkottai,University of Texas at Austin
ICML,2018,Compiling Combinatorial Prediction Games,Frederic Koriche,"CRIL UMR CNRS 8188, Univ. Artois"
ICML,2018,Rates of Convergence of Spectral Methods for Graphon Estimation,Jiaming Xu,Duke University
ICML,2018,Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions,Karren Yang,Massachusetts Institute of Technology
ICML,2018,Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions,Abigail Katoff,MIT
ICML,2018,Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions,Caroline Uhler,Massachusetts Institute of Technology
ICML,2018,Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models,Raj Agrawal,MIT
ICML,2018,Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models,Caroline Uhler,Massachusetts Institute of Technology
ICML,2018,Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models,Tamara Broderick,MIT
ICML,2018,StrassenNets: Deep Learning with a Multiplication Budget,Michael Tschannen,ETH Zurich
ICML,2018,StrassenNets: Deep Learning with a Multiplication Budget,Aran Khanna,Dolores Technologies
ICML,2018,StrassenNets: Deep Learning with a Multiplication Budget,Animashree Anandkumar,Caltech
ICML,2018,Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace,Yoonho Lee,Pohang University of Science and Techonology
ICML,2018,Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace,Seungjin Choi,POSTECH
ICML,2018,Candidates vs. Noises Estimation for Large Multi-Class Classification Problem,Lei Han,Tencent AI Lab
ICML,2018,Candidates vs. Noises Estimation for Large Multi-Class Classification Problem,Yiheng Huang,Tencent AI Lab
ICML,2018,Candidates vs. Noises Estimation for Large Multi-Class Classification Problem,Tong Zhang,Tecent AI Lab
ICML,2018,"CRAFTML, an Efficient Clustering-based Random Forest for Extreme Multi-label Learning",Wissam Siblini,Orange Labs
ICML,2018,"CRAFTML, an Efficient Clustering-based Random Forest for Extreme Multi-label Learning",Frank Meyer,Orange Labs Lannion
ICML,2018,"CRAFTML, an Efficient Clustering-based Random Forest for Extreme Multi-label Learning",Pascale Kuntz,LS2N
ICML,2018,Overcoming Catastrophic Forgetting with Hard Attention to the Task,Joan Serrà,"Telefónica Research, Barcelona"
ICML,2018,Overcoming Catastrophic Forgetting with Hard Attention to the Task,Didac Suris,Universitat Politecnica de Catalunya
ICML,2018,Overcoming Catastrophic Forgetting with Hard Attention to the Task,Marius Miron,Joint Research Centre of the European Commission
ICML,2018,Overcoming Catastrophic Forgetting with Hard Attention to the Task,Alexandros Karatzoglou,Telefonica
ICML,2018,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,Junru Wu,Texas A&M University
ICML,2018,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,Yue Wang,Rice University
ICML,2018,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,Zhenyu Wu,Texas A&M University
ICML,2018,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,Zhangyang Wang,Texas A&M University
ICML,2018,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,Ashok Veeraraghavan,Rice University
ICML,2018,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,Yingyan Lin,
ICML,2018,Efficient Neural Audio Synthesis,Nal Kalchbrenner,Google Brain Amsterdam
ICML,2018,Efficient Neural Audio Synthesis,Erich Elsen,
ICML,2018,Efficient Neural Audio Synthesis,Karen Simonyan,DeepMind
ICML,2018,Efficient Neural Audio Synthesis,Seb Noury,DeepMind
ICML,2018,Efficient Neural Audio Synthesis,Norman Casagrande,DeepMind
ICML,2018,Efficient Neural Audio Synthesis,Edward Lockhart,DeepMind
ICML,2018,Efficient Neural Audio Synthesis,Florian Stimberg,
ICML,2018,Efficient Neural Audio Synthesis,Aäron van den Oord,Google Deepmind
ICML,2018,Efficient Neural Audio Synthesis,Sander Dieleman,DeepMind
ICML,2018,Efficient Neural Audio Synthesis,koray kavukcuoglu,DeepMind
ICML,2018,Born Again Neural Networks,Tommaso Furlanello,University of Southern California
ICML,2018,Born Again Neural Networks,Zachary Lipton,Carnegie Mellon University
ICML,2018,Born Again Neural Networks,Michael Tschannen,ETH Zurich
ICML,2018,Born Again Neural Networks,Laurent Itti,University of Southern California
ICML,2018,Born Again Neural Networks,Anima Anandkumar,Amazon
ICML,2018,Adaptive Sampled Softmax with Kernel Based Sampling,Guy Blanc,Stanford University
ICML,2018,Adaptive Sampled Softmax with Kernel Based Sampling,Steffen Rendle,Google
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Yunchen Pu,Duke
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Shuyang Dai,Duke University
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Zhe Gan,Duke University
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Weiyao Wang,Duke
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Guoyin Wang,Duke University
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Yizhe Zhang,Duke University
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Ricardo Henao,Duke University
ICML,2018,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,Lawrence Carin,Duke
ICML,2018,Autoregressive Quantile Networks for Generative Modeling,Georg Ostrovski,DeepMind
ICML,2018,Autoregressive Quantile Networks for Generative Modeling,Will Dabney,DeepMind
ICML,2018,Autoregressive Quantile Networks for Generative Modeling,Remi Munos,DeepMind
ICML,2018,On the Power of Over-parametrization in Neural Networks with Quadratic Activation,Simon Du,Carnegie Mellon University
ICML,2018,On the Power of Over-parametrization in Neural Networks with Quadratic Activation,Jason Lee,University of Southern California
ICML,2018,On the Limitations of First-Order Approximation in GAN Dynamics,Jerry Li,MIT
ICML,2018,On the Limitations of First-Order Approximation in GAN Dynamics,Aleksander Madry,MIT
ICML,2018,On the Limitations of First-Order Approximation in GAN Dynamics,John Peebles,MIT
ICML,2018,On the Limitations of First-Order Approximation in GAN Dynamics,Ludwig Schmidt,UC Berkeley
ICML,2018,Learning to Explore via Meta-Policy Gradient,Tianbing Xu,"Baidu Research, USA"
ICML,2018,Learning to Explore via Meta-Policy Gradient,Qiang Liu,UT Austin
ICML,2018,Learning to Explore via Meta-Policy Gradient,Liang Zhao,Baidu Research USA
ICML,2018,Learning to Explore via Meta-Policy Gradient,Jian Peng,UIUC
ICML,2018,Mean Field Multi-Agent Reinforcement Learning,Yaodong Yang,University College London
ICML,2018,Mean Field Multi-Agent Reinforcement Learning,Rui Luo,UCL
ICML,2018,Mean Field Multi-Agent Reinforcement Learning,M. Li,University College London
ICML,2018,Mean Field Multi-Agent Reinforcement Learning,Ming Zhou,Shanghai Jiao Tong University
ICML,2018,Mean Field Multi-Agent Reinforcement Learning,Weinan Zhang,Shanghai Jiao Tong University
ICML,2018,Mean Field Multi-Agent Reinforcement Learning,Jun Wang,UCL
ICML,2018,Online Linear Quadratic Control,Alon Cohen,Google Inc.
ICML,2018,Online Linear Quadratic Control,Avinatan Hasidim,Google
ICML,2018,Online Linear Quadratic Control,Tomer Koren,Google Brain
ICML,2018,Online Linear Quadratic Control,Nevena Lazic,Google
ICML,2018,Online Linear Quadratic Control,Yishay Mansour,Google
ICML,2018,Online Linear Quadratic Control,Kunal Talwar,Google
ICML,2018,Online Learning with Abstention,Corinna Cortes,Google Research
ICML,2018,Online Learning with Abstention,Giulia DeSalvo,Google Research
ICML,2018,Online Learning with Abstention,Claudio Gentile,INRIA
ICML,2018,Online Learning with Abstention,Mehryar Mohri,Courant Institute and Google Research
ICML,2018,Online Learning with Abstention,Scott Yang,D. E. Shaw & Co.
ICML,2018,Celer: a Fast Solver for the Lasso with Dual Extrapolation,Mathurin MASSIAS,INRIA
ICML,2018,Celer: a Fast Solver for the Lasso with Dual Extrapolation,Joseph Salmon,Telecom ParisTech
ICML,2018,Celer: a Fast Solver for the Lasso with Dual Extrapolation,Alexandre Gramfort,Inria
ICML,2018,Cut-Pursuit Algorithm for Regularizing Nonsmooth Functionals with Graph Total Variation,Hugo Raguet,LIVE (CNRS)
ICML,2018,Cut-Pursuit Algorithm for Regularizing Nonsmooth Functionals with Graph Total Variation,loic landrieu,IGN
ICML,2018,Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data,Amjad Almahairi,"MILA, University of Montreal"
ICML,2018,Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data,Sai Rajeswar,University of Montreal
ICML,2018,Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data,Alessandro Sordoni,Microsoft Research
ICML,2018,Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data,Philip Bachman,Microsoft Research
ICML,2018,Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data,Aaron Courville,University of Montreal
ICML,2018,Mixed batches and symmetric discriminators for GAN training,Thomas LUCAS,Inria
ICML,2018,Mixed batches and symmetric discriminators for GAN training,Corentin Tallec,INRIA
ICML,2018,Mixed batches and symmetric discriminators for GAN training,Yann Ollivier,Facebook Artificial Intelligence Research
ICML,2018,Mixed batches and symmetric discriminators for GAN training,Jakob Verbeek,INRIA
ICML,2018,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,Li Shen,Tencent AI Lab
ICML,2018,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,Peng Sun,Tencent AI Lab
ICML,2018,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,Yitong Wang,Tencent AI Lab
ICML,2018,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,Wei Liu,Tencent AI Lab
ICML,2018,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,Tong Zhang,Tecent AI Lab
ICML,2018,Learning Hidden Markov Models from Pairwise Co-occurrences with Application to Topic Modeling,Kejun Huang,University of Minnesota
ICML,2018,Learning Hidden Markov Models from Pairwise Co-occurrences with Application to Topic Modeling,Xiao Fu,Oregon State University
ICML,2018,Learning Hidden Markov Models from Pairwise Co-occurrences with Application to Topic Modeling,Nicholas Sidiropoulos,University of Virginia
ICML,2018,DRACO: Byzantine-resilient Distributed Training via Redundant Gradients,Lingjiao Chen,University of Wisconsin-Madison
ICML,2018,DRACO: Byzantine-resilient Distributed Training via Redundant Gradients,Hongyi Wang,University of Wisconsin-Madison
ICML,2018,DRACO: Byzantine-resilient Distributed Training via Redundant Gradients,Zachary Charles,University of Wisconsin-Madison
ICML,2018,DRACO: Byzantine-resilient Distributed Training via Redundant Gradients,Dimitris Papailiopoulos,ECE at University of Wisconsin-Madison
ICML,2018,Communication-Computation Efficient Gradient Coding,Min Ye,Princeton University
ICML,2018,Communication-Computation Efficient Gradient Coding,Emmanuel Abbe,
ICML,2018,"Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral Clustering",Pan Li,University of Illinois Urbana-Champaign
ICML,2018,"Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral Clustering",Olgica Milenkovic,University of Illinois UC
ICML,2018,SMAC: Simultaneous Mapping and Clustering Using Spectral Decompositions,cbajaj bajaj,University of Texas at Austin
ICML,2018,SMAC: Simultaneous Mapping and Clustering Using Spectral Decompositions,Tingran Gao,University of Chicago
ICML,2018,SMAC: Simultaneous Mapping and Clustering Using Spectral Decompositions,Zihang He,Tsinghua University
ICML,2018,SMAC: Simultaneous Mapping and Clustering Using Spectral Decompositions,Qixing Huang,The University of Texas at Austin
ICML,2018,SMAC: Simultaneous Mapping and Clustering Using Spectral Decompositions,Zhenxiao Liang,Tsinghua University
ICML,2018,On Nesting Monte Carlo Estimators,Tom Rainforth,University of Oxford
ICML,2018,On Nesting Monte Carlo Estimators,Rob Cornish,Oxford
ICML,2018,On Nesting Monte Carlo Estimators,Hongseok Yang,KAIST
ICML,2018,On Nesting Monte Carlo Estimators,andrew warrington,University of Oxford
ICML,2018,On Nesting Monte Carlo Estimators,Frank Wood,University of Oxford
ICML,2018,Stein Variational Gradient Descent Without Gradient,Jun Han,Dartmouth College
ICML,2018,Stein Variational Gradient Descent Without Gradient,Qiang Liu,UT Austin
ICML,2018,Detecting non-causal artifacts in multivariate linear regression models,Dominik Janzing,Amazon Research Tübingen
ICML,2018,Detecting non-causal artifacts in multivariate linear regression models,Bernhard Schölkopf,"MPI for Intelligent Systems Tübingen, Germany"
ICML,2018,The Hierarchical Adaptive Forgetting Variational Filter,Vincent Moens,Université catholique de Louvain
ICML,2018,Junction Tree Variational Autoencoder for Molecular Graph Generation,Wengong Jin,MIT Computer Science and Artificial Intelligence Laboratory
ICML,2018,Junction Tree Variational Autoencoder for Molecular Graph Generation,Regina Barzilay,MIT CSAIL
ICML,2018,Junction Tree Variational Autoencoder for Molecular Graph Generation,Tommi Jaakkola,MIT
ICML,2018,Semi-Amortized Variational Autoencoders,Yoon Kim,Harvard University
ICML,2018,Semi-Amortized Variational Autoencoders,Sam Wiseman,Harvard University
ICML,2018,Semi-Amortized Variational Autoencoders,Andrew Miller,Harvard
ICML,2018,Semi-Amortized Variational Autoencoders,David Sontag,Massachusetts Institute of Technology
ICML,2018,Semi-Amortized Variational Autoencoders,Alexander Rush,Harvard University
ICML,2018,Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits,Huasen Wu,Twitter
ICML,2018,Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits,Xueying Guo,University of California Davis
ICML,2018,Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits,Xin Liu,"University of California, Davis"
ICML,2018,Semiparametric Contextual Bandits,Akshay Krishnamurthy,UMass
ICML,2018,Semiparametric Contextual Bandits,Zhiwei Wu,Microsoft Research
ICML,2018,Semiparametric Contextual Bandits,Vasilis Syrgkanis,Microsoft Research
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),Been Kim,Google
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),Martin Wattenberg,Google
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),Justin Gilmer,Google Brain
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),Carrie Cai,
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),James Wexler,Google
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),Fernanda Viégas,Google
ICML,2018,Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),Rory sayres,Google
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,Brandon Reagen,Harvard University
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,Udit Gupta,Harvard University
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,Bob Adolf,Harvard University
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,Michael Mitzenmacher,Harvard University
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,Alexander Rush,Harvard University
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,Gu-Yeon Wei,
ICML,2018,Weightless: Lossy weight encoding for deep neural network compression,David Brooks,Harvard University
ICML,2018,Parallel Bayesian Network Structure Learning,Tian Gao,IBM Research
ICML,2018,Parallel Bayesian Network Structure Learning,Dennis Wei,IBM Research
ICML,2018,Temporal Poisson Square Root Graphical Models,Sinong Geng,UW-Madison; Princeton University
ICML,2018,Temporal Poisson Square Root Graphical Models,Charles Kuang,"The University of Wisconsin, Madison"
ICML,2018,Temporal Poisson Square Root Graphical Models,Peggy Peissig,Marshfield Clinic Research Foundation
ICML,2018,Temporal Poisson Square Root Graphical Models,University of Wisconsin David Page,"University of Wisconsin, Madison"
ICML,2018,Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates,xue wang,THE PENNSYLVANIA STATE UNIVERSITY
ICML,2018,Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates,Mike Wei,University at Buffalo
ICML,2018,Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates,Tao Yao,penn state university
ICML,2018,Dynamic Regret of Strongly Adaptive Methods,Lijun Zhang,Nanjing University
ICML,2018,Dynamic Regret of Strongly Adaptive Methods,Tianbao Yang,The University of Iowa
ICML,2018,Dynamic Regret of Strongly Adaptive Methods,rong jin,alibaba group
ICML,2018,Dynamic Regret of Strongly Adaptive Methods,Zhi-Hua Zhou,Nanjing University
ICML,2018,Distributed Clustering via LSH Based Data Partitioning,Aditya Bhaskara,University of Utah
ICML,2018,Distributed Clustering via LSH Based Data Partitioning,Maheshakya Wijewardena,University of Utah
ICML,2018,Learning to Branch,Nina Balcan,Carnegie Mellon University
ICML,2018,Learning to Branch,Travis Dick,CMU
ICML,2018,Learning to Branch,Tuomas Sandholm,Carnegie Mellon University
ICML,2018,Learning to Branch,Ellen Vitercik,Carnegie Mellon University
ICML,2018,Minibatch Gibbs Sampling on Large Graphical Models,Chris De Sa,Cornell
ICML,2018,Minibatch Gibbs Sampling on Large Graphical Models,Zhiting Chen,Cornell University
ICML,2018,Minibatch Gibbs Sampling on Large Graphical Models,Wong,Stanford university
ICML,2018,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,Niladri S Chatterji,UC Berkeley
ICML,2018,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,Nicolas Flammarion,UC Berkeley
ICML,2018,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,Yian Ma,UC Berkeley
ICML,2018,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,Peter Bartlett,UC Berkeley
ICML,2018,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,Michael Jordan,UC Berkeley
ICML,2018,Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning,Rodrigo A Toro Icarte,University of Toronto
ICML,2018,Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning,Toryn Q Klassen,University of Toronto
ICML,2018,Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning,Richard Valenzano,Element AI
ICML,2018,Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning,Sheila McIlraith,University of Toronto
ICML,2018,Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks,Brenden Lake,New York University
ICML,2018,Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks,Marco Baroni,Facebook Artificial Intelligence Research
ICML,2018,Pathwise Derivatives Beyond the Reparameterization Trick,Martin Jankowiak,Uber AI Labs
ICML,2018,Pathwise Derivatives Beyond the Reparameterization Trick,Fritz Obermeyer,Uber AI Labs
ICML,2018,Message Passing Stein Variational Gradient Descent,Jingwei Zhuo,Tsinghua University
ICML,2018,Message Passing Stein Variational Gradient Descent,Chang Liu,Tsinghua University
ICML,2018,Message Passing Stein Variational Gradient Descent,Jiaxin Shi,Tsinghua University
ICML,2018,Message Passing Stein Variational Gradient Descent,Jun Zhu,Tsinghua University
ICML,2018,Message Passing Stein Variational Gradient Descent,Ning Chen,
ICML,2018,Message Passing Stein Variational Gradient Descent,Bo Zhang,Tsinghua University
ICML,2018,State Space Gaussian Processes with Non-Gaussian Likelihood,Hannes Nickisch,Philips Research
ICML,2018,State Space Gaussian Processes with Non-Gaussian Likelihood,Arno Solin,Aalto University
ICML,2018,State Space Gaussian Processes with Non-Gaussian Likelihood,Alexander Grigorevskiy,Aalto University
ICML,2018,Constant-Time Predictive Distributions for Gaussian Processes,Geoff Pleiss,Cornell University
ICML,2018,Constant-Time Predictive Distributions for Gaussian Processes,Jacob Gardner,Cornell University
ICML,2018,Constant-Time Predictive Distributions for Gaussian Processes,Kilian Weinberger,Cornell University
ICML,2018,Constant-Time Predictive Distributions for Gaussian Processes,Andrew Wilson,Cornell University
ICML,2018,Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks,Peter Bartlett,UC Berkeley
ICML,2018,Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks,Dave Helmbold,
ICML,2018,Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks,Phil Long,Google
ICML,2018,On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups,Risi Kondor,The University of Chicago
ICML,2018,On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups,Shubhendu Trivedi,Toyota Technological Institute
ICML,2018,Racing Thompson: an Efficient Algorithm for Thompson Sampling with Non-conjugate Priors,Yichi Zhou,Tsinghua University
ICML,2018,Racing Thompson: an Efficient Algorithm for Thompson Sampling with Non-conjugate Priors,Jun Zhu,Tsinghua University
ICML,2018,Racing Thompson: an Efficient Algorithm for Thompson Sampling with Non-conjugate Priors,Jingwei Zhuo,Tsinghua University
ICML,2018,Probably Approximately Metric-Fair Learning,Gal Yona,Weizmann Institute of Science
ICML,2018,Probably Approximately Metric-Fair Learning,Guy Rothblum,Weizmann Institute of Science
ICML,2018,Neural Program Synthesis from Diverse Demonstration Videos,Shao-Hua Sun,University of Southern California
ICML,2018,Neural Program Synthesis from Diverse Demonstration Videos,Hyeonwoo Noh,POSTECH
ICML,2018,Neural Program Synthesis from Diverse Demonstration Videos,Sriram Somasundaram,University of Southern California
ICML,2018,Neural Program Synthesis from Diverse Demonstration Videos,Joseph Lim,Univ. of Southern California
ICML,2018,Video Prediction with Appearance and Motion Conditions,Yunseok Jang,Seoul National University
ICML,2018,Video Prediction with Appearance and Motion Conditions,Gunhee Kim,Seoul National University
ICML,2018,Video Prediction with Appearance and Motion Conditions,Yale Song,Microsoft AI & Research
ICML,2018,CRVI: Convex Relaxation for Variational Inference,Ghazal Fazelnia,Columbia University
ICML,2018,CRVI: Convex Relaxation for Variational Inference,John Paisley,Columbia University
ICML,2018,Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent,Trevor Campbell,MIT
ICML,2018,Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent,Tamara Broderick,MIT
ICML,2018,Transformation Autoregressive Networks,Junier Oliva,Carnegie Mellon University
ICML,2018,Transformation Autoregressive Networks,Avinava Dubey,Carnegie Mellon University
ICML,2018,Transformation Autoregressive Networks,Manzil Zaheer,Carnegie Mellon University
ICML,2018,Transformation Autoregressive Networks,Barnabás Póczos,CMU
ICML,2018,Transformation Autoregressive Networks,Russ Salakhutdinov,Carnegie Mellen University
ICML,2018,Transformation Autoregressive Networks,Eric Xing,Carnegie Mellon University
ICML,2018,Transformation Autoregressive Networks,Jeff Schneider,Uber/CMU
ICML,2018,Learning equations for extrapolation and control,Subham S Sahoo,Indian Institute of Technology
ICML,2018,Learning equations for extrapolation and control,Christoph Lampert,IST Austria
ICML,2018,Learning equations for extrapolation and control,Georg Martius,Max Planck Institute for Intelligent Systems
ICML,2018,Analyzing Uncertainty in Neural Machine Translation,Myle Ott,Facebook
ICML,2018,Analyzing Uncertainty in Neural Machine Translation,Michael Auli,Facebook
ICML,2018,Analyzing Uncertainty in Neural Machine Translation,David Grangier,Facebook
ICML,2018,Analyzing Uncertainty in Neural Machine Translation,Marc'Aurelio Ranzato,Facebook AI Research
ICML,2018,Hierarchical Text Generation and Planning for Strategic Dialogue,Denis Yarats,Facebook AI Research
ICML,2018,Hierarchical Text Generation and Planning for Strategic Dialogue,Mike Lewis,Facebook
ICML,2018,Budgeted Experiment Design for Causal Structure Learning,AmirEmad Ghassami,UIUC
ICML,2018,Budgeted Experiment Design for Causal Structure Learning,Saber Salehkaleybar,Sharif University of Technology
ICML,2018,Budgeted Experiment Design for Causal Structure Learning,Negar Kiyavash,University of Illinois at Urbana-Champaign
ICML,2018,Budgeted Experiment Design for Causal Structure Learning,Elias Bareinboim,Purdue
ICML,2018,Accurate Inference for Adaptive Linear Models,Yash Deshpande,Massachusetts Institute of Technology
ICML,2018,Accurate Inference for Adaptive Linear Models,Lester Mackey,Microsoft Research
ICML,2018,Accurate Inference for Adaptive Linear Models,Vasilis Syrgkanis,Microsoft Research
ICML,2018,Accurate Inference for Adaptive Linear Models,Matt Taddy,MICROSOFT
ICML,2018,Path-Level Network Transformation for Efficient Architecture Search,Han Cai,Shanghai Jiao Tong University
ICML,2018,Path-Level Network Transformation for Efficient Architecture Search,Jiacheng Yang,Shanghai Jiao Tong University
ICML,2018,Path-Level Network Transformation for Efficient Architecture Search,Weinan Zhang,Shanghai Jiao Tong University
ICML,2018,Path-Level Network Transformation for Efficient Architecture Search,Song Han,MIT
ICML,2018,Path-Level Network Transformation for Efficient Architecture Search,Yong Yu,Shanghai Jiao Tong University
ICML,2018,Progress & Compress: A scalable framework for continual learning,Jonathan Schwarz,DeepMind
ICML,2018,Progress & Compress: A scalable framework for continual learning,Wojciech Czarnecki,DeepMind
ICML,2018,Progress & Compress: A scalable framework for continual learning,Jelena Luketina,The University of Oxford
ICML,2018,Progress & Compress: A scalable framework for continual learning,Agnieszka Grabska-Barwinska,DeepMind
ICML,2018,Progress & Compress: A scalable framework for continual learning,Yee Teh,DeepMind
ICML,2018,Progress & Compress: A scalable framework for continual learning,Razvan Pascanu,DeepMind
ICML,2018,Progress & Compress: A scalable framework for continual learning,Raia Hadsell,DeepMind
ICML,2018,Learning Longer-term Dependencies in RNNs with Auxiliary Losses,Trieu H Trinh,Google Brain
ICML,2018,Learning Longer-term Dependencies in RNNs with Auxiliary Losses,Andrew Dai,Google Brain
ICML,2018,Learning Longer-term Dependencies in RNNs with Auxiliary Losses,Thang Luong,Google Brain
ICML,2018,Learning Longer-term Dependencies in RNNs with Auxiliary Losses,Quoc Le,Google Brain
ICML,2018,Understanding and Simplifying One-Shot Architecture Search,Gabriel Bender,Google
ICML,2018,Understanding and Simplifying One-Shot Architecture Search,Pieter-Jan Kindermans,Google
ICML,2018,Understanding and Simplifying One-Shot Architecture Search,Barret Zoph,Google
ICML,2018,Understanding and Simplifying One-Shot Architecture Search,Vijay Vasudevan,Google
ICML,2018,Understanding and Simplifying One-Shot Architecture Search,Quoc Le,Google Brain
ICML,2018,Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents,Kaiqing Zhang,University of Illinois at Urbana-Champaign (UIUC)
ICML,2018,Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents,Zhuoran Yang,Princeton University
ICML,2018,Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents,Han Liu,Northwestern
ICML,2018,Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents,Tong Zhang,Tecent AI Lab
ICML,2018,Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents,Tamer Basar,
ICML,2018,State Abstractions for Lifelong Reinforcement Learning,David Abel,Brown University
ICML,2018,State Abstractions for Lifelong Reinforcement Learning,Dilip S. Arumugam,Stanford University
ICML,2018,State Abstractions for Lifelong Reinforcement Learning,Lucas Lehnert,Brown University
ICML,2018,State Abstractions for Lifelong Reinforcement Learning,Michael L. Littman,Brown University
ICML,2018,Bounding and Counting Linear Regions of Deep Neural Networks,Thiago Serra,Carnegie Mellon University
ICML,2018,Bounding and Counting Linear Regions of Deep Neural Networks,Christian Tjandraatmadja,Carnegie Mellon University
ICML,2018,Bounding and Counting Linear Regions of Deep Neural Networks,Srikumar Ramalingam,University of Utah
ICML,2018,Clipped Action Policy Gradient,Yasuhiro Fujita,"Preferred Networks, Inc."
ICML,2018,Clipped Action Policy Gradient,Shin-ichi Maeda,"Preferred Networks, Inc."
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Lasse Espeholt,Google Brain Amsterdam
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Hubert Soyer,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Remi Munos,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Karen Simonyan,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Vlad Mnih,Google Deepmind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Tom Ward,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Yotam Doron,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Vlad Firoiu,
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Tim Harley,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Iain Dunning,
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,Shane Legg,DeepMind
ICML,2018,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,koray kavukcuoglu,DeepMind
ICML,2018,Inter and Intra Topic Structure Learning with Word Embeddings,He Zhao,"FIT, Monash University"
ICML,2018,Inter and Intra Topic Structure Learning with Word Embeddings,Lan Du,"Faculty of Information Technology, Monash University"
ICML,2018,Inter and Intra Topic Structure Learning with Word Embeddings,Wray Buntine,Monash University
ICML,2018,Inter and Intra Topic Structure Learning with Word Embeddings,Mingyuan Zhou,University of Texas at Austin
ICML,2018,oi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis,Samuel Ainsworth,University of Washington
ICML,2018,oi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis,Nick J Foti,University of Washington
ICML,2018,oi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis,Adrian KC Lee,University of Washington
ICML,2018,oi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis,Emily Fox,University of Washington
ICML,2018,The Hidden Vulnerability of Distributed Learning in Byzantium,El Mahdi El Mhamdi,EPFL
ICML,2018,The Hidden Vulnerability of Distributed Learning in Byzantium,Rachid Guerraoui,EPFL
ICML,2018,The Hidden Vulnerability of Distributed Learning in Byzantium,Sébastien Rouault,EPFL
ICML,2018,Asynchronous Byzantine Machine Learning (the case of SGD),Georgios Damaskinos,EPFL
ICML,2018,Asynchronous Byzantine Machine Learning (the case of SGD),El Mahdi El Mhamdi,EPFL
ICML,2018,Asynchronous Byzantine Machine Learning (the case of SGD),Rachid Guerraoui,EPFL
ICML,2018,Asynchronous Byzantine Machine Learning (the case of SGD),Rhicheek Patra,EPFL
ICML,2018,Asynchronous Byzantine Machine Learning (the case of SGD),Mahsa Taziki,EPFL
NIPS,2016,Improved Dropout for Shallow and Deep Learning,Zhe Li,The University of Iowa
NIPS,2016,Improved Dropout for Shallow and Deep Learning,Boqing Gong,University of Central Florida
NIPS,2016,Improved Dropout for Shallow and Deep Learning,Tianbao Yang,University of Iowa
NIPS,2016,Communication-Optimal Distributed Clustering,Jiecao Chen,Indiana University Bloomington
NIPS,2016,Communication-Optimal Distributed Clustering,He Sun,The University of Bristol
NIPS,2016,Communication-Optimal Distributed Clustering,David Woodruff,IBM Research
NIPS,2016,Communication-Optimal Distributed Clustering,Qin Zhang,Indiana University Bloomington
NIPS,2016,On Robustness of Kernel Clustering,Bowei Yan,University of Texas at Austin
NIPS,2016,On Robustness of Kernel Clustering,Purnamrita Sarkar,U.C. Berkeley
NIPS,2016,Combinatorial semi-bandit with known covariance,Rémy Degenne,Université Paris Diderot
NIPS,2016,Combinatorial semi-bandit with known covariance,Vianney Perchet,Ensae - Criteo Labs
NIPS,2016,A posteriori error bounds for joint matrix decomposition problems,Nicolò Colombo,University College London
NIPS,2016,A posteriori error bounds for joint matrix decomposition problems,Nikos Vlassis,Adobe Research
NIPS,2016,Object based Scene Representations using Fisher Scores of Local Subspace Projections,Mandar D Dixit,UC San Diego
NIPS,2016,Object based Scene Representations using Fisher Scores of Local Subspace Projections,Nuno Vasconcelos,UC San Diego
NIPS,2016,MoCap-guided Data Augmentation for 3D Pose Estimation in the Wild,Gregory Rogez,Inria
NIPS,2016,MoCap-guided Data Augmentation for 3D Pose Estimation in the Wild,Cordelia Schmid,Inria / Google
NIPS,2016,Regret of Queueing Bandits,Subhashini Krishnasamy,The University of Texas at Austin
NIPS,2016,Regret of Queueing Bandits,Rajat Sen,The University of Texas at Austin
NIPS,2016,Regret of Queueing Bandits,Ramesh Johari,Stanford University
NIPS,2016,Regret of Queueing Bandits,Sanjay Shakkottai,The University of Texas at Aus
NIPS,2016,Efficient Nonparametric Smoothness Estimation,Shashank Singh,Carnegie Mellon University
NIPS,2016,Efficient Nonparametric Smoothness Estimation,Simon Du,Carnegie Mellon University
NIPS,2016,Efficient Nonparametric Smoothness Estimation,Barnabas Poczos,Carnegie Mellon University
NIPS,2016,Completely random measures for modelling block-structured sparse networks,Tue Herlau,Technical University of Denmark
NIPS,2016,Completely random measures for modelling block-structured sparse networks,Mikkel N Schmidt,DTU
NIPS,2016,Completely random measures for modelling block-structured sparse networks,Morten Mørup,Technical University of Denmark
NIPS,2016,DISCO Nets : DISsimilarity COefficients Networks,Diane Bouchacourt,University of Oxford
NIPS,2016,DISCO Nets : DISsimilarity COefficients Networks,Pawan K Mudigonda,University of Oxford
NIPS,2016,DISCO Nets : DISsimilarity COefficients Networks,Sebastian Nowozin,Microsoft Research
NIPS,2016,"An Architecture for Deep, Hierarchical Generative Models",Philip Bachman,Microsoft Research
NIPS,2016,A Multi-Batch L-BFGS Method for Machine Learning,Albert Berahas,Northwestern University
NIPS,2016,A Multi-Batch L-BFGS Method for Machine Learning,Jorge Nocedal,Northwestern University
NIPS,2016,A Multi-Batch L-BFGS Method for Machine Learning,Martin Takac,Lehigh University
NIPS,2016,Higher-Order Factorization Machines,Mathieu Blondel,NTT
NIPS,2016,Higher-Order Factorization Machines,Akinori Fujino,NTT
NIPS,2016,Higher-Order Factorization Machines,Naonori Ueda,NTT Communication Science Laboratories / RIKEN AIP
NIPS,2016,Higher-Order Factorization Machines,Masakazu Ishihata,Hokkaido University
NIPS,2016,A Bio-inspired Redundant Sensing Architecture,Anh Tuan Nguyen,University of Minnesota
NIPS,2016,A Bio-inspired Redundant Sensing Architecture,Jian Xu,University of Minnesota
NIPS,2016,A Bio-inspired Redundant Sensing Architecture,Zhi Yang,University of Minnesota
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Lev Bogolubsky,"Yandex, Moscow State University"
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Pavel Dvurechenskii,Weierstrass Institute for Appl
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Alexander Gasnikov,SkolTech
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Gleb Gusev,Yandex LLC
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Yurii Nesterov,Catholic University of Louvain (UCL)
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Andrei M Raigorodskii,Moscow Institute of Physics and Technology
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,altsoph Tikhonov,Yandex
NIPS,2016,Learning Supervised PageRank with Gradient-Based and Gradient-Free Optimization Methods,Maksim Zhukovskii,
NIPS,2016,Linear Relaxations for Finding Diverse Elements in Metric Spaces,Aditya Bhaskara,University of Utah
NIPS,2016,Linear Relaxations for Finding Diverse Elements in Metric Spaces,Mehrdad Ghadiri,Sharif University of Technolog
NIPS,2016,Linear Relaxations for Finding Diverse Elements in Metric Spaces,Vahab Mirrokni,Google
NIPS,2016,Linear Relaxations for Finding Diverse Elements in Metric Spaces,Ola Svensson,EPFL
NIPS,2016,Stochastic Optimization for Large-scale Optimal Transport,Aude Genevay,Université Paris Dauphine
NIPS,2016,Stochastic Optimization for Large-scale Optimal Transport,Marco Cuturi,"Université Paris-Saclay, CREST - ENSAE"
NIPS,2016,Stochastic Optimization for Large-scale Optimal Transport,Gabriel Peyré,Université Paris Dauphine
NIPS,2016,Stochastic Optimization for Large-scale Optimal Transport,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2016,"Threshold Bandits, With and Without Censored Feedback",Jacob D Abernethy,University of Michigan
NIPS,2016,"Threshold Bandits, With and Without Censored Feedback",Kareem Amin,University of Michigan
NIPS,2016,"Threshold Bandits, With and Without Censored Feedback",Ruihao Zhu,MIT
NIPS,2016,Mistake Bounds for Binary Matrix Completion,Mark Herbster,University College London
NIPS,2016,Mistake Bounds for Binary Matrix Completion,Stephen Pasteris,UCL
NIPS,2016,Mistake Bounds for Binary Matrix Completion,Massimiliano Pontil,IIT & UCL
NIPS,2016,SoundNet: Learning Sound Representations from Unlabeled Video,Yusuf Aytar,MIT
NIPS,2016,SoundNet: Learning Sound Representations from Unlabeled Video,Carl Vondrick,MIT
NIPS,2016,SoundNet: Learning Sound Representations from Unlabeled Video,Antonio Torralba,MIT
NIPS,2016,Doubly Convolutional Neural Networks,Shuangfei Zhai,Binghamton University
NIPS,2016,Doubly Convolutional Neural Networks,Yu Cheng,U of Southern California
NIPS,2016,Doubly Convolutional Neural Networks,Weining Lu,Tsinghua University
NIPS,2016,Doubly Convolutional Neural Networks,Zhongfei (Mark) Zhang,Binghamton University
NIPS,2016,Maximizing Influence in an Ising Network: A Mean-Field Optimal Solution,Christopher W Lynn,University of Pennsylvania
NIPS,2016,Maximizing Influence in an Ising Network: A Mean-Field Optimal Solution,Daniel Lee,University of Pennsylvania
NIPS,2016,Learning from Rational Behavior: Predicting Solutions to Unknown Linear Programs,Shahin Jabbari,University of Pennsylvania
NIPS,2016,Learning from Rational Behavior: Predicting Solutions to Unknown Linear Programs,Ryan Rogers,University of Pennsylvania
NIPS,2016,Learning from Rational Behavior: Predicting Solutions to Unknown Linear Programs,Aaron Roth,University of Pennsylvania
NIPS,2016,Learning from Rational Behavior: Predicting Solutions to Unknown Linear Programs,Steven Wu,University of Pennsylvania
NIPS,2016,Fairness in Learning: Classic and Contextual Bandits,Matthew Joseph,University of Pennsylvania
NIPS,2016,Fairness in Learning: Classic and Contextual Bandits,Michael Kearns,University of Pennsylvania
NIPS,2016,Fairness in Learning: Classic and Contextual Bandits,Jamie Morgenstern,University of Pennsylvania
NIPS,2016,Fairness in Learning: Classic and Contextual Bandits,Aaron Roth,University of Pennsylvania
NIPS,2016,A Powerful Generative Model Using Random Weights for the Deep Image Representation,Kun He,Huazhong University of Science and Technology
NIPS,2016,A Powerful Generative Model Using Random Weights for the Deep Image Representation,Yan Wang,HUAZHONG UNIVERSITY OF SCIENCE
NIPS,2016,A Powerful Generative Model Using Random Weights for the Deep Image Representation,John Hopcroft,Cornell University
NIPS,2016,Improved Error Bounds for Tree Representations of Metric Spaces,Samir Chowdhury,The Ohio State University
NIPS,2016,Improved Error Bounds for Tree Representations of Metric Spaces,Facundo Mémoli,The Ohio State University
NIPS,2016,Improved Error Bounds for Tree Representations of Metric Spaces,Zane T Smith,Ohio State University
NIPS,2016,Adaptive optimal training of animal behavior,Ji Hyun Bak,Princeton University
NIPS,2016,Adaptive optimal training of animal behavior,Jung Choi,
NIPS,2016,Adaptive optimal training of animal behavior,Athena Akrami,Princeton University
NIPS,2016,Adaptive optimal training of animal behavior,Ilana Witten,
NIPS,2016,Adaptive optimal training of animal behavior,Jonathan W Pillow,Princeton University
NIPS,2016,PAC-Bayesian Theory Meets Bayesian Inference,Pascal Germain,Laval University
NIPS,2016,PAC-Bayesian Theory Meets Bayesian Inference,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2016,PAC-Bayesian Theory Meets Bayesian Inference,Alexandre Lacoste,Universite de Montreal
NIPS,2016,PAC-Bayesian Theory Meets Bayesian Inference,Simon Lacoste-Julien,INRIA
NIPS,2016,Nearly Isometric Embedding by Relaxation,James McQueen,University of Washington
NIPS,2016,Nearly Isometric Embedding by Relaxation,Marina Meila,University of Washington
NIPS,2016,Nearly Isometric Embedding by Relaxation,Dominique Perrault-Joncas,Google
NIPS,2016,Graph Clustering: Block-models and model free results,Yali Wan,University of Washington
NIPS,2016,Graph Clustering: Block-models and model free results,Marina Meila,University of Washington
NIPS,2016,Learning Transferrable Representations for Unsupervised Domain Adaptation,Ozan Sener,Cornell University
NIPS,2016,Learning Transferrable Representations for Unsupervised Domain Adaptation,Hyun Oh Song,Google Research
NIPS,2016,Learning Transferrable Representations for Unsupervised Domain Adaptation,Ashutosh Saxena,Brain of Things
NIPS,2016,Learning Transferrable Representations for Unsupervised Domain Adaptation,Silvio Savarese,Stanford University
NIPS,2016,Measuring Neural Net Robustness with Constraints,Osbert Bastani,Stanford University
NIPS,2016,Measuring Neural Net Robustness with Constraints,Yani Ioannou,University of Cambridge
NIPS,2016,Measuring Neural Net Robustness with Constraints,Leonidas Lampropoulos,University of Pennsylvania
NIPS,2016,Measuring Neural Net Robustness with Constraints,Dimitrios Vytiniotis,Microsoft Research
NIPS,2016,Measuring Neural Net Robustness with Constraints,Aditya Nori,Microsoft Research
NIPS,2016,Measuring Neural Net Robustness with Constraints,Antonio Criminisi,Microsoft Research
NIPS,2016,A forward model at Purkinje cell synapses facilitates cerebellar anticipatory control,Ivan Herreros,Universitat Pompeu Fabra
NIPS,2016,A forward model at Purkinje cell synapses facilitates cerebellar anticipatory control,Xerxes Arsiwalla,Pompeu Fabra University
NIPS,2016,A forward model at Purkinje cell synapses facilitates cerebellar anticipatory control,Paul Verschure,ICREA - Universitat Pompeu Fabra
NIPS,2016,Estimating Nonlinear Neural Response Functions using GP Priors and Kronecker Methods,Cristina Savin,IST Austria
NIPS,2016,Estimating Nonlinear Neural Response Functions using GP Priors and Kronecker Methods,Gasper Tkacik,Institute of Science and Technology Austria
NIPS,2016,A Bayesian method for reducing bias in neural representational similarity analysis,Mingbo Cai,Princeton University
NIPS,2016,A Bayesian method for reducing bias in neural representational similarity analysis,Nicolas W Schuck,Princeton Neuroscience Institute
NIPS,2016,A Bayesian method for reducing bias in neural representational similarity analysis,Jonathan W Pillow,Princeton University
NIPS,2016,A Bayesian method for reducing bias in neural representational similarity analysis,Yael Niv,Princeton University
NIPS,2016,Learning to Communicate with Deep Multi-Agent Reinforcement Learning,Jakob Foerster,University of Oxford
NIPS,2016,Learning to Communicate with Deep Multi-Agent Reinforcement Learning,Yannis Assael,University of Oxford
NIPS,2016,Learning to Communicate with Deep Multi-Agent Reinforcement Learning,Nando de Freitas,Google
NIPS,2016,Learning to Communicate with Deep Multi-Agent Reinforcement Learning,Shimon Whiteson,University of Oxford
NIPS,2016,"Total Variation Classes Beyond 1d: Minimax Rates, and the Limitations of Linear Smoothers",Veeru Sadhanala,Carnegie Mellon University
NIPS,2016,"Total Variation Classes Beyond 1d: Minimax Rates, and the Limitations of Linear Smoothers",Yu-Xiang Wang,Carnegie Mellon University
NIPS,2016,"Total Variation Classes Beyond 1d: Minimax Rates, and the Limitations of Linear Smoothers",Ryan Tibshirani,Carnegie Mellon University
NIPS,2016,Exponential Family Embeddings,Maja Rudolph,Columbia University
NIPS,2016,Exponential Family Embeddings,Francisco J. R. Ruiz,Columbia University
NIPS,2016,Exponential Family Embeddings,Stephan Mandt,Disney Research
NIPS,2016,Exponential Family Embeddings,David Blei,Columbia University
NIPS,2016,k*-Nearest Neighbors: From Global to Local,Oren Anava,Technion
NIPS,2016,k*-Nearest Neighbors: From Global to Local,Yehuda Kfir Levy,Technion
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,Mohammad Norouzi,Google Brain
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,Samy Bengio,Google Brain
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,ZF Chen,Google Brain
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,Navdeep Jaitly,Google Brain
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,Mike Schuster,Google
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,Yonghui Wu,Google
NIPS,2016,Reward Augmented Maximum Likelihood for Neural Structured Prediction,Dale Schuurmans,University of Alberta & Google Brain
NIPS,2016,A Probabilistic Model of Social Decision Making based on Reward Maximization,Koosha Khalvati,University of Washington
NIPS,2016,A Probabilistic Model of Social Decision Making based on Reward Maximization,Seongmin A. Park,Cognitive Neuroscience Center
NIPS,2016,A Probabilistic Model of Social Decision Making based on Reward Maximization,Jean-Claude Dreher,Centre de Neurosciences Cognitives
NIPS,2016,A Probabilistic Model of Social Decision Making based on Reward Maximization,Rajesh P Rao,University of Washington
NIPS,2016,Active Learning with Oracle Epiphany,T.K. Huang,Uber Advanced Technologies Center
NIPS,2016,Active Learning with Oracle Epiphany,Lihong Li,Microsoft Research
NIPS,2016,Active Learning with Oracle Epiphany,Ara Vartanian,University of Wisconsin-Madison
NIPS,2016,Active Learning with Oracle Epiphany,Saleema Amershi,Microsoft
NIPS,2016,Active Learning with Oracle Epiphany,Jerry Zhu,University of Wisconsin-Madison
NIPS,2016,On Regularizing Rademacher Observation Losses,Richard Nock,Data61 and ANU
NIPS,2016,A Non-generative Framework and Convex Relaxations for Unsupervised Learning,Elad Hazan,Princeton University
NIPS,2016,A Non-generative Framework and Convex Relaxations for Unsupervised Learning,Tengyu Ma,Princeton University
NIPS,2016,Learning Tree Structured Potential Games,Vikas Garg,MIT
NIPS,2016,Learning Tree Structured Potential Games,Tommi Jaakkola,MIT
NIPS,2016,Equality of Opportunity in Supervised Learning,Moritz Hardt,Google Brain
NIPS,2016,Equality of Opportunity in Supervised Learning,,None
NIPS,2016,Equality of Opportunity in Supervised Learning,Eric Price,The University of Texas at Austin
NIPS,2016,Equality of Opportunity in Supervised Learning,Nati Srebro,TTI-Chicago
NIPS,2016,"Interaction Networks for Learning about Objects, Relations and Physics",Peter Battaglia,Google DeepMind
NIPS,2016,"Interaction Networks for Learning about Objects, Relations and Physics",Razvan Pascanu,Google DeepMind
NIPS,2016,"Interaction Networks for Learning about Objects, Relations and Physics",Matthew Lai,Google DeepMind
NIPS,2016,"Interaction Networks for Learning about Objects, Relations and Physics",Danilo Jimenez Rezende,Google DeepMind
NIPS,2016,"Interaction Networks for Learning about Objects, Relations and Physics",koray kavukcuoglu,Google DeepMind
NIPS,2016,beta-risk: a New Surrogate Risk for Learning from Weakly Labeled Data,Valentina Zantedeschi,UJM Saint-Etienne
NIPS,2016,beta-risk: a New Surrogate Risk for Learning from Weakly Labeled Data,Rémi Emonet,Hubert Curien Lab.
NIPS,2016,beta-risk: a New Surrogate Risk for Learning from Weakly Labeled Data,Marc Sebban,University Jean Monnet
NIPS,2016,Binarized Neural Networks,Itay Hubara,Technion
NIPS,2016,Binarized Neural Networks,Matthieu Courbariaux,Université de Montréal
NIPS,2016,Binarized Neural Networks,Daniel Soudry,Columbia University
NIPS,2016,Binarized Neural Networks,Ran El-Yaniv,Technion
NIPS,2016,Binarized Neural Networks,Yoshua Bengio,U. Montreal
NIPS,2016,Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning,Mehdi Sajjadi,University of Utah
NIPS,2016,Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning,Mehran Javanmardi,University of Utah
NIPS,2016,Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning,Tolga Tasdizen,University of Utah
NIPS,2016,Generating Images with Perceptual Similarity Metrics based on Deep Networks,Alexey Dosovitskiy,University of Freiburg
NIPS,2016,Generating Images with Perceptual Similarity Metrics based on Deep Networks,Thomas Brox,University of Freiburg
NIPS,2016,Exploiting Tradeoffs for Exact Recovery in Heterogeneous Stochastic Block Models,Amin Jalali,University of Washington
NIPS,2016,Exploiting Tradeoffs for Exact Recovery in Heterogeneous Stochastic Block Models,Qiyang Han,University of Washington
NIPS,2016,Exploiting Tradeoffs for Exact Recovery in Heterogeneous Stochastic Block Models,Ioana Dumitriu,University of Washington
NIPS,2016,Exploiting Tradeoffs for Exact Recovery in Heterogeneous Stochastic Block Models,Maryam Fazel,University of Washington
NIPS,2016,Tensor Switching Networks,Kenyon Tsai,Harvard University
NIPS,2016,Tensor Switching Networks,Andrew M Saxe,Stanford University
NIPS,2016,Tensor Switching Networks,David Cox,"MIT-IBM Watson AI Lab, IBM Research"
NIPS,2016,Finite-Dimensional BFRY Priors and Variational Bayesian Inference for Power Law Models,Juho Lee,POSTECH
NIPS,2016,Finite-Dimensional BFRY Priors and Variational Bayesian Inference for Power Law Models,Lancelot F James,HKUST
NIPS,2016,Finite-Dimensional BFRY Priors and Variational Bayesian Inference for Power Law Models,Seungjin Choi,POSTECH
NIPS,2016,Temporal Regularized Matrix Factorization for High-dimensional Time Series Prediction,Hsiang-Fu (Rofu) Yu,University of Texas at Austin
NIPS,2016,Temporal Regularized Matrix Factorization for High-dimensional Time Series Prediction,Nikhil Rao,Amazon
NIPS,2016,Temporal Regularized Matrix Factorization for High-dimensional Time Series Prediction,Inderjit S Dhillon,University of Texas at Austin
NIPS,2016,Composing graphical models with neural networks for structured representations and fast inference,Matthew Johnson,MIT
NIPS,2016,Composing graphical models with neural networks for structured representations and fast inference,David Duvenaud,University of Toronto
NIPS,2016,Composing graphical models with neural networks for structured representations and fast inference,Alex Wiltschko,Harvard University and Twitter
NIPS,2016,Composing graphical models with neural networks for structured representations and fast inference,Ryan Adams,Google Brain and Princeton University
NIPS,2016,Composing graphical models with neural networks for structured representations and fast inference,Sandeep R Datta,Harvard Medical School
NIPS,2016,PAC Reinforcement Learning with Rich Observations,Akshay Krishnamurthy,UMass Amherst
NIPS,2016,PAC Reinforcement Learning with Rich Observations,Alekh Agarwal,Microsoft
NIPS,2016,PAC Reinforcement Learning with Rich Observations,John Langford,Microsoft Research New York
NIPS,2016,Algorithms and matching lower bounds for approximately-convex optimization,Andrej Risteski,Princeton University
NIPS,2016,Algorithms and matching lower bounds for approximately-convex optimization,Yuanzhi Li,Princeton University
NIPS,2016,Proximal Stochastic Methods for Nonsmooth Nonconvex Finite-Sum Optimization,Sashank J. Reddi,Carnegie Mellon University
NIPS,2016,Proximal Stochastic Methods for Nonsmooth Nonconvex Finite-Sum Optimization,Suvrit Sra,MIT
NIPS,2016,Proximal Stochastic Methods for Nonsmooth Nonconvex Finite-Sum Optimization,Barnabas Poczos,Carnegie Mellon University
NIPS,2016,Proximal Stochastic Methods for Nonsmooth Nonconvex Finite-Sum Optimization,Alex Smola,Amazon - We are hiring!
NIPS,2016,A Simple Practical Accelerated Method for Finite Sums,Aaron Defazio,Ambiata
NIPS,2016,Unsupervised Learning for Physical Interaction through Video Prediction,Chelsea Finn,Google
NIPS,2016,Unsupervised Learning for Physical Interaction through Video Prediction,Ian Goodfellow,Google
NIPS,2016,Unsupervised Learning for Physical Interaction through Video Prediction,Sergey Levine,University of Washington
NIPS,2016,Threshold Learning for Optimal Decision Making,Nathan F Lepora,University of Bristol
NIPS,2016,Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks,Hao Wang,HKUST
NIPS,2016,Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks,Xingjian SHI,Hong Kong University of Science and Technology
NIPS,2016,Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks,Dit-Yan Yeung,"HKUST, Hong Kong"
NIPS,2016,Finding significant combinations of features in the presence of categorical covariates,Laetitia Papaxanthos,ETH Zurich
NIPS,2016,Finding significant combinations of features in the presence of categorical covariates,Felipe Llinares-Lopez,ETH Zurich
NIPS,2016,Finding significant combinations of features in the presence of categorical covariates,Dean Bodenham,ETH Zurich
NIPS,2016,Finding significant combinations of features in the presence of categorical covariates,Karsten Borgwardt,ETH Zurich
NIPS,2016,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,Anh Nguyen,University of Wyoming
NIPS,2016,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,Alexey Dosovitskiy,University of Freiburg
NIPS,2016,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,Jason Yosinski,Cornell
NIPS,2016,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,Thomas Brox,University of Freiburg
NIPS,2016,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,Jeff Clune,University of Wyoming
NIPS,2016,Learning Infinite RBMs with Frank-Wolfe,Wei Ping,UC Irvine
NIPS,2016,Learning Infinite RBMs with Frank-Wolfe,Qiang Liu,Dartmouth College
NIPS,2016,Learning Infinite RBMs with Frank-Wolfe,Alexander Ihler,UC Irvine
NIPS,2016,Sorting out typicality with the inverse moment matrix SOS polynomial,Edouard Pauwels,IRIT
NIPS,2016,Sorting out typicality with the inverse moment matrix SOS polynomial,Jean B Lasserre,LAAS-CNRS
NIPS,2016,Improving PAC Exploration Using the Median Of Means,Jason Pazis,MIT
NIPS,2016,Improving PAC Exploration Using the Median Of Means,Ron Parr,Duke University
NIPS,2016,Improving PAC Exploration Using the Median Of Means,Jonathan How,MIT
NIPS,2016,Reconstructing Parameters of Spreading Models from Partial Observations,Andrey Lokhov,Los Alamos National Laboratory
NIPS,2016,Dynamic Filter Networks,Xu Jia,KU Leuven
NIPS,2016,Dynamic Filter Networks,Bert De Brabandere,KU Leuven
NIPS,2016,Dynamic Filter Networks,Tinne Tuytelaars,KU Leuven
NIPS,2016,Dynamic Filter Networks,Luc V Gool,ETH Zürich
NIPS,2016,Generating Long-term Trajectories Using Deep Hierarchical Networks,Stephan Zheng,Caltech
NIPS,2016,Generating Long-term Trajectories Using Deep Hierarchical Networks,Yisong Yue,Caltech
NIPS,2016,Generating Long-term Trajectories Using Deep Hierarchical Networks,Patrick Lucey,Stats
NIPS,2016,Cooperative Inverse Reinforcement Learning,Dylan Hadfield-Menell,UC Berkeley
NIPS,2016,Cooperative Inverse Reinforcement Learning,Stuart J Russell,UC Berkeley
NIPS,2016,Cooperative Inverse Reinforcement Learning,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,Cooperative Inverse Reinforcement Learning,Anca Dragan,UC Berkeley
NIPS,2016,Review Networks for Caption Generation,Zhilin Yang,Carnegie Mellon University
NIPS,2016,Review Networks for Caption Generation,Ye Yuan,Carnegie Mellon University
NIPS,2016,Review Networks for Caption Generation,Yuexin Wu,Carnegie Mellon University
NIPS,2016,Review Networks for Caption Generation,William Cohen,Carnegie Mellon University
NIPS,2016,Review Networks for Caption Generation,Russ Salakhutdinov,University of Toronto
NIPS,2016,Gradient-based Sampling: An Adaptive Importance Sampling for Least-squares,Rong Zhu,Chinese Academy of Sciences
NIPS,2016,Robust k-means: a Theoretical Revisit,ALEX GEORGOGIANNIS,TECHNICAL UNIVERSITY OF CRETE
NIPS,2016,Boosting with Abstention,Corinna Cortes,Google Research
NIPS,2016,Boosting with Abstention,Giulia DeSalvo,New York University
NIPS,2016,Boosting with Abstention,Mehryar Mohri,Courant Inst. of Math. Sciences & Google Research
NIPS,2016,Estimating the class prior and posterior from noisy positives and unlabeled data,Shantanu Jain,Indiana University
NIPS,2016,Estimating the class prior and posterior from noisy positives and unlabeled data,Martha White,University of Alberta
NIPS,2016,Estimating the class prior and posterior from noisy positives and unlabeled data,Pedja Radivojac,Indiana University
NIPS,2016,Bootstrap Model Aggregation for Distributed Statistical Learning,JUN HAN,Dartmouth College
NIPS,2016,Bootstrap Model Aggregation for Distributed Statistical Learning,Qiang Liu,Dartmouth College
NIPS,2016,Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling,Maria-Florina Balcan,Carnegie Mellon University
NIPS,2016,Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling,Hongyang Zhang,CMU
NIPS,2016,FPNN: Field Probing Neural Networks for 3D Data,Yangyan Li,Stanford University
NIPS,2016,FPNN: Field Probing Neural Networks for 3D Data,pirk Pirk,Stanford University
NIPS,2016,FPNN: Field Probing Neural Networks for 3D Data,Hao Su,Stanford University
NIPS,2016,FPNN: Field Probing Neural Networks for 3D Data,Charles R Qi,Stanford University
NIPS,2016,FPNN: Field Probing Neural Networks for 3D Data,Leonidas J Guibas,Stanford University
NIPS,2016,Causal meets Submodular: Subset Selection with Directed Information,Yuxun Zhou,UC Berkeley
NIPS,2016,Causal meets Submodular: Subset Selection with Directed Information,Costas J Spanos,"University of California, Berkeley"
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Durk Kingma,Google
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Tim Salimans,Algoritmica
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Rafal Jozefowicz,OpenAI
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Xi Chen,Columbia University
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Peter Chen,UC Berkeley and OpenAI
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Ilya Sutskever,Google
NIPS,2016,Improving Variational Autoencoders with Inverse Autoregressive Flow,Max Welling,University of Amsterdam / Qualcomm AI Research
NIPS,2016,Adaptive Smoothed Online Multi-Task Learning,Keerthiram Murugesan,Carnegie Mellon University
NIPS,2016,Adaptive Smoothed Online Multi-Task Learning,Hanxiao Liu,Carnegie Mellon University
NIPS,2016,Adaptive Smoothed Online Multi-Task Learning,Jaime Carbonell,CMU
NIPS,2016,Adaptive Smoothed Online Multi-Task Learning,Yiming Yang,CMU
NIPS,2016,The Limits of Learning with Missing Data,Brian Bullins,Princeton University
NIPS,2016,The Limits of Learning with Missing Data,Elad Hazan,Princeton University
NIPS,2016,The Limits of Learning with Missing Data,Tomer Koren,Technion---Israel Inst. of Technology
NIPS,2016,Safe Exploration in Finite Markov Decision Processes with Gaussian Processes,Matteo Turchetta,ETH Zurich
NIPS,2016,Safe Exploration in Finite Markov Decision Processes with Gaussian Processes,Felix Berkenkamp,ETH Zurich
NIPS,2016,Safe Exploration in Finite Markov Decision Processes with Gaussian Processes,Andreas Krause,ETHZ
NIPS,2016,Sparse Support Recovery with Non-smooth Loss Functions,Kévin Degraux,Université catholique de Louva
NIPS,2016,Sparse Support Recovery with Non-smooth Loss Functions,Gabriel Peyré,Université Paris Dauphine
NIPS,2016,Sparse Support Recovery with Non-smooth Loss Functions,Jalal Fadili,CNRS-ENSICAEN-Univ. Caen
NIPS,2016,Sparse Support Recovery with Non-smooth Loss Functions,Laurent Jacques,Université catholique de Louvain
NIPS,2016,Crowdsourced Clustering: Querying Edges vs Triangles,Ramya Korlakai Vinayak,Caltech
NIPS,2016,Crowdsourced Clustering: Querying Edges vs Triangles,Babak Hassibi,Caltech
NIPS,2016,Dual Decomposed Learning with Factorwise Oracle for Structural SVM of Large Output Domain,Ian Yen,University of Texas at Austin
NIPS,2016,Dual Decomposed Learning with Factorwise Oracle for Structural SVM of Large Output Domain,Xiangru Huang,University of Texas at Austin
NIPS,2016,Dual Decomposed Learning with Factorwise Oracle for Structural SVM of Large Output Domain,Kai Zhong,UT AUSTIN
NIPS,2016,Dual Decomposed Learning with Factorwise Oracle for Structural SVM of Large Output Domain,Ruohan Zhang,University of Texas at Austin
NIPS,2016,Dual Decomposed Learning with Factorwise Oracle for Structural SVM of Large Output Domain,Pradeep Ravikumar,Carnegie Mellon University
NIPS,2016,Dual Decomposed Learning with Factorwise Oracle for Structural SVM of Large Output Domain,Inderjit S Dhillon,University of Texas at Austin
NIPS,2016,Sampling for Bayesian Program Learning,Kevin Ellis,MIT
NIPS,2016,Sampling for Bayesian Program Learning,Armando Solar-Lezama,MIT
NIPS,2016,Sampling for Bayesian Program Learning,Josh Tenenbaum,MIT
NIPS,2016,Multiple-Play Bandits in the Position-Based Model,Paul Lagrée,Université Paris Sud
NIPS,2016,Multiple-Play Bandits in the Position-Based Model,Claire Vernade,Université Paris Saclay
NIPS,2016,Multiple-Play Bandits in the Position-Based Model,Olivier Cappe,
NIPS,2016,Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections,Xiaojiao Mao,Nanjing University
NIPS,2016,Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections,Chunhua Shen,
NIPS,2016,Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections,Yu-Bin Yang,NanjingUniversity
NIPS,2016,Optimistic Bandit Convex Optimization,Scott Yang,New York University
NIPS,2016,Optimistic Bandit Convex Optimization,Mehryar Mohri,Courant Inst. of Math. Sciences & Google Research
NIPS,2016,Computing and maximizing influence in linear threshold and triggering models,Justin Khim,University of Pennsylvania
NIPS,2016,Computing and maximizing influence in linear threshold and triggering models,Varun Jog,University of Wisconsin - Madison
NIPS,2016,Computing and maximizing influence in linear threshold and triggering models,Po-Ling Loh,Berkeley
NIPS,2016,Clustering with Bregman Divergences: an Asymptotic Analysis,Chaoyue Liu,The Ohio State University
NIPS,2016,Clustering with Bregman Divergences: an Asymptotic Analysis,Mikhail Belkin,Ohio State University
NIPS,2016,Community Detection on Evolving Graphs,LEONARDI Leonardi,Sapienza University of Rome
NIPS,2016,Community Detection on Evolving Graphs,Aris Anagnostopoulos,Sapienza University of Rome
NIPS,2016,Community Detection on Evolving Graphs,Jakub Łącki,Sapienza University of Rome
NIPS,2016,Community Detection on Evolving Graphs,Silvio Lattanzi,Google
NIPS,2016,Community Detection on Evolving Graphs,Mohammad Mahdian,Google Research
NIPS,2016,Dueling Bandits: Beyond Condorcet Winners to General Tournament Solutions,Siddartha Y. Ramamohan,Indian Institute of Science
NIPS,2016,Dueling Bandits: Beyond Condorcet Winners to General Tournament Solutions,Arun Rajkumar,"Xerox Research Center, India."
NIPS,2016,Dueling Bandits: Beyond Condorcet Winners to General Tournament Solutions,Shivani Agarwal,Radcliffe Institute
NIPS,2016,Dueling Bandits: Beyond Condorcet Winners to General Tournament Solutions,Shivani Agarwal,Radcliffe Institute
NIPS,2016,Learning a Metric Embedding  for Face Recognition using the Multibatch Method,Oren Tadmor,OrCam
NIPS,2016,Learning a Metric Embedding  for Face Recognition using the Multibatch Method,Tal Rosenwein,Orcam
NIPS,2016,Learning a Metric Embedding  for Face Recognition using the Multibatch Method,Shai Shalev-Shwartz,OrCam
NIPS,2016,Learning a Metric Embedding  for Face Recognition using the Multibatch Method,Yonatan Wexler,OrCam
NIPS,2016,Learning a Metric Embedding  for Face Recognition using the Multibatch Method,Amnon Shashua,OrCam
NIPS,2016,Convergence guarantees for kernel-based quadrature rules in misspecified settings,Motonobu Kanagawa,The Institute of Statistical Mathematics
NIPS,2016,Convergence guarantees for kernel-based quadrature rules in misspecified settings,Bharath Sriperumbudur,Penn State University
NIPS,2016,Convergence guarantees for kernel-based quadrature rules in misspecified settings,Kenji Fukumizu,Institute of Statistical Mathematics
NIPS,2016,Stochastic Variational Deep Kernel Learning,Andrew Wilson,Carnegie Mellon University
NIPS,2016,Stochastic Variational Deep Kernel Learning,Zhiting Hu,Carnegie Mellon University
NIPS,2016,Stochastic Variational Deep Kernel Learning,Russ Salakhutdinov,University of Toronto
NIPS,2016,Stochastic Variational Deep Kernel Learning,Eric Xing,Carnegie Mellon University
NIPS,2016,Deep Submodular Functions: Definitions and Learning,Brian W Dolhansky,University of Washington
NIPS,2016,Deep Submodular Functions: Definitions and Learning,Jeff Bilmes,University of Washington
NIPS,2016,Scaled Least Squares Estimator for GLMs in Large-Scale Problems,Murat A Erdogdu,Stanford University
NIPS,2016,Scaled Least Squares Estimator for GLMs in Large-Scale Problems,Lee H Dicker,Rutgers University and Amazon
NIPS,2016,Scaled Least Squares Estimator for GLMs in Large-Scale Problems,Mohsen Bayati,Stanford University
NIPS,2016,High-Rank Matrix Completion and Clustering under Self-Expressive Models,Ehsan Elhamifar,Northeastern University
NIPS,2016,Stochastic Three-Composite Convex Minimization,Alp Yurtsever,EPFL
NIPS,2016,Stochastic Three-Composite Convex Minimization,Bang Cong Vu,"LIONS, EPFL"
NIPS,2016,Stochastic Three-Composite Convex Minimization,Volkan Cevher,EPFL
NIPS,2016,Tree-Structured Reinforcement Learning for Sequential Object Localization,Zequn Jie,National Univ of Singapore
NIPS,2016,Tree-Structured Reinforcement Learning for Sequential Object Localization,Xiaodan Liang,Sun Yat-sen University
NIPS,2016,Tree-Structured Reinforcement Learning for Sequential Object Localization,Jiashi Feng,National University of Singapo
NIPS,2016,Tree-Structured Reinforcement Learning for Sequential Object Localization,Xiaojie Jin,NUS
NIPS,2016,Tree-Structured Reinforcement Learning for Sequential Object Localization,Wen Lu,National Univ of Singapore
NIPS,2016,Tree-Structured Reinforcement Learning for Sequential Object Localization,Shuicheng Yan,National University of Singapore
NIPS,2016,The non-convex Burer-Monteiro approach works on smooth semidefinite programs,Nicolas Boumal,Princeton University
NIPS,2016,The non-convex Burer-Monteiro approach works on smooth semidefinite programs,Vlad Voroninski,MIT
NIPS,2016,The non-convex Burer-Monteiro approach works on smooth semidefinite programs,Afonso Bandeira,
NIPS,2016,Neurons Equipped with Intrinsic Plasticity Learn Stimulus Intensity Statistics,Travis Monk,University of Oldenburg
NIPS,2016,Neurons Equipped with Intrinsic Plasticity Learn Stimulus Intensity Statistics,Cristina Savin,IST Austria
NIPS,2016,Neurons Equipped with Intrinsic Plasticity Learn Stimulus Intensity Statistics,Jörg Lücke,University of Oldenburg
NIPS,2016,Greedy Feature Construction,Dino Oglic,University of Bonn
NIPS,2016,Greedy Feature Construction,Thomas Gärtner,The University of Nottingham
NIPS,2016,Dynamic Mode Decomposition with Reproducing Kernels for Koopman Spectral Analysis,Yoshinobu Kawahara,Osaka University
NIPS,2016,Learning the Number of Neurons in Deep Networks,Jose Alvarez,NICTA
NIPS,2016,Learning the Number of Neurons in Deep Networks,Mathieu Salzmann,EPFL
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,Alexander Vezhnevets,Google DeepMind
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,Volodymyr Mnih,DeepMind
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,Simon Osindero,Google DeepMind
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,Alex Graves,Google DeepMind
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,Oriol Vinyals,Google DeepMind
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,John Agapiou,Google DeepMind
NIPS,2016,Strategic Attentive Writer for Learning Macro-Actions,koray kavukcuoglu,Google DeepMind
NIPS,2016,Active Learning from Imperfect Labelers,Songbai Yan,University of California
NIPS,2016,Active Learning from Imperfect Labelers,Kamalika Chaudhuri,University of California
NIPS,2016,Active Learning from Imperfect Labelers,Tara Javidi,University of California
NIPS,2016,Probabilistic Linear Multistep Methods,Onur Teymur,Imperial College London
NIPS,2016,Probabilistic Linear Multistep Methods,Kostas Zygalakis,University of Edinburgh
NIPS,2016,Probabilistic Linear Multistep Methods,Ben Calderhead,Imperial College
NIPS,2016,"More Supervision, Less Computation: Statistical-Computational Tradeoffs in Weakly Supervised Learning",Xinyang Yi,UT Austin
NIPS,2016,"More Supervision, Less Computation: Statistical-Computational Tradeoffs in Weakly Supervised Learning",Zhaoran Wang,Princeton University
NIPS,2016,"More Supervision, Less Computation: Statistical-Computational Tradeoffs in Weakly Supervised Learning",Zhuoran Yang,Princeton University
NIPS,2016,"More Supervision, Less Computation: Statistical-Computational Tradeoffs in Weakly Supervised Learning",Constantine Caramanis,UT Austin
NIPS,2016,"More Supervision, Less Computation: Statistical-Computational Tradeoffs in Weakly Supervised Learning",Han Liu,Tencent AI Lab
NIPS,2016,Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula,jean barbier,EPFL
NIPS,2016,Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula,Mohamad Dia,EPFL
NIPS,2016,Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula,Nicolas Macris,EPFL
NIPS,2016,Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula,Florent Krzakala,ENS Paris & Sorbonnes Université
NIPS,2016,Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula,Thibault Lesieur,IPHT Saclay
NIPS,2016,Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula,Lenka Zdeborová,CEA Saclay
NIPS,2016,Coin Betting and Parameter-Free Online Learning,Francesco Orabona,Yahoo Research
NIPS,2016,Coin Betting and Parameter-Free Online Learning,David Pal,Google
NIPS,2016,Normalized Spectral Map Synchronization,Yanyao Shen,UT Austin
NIPS,2016,Normalized Spectral Map Synchronization,Qixing Huang,Toyota Technological Institute at Chicago
NIPS,2016,Normalized Spectral Map Synchronization,Nati Srebro,TTI-Chicago
NIPS,2016,Normalized Spectral Map Synchronization,Sujay Sanghavi,UT-Austin
NIPS,2016,On Explore-Then-Commit strategies,Aurélien Garivier,Ecole Normale Supérieure de Lyon
NIPS,2016,On Explore-Then-Commit strategies,Tor Lattimore,DeepMind
NIPS,2016,On Explore-Then-Commit strategies,Emilie Kaufmann,Telecom ParisTech
NIPS,2016,Learning Kernels with Random Features,Aman Sinha,Stanford University
NIPS,2016,Learning Kernels with Random Features,John Duchi,Stanford
NIPS,2016,Robustness of classifiers: from adversarial to random noise,Alhussein Fawzi,Ecole Polytechnique Federale de Lausanne (EPFL)
NIPS,2016,Robustness of classifiers: from adversarial to random noise,Seyed-Mohsen Moosavi-Dezfooli,EPFL
NIPS,2016,Robustness of classifiers: from adversarial to random noise,Pascal Frossard,EPFL
NIPS,2016,Adaptive Skills Adaptive Partitions (ASAP),Daniel J Mankowitz,Technion
NIPS,2016,Adaptive Skills Adaptive Partitions (ASAP),Timothy A Mann,Google DeepMind
NIPS,2016,Adaptive Skills Adaptive Partitions (ASAP),Shie Mannor,Technion
NIPS,2016,Gaussian Process Bandit Optimisation with Multi-fidelity Evaluations,Kirthevasan Kandasamy,CMU
NIPS,2016,Gaussian Process Bandit Optimisation with Multi-fidelity Evaluations,Gautam Dasarathy,Carnegie Mellon University
NIPS,2016,Gaussian Process Bandit Optimisation with Multi-fidelity Evaluations,Junier B Oliva,Carnegie Mellon University
NIPS,2016,Gaussian Process Bandit Optimisation with Multi-fidelity Evaluations,Jeff Schneider,CMU
NIPS,2016,Gaussian Process Bandit Optimisation with Multi-fidelity Evaluations,Barnabas Poczos,Carnegie Mellon University
NIPS,2016,Flexible Models for Microclustering with Application to Entity Resolution,Brenda Betancourt,Duke University
NIPS,2016,Flexible Models for Microclustering with Application to Entity Resolution,Giacomo Zanella,The University of Warick
NIPS,2016,Flexible Models for Microclustering with Application to Entity Resolution,Jeff Miller,Duke University
NIPS,2016,Flexible Models for Microclustering with Application to Entity Resolution,Hanna Wallach,Microsoft Research
NIPS,2016,Flexible Models for Microclustering with Application to Entity Resolution,Abbas Zaidi,Duke University
NIPS,2016,Flexible Models for Microclustering with Application to Entity Resolution,Rebecca Steorts,Duke University
NIPS,2016,Stochastic Gradient Richardson-Romberg Markov Chain Monte Carlo,Alain Durmus,Telecom ParisTech
NIPS,2016,Stochastic Gradient Richardson-Romberg Markov Chain Monte Carlo,Umut Simsekli,Télécom ParisTech
NIPS,2016,Stochastic Gradient Richardson-Romberg Markov Chain Monte Carlo,Eric Moulines,Ecole Polytechnique
NIPS,2016,Stochastic Gradient Richardson-Romberg Markov Chain Monte Carlo,Roland Badeau,Telecom ParisTech
NIPS,2016,Stochastic Gradient Richardson-Romberg Markov Chain Monte Carlo,Gaël RICHARD,Telecom ParisTech
NIPS,2016,Online and Differentially-Private Tensor Decomposition,Yining Wang,Carnegie Mellon University
NIPS,2016,Online and Differentially-Private Tensor Decomposition,Anima Anandkumar,UC Irvine
NIPS,2016,Maximal Sparsity with Deep Networks?,Bo Xin,Peking University
NIPS,2016,Maximal Sparsity with Deep Networks?,Yizhou Wang,Peking University
NIPS,2016,Maximal Sparsity with Deep Networks?,Wen Gao,peking university
NIPS,2016,Maximal Sparsity with Deep Networks?,Baoyuan Wang,Microsoft Research
NIPS,2016,Maximal Sparsity with Deep Networks?,David Wipf,Microsoft Research
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,Alexander Shishkin,Yandex
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,Anastasia Bezzubtseva,Yandex
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,Alexey Drutsa,Yandex
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,Ilia Shishkov,Yandex
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,kglad Gladkikh,Yandex
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,Gleb Gusev,Yandex LLC
NIPS,2016,Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information,Pavel Serdyukov,Yandex
NIPS,2016,Geometric Dirichlet Means Algorithm for topic inference,Werner Geyer,University of Michigan
NIPS,2016,Geometric Dirichlet Means Algorithm for topic inference,Long Nguyen,University of Michigan
NIPS,2016,Interaction Screening: Efficient and Sample-Optimal Learning of Ising Models,Marc Vuffray,Los Alamos National Laboratory
NIPS,2016,Interaction Screening: Efficient and Sample-Optimal Learning of Ising Models,Sidhant Misra,Los Alamos National Laboratory
NIPS,2016,Interaction Screening: Efficient and Sample-Optimal Learning of Ising Models,Andrey Lokhov,Los Alamos National Laboratory
NIPS,2016,Interaction Screening: Efficient and Sample-Optimal Learning of Ising Models,Michael Chertkov,Los Alamos National Laboratory
NIPS,2016,Multi-armed Bandits: Competing with Optimal Sequences,Zohar Karnin,Yahoo Research
NIPS,2016,Multi-armed Bandits: Competing with Optimal Sequences,Oren Anava,Technion
NIPS,2016,Catching heuristics are optimal control policies,Boris Belousov,TU Darmstadt
NIPS,2016,Catching heuristics are optimal control policies,Gerhard Neumann,University of Lincoln
NIPS,2016,Catching heuristics are optimal control policies,Constantin A Rothkopf,TU Darmstadt
NIPS,2016,Catching heuristics are optimal control policies,Jan Peters,TU Darmstadt & MPI Intelligent Systems
NIPS,2016,Riemannian SVRG: Fast Stochastic Optimization on Riemannian Manifolds,Hongyi Zhang,MIT
NIPS,2016,Riemannian SVRG: Fast Stochastic Optimization on Riemannian Manifolds,Sashank J. Reddi,Carnegie Mellon University
NIPS,2016,Riemannian SVRG: Fast Stochastic Optimization on Riemannian Manifolds,Suvrit Sra,MIT
NIPS,2016,A Comprehensive Linear Speedup Analysis for Asynchronous Stochastic Parallel Optimization from Zeroth-Order to First-Order,Xiangru Lian,University of Rochester
NIPS,2016,A Comprehensive Linear Speedup Analysis for Asynchronous Stochastic Parallel Optimization from Zeroth-Order to First-Order,Huan Zhang,UC-Davis
NIPS,2016,A Comprehensive Linear Speedup Analysis for Asynchronous Stochastic Parallel Optimization from Zeroth-Order to First-Order,Cho-Jui Hsieh,UCLA
NIPS,2016,A Comprehensive Linear Speedup Analysis for Asynchronous Stochastic Parallel Optimization from Zeroth-Order to First-Order,Yijun Huang,University of Rochester
NIPS,2016,A Comprehensive Linear Speedup Analysis for Asynchronous Stochastic Parallel Optimization from Zeroth-Order to First-Order,Ji Liu,"University of Rochester, Tencent AI lab"
NIPS,2016,Stochastic Gradient MCMC with Stale Gradients,Changyou Chen,University at Buffalo
NIPS,2016,Stochastic Gradient MCMC with Stale Gradients,Nan Ding,Google
NIPS,2016,Stochastic Gradient MCMC with Stale Gradients,Chunyuan Li,Duke
NIPS,2016,Stochastic Gradient MCMC with Stale Gradients,Yizhe Zhang,Duke university
NIPS,2016,Stochastic Gradient MCMC with Stale Gradients,Lawrence Carin,Duke University
NIPS,2016,Disentangling factors of variation in deep representation using adversarial training,Michael Mathieu,NYU
NIPS,2016,Disentangling factors of variation in deep representation using adversarial training,Junbo (Jake) Zhao,NYU
NIPS,2016,Disentangling factors of variation in deep representation using adversarial training,Junbo Zhao,NYU
NIPS,2016,Disentangling factors of variation in deep representation using adversarial training,Aditya Ramesh,NYU
NIPS,2016,Disentangling factors of variation in deep representation using adversarial training,Pablo Sprechmann,New York University
NIPS,2016,Disentangling factors of variation in deep representation using adversarial training,Yann LeCun,NYU
NIPS,2016,Consistent Kernel Mean Estimation for Functions of Random Variables,Carl-Johann Simon-Gabriel,MPI Tuebingen
NIPS,2016,Consistent Kernel Mean Estimation for Functions of Random Variables,Adam Scibior,University of Cambridge
NIPS,2016,Consistent Kernel Mean Estimation for Functions of Random Variables,Ilya Tolstikhin,MPI for Intelligent Systems
NIPS,2016,Consistent Kernel Mean Estimation for Functions of Random Variables,Bernhard Schölkopf,MPI for Intelligent Systems
NIPS,2016,DECOrrelated feature space partitioning for distributed sparse regression,Xiangyu Wang,Duke University
NIPS,2016,DECOrrelated feature space partitioning for distributed sparse regression,David B Dunson,Duke University
NIPS,2016,DECOrrelated feature space partitioning for distributed sparse regression,Chenlei Leng,University of Warwick
NIPS,2016,Coupled Generative Adversarial Networks,Ming-Yu Liu,MERL
NIPS,2016,Coupled Generative Adversarial Networks,Oncel Tuzel,Mitsubishi Electric Research Labs (MERL)
NIPS,2016,Matching Networks for One Shot Learning,Oriol Vinyals,Google DeepMind
NIPS,2016,Matching Networks for One Shot Learning,Charles Blundell,DeepMind
NIPS,2016,Matching Networks for One Shot Learning,Timothy Lillicrap,Google DeepMind
NIPS,2016,Matching Networks for One Shot Learning,koray kavukcuoglu,Google DeepMind
NIPS,2016,Matching Networks for One Shot Learning,Daan Wierstra,Google DeepMind
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Shandian Zhe,Purdue University
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Kai Zhang,NEC Labs America
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Pengyuan Wang,Yahoo! Research
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Kuang-chih Lee,Yahoo Inc.
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Zenglin Xu,University of Electronic Science & Technology of China
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Alan Qi,Ant financial service group
NIPS,2016,Distributed Flexible Nonlinear Tensor Factorization,Zoubin Ghahramani,Uber and University of Cambridge
NIPS,2016,Tracking the Best Expert in Non-stationary Stochastic Environments,Chen-Yu Wei,Academia Sinica
NIPS,2016,Tracking the Best Expert in Non-stationary Stochastic Environments,Yi-Te Hong,Academia Sinica
NIPS,2016,Tracking the Best Expert in Non-stationary Stochastic Environments,Chi-Jen Lu,Academia Sinica
NIPS,2016,Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition,Jinzhuo Wang,PKU
NIPS,2016,Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition,Wenmin Wang,peking university
NIPS,2016,Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition,xiongtao Chen,peking university
NIPS,2016,Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition,Ronggang Wang,peking university
NIPS,2016,Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition,Wen Gao,peking university
NIPS,2016,Learning Parametric Sparse Models for Image Super-Resolution,Yongbo Li,Xidian University
NIPS,2016,Learning Parametric Sparse Models for Image Super-Resolution,Weisheng Dong,Xidian University
NIPS,2016,Learning Parametric Sparse Models for Image Super-Resolution,Xuemei Xie,Xidian University
NIPS,2016,Learning Parametric Sparse Models for Image Super-Resolution,GUANGMING Shi,Xidian University
NIPS,2016,Learning Parametric Sparse Models for Image Super-Resolution,Xin Li,WVU
NIPS,2016,Learning Parametric Sparse Models for Image Super-Resolution,Donglai Xu,Teesside University
NIPS,2016,Kernel Observers: Systems-Theoretic Modeling and Inference of Spatiotemporally Evolving Processes,Hassan A Kingravi,Pindrop Security Services
NIPS,2016,Kernel Observers: Systems-Theoretic Modeling and Inference of Spatiotemporally Evolving Processes,Harshal R Maske,UIUC
NIPS,2016,Kernel Observers: Systems-Theoretic Modeling and Inference of Spatiotemporally Evolving Processes,Girish Chowdhary,UIUC
NIPS,2016,Learning brain regions via large-scale online structured sparse dictionary learning,Elvis DOHMATOB,Inria
NIPS,2016,Learning brain regions via large-scale online structured sparse dictionary learning,Arthur Mensch,inria
NIPS,2016,Learning brain regions via large-scale online structured sparse dictionary learning,Gael Varoquaux,"Parietal Team, INRIA"
NIPS,2016,Learning brain regions via large-scale online structured sparse dictionary learning,Bertrand Thirion,INRIA
NIPS,2016,Scaling Factorial Hidden Markov Models: Stochastic Variational Inference without Messages,Yin Cheng Ng,University College London
NIPS,2016,Scaling Factorial Hidden Markov Models: Stochastic Variational Inference without Messages,Pawel M Chilinski,University College London
NIPS,2016,Scaling Factorial Hidden Markov Models: Stochastic Variational Inference without Messages,Ricardo Silva,University College London
NIPS,2016,A Bandit Framework for Strategic Regression,Yang Liu,Harvard University
NIPS,2016,A Bandit Framework for Strategic Regression,Yiling Chen,Harvard University
NIPS,2016,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,Michaël Defferrard,EPFL
NIPS,2016,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,Xavier Bresson,EPFL
NIPS,2016,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,Pierre Vandergheynst,EPFL
NIPS,2016,Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm,Qiang Liu,Dartmouth College
NIPS,2016,Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm,Dilin Wang,Dartmouth College
NIPS,2016,Deep Learning Models of the Retinal Response to Natural Scenes,Lane McIntosh,Stanford University
NIPS,2016,Deep Learning Models of the Retinal Response to Natural Scenes,Niru Maheswaranathan,Stanford University
NIPS,2016,Deep Learning Models of the Retinal Response to Natural Scenes,Aran Nayebi,Stanford University
NIPS,2016,Deep Learning Models of the Retinal Response to Natural Scenes,Surya Ganguli,Stanford
NIPS,2016,Deep Learning Models of the Retinal Response to Natural Scenes,Stephen Baccus,Stanford University
NIPS,2016,Safe and Efficient Off-Policy Reinforcement Learning,Remi Munos,Google DeepMind
NIPS,2016,Safe and Efficient Off-Policy Reinforcement Learning,Tom Stepleton,Google DeepMind
NIPS,2016,Safe and Efficient Off-Policy Reinforcement Learning,Anna Harutyunyan,Vrije Universiteit Brussel
NIPS,2016,Safe and Efficient Off-Policy Reinforcement Learning,Marc Bellemare,Google DeepMind
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Firas Abuzaid,MIT
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Joseph K Bradley,Databricks
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Feynman T Liang,Cambridge University Engineering Department
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Andrew Feng,Yahoo!
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Lee Yang,Yahoo!
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Matei Zaharia,MIT
NIPS,2016,Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale,Ameet S Talwalkar,CMU
NIPS,2016,Sample Complexity of Automated Mechanism Design,Maria-Florina Balcan,Carnegie Mellon University
NIPS,2016,Sample Complexity of Automated Mechanism Design,Tuomas Sandholm,Carnegie Mellon University
NIPS,2016,Sample Complexity of Automated Mechanism Design,Ellen Vitercik,Carnegie Mellon University
NIPS,2016,Deep Exploration via Bootstrapped DQN,Ian Osband,DeepMind
NIPS,2016,Deep Exploration via Bootstrapped DQN,Charles Blundell,DeepMind
NIPS,2016,Deep Exploration via Bootstrapped DQN,Alexander Pritzel,Google Deepmind
NIPS,2016,Deep Exploration via Bootstrapped DQN,Benjamin Van Roy,Stanford University
NIPS,2016,Search Improves Label for Active Learning,Alina Beygelzimer,Yahoo Inc
NIPS,2016,Search Improves Label for Active Learning,Daniel Hsu,Columbia University
NIPS,2016,Search Improves Label for Active Learning,John Langford,Microsoft Research New York
NIPS,2016,Search Improves Label for Active Learning,Chicheng Zhang,UCSD
NIPS,2016,Efficient and Robust Spiking Neural Circuit for Navigation Inspired by Echolocating Bats,Bipin Rajendran,NJIT
NIPS,2016,Efficient and Robust Spiking Neural Circuit for Navigation Inspired by Echolocating Bats,Pulkit Tandon,IIT Bombay
NIPS,2016,Efficient and Robust Spiking Neural Circuit for Navigation Inspired by Echolocating Bats,Yash H Malviya,IIT Bombay
NIPS,2016,Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning,Gang Niu,University of Tokyo
NIPS,2016,Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning,Marthinus Christoffel du Plessis,The University of Tokyo
NIPS,2016,Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning,Tomoya Sakai,The University of Tokyo
NIPS,2016,Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning,Yao Ma,
NIPS,2016,Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2016,Quantized Random Projections and Non-Linear Estimation of Cosine Similarity,Ping Li,Rugters University
NIPS,2016,Quantized Random Projections and Non-Linear Estimation of Cosine Similarity,Michael Mitzenmacher,Harvard University
NIPS,2016,Quantized Random Projections and Non-Linear Estimation of Cosine Similarity,Martin Slawski,George Mason University
NIPS,2016,CNNpack: Packing Convolutional Neural Networks in the Frequency Domain,Yunhe Wang,Peking University
NIPS,2016,CNNpack: Packing Convolutional Neural Networks in the Frequency Domain,Chang Xu,Peking University
NIPS,2016,CNNpack: Packing Convolutional Neural Networks in the Frequency Domain,Shan You,
NIPS,2016,CNNpack: Packing Convolutional Neural Networks in the Frequency Domain,Dacheng Tao,Nanyang Technological University
NIPS,2016,CNNpack: Packing Convolutional Neural Networks in the Frequency Domain,Chao Xu,Peking University
NIPS,2016,Verification Based Solution for Structured MAB Problems,Zohar Karnin,Yahoo Research
NIPS,2016,Neurally-Guided Procedural Models: Amortized Inference for Procedural Graphics Programs using Neural Networks,Daniel Ritchie,Stanford University
NIPS,2016,Neurally-Guided Procedural Models: Amortized Inference for Procedural Graphics Programs using Neural Networks,Anna Thomas,Stanford University
NIPS,2016,Neurally-Guided Procedural Models: Amortized Inference for Procedural Graphics Programs using Neural Networks,Pat Hanrahan,Stanford University
NIPS,2016,Neurally-Guided Procedural Models: Amortized Inference for Procedural Graphics Programs using Neural Networks,Noah Goodman,Stanford University
NIPS,2016,Edge-exchangeable graphs and sparsity,Diana Cai,University of Chicago
NIPS,2016,Edge-exchangeable graphs and sparsity,Trevor Campbell,MIT
NIPS,2016,Edge-exchangeable graphs and sparsity,Tamara Broderick,MIT
NIPS,2016,Learning and Forecasting Opinion Dynamics in Social Networks,Abir De,IIT Kharagpur
NIPS,2016,Learning and Forecasting Opinion Dynamics in Social Networks,Isabel Valera,Max Planck Institute for Software Systems (MPI-SWS)
NIPS,2016,Learning and Forecasting Opinion Dynamics in Social Networks,Niloy Ganguly,IIT Kharagpur
NIPS,2016,Learning and Forecasting Opinion Dynamics in Social Networks,Sourangshu Bhattacharya,IIT Kharagpur
NIPS,2016,Learning and Forecasting Opinion Dynamics in Social Networks,Manuel Gomez Rodriguez,MPI-SWS
NIPS,2016,Probing the Compositionality of Intuitive Functions,Eric Schulz,University College London
NIPS,2016,Probing the Compositionality of Intuitive Functions,Josh Tenenbaum,MIT
NIPS,2016,Probing the Compositionality of Intuitive Functions,David Duvenaud,University of Toronto
NIPS,2016,Probing the Compositionality of Intuitive Functions,Maarten Speekenbrink,University College London
NIPS,2016,Probing the Compositionality of Intuitive Functions,Samuel J Gershman,Harvard University
NIPS,2016,Learning shape correspondence with anisotropic convolutional neural networks,Davide Boscaini,University of Lugano
NIPS,2016,Learning shape correspondence with anisotropic convolutional neural networks,Jonathan Masci,Università della Svizzera italiana
NIPS,2016,Learning shape correspondence with anisotropic convolutional neural networks,Emanuele Rodolà,University of Lugano
NIPS,2016,Learning shape correspondence with anisotropic convolutional neural networks,Michael Bronstein,University of Lugano
NIPS,2016,Improved Techniques for Training GANs,Tim Salimans,Algoritmica
NIPS,2016,Improved Techniques for Training GANs,Ian Goodfellow,Google
NIPS,2016,Improved Techniques for Training GANs,Wojciech Zaremba,OpenAI
NIPS,2016,Improved Techniques for Training GANs,Vicki Cheung,OpenAI
NIPS,2016,Improved Techniques for Training GANs,Alec Radford,OpenAI
NIPS,2016,Improved Techniques for Training GANs,Xi Chen,Columbia University
NIPS,2016,Improved Techniques for Training GANs,Peter Chen,UC Berkeley and OpenAI
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Uygar Sümbül,Columbia University
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Douglas Roossien,University of Michigan
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Fei Chen,Massachusetts Institute of Technology
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Dawen Cai,University of Michigan
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Nick Barry,Massachusetts Institute of Technology
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,John Cunningham,University of Columbia
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Liam Paninski,Columbia University
NIPS,2016,Automated scalable segmentation of neurons from multispectral images,Edward Boyden,Massachusetts Institute of Technology
NIPS,2016,Optimal Cluster Recovery in the Labeled Stochastic Block Model,Se-Young Yun,Los Alamos National Laboratory
NIPS,2016,Optimal Cluster Recovery in the Labeled Stochastic Block Model,Alexandre Proutiere,KTH
NIPS,2016,Phased Exploration with Greedy Exploitation in Stochastic Combinatorial Partial Monitoring Games,Sougata Chaudhuri,University of Michigan
NIPS,2016,Phased Exploration with Greedy Exploitation in Stochastic Combinatorial Partial Monitoring Games,Ambuj Tewari,University of Michigan
NIPS,2016,Dual Space Gradient Descent for Online Learning,Trung Le,University of Pedagogy Ho Chi Minh city
NIPS,2016,Dual Space Gradient Descent for Online Learning,Tu Nguyen,Deakin University
NIPS,2016,Dual Space Gradient Descent for Online Learning,Vu Nguyen,Deakin University
NIPS,2016,Dual Space Gradient Descent for Online Learning,Dinh Phung,Deakin University
NIPS,2016,"Data Programming: Creating Large Training Sets, Quickly",Alexander Ratner,Stanford University
NIPS,2016,"Data Programming: Creating Large Training Sets, Quickly",Christopher M De Sa,Stanford University
NIPS,2016,"Data Programming: Creating Large Training Sets, Quickly",Sen Wu,Stanford University
NIPS,2016,"Data Programming: Creating Large Training Sets, Quickly",Daniel Selsam,Stanford
NIPS,2016,"Data Programming: Creating Large Training Sets, Quickly",Christopher Ré,Stanford University
NIPS,2016,Near-Optimal Smoothing of Structured Conditional Probability Matrices,Moein Falahatgar,UCSD
NIPS,2016,Near-Optimal Smoothing of Structured Conditional Probability Matrices,Mesrob Ohannessian,Toyota Technological Institute at Chicago
NIPS,2016,Near-Optimal Smoothing of Structured Conditional Probability Matrices,Alon Orlitsky,"University of California, San Diego"
NIPS,2016,An urn model for majority voting in classification ensembles,Victor Soto,Columbia University
NIPS,2016,An urn model for majority voting in classification ensembles,Alberto Suárez,Universidad Autónoma de Madrid
NIPS,2016,An urn model for majority voting in classification ensembles,Gonzalo Martinez-Muñoz,Universidad Autónoma de Madrid
NIPS,2016,The Multi-fidelity Multi-armed Bandit,Kirthevasan Kandasamy,CMU
NIPS,2016,The Multi-fidelity Multi-armed Bandit,Gautam Dasarathy,Carnegie Mellon University
NIPS,2016,The Multi-fidelity Multi-armed Bandit,Barnabas Poczos,Carnegie Mellon University
NIPS,2016,The Multi-fidelity Multi-armed Bandit,Jeff Schneider,CMU
NIPS,2016,Probabilistic Inference with Generating Functions for Poisson Latent Variable Models,Kevin Winner,UMass CICS
NIPS,2016,Probabilistic Inference with Generating Functions for Poisson Latent Variable Models,Dan Sheldon,University of Massachusetts Amherst
NIPS,2016,Adaptive Maximization of Pointwise Submodular Functions With Budget Constraint,Nguyen Viet Cuong,National University of Singapore
NIPS,2016,Adaptive Maximization of Pointwise Submodular Functions With Budget Constraint,Huan Xu,NUS
NIPS,2016,Dual Learning for Machine Translation,Di He,Microsoft
NIPS,2016,Dual Learning for Machine Translation,Yingce Xia,USTC
NIPS,2016,Dual Learning for Machine Translation,Tao Qin,Microsoft
NIPS,2016,Dual Learning for Machine Translation,Liwei Wang,Peking University
NIPS,2016,Dual Learning for Machine Translation,Nenghai Yu,USTC
NIPS,2016,Dual Learning for Machine Translation,Tie-Yan Liu,Microsoft Research
NIPS,2016,Dual Learning for Machine Translation,Wei-Ying Ma,Microsoft
NIPS,2016,Iterative Refinement of the Approximate Posterior for Directed Belief Networks,devon Hjelm,University of New Mexico
NIPS,2016,Iterative Refinement of the Approximate Posterior for Directed Belief Networks,Russ Salakhutdinov,University of Toronto
NIPS,2016,Iterative Refinement of the Approximate Posterior for Directed Belief Networks,Kyunghyun Cho,University of Montreal
NIPS,2016,Iterative Refinement of the Approximate Posterior for Directed Belief Networks,Nebojsa Jojic,Microsoft Research
NIPS,2016,Iterative Refinement of the Approximate Posterior for Directed Belief Networks,Vince Calhoun,Mind Research Network
NIPS,2016,Iterative Refinement of the Approximate Posterior for Directed Belief Networks,Junyoung Chung,University of Montreal
NIPS,2016,Unsupervised Risk Estimation Using Only Conditional Independence Structure,Jacob Steinhardt,Stanford University
NIPS,2016,Unsupervised Risk Estimation Using Only Conditional Independence Structure,Percy Liang,Stanford University
NIPS,2016,Hierarchical Question-Image Co-Attention for Visual Question Answering,Jiasen Lu,Virginia Tech
NIPS,2016,Hierarchical Question-Image Co-Attention for Visual Question Answering,Jianwei Yang,Virginia Tech
NIPS,2016,Hierarchical Question-Image Co-Attention for Visual Question Answering,Dhruv Batra,Georgia Tech / Facebook AI Research (FAIR)
NIPS,2016,Hierarchical Question-Image Co-Attention for Visual Question Answering,Devi Parikh,Virginia Tech
NIPS,2016,Bayesian Optimization with a Finite Budget: An Approximate Dynamic Programming Approach,Remi Lam,MIT
NIPS,2016,Bayesian Optimization with a Finite Budget: An Approximate Dynamic Programming Approach,Karen Willcox,MIT
NIPS,2016,Bayesian Optimization with a Finite Budget: An Approximate Dynamic Programming Approach,David Wolpert,NASA Ames Research  Center
NIPS,2016,Learning to learn by gradient descent by gradient descent,Marcin Andrychowicz,Google Deepmind
NIPS,2016,Learning to learn by gradient descent by gradient descent,Misha Denil,DeepMind
NIPS,2016,Learning to learn by gradient descent by gradient descent,Sergio Gómez,Google DeepMind
NIPS,2016,Learning to learn by gradient descent by gradient descent,Matthew Hoffman,Google DeepMind
NIPS,2016,Learning to learn by gradient descent by gradient descent,David Pfau,Google DeepMind
NIPS,2016,Learning to learn by gradient descent by gradient descent,Tom Schaul,DeepMind
NIPS,2016,Learning to learn by gradient descent by gradient descent,Nando de Freitas,Google
NIPS,2016,Computational and Statistical Tradeoffs in Learning to Rank,Ashish Khetan,University of Illinois Urbana-
NIPS,2016,Computational and Statistical Tradeoffs in Learning to Rank,Sewoong Oh,UIUC
NIPS,2016,Pairwise Choice Markov Chains,Stephen Ragain,Stanford University
NIPS,2016,Pairwise Choice Markov Chains,Johan Ugander,Stanford University
NIPS,2016,Incremental Variational Sparse Gaussian Process Regression,Ching-An Cheng,Georgia Institute of Technolog
NIPS,2016,Incremental Variational Sparse Gaussian Process Regression,Byron Boots,Georgia Tech / Google Brain
NIPS,2016,Combinatorial Multi-Armed Bandit with General Reward Functions,Wei Chen,Microsoft Research
NIPS,2016,Combinatorial Multi-Armed Bandit with General Reward Functions,Wei Hu,Princeton University
NIPS,2016,Combinatorial Multi-Armed Bandit with General Reward Functions,Fu Li,The University of Texas at Austin
NIPS,2016,Combinatorial Multi-Armed Bandit with General Reward Functions,Jian Li,Tsinghua University
NIPS,2016,Combinatorial Multi-Armed Bandit with General Reward Functions,Yu Liu,Tsinghua University
NIPS,2016,Combinatorial Multi-Armed Bandit with General Reward Functions,Pinyan Lu,Shanghai University of Finance and Economics
NIPS,2016,Observational-Interventional Priors for Dose-Response Learning,Ricardo Silva,University College London
NIPS,2016,On Graph Reconstruction via Empirical Risk Minimization: Fast Learning Rates and Scalability,Guillaume Papa,Télécom ParisTech
NIPS,2016,On Graph Reconstruction via Empirical Risk Minimization: Fast Learning Rates and Scalability,Aurélien Bellet,INRIA
NIPS,2016,On Graph Reconstruction via Empirical Risk Minimization: Fast Learning Rates and Scalability,Stephan Clémençon,Telecom ParisTech
NIPS,2016,DeepMath - Deep Sequence Models for Premise Selection,Geoffrey Irving,Google
NIPS,2016,DeepMath - Deep Sequence Models for Premise Selection,Christian Szegedy,Google
NIPS,2016,DeepMath - Deep Sequence Models for Premise Selection,Niklas Een,Google Inc.
NIPS,2016,DeepMath - Deep Sequence Models for Premise Selection,Alex Alemi,Google
NIPS,2016,DeepMath - Deep Sequence Models for Premise Selection,Francois Chollet,"Google, Inc"
NIPS,2016,DeepMath - Deep Sequence Models for Premise Selection,Josef Urban,Czech Technical University in Prague
NIPS,2016,Efficient Second Order Online Learning by Sketching,Haipeng Luo,Princeton University
NIPS,2016,Efficient Second Order Online Learning by Sketching,Alekh Agarwal,Microsoft
NIPS,2016,Efficient Second Order Online Learning by Sketching,Nicolò Cesa-Bianchi,"Università degli Studi di Milano, Italy"
NIPS,2016,Efficient Second Order Online Learning by Sketching,John Langford,Microsoft Research New York
NIPS,2016,Gaussian Processes for Survival Analysis,Tamara Fernandez,Oxford
NIPS,2016,Gaussian Processes for Survival Analysis,Nicolás Rivera,King's College London
NIPS,2016,Gaussian Processes for Survival Analysis,Yee Whye Teh,"University of Oxford, DeepMind"
NIPS,2016,The Power of Optimization from Samples,Eric Balkanski,Harvard University
NIPS,2016,The Power of Optimization from Samples,Aviad Rubinstein,UC Berkeley
NIPS,2016,The Power of Optimization from Samples,Yaron Singer,Harvard University
NIPS,2016,Global Optimality of Local Search for Low Rank Matrix Recovery,Srinadh Bhojanapalli,TTI Chicago
NIPS,2016,Global Optimality of Local Search for Low Rank Matrix Recovery,Behnam Neyshabur,TTI-Chicago
NIPS,2016,Global Optimality of Local Search for Low Rank Matrix Recovery,Nati Srebro,TTI-Chicago
NIPS,2016,A state-space model of cross-region dynamic connectivity in MEG/EEG,Ying Yang,Carnegie Mellon University
NIPS,2016,A state-space model of cross-region dynamic connectivity in MEG/EEG,Elissa Aminoff,Carnegie Mellon University
NIPS,2016,A state-space model of cross-region dynamic connectivity in MEG/EEG,Michael Tarr,Carnegie Mellon University
NIPS,2016,A state-space model of cross-region dynamic connectivity in MEG/EEG,Rob E Robert,Carnegie Mellon University
NIPS,2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Hao Zhou,University of Wisconsin Madiso
NIPS,2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Vamsi K Ithapu,University of Wisconsin Madison
NIPS,2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Sathya Narayanan Ravi,University of Wisconsin Madiso
NIPS,2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Vikas Singh,UW Madison
NIPS,2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Grace Wahba,University of Wisconsin Madison
NIPS,2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Sterling C Johnson,University of Wisconsin Madison
NIPS,2016,Bi-Objective Online Matching and Submodular  Allocations,Hossein Esfandiari,University of Maryland
NIPS,2016,Bi-Objective Online Matching and Submodular  Allocations,Nitish Korula,Google Research
NIPS,2016,Bi-Objective Online Matching and Submodular  Allocations,Vahab Mirrokni,Google
NIPS,2016,A Constant-Factor Bi-Criteria Approximation Guarantee for k-means++,Dennis Wei,IBM Research
NIPS,2016,Causal Bandits: Learning Good Interventions via Causal Inference,Finnian Lattimore,Australian National University
NIPS,2016,Causal Bandits: Learning Good Interventions via Causal Inference,Tor Lattimore,DeepMind
NIPS,2016,Causal Bandits: Learning Good Interventions via Causal Inference,Mark Reid,Apple
NIPS,2016,Unsupervised Domain Adaptation with Residual Transfer Networks,Mingsheng Long,Tsinghua University
NIPS,2016,Unsupervised Domain Adaptation with Residual Transfer Networks,Han Zhu,Tsinghua University
NIPS,2016,Unsupervised Domain Adaptation with Residual Transfer Networks,Jianmin Wang,Tsinghua University
NIPS,2016,Unsupervised Domain Adaptation with Residual Transfer Networks,Michael Jordan,UC Berkeley
NIPS,2016,Data driven estimation of Laplace-Beltrami operator,Frederic Chazal,INRIA
NIPS,2016,Data driven estimation of Laplace-Beltrami operator,Ilaria Giulini,INRIA and Paris Diderot
NIPS,2016,Data driven estimation of Laplace-Beltrami operator,Bertrand Michel,UPMC
NIPS,2016,Fast Algorithms for Robust PCA via Gradient Descent,Xinyang Yi,UT Austin
NIPS,2016,Fast Algorithms for Robust PCA via Gradient Descent,Dohyung Park,University of Texas at Austin
NIPS,2016,Fast Algorithms for Robust PCA via Gradient Descent,Yudong Chen,Cornell University
NIPS,2016,Fast Algorithms for Robust PCA via Gradient Descent,Constantine Caramanis,UT Austin
NIPS,2016,NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization,Davood Hajinezhad,Iowa State University
NIPS,2016,NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization,Mingyi Hong,iowa state university
NIPS,2016,NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization,Tuo Zhao,Johns Hopkins University
NIPS,2016,NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization,Zhaoran Wang,Princeton University
NIPS,2016,Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing,Farshad Lahouti,Caltech
NIPS,2016,Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing,Babak Hassibi,Caltech
NIPS,2016,Supervised Learning with Tensor Networks,Miles Stoudenmire,Univ of California Irvine
NIPS,2016,Supervised Learning with Tensor Networks,David Schwab,Northwestern University
NIPS,2016,Understanding Probabilistic Sparse Gaussian Process Approximations,Matthias Bauer,University of Cambridge
NIPS,2016,Understanding Probabilistic Sparse Gaussian Process Approximations,Mark van der Wilk,University of Cambridge
NIPS,2016,Understanding Probabilistic Sparse Gaussian Process Approximations,Carl Edward Rasmussen,University of Cambridge
NIPS,2016,A Locally Adaptive Normal Distribution,Georgios Arvanitidis,DTU
NIPS,2016,A Locally Adaptive Normal Distribution,Lars K Hansen,Technical University of Denmark
NIPS,2016,A Locally Adaptive Normal Distribution,Søren Hauberg,Technical University of Denmark
NIPS,2016,Anchor-Free Correlated Topic Modeling: Identifiability and Algorithm,Kejun Huang,University of Minnesota
NIPS,2016,Anchor-Free Correlated Topic Modeling: Identifiability and Algorithm,Xiao Fu,University of Minnesota
NIPS,2016,Anchor-Free Correlated Topic Modeling: Identifiability and Algorithm,Nikos D. Sidiropoulos,University of Minnesota
NIPS,2016,Optimal Learning for Multi-pass Stochastic Gradient Methods,Junhong Lin,Istituto Italiano di Tecnologia
NIPS,2016,Optimal Learning for Multi-pass Stochastic Gradient Methods,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2016,Contextual semibandits via supervised learning oracles,Akshay Krishnamurthy,UMass Amherst
NIPS,2016,Contextual semibandits via supervised learning oracles,Alekh Agarwal,Microsoft
NIPS,2016,Contextual semibandits via supervised learning oracles,Miro Dudik,Microsoft Research
NIPS,2016,One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities,Michalis Titsias,Athens University of Economics and Business
NIPS,2016,Satisfying Real-world Goals with Dataset Constraints,Gabe Goh,UC Davis
NIPS,2016,Satisfying Real-world Goals with Dataset Constraints,Andy Cotter,Google
NIPS,2016,Satisfying Real-world Goals with Dataset Constraints,Maya Gupta,Google
NIPS,2016,Satisfying Real-world Goals with Dataset Constraints,Michael P Friedlander,UC Davis
NIPS,2016,Blind Regression: Nonparametric Regression for Latent Variable Models via Collaborative Filtering,Dogyoon Song,MIT
NIPS,2016,Blind Regression: Nonparametric Regression for Latent Variable Models via Collaborative Filtering,Christina Lee,MIT
NIPS,2016,Blind Regression: Nonparametric Regression for Latent Variable Models via Collaborative Filtering,Yihua Li,MIT
NIPS,2016,Blind Regression: Nonparametric Regression for Latent Variable Models via Collaborative Filtering,Devavrat Shah,Massachusetts Institute of Technology
NIPS,2016,Generative Adversarial Imitation Learning,Jonathan Ho,Stanford
NIPS,2016,Generative Adversarial Imitation Learning,Stefano Ermon,Stanford
NIPS,2016,Fast Active Set Methods for Online Spike Inference from Calcium Imaging,Johannes Friedrich,Columbia University
NIPS,2016,Fast Active Set Methods for Online Spike Inference from Calcium Imaging,Liam Paninski,Columbia University
NIPS,2016,Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations,Behnam Neyshabur,TTI-Chicago
NIPS,2016,Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations,Yuhuai Wu,University of Toronto
NIPS,2016,Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations,Russ Salakhutdinov,University of Toronto
NIPS,2016,Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations,Nati Srebro,TTI-Chicago
NIPS,2016,Improved Regret Bounds for Oracle-Based Adversarial Contextual Bandits,Vasilis Syrgkanis,Microsoft Research
NIPS,2016,Improved Regret Bounds for Oracle-Based Adversarial Contextual Bandits,Haipeng Luo,Princeton University
NIPS,2016,Improved Regret Bounds for Oracle-Based Adversarial Contextual Bandits,Akshay Krishnamurthy,UMass Amherst
NIPS,2016,Improved Regret Bounds for Oracle-Based Adversarial Contextual Bandits,Robert Schapire,MIcrosoft Research
NIPS,2016,Diffusion-Convolutional Neural Networks,James Atwood,UMass Amherst
NIPS,2016,Diffusion-Convolutional Neural Networks,Don Towsley,UMass Amherst
NIPS,2016,Faster Projection-free Convex Optimization over the Spectrahedron,Dan Garber,Toyota Technological Institute at Chicago
NIPS,2016,Faster Projection-free Convex Optimization over the Spectrahedron,Dan Garber,Toyota Technological Institute at Chicago
NIPS,2016,Structured Matrix Recovery via the Generalized Dantzig Selector,Sheng Chen,University of Minnesota
NIPS,2016,Structured Matrix Recovery via the Generalized Dantzig Selector,Arindam Banerjee,Voleon
NIPS,2016,Convex Two-Layer Modeling with Latent Structure,Vignesh Ganapathiraman,University Of Illinois at Chicago
NIPS,2016,Convex Two-Layer Modeling with Latent Structure,Xinhua Zhang,UIC
NIPS,2016,Convex Two-Layer Modeling with Latent Structure,Yaoliang Yu,Carnegie Mellon University
NIPS,2016,Convex Two-Layer Modeling with Latent Structure,Junfeng Wen,UofA
NIPS,2016,Finite-Sample Analysis of Fixed-k Nearest Neighbor Density Functional Estimators,Shashank Singh,Carnegie Mellon University
NIPS,2016,Finite-Sample Analysis of Fixed-k Nearest Neighbor Density Functional Estimators,Barnabas Poczos,Carnegie Mellon University
NIPS,2016,Deep Learning Games,Dale Schuurmans,University of Alberta & Google Brain
NIPS,2016,Deep Learning Games,Martin A Zinkevich,Google
NIPS,2016,“Congruent” and “Opposite” Neurons: Sisters for Multisensory Integration and Segregation,Wen-Hao Zhang,Institute of Neuroscience
NIPS,2016,“Congruent” and “Opposite” Neurons: Sisters for Multisensory Integration and Segregation,He Wang,HKUST
NIPS,2016,“Congruent” and “Opposite” Neurons: Sisters for Multisensory Integration and Segregation,K. Y. Michael Wong,HKUST
NIPS,2016,“Congruent” and “Opposite” Neurons: Sisters for Multisensory Integration and Segregation,Si Wu,Beijing Normal University
NIPS,2016,Statistical Inference for Cluster Trees,Jisu KIM,Carnegie Mellon University
NIPS,2016,Statistical Inference for Cluster Trees,Yen-Chi Chen,Carnegie Mellon University
NIPS,2016,Statistical Inference for Cluster Trees,Sivaraman Balakrishnan,CMU
NIPS,2016,Statistical Inference for Cluster Trees,Alessandro Rinaldo,Carnegie Mellon University
NIPS,2016,Statistical Inference for Cluster Trees,Larry Wasserman,Carnegie Mellon University
NIPS,2016,Minimizing Regret on Reflexive Banach Spaces and Nash Equilibria in Continuous Zero-Sum Games,Maximilian Balandat,UC Berkeley
NIPS,2016,Minimizing Regret on Reflexive Banach Spaces and Nash Equilibria in Continuous Zero-Sum Games,Walid Krichene,UC Berkeley
NIPS,2016,Minimizing Regret on Reflexive Banach Spaces and Nash Equilibria in Continuous Zero-Sum Games,Claire Tomlin,UC Berkeley
NIPS,2016,Minimizing Regret on Reflexive Banach Spaces and Nash Equilibria in Continuous Zero-Sum Games,Alexandre Bayen,UC Berkeley
NIPS,2016,An Online Sequence-to-Sequence Model Using Partial Conditioning,Navdeep Jaitly,Google Brain
NIPS,2016,An Online Sequence-to-Sequence Model Using Partial Conditioning,Quoc V Le,Google
NIPS,2016,An Online Sequence-to-Sequence Model Using Partial Conditioning,Oriol Vinyals,Google DeepMind
NIPS,2016,An Online Sequence-to-Sequence Model Using Partial Conditioning,Ilya Sutskever,Google
NIPS,2016,An Online Sequence-to-Sequence Model Using Partial Conditioning,David Sussillo,Google
NIPS,2016,An Online Sequence-to-Sequence Model Using Partial Conditioning,Samy Bengio,Google Brain
NIPS,2016,Feature selection in functional data classification with recursive maxima hunting,José L. Torrecilla,Universidad Autónoma de Madrid
NIPS,2016,Feature selection in functional data classification with recursive maxima hunting,Alberto Suárez,Universidad Autónoma de Madrid
NIPS,2016,Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/\epsilon)$,Yi Xu,The University of Iowa
NIPS,2016,Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/\epsilon)$,Yan Yan,University of Technology Sydney
NIPS,2016,Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/\epsilon)$,Qihang Lin,University of Iowa
NIPS,2016,Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/\epsilon)$,Tianbao Yang,University of Iowa
NIPS,2016,Nested Mini-Batch K-Means,James Newling,Idiap Research Institute
NIPS,2016,Nested Mini-Batch K-Means,François Fleuret,Idiap Research Institute
NIPS,2016,Density Estimation via Discrepancy Based Adaptive Sequential Partition,Dangna Li,Stanford university
NIPS,2016,Density Estimation via Discrepancy Based Adaptive Sequential Partition,Kun Yang,Google Inc
NIPS,2016,Density Estimation via Discrepancy Based Adaptive Sequential Partition,Wing Hung Wong,Stanford university
NIPS,2016,Budgeted stream-based active learning via adaptive submodular maximization,Kaito Fujii,Kyoto University
NIPS,2016,Budgeted stream-based active learning via adaptive submodular maximization,Hisashi Kashima,Kyoto University
NIPS,2016,Lifelong Learning with Weighted Majority Votes,Anastasia Pentina,IST Austria
NIPS,2016,Lifelong Learning with Weighted Majority Votes,Ruth Urner,MPI Tuebingen
NIPS,2016,How Deep is the Feature Analysis underlying Rapid Visual Categorization?,Sven2 Eberhardt,Brown University
NIPS,2016,How Deep is the Feature Analysis underlying Rapid Visual Categorization?,Jonah G Cader,Brown University
NIPS,2016,How Deep is the Feature Analysis underlying Rapid Visual Categorization?,Thomas Serre,Brown University
NIPS,2016,Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition,Shizhong Han,University of South Carolina
NIPS,2016,Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition,Zibo Meng,University of South Carolina
NIPS,2016,Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition,AHMED-SHEHAB KHAN,University of South Carolina
NIPS,2016,Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition,Yan Tong,University of South Carolina
NIPS,2016,Multivariate tests of association based on univariate tests,Ruth Heller,Tel-Aviv University
NIPS,2016,Multivariate tests of association based on univariate tests,Yair Heller,Independent
NIPS,2016,SURGE: Surface Regularized Geometry Estimation from a Single Image,Peng Wang,UCLA
NIPS,2016,SURGE: Surface Regularized Geometry Estimation from a Single Image,Xiaohui Shen,Adobe Research
NIPS,2016,SURGE: Surface Regularized Geometry Estimation from a Single Image,Bryan Russell,Adobe
NIPS,2016,SURGE: Surface Regularized Geometry Estimation from a Single Image,Scott Cohen,Adobe Research
NIPS,2016,SURGE: Surface Regularized Geometry Estimation from a Single Image,Brian Price,
NIPS,2016,SURGE: Surface Regularized Geometry Estimation from a Single Image,Alan L Yuille,UCLA
NIPS,2016,Memory-Efficient Backpropagation Through Time,Audrunas Gruslys,Google DeepMind
NIPS,2016,Memory-Efficient Backpropagation Through Time,Remi Munos,Google DeepMind
NIPS,2016,Memory-Efficient Backpropagation Through Time,Ivo Danihelka,DeepMind
NIPS,2016,Memory-Efficient Backpropagation Through Time,Marc Lanctot,Google DeepMind
NIPS,2016,Memory-Efficient Backpropagation Through Time,Alex Graves,Google DeepMind
NIPS,2016,Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much,Bryan He,Stanford University
NIPS,2016,Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much,Christopher M De Sa,Stanford University
NIPS,2016,Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much,Ioannis Mitliagkas,Stanford
NIPS,2016,Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much,Christopher Ré,Stanford University
NIPS,2016,LightRNN: Memory and Computation-Efficient Recurrent Neural Networks,Xiang Li,NJUST
NIPS,2016,LightRNN: Memory and Computation-Efficient Recurrent Neural Networks,Tao Qin,Microsoft
NIPS,2016,LightRNN: Memory and Computation-Efficient Recurrent Neural Networks,Jian Yang,Facebook Inc.
NIPS,2016,LightRNN: Memory and Computation-Efficient Recurrent Neural Networks,Xiaolin Hu,Tsinghua University
NIPS,2016,LightRNN: Memory and Computation-Efficient Recurrent Neural Networks,Tie-Yan Liu,Microsoft Research
NIPS,2016,Direct Feedback Alignment Provides Learning in Deep Neural Networks,Arild Nøkland,None
NIPS,2016,Variational Bayes on Monte Carlo Steroids,Aditya Grover,Stanford University
NIPS,2016,Variational Bayes on Monte Carlo Steroids,Stefano Ermon,Stanford
NIPS,2016,Agnostic Estimation for Misspecified Phase Retrieval Models,Matey Neykov,Princeton University
NIPS,2016,Agnostic Estimation for Misspecified Phase Retrieval Models,Zhaoran Wang,Princeton University
NIPS,2016,Agnostic Estimation for Misspecified Phase Retrieval Models,Han Liu,Tencent AI Lab
NIPS,2016,Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities,Ruitong Huang,University of Alberta
NIPS,2016,Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities,Tor Lattimore,DeepMind
NIPS,2016,Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities,András György,DeepMind
NIPS,2016,Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities,Csaba Szepesvari,U. Alberta
NIPS,2016,Combining Fully Convolutional and Recurrent Neural Networks for 3D Biomedical Image Segmentation,Jianxu Chen,University of Notre Dame
NIPS,2016,Combining Fully Convolutional and Recurrent Neural Networks for 3D Biomedical Image Segmentation,Lin Yang,University of Notre Dame
NIPS,2016,Combining Fully Convolutional and Recurrent Neural Networks for 3D Biomedical Image Segmentation,Yizhe Zhang,Duke university
NIPS,2016,Combining Fully Convolutional and Recurrent Neural Networks for 3D Biomedical Image Segmentation,Mark Alber,University of Notre Dame
NIPS,2016,Combining Fully Convolutional and Recurrent Neural Networks for 3D Biomedical Image Segmentation,Danny Z Chen,University of Notre Dame
NIPS,2016,The Product Cut,Thomas Laurent,Loyola Marymount University
NIPS,2016,The Product Cut,James von Brecht,CSULB
NIPS,2016,The Product Cut,Xavier Bresson,EPFL
NIPS,2016,The Product Cut,arthur szlam,Facebook
NIPS,2016,Stochastic Gradient Methods for Distributionally Robust Optimization with f-divergences,Hong Namkoong,Stanford University
NIPS,2016,Stochastic Gradient Methods for Distributionally Robust Optimization with f-divergences,John Duchi,Stanford
NIPS,2016,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,Tolga Bolukbasi,Boston University
NIPS,2016,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,Kai-Wei Chang,UCLA
NIPS,2016,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,James Y Zou,Microsoft Research
NIPS,2016,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,Venkatesh Saligrama,Boston University
NIPS,2016,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,Adam T Kalai,Microsoft Research
NIPS,2016,Optimal spectral transportation with application to music transcription,Rémi Flamary,Université Côte d'Azur
NIPS,2016,Optimal spectral transportation with application to music transcription,Cédric Févotte,CNRS
NIPS,2016,Optimal spectral transportation with application to music transcription,Nicolas Courty,IRISA / University South Brittany
NIPS,2016,Optimal spectral transportation with application to music transcription,Valentin Emiya,Aix-Marseille University
NIPS,2016,Combining Adversarial Guarantees and Stochastic Fast Rates in Online Learning,Wouter Koolen,"Centrum Wiskunde & Informatica, Amsterdam"
NIPS,2016,Combining Adversarial Guarantees and Stochastic Fast Rates in Online Learning,Peter Grünwald,CWI
NIPS,2016,Combining Adversarial Guarantees and Stochastic Fast Rates in Online Learning,Tim van Erven,Leiden University
NIPS,2016,Towards Conceptual Compression,Karol Gregor,Google DeepMind
NIPS,2016,Towards Conceptual Compression,Frederic Besse,Google DeepMind
NIPS,2016,Towards Conceptual Compression,Danilo Jimenez Rezende,Google DeepMind
NIPS,2016,Towards Conceptual Compression,Ivo Danihelka,DeepMind
NIPS,2016,Towards Conceptual Compression,Daan Wierstra,Google DeepMind
NIPS,2016,Can Peripheral Representations Improve Clutter Metrics on Complex Scenes?,Arturo Deza,UCSB
NIPS,2016,Can Peripheral Representations Improve Clutter Metrics on Complex Scenes?,Miguel Eckstein,UCSB
NIPS,2016,GAP Safe Screening Rules for Sparse-Group Lasso,Eugene Ndiaye,Télécom ParisTech
NIPS,2016,GAP Safe Screening Rules for Sparse-Group Lasso,Olivier Fercoq,Telecom ParisTech
NIPS,2016,GAP Safe Screening Rules for Sparse-Group Lasso,Alexandre Gramfort,"INRIA, Université Paris-Saclay"
NIPS,2016,GAP Safe Screening Rules for Sparse-Group Lasso,Joseph Salmon,Télécom ParisTech
NIPS,2016,Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables,Mauro Scanagatta,Idsia
NIPS,2016,Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables,Giorgio Corani,Idsia
NIPS,2016,Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables,Cassio P de Campos,Queen's University Belfast
NIPS,2016,Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables,Marco Zaffalon,IDSIA
NIPS,2016,Ancestral Causal Inference,Sara Magliacane,VU University Amsterdam
NIPS,2016,Ancestral Causal Inference,Tom Claassen,Radboud University Nijmegen
NIPS,2016,Ancestral Causal Inference,Joris M Mooij,Radboud University Nijmegen
NIPS,2016,Visual Question Answering with Question Representation Update (QRU),Ruiyu Li,CUHK
NIPS,2016,Visual Question Answering with Question Representation Update (QRU),Jiaya Jia,CUHK
NIPS,2016,Identification and Overidentification of Linear Structural Equation Models,Bryant Chen,UCLA
NIPS,2016,On Valid Optimal Assignment Kernels and Applications to Graph Classification,Nils M. Kriege,TU Dortmund
NIPS,2016,On Valid Optimal Assignment Kernels and Applications to Graph Classification,Pierre-Louis Giscard,University of York
NIPS,2016,On Valid Optimal Assignment Kernels and Applications to Graph Classification,Richard Wilson,University of York
NIPS,2016,Constraints Based Convex Belief Propagation,Yaniv Tenzer,The Hebrew University
NIPS,2016,Constraints Based Convex Belief Propagation,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2016,Constraints Based Convex Belief Propagation,Kevin Gimpel,Carnegie Mellon University
NIPS,2016,Constraints Based Convex Belief Propagation,Tamir Hazan,Technion
NIPS,2016,Combinatorial Energy Learning for Image Segmentation,Jeremy Maitin-Shepard,Google
NIPS,2016,Combinatorial Energy Learning for Image Segmentation,Viren Jain,Google
NIPS,2016,Combinatorial Energy Learning for Image Segmentation,Michal Januszewski,Google
NIPS,2016,Combinatorial Energy Learning for Image Segmentation,Peter Li,Google
NIPS,2016,Combinatorial Energy Learning for Image Segmentation,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,A scalable end-to-end Gaussian process adapter for irregularly sampled time series classification,Steve Li,UMass Amherst
NIPS,2016,A scalable end-to-end Gaussian process adapter for irregularly sampled time series classification,Benjamin M Marlin,University of Massachusetts Amherst
NIPS,2016,Stochastic Variance Reduction Methods for Saddle-Point Problems,Balamurugan Palaniappan,INRIA
NIPS,2016,Stochastic Variance Reduction Methods for Saddle-Point Problems,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2016,Dimensionality Reduction of Massive Sparse Datasets Using Coresets,Dan Feldman,University of Haifa
NIPS,2016,Dimensionality Reduction of Massive Sparse Datasets Using Coresets,Mikhail Volkov,MIT
NIPS,2016,Dimensionality Reduction of Massive Sparse Datasets Using Coresets,Daniela Rus,MIT
NIPS,2016,"Efficient state-space modularization for planning: theory, behavioral and neural signatures",Daniel McNamee,University of Cambridge
NIPS,2016,"Efficient state-space modularization for planning: theory, behavioral and neural signatures",Daniel M Wolpert,University of Cambridge
NIPS,2016,"Efficient state-space modularization for planning: theory, behavioral and neural signatures",Mate Lengyel,University of Cambridge
NIPS,2016,Adaptive Newton Method for Empirical Risk Minimization to Statistical Accuracy,Aryan Mokhtari,University of Pennsylvania
NIPS,2016,Adaptive Newton Method for Empirical Risk Minimization to Statistical Accuracy,Hadi Daneshmand,ETH Zurich
NIPS,2016,Adaptive Newton Method for Empirical Risk Minimization to Statistical Accuracy,Aurelien Lucchi,ETH Zurich
NIPS,2016,Adaptive Newton Method for Empirical Risk Minimization to Statistical Accuracy,Thomas Hofmann,ETH Zurich
NIPS,2016,Adaptive Newton Method for Empirical Risk Minimization to Statistical Accuracy,Alejandro Ribeiro,University of Pennsylvania
NIPS,2016,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,Edward Choi,Georgia Institute of Technolog
NIPS,2016,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,Taha Bahadori,Gatech
NIPS,2016,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,Joshua Kulas,Georgia Institute of Technology
NIPS,2016,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,Jimeng Sun,Georgia Tech
NIPS,2016,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,Andy Schuetz,Sutter Health
NIPS,2016,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,Walter Stewart,Sutter Health
NIPS,2016,Joint quantile regression in vector-valued RKHSs,Maxime Sangnier,LTCI
NIPS,2016,Joint quantile regression in vector-valued RKHSs,Olivier Fercoq,Telecom ParisTech
NIPS,2016,Joint quantile regression in vector-valued RKHSs,Florence d'Alché-Buc,"LTCI,Télécom ParisTech, University of Paris-Saclay"
NIPS,2016,Learnable Visual Markers,Oleg Grinchuk,Skolkovo Institute of Science and Technology
NIPS,2016,Learnable Visual Markers,Vadim Lebedev,Skolkovo Institute of Science and Technology
NIPS,2016,Learnable Visual Markers,Victor Lempitsky,Samsung
NIPS,2016,Exponential expressivity in deep neural networks through transient chaos,Ben Poole,Stanford University
NIPS,2016,Exponential expressivity in deep neural networks through transient chaos,Subhaneil Lahiri,Stanford University
NIPS,2016,Exponential expressivity in deep neural networks through transient chaos,Maithra Raghu,Cornell University
NIPS,2016,Exponential expressivity in deep neural networks through transient chaos,Jascha Sohl-Dickstein,Google Brain
NIPS,2016,Exponential expressivity in deep neural networks through transient chaos,Surya Ganguli,Stanford
NIPS,2016,On Multiplicative Integration with Recurrent Neural Networks,Yuhuai Wu,University of Toronto
NIPS,2016,On Multiplicative Integration with Recurrent Neural Networks,Saizheng Zhang,University of Montreal
NIPS,2016,On Multiplicative Integration with Recurrent Neural Networks,Ying Zhang,University of Montreal
NIPS,2016,On Multiplicative Integration with Recurrent Neural Networks,Yoshua Bengio,U. Montreal
NIPS,2016,On Multiplicative Integration with Recurrent Neural Networks,Russ Salakhutdinov,University of Toronto
NIPS,2016,Interpretable Nonlinear Dynamic Modeling of Neural Trajectories,Yuan Zhao,Stony Brook University
NIPS,2016,Interpretable Nonlinear Dynamic Modeling of Neural Trajectories,Memming Park,Stony Brook University
NIPS,2016,Globally Optimal Training of Generalized Polynomial Neural Networks with Nonlinear Spectral Methods,Antoine Gautier,Saarland University
NIPS,2016,Globally Optimal Training of Generalized Polynomial Neural Networks with Nonlinear Spectral Methods,Quynh N Nguyen,Saarland University
NIPS,2016,Globally Optimal Training of Generalized Polynomial Neural Networks with Nonlinear Spectral Methods,Matthias Hein,Saarland University
NIPS,2016,Linear Feature Encoding for Reinforcement Learning,Zhao Song,Duke University
NIPS,2016,Linear Feature Encoding for Reinforcement Learning,Ron Parr,Duke University
NIPS,2016,Linear Feature Encoding for Reinforcement Learning,Xuejun Liao,Duke University
NIPS,2016,Linear Feature Encoding for Reinforcement Learning,Lawrence Carin,Duke University
NIPS,2016,Graphical Time Warping for Joint Alignment of Multiple Curves,Yizhi Wang,Virginia Tech
NIPS,2016,Graphical Time Warping for Joint Alignment of Multiple Curves,David J Miller,The Pennsylvania State University
NIPS,2016,Graphical Time Warping for Joint Alignment of Multiple Curves,Kira Poskanzer,University of California
NIPS,2016,Graphical Time Warping for Joint Alignment of Multiple Curves,Yue Wang,Virginia Tech
NIPS,2016,Graphical Time Warping for Joint Alignment of Multiple Curves,Lin Tian,The University of California
NIPS,2016,Graphical Time Warping for Joint Alignment of Multiple Curves,Guoqiang Yu,Virginia Tech
NIPS,2016,Mixed Linear Regression with Multiple Components,Kai Zhong,UT AUSTIN
NIPS,2016,Mixed Linear Regression with Multiple Components,Prateek Jain,Microsoft Research
NIPS,2016,Mixed Linear Regression with Multiple Components,Inderjit S Dhillon,University of Texas at Austin
NIPS,2016,Statistical Inference for Pairwise Graphical Models Using Score Matching,Ming Yu,The University of Chicago
NIPS,2016,Statistical Inference for Pairwise Graphical Models Using Score Matching,Mladen Kolar,University of Chicago
NIPS,2016,Statistical Inference for Pairwise Graphical Models Using Score Matching,Varun Gupta,University of Chicago
NIPS,2016,Hardness of Online Sleeping Combinatorial Optimization Problems,Satyen Kale,Google
NIPS,2016,Hardness of Online Sleeping Combinatorial Optimization Problems,Chansoo Lee,University of Michigan
NIPS,2016,Hardness of Online Sleeping Combinatorial Optimization Problems,David Pal,Google
NIPS,2016,An algorithm for L1 nearest neighbor search via monotonic embedding,Xinan Wang,UCSD
NIPS,2016,An algorithm for L1 nearest neighbor search via monotonic embedding,Sanjoy Dasgupta,UC San Diego
NIPS,2016,Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences,Chi Jin,UC Berkeley
NIPS,2016,Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences,Yuchen Zhang,UC Berkeley
NIPS,2016,Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences,Sivaraman Balakrishnan,CMU
NIPS,2016,Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences,Martin J Wainwright,UC Berkeley
NIPS,2016,Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences,Michael Jordan,UC Berkeley
NIPS,2016,Learning User Perceived Clusters with Feature-Level Supervision,Ting-Yu Cheng,
NIPS,2016,Learning User Perceived Clusters with Feature-Level Supervision,Guiguan Lin,Appier
NIPS,2016,Learning User Perceived Clusters with Feature-Level Supervision,xinyang gong,NTHU
NIPS,2016,Learning User Perceived Clusters with Feature-Level Supervision,Kang-Jun Liu,National Tsing Hua University
NIPS,2016,Learning User Perceived Clusters with Feature-Level Supervision,Shan-Hung Wu,National Tsing Hua University
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Xi Chen,Columbia University
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Peter Chen,UC Berkeley and OpenAI
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Yan Duan,UC Berkeley
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Rein Houthooft,Ghent University - iMinds and UC Berkeley and OpenAI
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,John Schulman,OpenAI
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Ilya Sutskever,Google
NIPS,2016,InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,Neural Universal Discrete Denoiser,Taesup Moon,DGIST
NIPS,2016,Neural Universal Discrete Denoiser,Seonwoo Min,Seoul National University
NIPS,2016,Neural Universal Discrete Denoiser,Byunghan Lee,Seoul National University
NIPS,2016,Neural Universal Discrete Denoiser,Sungroh Yoon,Seoul National University
NIPS,2016,A primal-dual method for conic constrained distributed optimization problems,Necdet Serhat Aybat,Penn State University
NIPS,2016,A primal-dual method for conic constrained distributed optimization problems,Erfan Yazdandoost Hamedani,Penn State University
NIPS,2016,Simple and Efficient Weighted Minwise Hashing,ANSHUMALI Shrivastava,Rice University
NIPS,2016,Eliciting Categorical Data for Optimal Aggregation,Chien-Ju Ho,Cornell University
NIPS,2016,Eliciting Categorical Data for Optimal Aggregation,Rafael Frongillo,CU Boulder
NIPS,2016,Eliciting Categorical Data for Optimal Aggregation,Yiling Chen,Harvard University
NIPS,2016,Depth from a Single Image by Harmonizing Overcomplete Local Network Predictions,Ayan Chakrabarti,TTI Chicago
NIPS,2016,Depth from a Single Image by Harmonizing Overcomplete Local Network Predictions,Jingyu Shao,UCLA
NIPS,2016,Depth from a Single Image by Harmonizing Overcomplete Local Network Predictions,Greg Shakhnarovich,TTI-Chicago
NIPS,2016,SEBOOST - Boosting Stochastic Learning Using Subspace Optimization Techniques,Elad Richardson,Technion
NIPS,2016,SEBOOST - Boosting Stochastic Learning Using Subspace Optimization Techniques,Rom Herskovitz,Technion - Israel Institute of Technology
NIPS,2016,SEBOOST - Boosting Stochastic Learning Using Subspace Optimization Techniques,Boris Ginsburg,NVIDIA
NIPS,2016,SEBOOST - Boosting Stochastic Learning Using Subspace Optimization Techniques,Michael Zibulevsky,Technion - Israel Institute of Technology
NIPS,2016,Reshaped Wirtinger Flow for Solving Quadratic System of Equations,Huishuai Zhang,Syracuse University
NIPS,2016,Reshaped Wirtinger Flow for Solving Quadratic System of Equations,Yingbin Liang,Syracuse University
NIPS,2016,Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images,Junhua Mao,UCLA
NIPS,2016,Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images,Jiajing Xu,Pinterest
NIPS,2016,Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images,Kevin Jing,Pinterest
NIPS,2016,Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images,Alan L Yuille,UCLA
NIPS,2016,Online ICA: Understanding Global Dynamics of Nonconvex Optimization via Diffusion Processes,Chris Junchi Li,Princeton University
NIPS,2016,Online ICA: Understanding Global Dynamics of Nonconvex Optimization via Diffusion Processes,Zhaoran Wang,Princeton University
NIPS,2016,Online ICA: Understanding Global Dynamics of Nonconvex Optimization via Diffusion Processes,Han Liu,Tencent AI Lab
NIPS,2016,VIME: Variational Information Maximizing Exploration,Rein Houthooft,Ghent University - iMinds and UC Berkeley and OpenAI
NIPS,2016,VIME: Variational Information Maximizing Exploration,Xi Chen,Columbia University
NIPS,2016,VIME: Variational Information Maximizing Exploration,Peter Chen,UC Berkeley and OpenAI
NIPS,2016,VIME: Variational Information Maximizing Exploration,Yan Duan,UC Berkeley
NIPS,2016,VIME: Variational Information Maximizing Exploration,John Schulman,OpenAI
NIPS,2016,VIME: Variational Information Maximizing Exploration,Filip De Turck,Ghent University - iMinds
NIPS,2016,VIME: Variational Information Maximizing Exploration,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,Deconvolving Feedback Loops in Recommender Systems,Ayan Sinha,Purdue
NIPS,2016,Deconvolving Feedback Loops in Recommender Systems,David Gleich,Purdue University
NIPS,2016,Deconvolving Feedback Loops in Recommender Systems,Karthik Ramani,Purdue University
NIPS,2016,A Non-parametric Learning Method for Confidently Estimating Patient's Clinical State and Dynamics,William Hoiles,University of California
NIPS,2016,A Non-parametric Learning Method for Confidently Estimating Patient's Clinical State and Dynamics,Mihaela Van Der Schaar,"University of California, Los Angeles"
NIPS,2016,Semiparametric Differential Graph Models,Pan Xu,University of Virginia
NIPS,2016,Semiparametric Differential Graph Models,Quanquan Gu,University of Virginia
NIPS,2016,A Non-convex One-Pass Framework for Generalized Factorization Machine and Rank-One Matrix Sensing,Ming Lin,University of Michigan
NIPS,2016,A Non-convex One-Pass Framework for Generalized Factorization Machine and Rank-One Matrix Sensing,Jieping Ye,University of Michigan
NIPS,2016,Sublinear Time Orthogonal Tensor Decomposition,Zhao Song,Duke University
NIPS,2016,Sublinear Time Orthogonal Tensor Decomposition,David Woodruff,IBM Research
NIPS,2016,Sublinear Time Orthogonal Tensor Decomposition,Huan Zhang,UC-Davis
NIPS,2016,Achieving budget-optimality with adaptive schemes in crowdsourcing,Ashish Khetan,University of Illinois Urbana-
NIPS,2016,Achieving budget-optimality with adaptive schemes in crowdsourcing,Sewoong Oh,UIUC
NIPS,2016,Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition,Theodore Bluche,A2iA
NIPS,2016,Human Decision-Making under Limited Time,Pedro Ortega,DeepMind
NIPS,2016,Human Decision-Making under Limited Time,Alan A Stocker,University of Pennsylvania
NIPS,2016,Joint M-Best-Diverse Labelings as a Parametric Submodular Minimization,Alexander Kirillov,TU Dresden
NIPS,2016,Joint M-Best-Diverse Labelings as a Parametric Submodular Minimization,Sasha Shekhovtsov,Graz University of Technology
NIPS,2016,Joint M-Best-Diverse Labelings as a Parametric Submodular Minimization,Carsten Rother,TU Dresden
NIPS,2016,Joint M-Best-Diverse Labelings as a Parametric Submodular Minimization,Bogdan Savchynskyy,TU Dresden
NIPS,2016,Even Faster SVD Decomposition Yet Without Agonizing Pain,Zeyuan Allen-Zhu,Princeton University
NIPS,2016,Even Faster SVD Decomposition Yet Without Agonizing Pain,Yuanzhi Li,Princeton University
NIPS,2016,Fast and accurate spike sorting of high-channel count probes with KiloSort,Marius Pachitariu,"Gatsby Unit, UCL"
NIPS,2016,Fast and accurate spike sorting of high-channel count probes with KiloSort,Nicholas A Steinmetz,UCL
NIPS,2016,Fast and accurate spike sorting of high-channel count probes with KiloSort,Shabnam N Kadir,University College London
NIPS,2016,Fast and accurate spike sorting of high-channel count probes with KiloSort,Matteo Carandini,UCL
NIPS,2016,Fast and accurate spike sorting of high-channel count probes with KiloSort,Daniel D Harris,UCL
NIPS,2016,Batched Gaussian Process Bandit Optimization via Determinantal Point Processes,Tarun Kathuria,Microsoft Research
NIPS,2016,Batched Gaussian Process Bandit Optimization via Determinantal Point Processes,Amit Deshpande,
NIPS,2016,Batched Gaussian Process Bandit Optimization via Determinantal Point Processes,Pushmeet Kohli,Microsoft Research
NIPS,2016,Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles,Stefan Lee,Indiana University
NIPS,2016,Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles,Senthil Purushwalkam Shiva Prakash,Carnegie Mellon
NIPS,2016,Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles,mcogswell Cogswell,Virginia Tech
NIPS,2016,Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles,Viresh Ranjan,Virginia Tech
NIPS,2016,Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles,David Crandall,Indiana University
NIPS,2016,Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles,Dhruv Batra,Georgia Tech / Facebook AI Research (FAIR)
NIPS,2016,Optimal Sparse Linear Encoders and Sparse PCA,Malik Magdon-Ismail,Rensselaer
NIPS,2016,Optimal Sparse Linear Encoders and Sparse PCA,Christos Boutsidis,Yahoo Labs
NIPS,2016,Using Social Dynamics to Make Individual Predictions: Variational Inference with a Stochastic Kinetic Model,Zhen Xu,SUNY at Buffalo
NIPS,2016,Using Social Dynamics to Make Individual Predictions: Variational Inference with a Stochastic Kinetic Model,Wen Dong,University at Buffalo
NIPS,2016,Using Social Dynamics to Make Individual Predictions: Variational Inference with a Stochastic Kinetic Model,Sargur N Srihari,University at Buffalo
NIPS,2016,"Learning Additive Exponential Family Graphical Models via $\ell_{2,1}$-norm Regularized M-Estimation",Xiaotong Yuan,Nanjing University of Informat
NIPS,2016,"Learning Additive Exponential Family Graphical Models via $\ell_{2,1}$-norm Regularized M-Estimation",Ping Li,Rugters University
NIPS,2016,"Learning Additive Exponential Family Graphical Models via $\ell_{2,1}$-norm Regularized M-Estimation",Tong Zhang,Tencent
NIPS,2016,"Learning Additive Exponential Family Graphical Models via $\ell_{2,1}$-norm Regularized M-Estimation",Qingshan Liu,
NIPS,2016,"Learning Additive Exponential Family Graphical Models via $\ell_{2,1}$-norm Regularized M-Estimation",Guangcan Liu,NUIST
NIPS,2016,Residual Networks Behave Like Ensembles of Relatively Shallow Networks,Andreas Veit,Cornell University
NIPS,2016,Residual Networks Behave Like Ensembles of Relatively Shallow Networks,Michael J Wilber,Cornell Tech
NIPS,2016,Residual Networks Behave Like Ensembles of Relatively Shallow Networks,Serge Belongie,Cornell University
NIPS,2016,Full-Capacity Unitary Recurrent Neural Networks,Scott Wisdom,University of Washington
NIPS,2016,Full-Capacity Unitary Recurrent Neural Networks,Thomas Powers,University of Washington
NIPS,2016,Full-Capacity Unitary Recurrent Neural Networks,John Hershey,MERL
NIPS,2016,Full-Capacity Unitary Recurrent Neural Networks,Jonathan Le Roux,Mitsubishi Electric Research Laboratories (MERL)
NIPS,2016,Full-Capacity Unitary Recurrent Neural Networks,Les Atlas,University of Washington
NIPS,2016,Quantum Perceptron Models,Ashish Kapoor,Microsoft Research
NIPS,2016,Quantum Perceptron Models,Nathan Wiebe,Microsoft Research
NIPS,2016,Quantum Perceptron Models,Krysta Svore,Microsoft
NIPS,2016,Mapping Estimation for Discrete Optimal Transport,Michaël Perrot,University of Saint-Etienne
NIPS,2016,Mapping Estimation for Discrete Optimal Transport,Nicolas Courty,IRISA / University South Brittany
NIPS,2016,Mapping Estimation for Discrete Optimal Transport,Rémi Flamary,Université Côte d'Azur
NIPS,2016,Mapping Estimation for Discrete Optimal Transport,Amaury Habrard,University of Saint-Etienne
NIPS,2016,Stochastic Gradient Geodesic MCMC Methods,Chang Liu,Tsinghua University
NIPS,2016,Stochastic Gradient Geodesic MCMC Methods,Jun Zhu,Tsinghua University
NIPS,2016,Stochastic Gradient Geodesic MCMC Methods,Yang Song,Stanford University
NIPS,2016,Variational Information Maximization for Feature Selection,Shuyang Gao,University of Southern California
NIPS,2016,Variational Information Maximization for Feature Selection,Greg Ver Steeg,University of Southern California
NIPS,2016,Variational Information Maximization for Feature Selection,Aram Galstyan,USC Information Sciences Inst
NIPS,2016,A Minimax Approach to Supervised Learning,Farzan Farnia,Stanford University
NIPS,2016,A Minimax Approach to Supervised Learning,David Tse,Stanford University
NIPS,2016,Fast Distributed Submodular Cover: Public-Private Data Summarization,Baharan Mirzasoleiman,ETH Zurich
NIPS,2016,Fast Distributed Submodular Cover: Public-Private Data Summarization,Morteza Zadimoghaddam,Google Research
NIPS,2016,Fast Distributed Submodular Cover: Public-Private Data Summarization,Amin Karbasi,Yale
NIPS,2016,Domain Separation Networks,Konstantinos Bousmalis,Google Brain
NIPS,2016,Domain Separation Networks,George Trigeorgis,Google
NIPS,2016,Domain Separation Networks,Nathan Silberman,Google
NIPS,2016,Domain Separation Networks,Dilip Krishnan,Google
NIPS,2016,Domain Separation Networks,Dumitru Erhan,Google
NIPS,2016,Multimodal Residual Learning for Visual QA,Jin-Hwa Kim,Seoul National University
NIPS,2016,Multimodal Residual Learning for Visual QA,Sang-Woo Lee,Seoul National University
NIPS,2016,Multimodal Residual Learning for Visual QA,Donghyun Kwak,Seoul National University
NIPS,2016,Multimodal Residual Learning for Visual QA,Min-Oh Heo,Seoul National University
NIPS,2016,Multimodal Residual Learning for Visual QA,Jeonghee Kim,Naver Labs
NIPS,2016,Multimodal Residual Learning for Visual QA,Jung-Woo Ha,Naver Labs
NIPS,2016,Multimodal Residual Learning for Visual QA,Byoung-Tak Zhang,Seoul National University
NIPS,2016,Optimizing affinity-based binary hashing using auxiliary coordinates,Ramin Raziperchikolaei,UC Merced
NIPS,2016,Optimizing affinity-based binary hashing using auxiliary coordinates,Miguel A. Carreira-Perpinan,UC Merced
NIPS,2016,Coresets for Scalable Bayesian Logistic Regression,Jonathan Huggins,MIT
NIPS,2016,Coresets for Scalable Bayesian Logistic Regression,Trevor Campbell,MIT
NIPS,2016,Coresets for Scalable Bayesian Logistic Regression,Tamara Broderick,MIT
NIPS,2016,The Parallel Knowledge Gradient Method for Batch Bayesian Optimization,Jian Wu,Cornell University
NIPS,2016,The Parallel Knowledge Gradient Method for Batch Bayesian Optimization,Peter Frazier,Princeton University
NIPS,2016,Learning Multiagent Communication with Backpropagation,Sainaa Sukhbaatar,NYU
NIPS,2016,Learning Multiagent Communication with Backpropagation,arthur szlam,Facebook
NIPS,2016,Learning Multiagent Communication with Backpropagation,Rob Fergus,New York University
NIPS,2016,Optimal Binary Classifier Aggregation for General Losses,Akshay Balsubramani,UC San Diego
NIPS,2016,Optimal Binary Classifier Aggregation for General Losses,Yoav S Freund,"University of California, San Diego"
NIPS,2016,The Generalized Reparameterization Gradient,Francisco Ruiz,Columbia University
NIPS,2016,The Generalized Reparameterization Gradient,Michalis Titsias,Athens University of Economics and Business
NIPS,2016,The Generalized Reparameterization Gradient,David Blei,Columbia University
NIPS,2016,Conditional Generative Moment-Matching Networks,Yong Ren,Tsinghua University
NIPS,2016,Conditional Generative Moment-Matching Networks,Jun Zhu,Tsinghua University
NIPS,2016,Conditional Generative Moment-Matching Networks,Jialian Li,Tsinghua University
NIPS,2016,Conditional Generative Moment-Matching Networks,Yucen Luo,Tsinghua University
NIPS,2016,A Credit Assignment Compiler for Joint Prediction,Kai-Wei Chang,UCLA
NIPS,2016,A Credit Assignment Compiler for Joint Prediction,He He,University of Maryland
NIPS,2016,A Credit Assignment Compiler for Joint Prediction,Stephane Ross,Google
NIPS,2016,A Credit Assignment Compiler for Joint Prediction,Hal Daumé III,Univ of Maryland / Microsoft Research
NIPS,2016,A Credit Assignment Compiler for Joint Prediction,John Langford,Microsoft Research New York
NIPS,2016,Short-Dot: Computing Large Linear Transforms Distributedly Using Coded Short Dot Products,Sanghamitra Dutta,Carnegie Mellon University
NIPS,2016,Short-Dot: Computing Large Linear Transforms Distributedly Using Coded Short Dot Products,Viveck Cadambe,Pennsylvania State University
NIPS,2016,Short-Dot: Computing Large Linear Transforms Distributedly Using Coded Short Dot Products,Pulkit Grover,Carnegie Mellon University
NIPS,2016,Spatio-Temporal Hilbert Maps for Continuous Occupancy Representation in Dynamic Environments,Ransalu Senanayake,The University of Sydney
NIPS,2016,Spatio-Temporal Hilbert Maps for Continuous Occupancy Representation in Dynamic Environments,Lionel Ott,The University of Sydney
NIPS,2016,Spatio-Temporal Hilbert Maps for Continuous Occupancy Representation in Dynamic Environments,Simon O'Callaghan,NICTA
NIPS,2016,Spatio-Temporal Hilbert Maps for Continuous Occupancy Representation in Dynamic Environments,Fabio Ramos,The University of Sydney
NIPS,2016,Learning HMMs with Nonparametric Emissions via Spectral Decompositions of Continuous Matrices,Kirthevasan Kandasamy,CMU
NIPS,2016,Learning HMMs with Nonparametric Emissions via Spectral Decompositions of Continuous Matrices,Maruan Al-Shedivat,CMU
NIPS,2016,Learning HMMs with Nonparametric Emissions via Spectral Decompositions of Continuous Matrices,Eric Xing,Carnegie Mellon University
NIPS,2016,Integrated perception with recurrent multi-task neural networks,Hakan Bilen,University of Oxford
NIPS,2016,Integrated perception with recurrent multi-task neural networks,Andrea Vedaldi,University of Oxford and Facebook
NIPS,2016,Blind Attacks on Machine Learners,Alex Beatson,Princeton University
NIPS,2016,Blind Attacks on Machine Learners,Zhaoran Wang,Princeton University
NIPS,2016,Blind Attacks on Machine Learners,Han Liu,Tencent AI Lab
NIPS,2016,Optimistic Gittins Indices,Eli Gutin,Massachusetts Institute of Tec
NIPS,2016,Optimistic Gittins Indices,Vivek Farias,Massachusetts Institute of Technology
NIPS,2016,Sub-sampled Newton Methods with Non-uniform Sampling,Peng Xu,Stanford University
NIPS,2016,Sub-sampled Newton Methods with Non-uniform Sampling,Jiyan Yang,Stanford University
NIPS,2016,Sub-sampled Newton Methods with Non-uniform Sampling,Farbod Roosta-Khorasani,University of California Berkeley
NIPS,2016,Sub-sampled Newton Methods with Non-uniform Sampling,Chris Ré,Stanford
NIPS,2016,Sub-sampled Newton Methods with Non-uniform Sampling,Michael W Mahoney,UC Berkeley
NIPS,2016,Learned Region Sparsity and Diversity Also Predicts Visual Attention,Zijun Wei,Stony Brook
NIPS,2016,Learned Region Sparsity and Diversity Also Predicts Visual Attention,Hossein Adeli,Stony Brook University
NIPS,2016,Learned Region Sparsity and Diversity Also Predicts Visual Attention,Minh Hoai Nguyen,Stony Brook University
NIPS,2016,Learned Region Sparsity and Diversity Also Predicts Visual Attention,Greg Zelinsky,Stony Brook University
NIPS,2016,Learned Region Sparsity and Diversity Also Predicts Visual Attention,Dimitris Samaras,Stony Brook University
NIPS,2016,Adaptive Concentration Inequalities for Sequential Decision Problems,Shengjia Zhao,Tsinghua University
NIPS,2016,Adaptive Concentration Inequalities for Sequential Decision Problems,Enze Zhou,Tsinghua University
NIPS,2016,Adaptive Concentration Inequalities for Sequential Decision Problems,Ashish Sabharwal,Allen Institute for AI
NIPS,2016,Adaptive Concentration Inequalities for Sequential Decision Problems,Stefano Ermon,Stanford
NIPS,2016,Cooperative Graphical Models,Josip Djolonga,ETH Zurich
NIPS,2016,Cooperative Graphical Models,Stefanie Jegelka,MIT
NIPS,2016,Cooperative Graphical Models,Sebastian Tschiatschek,ETH Zurich
NIPS,2016,Cooperative Graphical Models,Andreas Krause,ETHZ
NIPS,2016,Correlated-PCA: Principal Components' Analysis when Data and Noise are Correlated,Namrata Vaswani,Iowa State University
NIPS,2016,Correlated-PCA: Principal Components' Analysis when Data and Noise are Correlated,Han Guo,Iowa State University
NIPS,2016,Hierarchical Object Representation for Open-Ended Object Category Learning and Recognition,Hamidreza Kasaei,IEETA
NIPS,2016,Hierarchical Object Representation for Open-Ended Object Category Learning and Recognition,Ana Maria Tomé,University of Averio
NIPS,2016,Hierarchical Object Representation for Open-Ended Object Category Learning and Recognition,Luís Seabra Lopes,University of Averio
NIPS,2016,Optimal Tagging with Markov Chain Optimization,Nir Rosenfeld,Hebrew University of Jerusalem
NIPS,2016,Optimal Tagging with Markov Chain Optimization,Amir Globerson,Tel Aviv University
NIPS,2016,Bayesian optimization for automated model selection,Gustavo Malkomes,Washington University
NIPS,2016,Bayesian optimization for automated model selection,Charles Schaff,Washington University in St. Louis
NIPS,2016,Bayesian optimization for automated model selection,Roman Garnett,Washington University in St. Louis
NIPS,2016,Multi-view Anomaly Detection via Robust Probabilistic Latent Variable Models,Tomoharu Iwata,NTT
NIPS,2016,Multi-view Anomaly Detection via Robust Probabilistic Latent Variable Models,Makoto Yamada,Kyoto University
NIPS,2016,Inference by Reparameterization in Neural Population Codes,Rajkumar Vasudeva Raju,Rice University
NIPS,2016,Inference by Reparameterization in Neural Population Codes,Zachary Pitkow,BCM/Rice
NIPS,2016,Efficient Neural Codes under Metabolic Constraints,Zhuo Wang,University of Pennsylvania
NIPS,2016,Efficient Neural Codes under Metabolic Constraints,Xue-Xin Wei,University of Pennsylvania
NIPS,2016,Efficient Neural Codes under Metabolic Constraints,Alan A Stocker,University of Pennsylvania
NIPS,2016,Efficient Neural Codes under Metabolic Constraints,Daniel Lee,University of Pennsylvania
NIPS,2016,Learning Deep Parsimonious Representations,Renjie Liao,UofT
NIPS,2016,Learning Deep Parsimonious Representations,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2016,Learning Deep Parsimonious Representations,Richard Zemel,Vector Institute/University of Toronto
NIPS,2016,Learning Deep Parsimonious Representations,Raquel Urtasun,University of Toronto
NIPS,2016,An equivalence between high dimensional Bayes optimal inference and M-estimation,Madhu Advani,Stanford University
NIPS,2016,An equivalence between high dimensional Bayes optimal inference and M-estimation,Surya Ganguli,Stanford
NIPS,2016,Minimizing Quadratic Functions in Constant Time,Kohei Hayashi,AIST
NIPS,2016,Minimizing Quadratic Functions in Constant Time,Yuichi Yoshida,NII
NIPS,2016,Learning Structured Sparsity in Deep Neural Networks,Wei Wen,University of Pittsburgh
NIPS,2016,Learning Structured Sparsity in Deep Neural Networks,Chunpeng Wu,University of Pittsburgh
NIPS,2016,Learning Structured Sparsity in Deep Neural Networks,Yandan Wang,University of Pittsburgh
NIPS,2016,Learning Structured Sparsity in Deep Neural Networks,Yiran Chen,University of Pittsburgh
NIPS,2016,Learning Structured Sparsity in Deep Neural Networks,Hai Li,University of Pittsburg
NIPS,2016,Adversarial Multiclass Classification: A Risk Minimization Perspective,Rizal Fathony,U. of Illinois at Chicago
NIPS,2016,Adversarial Multiclass Classification: A Risk Minimization Perspective,Angie Liu,Caltech
NIPS,2016,Adversarial Multiclass Classification: A Risk Minimization Perspective,Kaiser Asif,University of Illinois at Chicago
NIPS,2016,Adversarial Multiclass Classification: A Risk Minimization Perspective,Brian Ziebart,University of Illinois at Chicago
NIPS,2016,Unified Methods for Exploiting Piecewise Linear Structure in Convex Optimization,Tyler Johnson,University of Washington
NIPS,2016,Unified Methods for Exploiting Piecewise Linear Structure in Convex Optimization,Carlos Guestrin,University of Washington
NIPS,2016,Fast and Provably Good Seedings for k-Means,Olivier Bachem,ETH Zurich
NIPS,2016,Fast and Provably Good Seedings for k-Means,Mario Lucic,ETH Zurich
NIPS,2016,Fast and Provably Good Seedings for k-Means,Hamed Hassani,ETH Zurich
NIPS,2016,Fast and Provably Good Seedings for k-Means,Andreas Krause,ETHZ
NIPS,2016,Testing for Differences in Gaussian Graphical Models:  Applications to Brain Connectivity,Eugene Belilovsky,CentraleSupelec
NIPS,2016,Testing for Differences in Gaussian Graphical Models:  Applications to Brain Connectivity,Gaël Varoquaux,INRIA
NIPS,2016,Testing for Differences in Gaussian Graphical Models:  Applications to Brain Connectivity,Matthew Blaschko,KU Leuven
NIPS,2016,Synthesis of MCMC and Belief Propagation,Sung-Soo Ahn,KAIST
NIPS,2016,Synthesis of MCMC and Belief Propagation,Michael Chertkov,Los Alamos National Laboratory
NIPS,2016,Synthesis of MCMC and Belief Propagation,Jinwoo Shin,KAIST
NIPS,2016,Value Iteration Networks,Aviv Tamar,UC Berkeley
NIPS,2016,Value Iteration Networks,Sergey Levine,University of Washington
NIPS,2016,Value Iteration Networks,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,Value Iteration Networks,YI WU,UC Berkeley
NIPS,2016,Value Iteration Networks,Garrett Thomas,UC Berkeley
NIPS,2016,Sequential Neural Models with Stochastic Layers,Marco Fraccaro,DTU
NIPS,2016,Sequential Neural Models with Stochastic Layers,Søren Kaae Sønderby,KU
NIPS,2016,Sequential Neural Models with Stochastic Layers,Ulrich Paquet,DeepMind
NIPS,2016,Sequential Neural Models with Stochastic Layers,Ole Winther,Technical University of Denmark
NIPS,2016,"Graphons, mergeons, and so on!",Justin Eldridge,The Ohio State University
NIPS,2016,"Graphons, mergeons, and so on!",Mikhail Belkin,Ohio State University
NIPS,2016,"Graphons, mergeons, and so on!",Yusu Wang,The Ohio State University
NIPS,2016,Hierarchical Clustering via Spreading Metrics,Aurko Roy,Georgia Tech
NIPS,2016,Hierarchical Clustering via Spreading Metrics,Sebastian Pokutta,GeorgiaTech
NIPS,2016,Deep Learning for Predicting Human Strategic Behavior,Jason Hartford,University of British Columbia
NIPS,2016,Deep Learning for Predicting Human Strategic Behavior,James R Wright,University of British Columbia
NIPS,2016,Deep Learning for Predicting Human Strategic Behavior,Kevin Leyton-Brown,University of British Columbia
NIPS,2016,Global Analysis of Expectation Maximization for Mixtures of Two Gaussians,Ji Xu,Columbia university
NIPS,2016,Global Analysis of Expectation Maximization for Mixtures of Two Gaussians,Daniel Hsu,Columbia University
NIPS,2016,Global Analysis of Expectation Maximization for Mixtures of Two Gaussians,Arian Maleki,Columbia University
NIPS,2016,Supervised learning through the lens of compression,Ofir David,Technion - Israel institute of technology
NIPS,2016,Supervised learning through the lens of compression,Shay Moran,Technion - Israel institue of Technology
NIPS,2016,Supervised learning through the lens of compression,Amir Yehudayoff,Technion - Israel institue of Technology
NIPS,2016,Matrix Completion has No Spurious Local Minimum,Rong Ge,Princeton University
NIPS,2016,Matrix Completion has No Spurious Local Minimum,Jason Lee,UC Berkeley
NIPS,2016,Matrix Completion has No Spurious Local Minimum,Tengyu Ma,Princeton University
NIPS,2016,Clustering with Same-Cluster Queries,Hassan Ashtiani,University of Waterloo
NIPS,2016,Clustering with Same-Cluster Queries,Shrinu Kushagra,University of Waterloo
NIPS,2016,Clustering with Same-Cluster Queries,Shai Ben-David,U. Waterloo
NIPS,2016,MetaGrad: Multiple Learning Rates in Online Learning,Tim van Erven,Leiden University
NIPS,2016,MetaGrad: Multiple Learning Rates in Online Learning,Wouter Koolen,"Centrum Wiskunde & Informatica, Amsterdam"
NIPS,2016,Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA,Aapo Hyvarinen,University of Helsinki
NIPS,2016,Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA,Hiroshi Morioka,University of Helsinki
NIPS,2016,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,Daniel Neil,Institute of Neuroinformatics
NIPS,2016,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,Michael Pfeiffer,Institute of Neuroinformatics
NIPS,2016,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,Shih-Chii Liu,"Institute for Neuroinformatics, University of Zurich and ETH Zurich"
NIPS,2016,Tractable Operations for Arithmetic Circuits of Probabilistic Models,Yujia Shen,UCLA
NIPS,2016,Tractable Operations for Arithmetic Circuits of Probabilistic Models,Arthur Choi,UCLA
NIPS,2016,Tractable Operations for Arithmetic Circuits of Probabilistic Models,Adnan Darwiche,UCLA
NIPS,2016,Using Fast Weights to Attend to the Recent Past,Jimmy Ba,University of Toronto
NIPS,2016,Using Fast Weights to Attend to the Recent Past,Geoffrey E Hinton,Google
NIPS,2016,Using Fast Weights to Attend to the Recent Past,Volodymyr Mnih,DeepMind
NIPS,2016,Using Fast Weights to Attend to the Recent Past,Joel Leibo,Google DeepMind
NIPS,2016,Using Fast Weights to Attend to the Recent Past,Catalin Ionescu,Google
NIPS,2016,Bayesian Intermittent Demand Forecasting for Large Inventories,Matthias W Seeger,Amazon
NIPS,2016,Bayesian Intermittent Demand Forecasting for Large Inventories,David Salinas,Amazon
NIPS,2016,Bayesian Intermittent Demand Forecasting for Large Inventories,Valentin Flunkert,Amazon
NIPS,2016,Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning,Jean-Bastien Grill,Inria Lille - Nord Europe
NIPS,2016,Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning,Michal Valko,Inria Lille - Nord Europe
NIPS,2016,Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning,Remi Munos,Google DeepMind
NIPS,2016,SDP Relaxation with Randomized Rounding for Energy Disaggregation,Kiarash Shaloudegi,Imperial College London
NIPS,2016,SDP Relaxation with Randomized Rounding for Energy Disaggregation,András György,DeepMind
NIPS,2016,SDP Relaxation with Randomized Rounding for Energy Disaggregation,Csaba Szepesvari,U. Alberta
NIPS,2016,SDP Relaxation with Randomized Rounding for Energy Disaggregation,Wilsun Xu,University of Alberta
NIPS,2016,"Fast Mixing Markov Chains for Strongly Rayleigh Measures, DPPs, and Constrained Sampling",Chengtao Li,MIT
NIPS,2016,"Fast Mixing Markov Chains for Strongly Rayleigh Measures, DPPs, and Constrained Sampling",Suvrit Sra,MIT
NIPS,2016,"Fast Mixing Markov Chains for Strongly Rayleigh Measures, DPPs, and Constrained Sampling",Stefanie Jegelka,MIT
NIPS,2016,Unsupervised Learning of 3D Structure from Images,Danilo Jimenez Rezende,Google DeepMind
NIPS,2016,Unsupervised Learning of 3D Structure from Images,Ali Eslami,Google DeepMind
NIPS,2016,Unsupervised Learning of 3D Structure from Images,Shakir Mohamed,Google DeepMind
NIPS,2016,Unsupervised Learning of 3D Structure from Images,Peter Battaglia,Google DeepMind
NIPS,2016,Unsupervised Learning of 3D Structure from Images,Max Jaderberg,DeepMind
NIPS,2016,Unsupervised Learning of 3D Structure from Images,Nicolas Heess,Google DeepMind
NIPS,2016,The Multiple Quantile Graphical Model,Alnur Ali,Carnegie Mellon University
NIPS,2016,The Multiple Quantile Graphical Model,J. Zico Kolter,Carnegie Mellon University / Bosch Center for AI
NIPS,2016,The Multiple Quantile Graphical Model,Ryan Tibshirani,Carnegie Mellon University
NIPS,2016,Unsupervised Learning from Noisy Networks with Applications to Hi-C Data,Bo Wang,Stanford University
NIPS,2016,Unsupervised Learning from Noisy Networks with Applications to Hi-C Data,Junjie Zhu,Stanford University
NIPS,2016,Unsupervised Learning from Noisy Networks with Applications to Hi-C Data,Armin Pourshafeie,Stanford University
NIPS,2016,Unsupervised Learning from Noisy Networks with Applications to Hi-C Data,Oana Ursu,Dept. of Genetics
NIPS,2016,Unsupervised Learning from Noisy Networks with Applications to Hi-C Data,Serafim Batzoglou,Dept. of Computer Science
NIPS,2016,Unsupervised Learning from Noisy Networks with Applications to Hi-C Data,Anshul Kundaje,Stanford University
NIPS,2016,Towards Unifying Hamiltonian Monte Carlo and Slice Sampling,Yizhe Zhang,Duke university
NIPS,2016,Towards Unifying Hamiltonian Monte Carlo and Slice Sampling,Xiangyu Wang,Duke University
NIPS,2016,Towards Unifying Hamiltonian Monte Carlo and Slice Sampling,Changyou Chen,University at Buffalo
NIPS,2016,Towards Unifying Hamiltonian Monte Carlo and Slice Sampling,Ricardo Henao,Duke University
NIPS,2016,Towards Unifying Hamiltonian Monte Carlo and Slice Sampling,Kai Fan,Duke university
NIPS,2016,Towards Unifying Hamiltonian Monte Carlo and Slice Sampling,Lawrence Carin,Duke University
NIPS,2016,Differential Privacy without Sensitivity,Kentaro Minami,The University of Tokyo
NIPS,2016,Differential Privacy without Sensitivity,Hiromi Arai,The University of Tokyo
NIPS,2016,Differential Privacy without Sensitivity,Issei Sato,The University of Tokyo
NIPS,2016,Differential Privacy without Sensitivity,Hiroshi Nakagawa,The University of Tokyo
NIPS,2016,Generalized Correspondence-LDA Models (GC-LDA) for Identifying Functional Regions in the Brain,Tim Rubin,Indiana University
NIPS,2016,Generalized Correspondence-LDA Models (GC-LDA) for Identifying Functional Regions in the Brain,Sanmi Koyejo,UIUC
NIPS,2016,Generalized Correspondence-LDA Models (GC-LDA) for Identifying Functional Regions in the Brain,Michael Jones,Indiana University
NIPS,2016,Generalized Correspondence-LDA Models (GC-LDA) for Identifying Functional Regions in the Brain,Tal Yarkoni,University of Texas at Austin
NIPS,2016,Kronecker Determinantal Point Processes,Zelda Mariet,MIT
NIPS,2016,Kronecker Determinantal Point Processes,Suvrit Sra,MIT
NIPS,2016,Variance Reduction in Stochastic Gradient Langevin Dynamics,Avinava Dubey,Carnegie Mellon University
NIPS,2016,Variance Reduction in Stochastic Gradient Langevin Dynamics,Sashank J. Reddi,Carnegie Mellon University
NIPS,2016,Variance Reduction in Stochastic Gradient Langevin Dynamics,Sinead Williamson,University of Texas at Austin
NIPS,2016,Variance Reduction in Stochastic Gradient Langevin Dynamics,Barnabas Poczos,Carnegie Mellon University
NIPS,2016,Variance Reduction in Stochastic Gradient Langevin Dynamics,Alex Smola,Amazon - We are hiring!
NIPS,2016,Variance Reduction in Stochastic Gradient Langevin Dynamics,Eric Xing,Carnegie Mellon University
NIPS,2016,Online Pricing with Strategic and Patient Buyers,Michal Feldman,TAU
NIPS,2016,Online Pricing with Strategic and Patient Buyers,Tomer Koren,Technion---Israel Inst. of Technology
NIPS,2016,Online Pricing with Strategic and Patient Buyers,Roi Livni,Huji
NIPS,2016,Online Pricing with Strategic and Patient Buyers,Yishay Mansour,Microsoft
NIPS,2016,Online Pricing with Strategic and Patient Buyers,Aviv Zohar,huji
NIPS,2016,Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters,Zeyuan Allen-Zhu,Princeton University
NIPS,2016,Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters,Yang Yuan,Cornell University
NIPS,2016,Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters,Karthik Sridharan,University of Pennsylvania
NIPS,2016,Clustering Signed Networks with the Geometric Mean of Laplacians,Pedro Mercado,Saarland University
NIPS,2016,Clustering Signed Networks with the Geometric Mean of Laplacians,Francesco Tudisco,Saarland University
NIPS,2016,Clustering Signed Networks with the Geometric Mean of Laplacians,Matthias Hein,Saarland University
NIPS,2016,Robust Spectral Detection of Global Structures in the Data by Learning a Regularization,Pan Zhang,Institute of Theoretical Physics
NIPS,2016,Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision,Xinchen Yan,University of Michigan
NIPS,2016,Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision,Jimei Yang,Adobe Research
NIPS,2016,Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision,Ersin Yumer,Adobe Research
NIPS,2016,Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision,Yijie Guo,University of Michigan
NIPS,2016,Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision,Honglak Lee,University of Michigan
NIPS,2016,Launch and Iterate: Reducing Prediction Churn,Mahdi Milani Fard,Google
NIPS,2016,Launch and Iterate: Reducing Prediction Churn,Quentin Cormier,Google
NIPS,2016,Launch and Iterate: Reducing Prediction Churn,Kevin Canini,Google
NIPS,2016,Launch and Iterate: Reducing Prediction Churn,Maya Gupta,Google
NIPS,2016,Data Poisoning Attacks on Factorization-Based Collaborative Filtering,Bo Li,Vanderbilt University
NIPS,2016,Data Poisoning Attacks on Factorization-Based Collaborative Filtering,Yining Wang,Carnegie Mellon University
NIPS,2016,Data Poisoning Attacks on Factorization-Based Collaborative Filtering,Aarti Singh,Carnegie Mellon University
NIPS,2016,Data Poisoning Attacks on Factorization-Based Collaborative Filtering,Yevgeniy Vorobeychik,Vanderbilt University
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Jack Rae,Google DeepMind
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Jonathan J Hunt,Brain Corporation
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Ivo Danihelka,DeepMind
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Tim Harley,Google DeepMind
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Andrew Senior,DeepMind
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Greg Wayne,Google DeepMind
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Alex Graves,Google DeepMind
NIPS,2016,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,Timothy Lillicrap,Google DeepMind
NIPS,2016,Optimal Architectures in a Solvable Model of Deep Networks,Jonathan Kadmon,Hebrew University
NIPS,2016,Optimal Architectures in a Solvable Model of Deep Networks,Haim Sompolinsky,Hebrew University and Harvard University
NIPS,2016,Scalable Adaptive Stochastic Optimization Using Random Projections,Gabriel Krummenacher,ETH Zurich
NIPS,2016,Scalable Adaptive Stochastic Optimization Using Random Projections,Brian McWilliams,Disney Research
NIPS,2016,Scalable Adaptive Stochastic Optimization Using Random Projections,Yannic Kilcher,ETH Zurich
NIPS,2016,Scalable Adaptive Stochastic Optimization Using Random Projections,Joachim M Buhmann,ETH Zurich
NIPS,2016,Scalable Adaptive Stochastic Optimization Using Random Projections,Nicolai Meinshausen,ETH Zurich
NIPS,2016,Spectral Learning of Dynamic Systems from Nonequilibrium Data,Hao Wu,Free University of Berlin
NIPS,2016,Spectral Learning of Dynamic Systems from Nonequilibrium Data,Frank Noe,FU Berlin
NIPS,2016,Local Minimax Complexity of Stochastic Convex Optimization,sabyasachi chatterjee,University of Chicago
NIPS,2016,Local Minimax Complexity of Stochastic Convex Optimization,John Duchi,Stanford
NIPS,2016,Local Minimax Complexity of Stochastic Convex Optimization,John Lafferty,Yale University
NIPS,2016,Local Minimax Complexity of Stochastic Convex Optimization,Yuancheng Zhu,University of Chicago
NIPS,2016,A Theoretically Grounded Application of Dropout in Recurrent Neural Networks,Yarin Gal,University of Cambridge
NIPS,2016,A Theoretically Grounded Application of Dropout in Recurrent Neural Networks,Zoubin Ghahramani,Uber and University of Cambridge
NIPS,2016,Brains on Beats,Umut Güçlü,Radboud University
NIPS,2016,Brains on Beats,Jordy Thielen,Radboud University
NIPS,2016,Brains on Beats,Michael Hanke,Otto-von-Guericke University Magdeburg
NIPS,2016,Brains on Beats,Marcel van Gerven,Radboud University
NIPS,2016,Brains on Beats,Marcel A. J. van Gerven,Radboud University
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,dreamqi Meng,Peking University
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,Guolin Ke,Microsoft Research
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,Taifeng Wang,Microsoft Research
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,Wei Chen,Microsoft Research
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,Qiwei Ye,Microsoft Research
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,Zhi-Ming Ma,Academy of Mathematics and Systems Science
NIPS,2016,A Communication-Efficient Parallel Algorithm for Decision Tree,Tie-Yan Liu,Microsoft Research
NIPS,2016,Leveraging Sparsity for Efficient Submodular Data Summarization,Erik Lindgren,University of Texas at Austin
NIPS,2016,Leveraging Sparsity for Efficient Submodular Data Summarization,Shanshan Wu,UT Austin
NIPS,2016,Leveraging Sparsity for Efficient Submodular Data Summarization,Alex Dimakis,"University of Texas, Austin"
NIPS,2016,Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction,Jacob Steinhardt,Stanford University
NIPS,2016,Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction,Gregory Valiant,Stanford University
NIPS,2016,Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction,Moses Charikar,Stanford University
NIPS,2016,Designing smoothing functions for improved worst-case competitive ratio in online optimization,Reza Eghbali,University of washington
NIPS,2016,Designing smoothing functions for improved worst-case competitive ratio in online optimization,Maryam Fazel,University of Washington
NIPS,2016,The Forget-me-not Process,Kieran Milan,Google DeepMind
NIPS,2016,The Forget-me-not Process,Joel Veness,DeepMind
NIPS,2016,The Forget-me-not Process,James Kirkpatrick,Google DeepMind
NIPS,2016,The Forget-me-not Process,Michael Bowling,DeepMind / University of Alberta
NIPS,2016,The Forget-me-not Process,Anna Koop,University of Alberta
NIPS,2016,The Forget-me-not Process,Demis Hassabis,DeepMind
NIPS,2016,Generating Videos with Scene Dynamics,Carl Vondrick,MIT
NIPS,2016,Generating Videos with Scene Dynamics,Hamed Pirsiavash,"University of Maryland, Baltimore County"
NIPS,2016,Generating Videos with Scene Dynamics,Antonio Torralba,MIT
NIPS,2016,The Robustness of Estimator Composition,Pingfan Tang,University of Utah
NIPS,2016,The Robustness of Estimator Composition,Jeff M Phillips,University of Utah
NIPS,2016,Improved Deep Metric Learning with Multi-class N-pair Loss Objective,Kihyuk Sohn,NEC Laboratories America
NIPS,2016,Preference Completion from Partial Rankings,Suriya Gunasekar,UT Austin
NIPS,2016,Preference Completion from Partial Rankings,Sanmi Koyejo,UIUC
NIPS,2016,Preference Completion from Partial Rankings,Joydeep Ghosh,UT Austin
NIPS,2016,Bayesian optimization under mixed constraints  with a slack-variable augmented Lagrangian,Victor Picheny,Institut National de la Recherche Agronomique
NIPS,2016,Bayesian optimization under mixed constraints  with a slack-variable augmented Lagrangian,Robert B Gramacy,Virginia Tech
NIPS,2016,Bayesian optimization under mixed constraints  with a slack-variable augmented Lagrangian,Stefan Wild,Argonne National Lab
NIPS,2016,Bayesian optimization under mixed constraints  with a slack-variable augmented Lagrangian,Sebastien Le Digabel,École Polytechnique de Montréal
NIPS,2016,Privacy Odometers and Filters: Pay-as-you-Go Composition,Ryan Rogers,University of Pennsylvania
NIPS,2016,Privacy Odometers and Filters: Pay-as-you-Go Composition,Salil Vadhan,Harvard University
NIPS,2016,Privacy Odometers and Filters: Pay-as-you-Go Composition,Aaron Roth,University of Pennsylvania
NIPS,2016,Privacy Odometers and Filters: Pay-as-you-Go Composition,Jonathan Ullman,Northeastern University
NIPS,2016,Large Margin Discriminant Dimensionality Reduction in Prediction Space,Ehsan Saberian,Netflix
NIPS,2016,Large Margin Discriminant Dimensionality Reduction in Prediction Space,Jose Costa Pereira,UC San Diego
NIPS,2016,Large Margin Discriminant Dimensionality Reduction in Prediction Space,Nuno Nvasconcelos,UC San Diego
NIPS,2016,Large Margin Discriminant Dimensionality Reduction in Prediction Space,Can Xu,Google
NIPS,2016,Tight Complexity Bounds for Optimizing Composite Objectives,Blake Woodworth,Toyota Technological Institute
NIPS,2016,Tight Complexity Bounds for Optimizing Composite Objectives,Nati Srebro,TTI-Chicago
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,Noah Apthorpe,Princeton University
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,Alexander Riordan,Princeton University
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,Robert Aguilar,Princeton University
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,Jan Homann,Princeton University
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,Yi Gu,Princeton University
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,David Tank,Princeton University
NIPS,2016,Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks,H. Sebastian Seung,Princeton University
NIPS,2016,Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation,Tejas Kulkarni,MIT
NIPS,2016,Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation,Karthik Narasimhan,MIT
NIPS,2016,Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation,Ardavan Saeedi,MIT
NIPS,2016,Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation,Josh Tenenbaum,MIT
NIPS,2016,Conditional Image Generation with PixelCNN Decoders,Aaron van den Oord,Google Deepmind
NIPS,2016,Conditional Image Generation with PixelCNN Decoders,Nal Kalchbrenner,Google Brain
NIPS,2016,Conditional Image Generation with PixelCNN Decoders,Lasse Espeholt,Google Brain Amsterdam
NIPS,2016,Conditional Image Generation with PixelCNN Decoders,koray kavukcuoglu,Google DeepMind
NIPS,2016,Conditional Image Generation with PixelCNN Decoders,Oriol Vinyals,Google DeepMind
NIPS,2016,Conditional Image Generation with PixelCNN Decoders,Alex Graves,Google DeepMind
NIPS,2016,Natural-Parameter Networks: A Class of Probabilistic Neural Networks,Hao Wang,HKUST
NIPS,2016,Natural-Parameter Networks: A Class of Probabilistic Neural Networks,Xingjian SHI,Hong Kong University of Science and Technology
NIPS,2016,Natural-Parameter Networks: A Class of Probabilistic Neural Networks,Dit-Yan Yeung,"HKUST, Hong Kong"
NIPS,2016,Long-term Causal Effects via Behavioral Game Theory,Panos Toulis,University of Chicago
NIPS,2016,Long-term Causal Effects via Behavioral Game Theory,David Parkes,Harvard University
NIPS,2016,PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions,Michael Figurnov,Skolkovo Inst. of Sc and Tech
NIPS,2016,PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions,Aizhan Ibraimova,Skolkovo Institute of Science and Technology
NIPS,2016,PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions,Dmitry Vetrov,"Higher School of Economics, Samsung AI Center, Moscow"
NIPS,2016,PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions,Pushmeet Kohli,Microsoft Research
NIPS,2016,A Probabilistic Programming Approach To Probabilistic Data Analysis,Feras Saad,MIT
NIPS,2016,A Probabilistic Programming Approach To Probabilistic Data Analysis,Vikash K Mansinghka,MIT
NIPS,2016,Learning Bayesian networks with ancestral constraints,Eunice Yuh-Jie Chen,UCLA
NIPS,2016,Learning Bayesian networks with ancestral constraints,Yujia Shen,UCLA
NIPS,2016,Learning Bayesian networks with ancestral constraints,Arthur Choi,UCLA
NIPS,2016,Learning Bayesian networks with ancestral constraints,Adnan Darwiche,UCLA
NIPS,2016,Solving Random Systems of Quadratic Equations via Truncated Generalized Gradient Flow,Gang Wang,University of Minnesota
NIPS,2016,Solving Random Systems of Quadratic Equations via Truncated Generalized Gradient Flow,Georgios Giannakis,University of Minnesota
NIPS,2016,Balancing Suspense and Surprise: Timely Decision Making with Endogenous Information Acquisition,Ahmed M. Alaa,UCLA
NIPS,2016,Balancing Suspense and Surprise: Timely Decision Making with Endogenous Information Acquisition,Mihaela Van Der Schaar,"University of California, Los Angeles"
NIPS,2016,Structure-Blind Signal Recovery,Dmitry Ostrovsky,Univ. Grenoble Alpes
NIPS,2016,Structure-Blind Signal Recovery,Zaid Harchaoui,NYU
NIPS,2016,Structure-Blind Signal Recovery,Anatoli Juditsky,UJF
NIPS,2016,Structure-Blind Signal Recovery,Arkadi S Nemirovski,Gerogia Institute of Technology
NIPS,2016,Spatiotemporal Residual Networks for Video Action Recognition,Christoph Feichtenhofer,Graz University of Technology
NIPS,2016,Spatiotemporal Residual Networks for Video Action Recognition,Axel Pinz,Graz University of Technology
NIPS,2016,Spatiotemporal Residual Networks for Video Action Recognition,Richard Wildes,York University Toronto
NIPS,2016,CMA-ES with Optimal Covariance Update and Storage Complexity,Oswin Krause,University of Copenhagen
NIPS,2016,CMA-ES with Optimal Covariance Update and Storage Complexity,Dídac Rodríguez Arbonès,University of Copenhagen
NIPS,2016,CMA-ES with Optimal Covariance Update and Storage Complexity,Christian Igel,University of Copenhagen
NIPS,2016,Latent Attention For If-Then Program Synthesis,Chang Liu,Tsinghua University
NIPS,2016,Latent Attention For If-Then Program Synthesis,Xinyun Chen,Shanghai Jiaotong University
NIPS,2016,Latent Attention For If-Then Program Synthesis,Richard Shin,UC Berkeley
NIPS,2016,Latent Attention For If-Then Program Synthesis,Mingcheng Chen,University of Illinois
NIPS,2016,Latent Attention For If-Then Program Synthesis,Dawn Song,UC Berkeley
NIPS,2016,The Sound of APALM Clapping: Faster Nonsmooth Nonconvex Optimization with Stochastic Asynchronous PALM,damekdavis Davis,Cornell University
NIPS,2016,The Sound of APALM Clapping: Faster Nonsmooth Nonconvex Optimization with Stochastic Asynchronous PALM,Brent Edmunds,University of California
NIPS,2016,The Sound of APALM Clapping: Faster Nonsmooth Nonconvex Optimization with Stochastic Asynchronous PALM,Madeleine Udell,Cornell University
NIPS,2016,An Efficient Streaming Algorithm for the Submodular Cover Problem,Ashkan Norouzi-Fard,EPFL
NIPS,2016,An Efficient Streaming Algorithm for the Submodular Cover Problem,Abbas Bazzi,EPFL
NIPS,2016,An Efficient Streaming Algorithm for the Submodular Cover Problem,Ilija Bogunovic,EPFL Lausanne
NIPS,2016,An Efficient Streaming Algorithm for the Submodular Cover Problem,Marwa El Halabi,l
NIPS,2016,An Efficient Streaming Algorithm for the Submodular Cover Problem,Ya-Ping Hsieh,EPFL
NIPS,2016,An Efficient Streaming Algorithm for the Submodular Cover Problem,Volkan Cevher,EPFL
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",Ali Eslami,Google DeepMind
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",Nicolas Heess,Google DeepMind
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",Theophane Weber,DeepMind
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",Yuval Tassa,Google DeepMind
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",David Szepesvari,Google DeepMind
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",koray kavukcuoglu,Google DeepMind
NIPS,2016,"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models",Geoffrey E Hinton,Google
NIPS,2016,An ensemble diversity approach to supervised binary hashing,Miguel A. Carreira-Perpinan,UC Merced
NIPS,2016,An ensemble diversity approach to supervised binary hashing,Ramin Raziperchikolaei,UC Merced
NIPS,2016,End-to-End Goal-Driven Web Navigation,Rodrigo Nogueira,New York University
NIPS,2016,End-to-End Goal-Driven Web Navigation,Kyunghyun Cho,University of Montreal
NIPS,2016,The Power of Adaptivity in Identifying Statistical Alternatives,Kevin Jamieson,UC Berkeley
NIPS,2016,The Power of Adaptivity in Identifying Statistical Alternatives,Daniel Haas,UC Berkeley
NIPS,2016,The Power of Adaptivity in Identifying Statistical Alternatives,Benjamin Recht,UC Berkeley
NIPS,2016,A Probabilistic Framework for Deep Learning,Ankit B Patel,Baylor College of Medicine and Rice University
NIPS,2016,A Probabilistic Framework for Deep Learning,Minh Nguyen,Rice University
NIPS,2016,A Probabilistic Framework for Deep Learning,Richard Baraniuk,Rice University
NIPS,2016,Minimax Estimation of Maximum Mean Discrepancy with Radial Kernels,Ilya Tolstikhin,MPI for Intelligent Systems
NIPS,2016,Minimax Estimation of Maximum Mean Discrepancy with Radial Kernels,Bharath Sriperumbudur,Penn State University
NIPS,2016,Minimax Estimation of Maximum Mean Discrepancy with Radial Kernels,Bernhard Schölkopf,MPI for Intelligent Systems
NIPS,2016,Adaptive Neural Compilation,Rudy Bunel,Oxford University
NIPS,2016,Adaptive Neural Compilation,Alban Desmaison,Oxford
NIPS,2016,Adaptive Neural Compilation,Pawan K Mudigonda,University of Oxford
NIPS,2016,Adaptive Neural Compilation,Pushmeet Kohli,Microsoft Research
NIPS,2016,Adaptive Neural Compilation,Philip Torr,Oxford University
NIPS,2016,Tagger: Deep Unsupervised Perceptual Grouping,Klaus Greff,IDSIA
NIPS,2016,Tagger: Deep Unsupervised Perceptual Grouping,Antti Rasmus,The Curious AI Company
NIPS,2016,Tagger: Deep Unsupervised Perceptual Grouping,Mathias Berglund,The Curious AI Company
NIPS,2016,Tagger: Deep Unsupervised Perceptual Grouping,Hotloo Hao,The Curious AI Company
NIPS,2016,Tagger: Deep Unsupervised Perceptual Grouping,Harri Valpola,The Curious AI Company
NIPS,2016,Tagger: Deep Unsupervised Perceptual Grouping,Jürgen Schmidhuber,"Swiss AI Lab, IDSIA (USI & SUPSI) - NNAISENSE"
NIPS,2016,A scaled Bregman theorem with applications,Richard Nock,Data61 and ANU
NIPS,2016,A scaled Bregman theorem with applications,Aditya Menon,NICTA
NIPS,2016,A scaled Bregman theorem with applications,Cheng Soon Ong,Data61
NIPS,2016,Learning feed-forward one-shot learners,Luca Bertinetto,University of Oxford
NIPS,2016,Learning feed-forward one-shot learners,João F. Henriques,University of Oxford
NIPS,2016,Learning feed-forward one-shot learners,Jack Valmadre,University of Oxford
NIPS,2016,Learning feed-forward one-shot learners,Philip Torr,Oxford University
NIPS,2016,Learning feed-forward one-shot learners,Andrea Vedaldi,University of Oxford and Facebook
NIPS,2016,Error Analysis of Generalized Nyström Kernel Regression,Hong Chen,University of Texas
NIPS,2016,Error Analysis of Generalized Nyström Kernel Regression,Haifeng Xia,Huazhong Agricultural University
NIPS,2016,Error Analysis of Generalized Nyström Kernel Regression,Heng Huang,University of Texas Arlington
NIPS,2016,Error Analysis of Generalized Nyström Kernel Regression,Weidong Cai,University of Sydney
NIPS,2016,Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation,Weihao Gao,UIUC
NIPS,2016,Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation,Sewoong Oh,UIUC
NIPS,2016,Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation,Pramod Viswanath,UIUC
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,Yang You,UC Berkeley
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,Xiangru Lian,University of Rochester
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,Ji Liu,"University of Rochester, Tencent AI lab"
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,Hsiang-Fu (Rofu) Yu,University of Texas at Austin
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,Inderjit S Dhillon,University of Texas at Austin
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,James Demmel,UC Berkeley
NIPS,2016,Asynchronous Parallel Greedy Coordinate Descent,Cho-Jui Hsieh,UCLA
NIPS,2016,Structured Prediction Theory Based on Factor Graph Complexity,Corinna Cortes,Google Research
NIPS,2016,Structured Prediction Theory Based on Factor Graph Complexity,Vitaly Kuznetsov,Courant Institute
NIPS,2016,Structured Prediction Theory Based on Factor Graph Complexity,Mehryar Mohri,Courant Inst. of Math. Sciences & Google Research
NIPS,2016,Structured Prediction Theory Based on Factor Graph Complexity,Scott Yang,New York University
NIPS,2016,Parameter Learning for Log-supermodular Distributions,Tatiana Shpakova,Inria - ENS Paris
NIPS,2016,Parameter Learning for Log-supermodular Distributions,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2016,Exact Recovery of Hard Thresholding Pursuit,Xiaotong Yuan,Nanjing University of Informat
NIPS,2016,Exact Recovery of Hard Thresholding Pursuit,Ping Li,Rugters University
NIPS,2016,Exact Recovery of Hard Thresholding Pursuit,Tong Zhang,Tencent
NIPS,2016,New Liftable Classes for First-Order Probabilistic Inference,Seyed Mehran Kazemi,UBC
NIPS,2016,New Liftable Classes for First-Order Probabilistic Inference,Angelika Kimmig,KU Leuven
NIPS,2016,New Liftable Classes for First-Order Probabilistic Inference,Guy Van den Broeck,UCLA
NIPS,2016,New Liftable Classes for First-Order Probabilistic Inference,David Poole,UBC
NIPS,2016,Variational Inference in Mixed Probabilistic Submodular Models,Josip Djolonga,ETH Zurich
NIPS,2016,Variational Inference in Mixed Probabilistic Submodular Models,Sebastian Tschiatschek,ETH Zurich
NIPS,2016,Variational Inference in Mixed Probabilistic Submodular Models,Andreas Krause,ETHZ
NIPS,2016,Unifying Count-Based Exploration and Intrinsic Motivation,Marc Bellemare,Google DeepMind
NIPS,2016,Unifying Count-Based Exploration and Intrinsic Motivation,Sriram Srinivasan,Google
NIPS,2016,Unifying Count-Based Exploration and Intrinsic Motivation,Georg Ostrovski,Google DeepMind
NIPS,2016,Unifying Count-Based Exploration and Intrinsic Motivation,Tom Schaul,DeepMind
NIPS,2016,Unifying Count-Based Exploration and Intrinsic Motivation,David Saxton,Google DeepMind
NIPS,2016,Unifying Count-Based Exploration and Intrinsic Motivation,Remi Munos,Google DeepMind
NIPS,2016,Approximate maximum entropy principles via Goemans-Williamson with applications to provable variational methods,Andrej Risteski,Princeton University
NIPS,2016,Approximate maximum entropy principles via Goemans-Williamson with applications to provable variational methods,Yuanzhi Li,Princeton University
NIPS,2016,A Multi-step Inertial Forward-Backward Splitting Method for Non-convex Optimization,Jingwei Liang,GREYC
NIPS,2016,A Multi-step Inertial Forward-Backward Splitting Method for Non-convex Optimization,Jalal Fadili,CNRS-ENSICAEN-Univ. Caen
NIPS,2016,A Multi-step Inertial Forward-Backward Splitting Method for Non-convex Optimization,Gabriel Peyré,Université Paris Dauphine
NIPS,2016,Fast and Flexible Monotonic Functions with Ensembles of Lattices,Mahdi Milani Fard,Google
NIPS,2016,Fast and Flexible Monotonic Functions with Ensembles of Lattices,Kevin Canini,Google
NIPS,2016,Fast and Flexible Monotonic Functions with Ensembles of Lattices,Andy Cotter,Google
NIPS,2016,Fast and Flexible Monotonic Functions with Ensembles of Lattices,Jan Pfeifer Pfeifer,Google
NIPS,2016,Fast and Flexible Monotonic Functions with Ensembles of Lattices,Maya Gupta,Google
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Saizheng Zhang,University of Montreal
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Yuhuai Wu,University of Toronto
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Tong Che,IHES
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Zhouhan Lin,University of Montreal
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Roland Memisevic,University of Montreal
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Russ Salakhutdinov,University of Toronto
NIPS,2016,Architectural Complexity Measures of Recurrent Neural Networks,Yoshua Bengio,U. Montreal
NIPS,2016,Online Convex Optimization with Unconstrained Domains and Losses,Ashok Cutkosky,Stanford University
NIPS,2016,Online Convex Optimization with Unconstrained Domains and Losses,Kwabena A Boahen,Stanford University
NIPS,2016,Split LBI: An Iterative Regularization Path with Structural Sparsity,Chendi Huang,Peking University
NIPS,2016,Split LBI: An Iterative Regularization Path with Structural Sparsity,Xinwei Sun,Peking University
NIPS,2016,Split LBI: An Iterative Regularization Path with Structural Sparsity,Jiechao Xiong,Peking University
NIPS,2016,Split LBI: An Iterative Regularization Path with Structural Sparsity,Yuan Yao,Stanford University
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Yunchen Pu,Duke University
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Zhe Gan,Duke
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Ricardo Henao,Duke University
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Xin Yuan,Bell Labs
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Chunyuan Li,Duke
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Andrew Stevens,Duke University
NIPS,2016,"Variational Autoencoder for Deep Learning of Images, Labels and Captions",Lawrence Carin,Duke University
NIPS,2016,Recovery Guarantee of Non-negative Matrix Factorization  via Alternating Updates,Yuanzhi Li,Princeton University
NIPS,2016,Recovery Guarantee of Non-negative Matrix Factorization  via Alternating Updates,Yingyu Liang,Princeton University
NIPS,2016,Recovery Guarantee of Non-negative Matrix Factorization  via Alternating Updates,Andrej Risteski,Princeton University
NIPS,2016,Proximal Deep Structured Models,Shenlong Wang,University of Toronto
NIPS,2016,Proximal Deep Structured Models,Sanja Fidler,University of Toronto
NIPS,2016,Proximal Deep Structured Models,Raquel Urtasun,University of Toronto
NIPS,2016,Safe Policy Improvement by Minimizing Robust Baseline Regret,Mohammad Ghavamzadeh,FaceBook FAIR
NIPS,2016,Safe Policy Improvement by Minimizing Robust Baseline Regret,Marek Petrik,University of New Hampshire
NIPS,2016,Safe Policy Improvement by Minimizing Robust Baseline Regret,Yinlam Chow,Stanford University
NIPS,2016,A Pseudo-Bayesian Algorithm for Robust PCA,Tae-Hyun Oh,KAIST
NIPS,2016,A Pseudo-Bayesian Algorithm for Robust PCA,Yasuyuki Matsushita,Osaka University
NIPS,2016,A Pseudo-Bayesian Algorithm for Robust PCA,In Kweon,KAIST
NIPS,2016,A Pseudo-Bayesian Algorithm for Robust PCA,David Wipf,Microsoft Research
NIPS,2016,Learning values across many orders of magnitude,Hado van Hasselt,DeepMind
NIPS,2016,Learning values across many orders of magnitude,Arthur Guez,Google
NIPS,2016,Learning values across many orders of magnitude,Arthur Guez,Google
NIPS,2016,Learning values across many orders of magnitude,Matteo Hessel,Google DeepMind
NIPS,2016,Learning values across many orders of magnitude,Volodymyr Mnih,DeepMind
NIPS,2016,Learning values across many orders of magnitude,David Silver,DeepMind
NIPS,2016,Single Pass PCA of Matrix Products,Shanshan Wu,UT Austin
NIPS,2016,Single Pass PCA of Matrix Products,Srinadh Bhojanapalli,TTI Chicago
NIPS,2016,Single Pass PCA of Matrix Products,Sujay Sanghavi,UT-Austin
NIPS,2016,Single Pass PCA of Matrix Products,Alex Dimakis,"University of Texas, Austin"
NIPS,2016,Convolutional Neural Fabrics,Shreyas Saxena,INRIA
NIPS,2016,Convolutional Neural Fabrics,Jakob Verbeek,INRIA
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,Xinghua Lou,Vicarious FPC Inc
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,Ken Kansky,"Vicarious FPC, Inc."
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,Wolfgang Lehrach,Vicarious
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,CC Laan,
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,Bhaskara Marthi,Vicarious
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,D. Phoenix,
NIPS,2016,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,Dileep George,Vicarious
NIPS,2016,Mixed vine copulas as joint models of spike counts and local field potentials,Arno Onken,IIT
NIPS,2016,Mixed vine copulas as joint models of spike counts and local field potentials,Stefano Panzeri,IIT
NIPS,2016,Optimal Black-Box Reductions Between Optimization Objectives,Zeyuan Allen-Zhu,Princeton University
NIPS,2016,Optimal Black-Box Reductions Between Optimization Objectives,Elad Hazan,Princeton University
NIPS,2016,Dialog-based Language Learning,Jason E Weston,Facebook AI Research
NIPS,2016,Online Bayesian Moment Matching for Topic Modeling with Unknown Number of Topics,Wei-Shou Hsu,University of Waterloo
NIPS,2016,Online Bayesian Moment Matching for Topic Modeling with Unknown Number of Topics,Pascal Poupart,University of Waterloo & RBC Borealis AI
NIPS,2016,A Sparse Interactive Model for Matrix Completion with Side Information,Jin Lu,University of Connecticut
NIPS,2016,A Sparse Interactive Model for Matrix Completion with Side Information,Guannan Liang,University of Connecticut
NIPS,2016,A Sparse Interactive Model for Matrix Completion with Side Information,Jiangwen Sun,University of Connecticut
NIPS,2016,A Sparse Interactive Model for Matrix Completion with Side Information,Jinbo Bi,University of Connecticut
NIPS,2016,Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation,Ilija Bogunovic,EPFL Lausanne
NIPS,2016,Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation,Jonathan Scarlett,EPFL
NIPS,2016,Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation,Andreas Krause,ETHZ
NIPS,2016,Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation,Volkan Cevher,EPFL
NIPS,2016,On Mixtures of Markov Chains,Rishi Gupta,Stanford
NIPS,2016,On Mixtures of Markov Chains,Ravi Kumar,Yahoo!
NIPS,2016,On Mixtures of Markov Chains,Sergei Vassilvitskii,Google
NIPS,2016,High Dimensional Structured Superposition Models,Qilong Gu,University of Minnesota
NIPS,2016,High Dimensional Structured Superposition Models,Arindam Banerjee,Voleon
NIPS,2016,Finite Sample Prediction and Recovery Bounds for Ordinal Embedding,Lalit Jain,University of Michigan
NIPS,2016,Finite Sample Prediction and Recovery Bounds for Ordinal Embedding,Kevin Jamieson,UC Berkeley
NIPS,2016,Finite Sample Prediction and Recovery Bounds for Ordinal Embedding,Rob Nowak,University of Wisconsin Madison
NIPS,2016,What Makes Objects Similar: A Unified Multi-Metric Learning Approach,Han-Jia Ye,Nanjing University
NIPS,2016,What Makes Objects Similar: A Unified Multi-Metric Learning Approach,De-Chuan Zhan,Nanjing University
NIPS,2016,What Makes Objects Similar: A Unified Multi-Metric Learning Approach,Xue-Min Si,Nanjing University
NIPS,2016,What Makes Objects Similar: A Unified Multi-Metric Learning Approach,Yuan Jiang,Nanjing University
NIPS,2016,What Makes Objects Similar: A Unified Multi-Metric Learning Approach,Zhi-Hua Zhou,Nanjing University
NIPS,2016,Unsupervised Learning of Spoken Language with Visual Context,David Harwath,MIT CSAIL
NIPS,2016,Unsupervised Learning of Spoken Language with Visual Context,Antonio Torralba,MIT
NIPS,2016,Unsupervised Learning of Spoken Language with Visual Context,James Glass,MIT CSAIL
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Xinghao Pan,UC Berkeley
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Maximilian Lam,UC Berkeley
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Stephen Tu,UC Berkeley
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Dimitrios Papailiopoulos,UW-Madison
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Ce Zhang,Stanford
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Michael Jordan,UC Berkeley
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Kannan Ramchandran,UC Berkeley
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Chris Ré,Stanford
NIPS,2016,Cyclades: Conflict-free Asynchronous Machine Learning,Benjamin Recht,UC Berkeley
NIPS,2016,Disease Trajectory Maps,Peter Schulam,Johns Hopkins University
NIPS,2016,Disease Trajectory Maps,Raman Arora,Johns Hopkins University
NIPS,2016,Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation,George Papamakarios,University of Edinburgh
NIPS,2016,Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation,Iain Murray,University of Edinburgh
NIPS,2016,Stochastic Structured Prediction under Bandit Feedback,Artem Sokolov,Heidelberg University
NIPS,2016,Stochastic Structured Prediction under Bandit Feedback,Julia Kreutzer,Heidelberg University
NIPS,2016,Stochastic Structured Prediction under Bandit Feedback,Stefan Riezler,Heidelberg University
NIPS,2016,Stochastic Structured Prediction under Bandit Feedback,Christopher Lo,Tufts University
NIPS,2016,Learning under uncertainty: a comparison between R-W and Bayesian approach,Crane Huang,LIBR
NIPS,2016,Learning under uncertainty: a comparison between R-W and Bayesian approach,Martin Paulus,LIBR
NIPS,2016,Minimax Optimal Alternating Minimization for Kernel Nonparametric Tensor Learning,Taiji Suzuki,The University of Tokyo/JST-PRESTO/RIKEN
NIPS,2016,Minimax Optimal Alternating Minimization for Kernel Nonparametric Tensor Learning,Heishiro Kanagawa,"Gatsby Unit, University College London"
NIPS,2016,Minimax Optimal Alternating Minimization for Kernel Nonparametric Tensor Learning,Hayato Kobayashi,Yahoo Japan Corporation
NIPS,2016,Minimax Optimal Alternating Minimization for Kernel Nonparametric Tensor Learning,Nobuyuki Shimizu,Yahoo Japan Corporation
NIPS,2016,Minimax Optimal Alternating Minimization for Kernel Nonparametric Tensor Learning,Yukihiro Tagami,Yahoo Japan Corporation
NIPS,2016,On the Recursive Teaching Dimension of VC Classes,Peter Chen,UC Berkeley and OpenAI
NIPS,2016,On the Recursive Teaching Dimension of VC Classes,Xi Chen,Columbia University
NIPS,2016,On the Recursive Teaching Dimension of VC Classes,Yu Cheng,U of Southern California
NIPS,2016,On the Recursive Teaching Dimension of VC Classes,Bo Tang,University of Oxford
NIPS,2016,Dimension-Free Iteration Complexity of Finite Sum Optimization Problems,Yossi Arjevani,Weizmann Institute of Science
NIPS,2016,Dimension-Free Iteration Complexity of Finite Sum Optimization Problems,Ohad Shamir,Weizmann Institute of Science
NIPS,2016,f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization,Sebastian Nowozin,Microsoft Research
NIPS,2016,f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization,Botond Cseke,Microsoft Research
NIPS,2016,f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization,Ryota Tomioka,MSRC
NIPS,2016,Low-Rank Regression with Tensor Responses,Guillaume Rabusseau,Aix-Marseille University
NIPS,2016,Low-Rank Regression with Tensor Responses,Hachem Kadri,Aix-Marseille University
NIPS,2016,Double Thompson Sampling for Dueling Bandits,Huasen Wu,University of California at Davis
NIPS,2016,Double Thompson Sampling for Dueling Bandits,Xin Liu,University of California
NIPS,2016,Linear dynamical neural population models through nonlinear embeddings,Yuanjun Gao,Columbia University
NIPS,2016,Linear dynamical neural population models through nonlinear embeddings,Evan W Archer,Columbia University
NIPS,2016,Linear dynamical neural population models through nonlinear embeddings,Liam Paninski,Columbia University
NIPS,2016,Linear dynamical neural population models through nonlinear embeddings,John Cunningham,University of Columbia
NIPS,2016,Regret Bounds for Non-decomposable Metrics with Missing Labels,Nagarajan Natarajan,Microsoft Research
NIPS,2016,Regret Bounds for Non-decomposable Metrics with Missing Labels,Prateek Jain,Microsoft Research
NIPS,2016,Dynamic matrix recovery from incomplete observations under an exact low-rank constraint,Liangbei Xu,Gatech
NIPS,2016,Dynamic matrix recovery from incomplete observations under an exact low-rank constraint,Mark Davenport,Georgia Institute of Technology
NIPS,2016,Rényi Divergence Variational Inference,Yingzhen Li,University of Cambridge
NIPS,2016,Rényi Divergence Variational Inference,Richard E Turner,University of Cambridge
NIPS,2016,Confusions over Time: An Interpretable Bayesian Model to Characterize Trends in Decision Making,Himabindu Lakkaraju,Stanford University
NIPS,2016,Confusions over Time: An Interpretable Bayesian Model to Characterize Trends in Decision Making,Jure Leskovec,Stanford University and Pinterest
NIPS,2016,Adaptive Averaging in Accelerated Descent Dynamics,Walid Krichene,UC Berkeley
NIPS,2016,Adaptive Averaging in Accelerated Descent Dynamics,Alexandre Bayen,UC Berkeley
NIPS,2016,Adaptive Averaging in Accelerated Descent Dynamics,Peter Bartlett,UC Berkeley
NIPS,2016,Bayesian Optimization for Probabilistic Programs,Tom Rainforth,University of Oxford
NIPS,2016,Bayesian Optimization for Probabilistic Programs,Tuan Anh Le,University of Oxford
NIPS,2016,Bayesian Optimization for Probabilistic Programs,Jan-Willem van de Meent,University of Oxford
NIPS,2016,Bayesian Optimization for Probabilistic Programs,Michael A Osborne,U Oxford
NIPS,2016,Bayesian Optimization for Probabilistic Programs,Frank Wood,University of Oxford
NIPS,2016,Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis,Weiran Wang,"University of California, Merced"
NIPS,2016,Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis,Jialei Wang,University of Chicago
NIPS,2016,Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis,Dan Garber,Toyota Technological Institute at Chicago
NIPS,2016,Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis,Dan Garber,Toyota Technological Institute at Chicago
NIPS,2016,Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis,Nati Srebro,TTI-Chicago
NIPS,2016,A Unified Approach for Learning the Parameters of Sum-Product Networks,Han Zhao,Carnegie Mellon University
NIPS,2016,A Unified Approach for Learning the Parameters of Sum-Product Networks,Pascal Poupart,University of Waterloo & RBC Borealis AI
NIPS,2016,A Unified Approach for Learning the Parameters of Sum-Product Networks,Geoffrey Gordon,MSR Montréal & CMU
NIPS,2016,Feature-distributed sparse regression: a screen-and-clean approach,Jiyan Yang,Stanford University
NIPS,2016,Feature-distributed sparse regression: a screen-and-clean approach,Michael W Mahoney,UC Berkeley
NIPS,2016,Feature-distributed sparse regression: a screen-and-clean approach,Michael Saunders,Stanford University
NIPS,2016,Feature-distributed sparse regression: a screen-and-clean approach,Yuekai Sun,University of Michigan
NIPS,2016,Backprop KF: Learning Discriminative Deterministic State Estimators,Tuomas Haarnoja,UC Berkeley
NIPS,2016,Backprop KF: Learning Discriminative Deterministic State Estimators,Anurag Ajay,UC Berkeley
NIPS,2016,Backprop KF: Learning Discriminative Deterministic State Estimators,Sergey Levine,University of Washington
NIPS,2016,Backprop KF: Learning Discriminative Deterministic State Estimators,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,Swapout: Learning an ensemble of deep architectures,Saurabh Singh,UIUC
NIPS,2016,Swapout: Learning an ensemble of deep architectures,Derek Hoiem,UIUC
NIPS,2016,Swapout: Learning an ensemble of deep architectures,David Forsyth,UIUC
NIPS,2016,Assortment Optimization Under the Mallows model,Antoine Desir,Columbia University
NIPS,2016,Assortment Optimization Under the Mallows model,Vineet Goyal,Columbia University
NIPS,2016,Assortment Optimization Under the Mallows model,Srikanth Jagabathula,NYU Stern School of Business
NIPS,2016,Assortment Optimization Under the Mallows model,Danny Segev,University of Haifa
NIPS,2016,Operator Variational Inference,Rajesh Ranganath,Princeton University
NIPS,2016,Operator Variational Inference,Dustin Tran,Columbia University
NIPS,2016,Operator Variational Inference,Jaan Altosaar,Princeton University
NIPS,2016,Operator Variational Inference,David Blei,Columbia University
NIPS,2016,Select-and-Sample for Spike-and-Slab Sparse Coding,Abdul-Saboor Sheikh,SAP Labs Berlin
NIPS,2016,Select-and-Sample for Spike-and-Slab Sparse Coding,Jörg Lücke,University of Oldenburg
NIPS,2016,Fast recovery from a union of subspaces,Chinmay Hegde,Iowa State University
NIPS,2016,Fast recovery from a union of subspaces,Piotr Indyk,MIT
NIPS,2016,Fast recovery from a union of subspaces,Ludwig Schmidt,MIT
NIPS,2016,Ladder Variational Autoencoders,Casper Kaae Sønderby,University of Copenhagen
NIPS,2016,Ladder Variational Autoencoders,Tapani Raiko,Apple Inc.
NIPS,2016,Ladder Variational Autoencoders,Lars Maaløe,Technical University of Denmark
NIPS,2016,Ladder Variational Autoencoders,Søren Kaae Sønderby,KU
NIPS,2016,Ladder Variational Autoencoders,Ole Winther,Technical University of Denmark
NIPS,2016,SPALS: Fast Alternating Least Squares via Implicit Leverage Scores Sampling,Dehua Cheng,Univ. of Southern California
NIPS,2016,SPALS: Fast Alternating Least Squares via Implicit Leverage Scores Sampling,Richard Peng,
NIPS,2016,SPALS: Fast Alternating Least Squares via Implicit Leverage Scores Sampling,Yan Liu,DiDi AI Labs
NIPS,2016,SPALS: Fast Alternating Least Squares via Implicit Leverage Scores Sampling,Kimis Perros,Georgia Institute of Technology
NIPS,2016,CRF-CNN: Modeling Structured Information in Human Pose Estimation,Xiao Chu,Cuhk
NIPS,2016,CRF-CNN: Modeling Structured Information in Human Pose Estimation,Wanli Ouyang,The Chinese University of Hong Kong
NIPS,2016,CRF-CNN: Modeling Structured Information in Human Pose Estimation,hongsheng Li,cuhk
NIPS,2016,CRF-CNN: Modeling Structured Information in Human Pose Estimation,Xiaogang Wang,Chinese University of Hong Kong
NIPS,2016,A Consistent Regularization Approach for Structured Prediction,Carlo Ciliberto,MIT
NIPS,2016,A Consistent Regularization Approach for Structured Prediction,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2016,A Consistent Regularization Approach for Structured Prediction,Alessandro Rudi,"École Normale Supérieure, INRIA"
NIPS,2016,Refined Lower Bounds for Adversarial Bandits,Sébastien Gerchinovitz,Université Toulouse 3 - Paul Sabatier
NIPS,2016,Refined Lower Bounds for Adversarial Bandits,Tor Lattimore,DeepMind
NIPS,2016,Learning Deep Embeddings with Histogram Loss,Evgeniya Ustinova,Skoltech
NIPS,2016,Learning Deep Embeddings with Histogram Loss,Victor Lempitsky,Samsung
NIPS,2016,Solving Marginal MAP Problems with NP Oracles and Parity Constraints,Yexiang Xue,Cornell University
NIPS,2016,Solving Marginal MAP Problems with NP Oracles and Parity Constraints,zhiyuan li,Tsinghua University
NIPS,2016,Solving Marginal MAP Problems with NP Oracles and Parity Constraints,Stefano Ermon,Stanford
NIPS,2016,Solving Marginal MAP Problems with NP Oracles and Parity Constraints,Carla P Gomes,Cornell University
NIPS,2016,Solving Marginal MAP Problems with NP Oracles and Parity Constraints,Bart Selman,Cornell University
NIPS,2016,Kernel Bayesian Inference with Posterior Regularization,Yang Song,Stanford University
NIPS,2016,Kernel Bayesian Inference with Posterior Regularization,Jun Zhu,Tsinghua University
NIPS,2016,Kernel Bayesian Inference with Posterior Regularization,Yong Ren,Tsinghua University
NIPS,2016,Learning Influence Functions from Incomplete Observations,Xinran He,USC
NIPS,2016,Learning Influence Functions from Incomplete Observations,Ke Xu,USC
NIPS,2016,Learning Influence Functions from Incomplete Observations,David Kempe,USC
NIPS,2016,Learning Influence Functions from Incomplete Observations,Yan Liu,DiDi AI Labs
NIPS,2016,General Tensor Spectral Co-clustering for Higher-Order Data,Tao Wu,Purdue University
NIPS,2016,General Tensor Spectral Co-clustering for Higher-Order Data,Austin Benson,Stanford University
NIPS,2016,General Tensor Spectral Co-clustering for Higher-Order Data,David Gleich,Purdue University
NIPS,2016,Bayesian latent structure discovery from multi-neuron recordings,Scott Linderman,Columbia University
NIPS,2016,Bayesian latent structure discovery from multi-neuron recordings,Ryan Adams,Google Brain and Princeton University
NIPS,2016,Bayesian latent structure discovery from multi-neuron recordings,Jonathan W Pillow,Princeton University
NIPS,2016,Estimating the Size of a Large Network and its Communities from a Random Sample,Lin Chen,Yale University
NIPS,2016,Estimating the Size of a Large Network and its Communities from a Random Sample,Amin Karbasi,Yale
NIPS,2016,Estimating the Size of a Large Network and its Communities from a Random Sample,Forrest W. Crawford,Yale University
NIPS,2016,Wasserstein Training of Restricted Boltzmann Machines,Grégoire Montavon,TU Berlin
NIPS,2016,Wasserstein Training of Restricted Boltzmann Machines,Klaus-Robert Müller,TU Berlin
NIPS,2016,Wasserstein Training of Restricted Boltzmann Machines,Marco Cuturi,"Université Paris-Saclay, CREST - ENSAE"
NIPS,2016,Deep ADMM-Net for Compressive Sensing MRI,yan yang,Xi'an Jiaotong University
NIPS,2016,Deep ADMM-Net for Compressive Sensing MRI,Jian Sun,Microsoft
NIPS,2016,Deep ADMM-Net for Compressive Sensing MRI,Huibin Li,Xi'an Jiaotong University
NIPS,2016,Deep ADMM-Net for Compressive Sensing MRI,Zongben Xu,
NIPS,2016,Maximization of Approximately Submodular Functions,Thibaut Horel,Harvard University
NIPS,2016,Maximization of Approximately Submodular Functions,Yaron Singer,Harvard University
NIPS,2016,Combining Low-Density Separators with CNNs,Yu-Xiong Wang,Carnegie Mellon University
NIPS,2016,Combining Low-Density Separators with CNNs,Martial Hebert,Carnegie Mellon University
NIPS,2016,Learning Sensor Multiplexing Design through Back-propagation,Ayan Chakrabarti,TTI Chicago
NIPS,2016,High resolution neural connectivity from incomplete tracing data using nonnegative spline regression,Kameron D Harris,University of Washington
NIPS,2016,High resolution neural connectivity from incomplete tracing data using nonnegative spline regression,Stefan Mihalas,Allen Institute for Brain Science
NIPS,2016,High resolution neural connectivity from incomplete tracing data using nonnegative spline regression,Eric Shea-Brown,University of Washington
NIPS,2016,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,Jiajun Wu,MIT
NIPS,2016,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,Chengkai Zhang,Massachusetts Institute of Technology
NIPS,2016,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,Tianfan Xue,MIT CSAIL
NIPS,2016,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,Bill Freeman,MIT/Google
NIPS,2016,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,Josh Tenenbaum,MIT
NIPS,2016,Learning Sparse Gaussian Graphical Models with Overlapping Blocks,Mohammad Javad Hosseini,University of Washington
NIPS,2016,Learning Sparse Gaussian Graphical Models with Overlapping Blocks,Su-In Lee,University of Washington
NIPS,2016,Multi-step learning and underlying structure in statistical models,Maia Fraser,University of Ottawa
NIPS,2016,Dynamic Network Surgery for Efficient DNNs,Yiwen Guo,Intel Labs China
NIPS,2016,Dynamic Network Surgery for Efficient DNNs,Anbang Yao,Intel Labs China
NIPS,2016,Dynamic Network Surgery for Efficient DNNs,Yurong Chen,Intel Labs China
NIPS,2016,Active Nearest-Neighbor Learning in Metric Spaces,Aryeh Kontorovich,Ben Gurion University
NIPS,2016,Active Nearest-Neighbor Learning in Metric Spaces,Sivan Sabato,Ben-Gurion University of the Negev
NIPS,2016,Active Nearest-Neighbor Learning in Metric Spaces,Ruth Urner,MPI Tuebingen
NIPS,2016,Discriminative Gaifman Models,Mathias Niepert,NEC Labs Europe
NIPS,2016,Professor Forcing: A New Algorithm for Training Recurrent Networks,Alex M Lamb,Montreal
NIPS,2016,Professor Forcing: A New Algorithm for Training Recurrent Networks,Anirudh Goyal ALIAS PARTH GOYAL,University of Montreal
NIPS,2016,Professor Forcing: A New Algorithm for Training Recurrent Networks,Ying Zhang,University of Montreal
NIPS,2016,Professor Forcing: A New Algorithm for Training Recurrent Networks,Saizheng Zhang,University of Montreal
NIPS,2016,Professor Forcing: A New Algorithm for Training Recurrent Networks,Aaron Courville,University of Montreal
NIPS,2016,Professor Forcing: A New Algorithm for Training Recurrent Networks,Yoshua Bengio,U. Montreal
NIPS,2016,Pruning Random Forests for Prediction on a Budget,Feng Nan,Boston University
NIPS,2016,Pruning Random Forests for Prediction on a Budget,Joe Wang,Boston University
NIPS,2016,Pruning Random Forests for Prediction on a Budget,Venkatesh Saligrama,Boston University
NIPS,2016,Multistage Campaigning in Social Networks,Mehrdad Farajtabar,Georgia Tech
NIPS,2016,Multistage Campaigning in Social Networks,Xiaojing Ye,Georgia State University
NIPS,2016,Multistage Campaigning in Social Networks,Sahar Harati,Emory University
NIPS,2016,Multistage Campaigning in Social Networks,Le Song,Ant Financial & Georgia Institute of Technology
NIPS,2016,Multistage Campaigning in Social Networks,Hongyuan Zha,Georgia Institute of Technology
NIPS,2016,Coevolutionary Latent Feature Processes for Continuous-Time User-Item Interactions,Yichen Wang,Georgia Tech
NIPS,2016,Coevolutionary Latent Feature Processes for Continuous-Time User-Item Interactions,Nan Du,Georgia Tech
NIPS,2016,Coevolutionary Latent Feature Processes for Continuous-Time User-Item Interactions,Rakshit Trivedi,Georgia Institute of Technolo
NIPS,2016,Coevolutionary Latent Feature Processes for Continuous-Time User-Item Interactions,Le Song,Ant Financial & Georgia Institute of Technology
NIPS,2016,Coordinate-wise Power Method,Qi Lei,UT AUSTIN
NIPS,2016,Coordinate-wise Power Method,Kai Zhong,UT AUSTIN
NIPS,2016,Coordinate-wise Power Method,Inderjit S Dhillon,University of Texas at Austin
NIPS,2016,Barzilai-Borwein Step Size for Stochastic Gradient Descent,Conghui Tan,The Chinese University of HK
NIPS,2016,Barzilai-Borwein Step Size for Stochastic Gradient Descent,Shiqian Ma,UC Davis
NIPS,2016,Barzilai-Borwein Step Size for Stochastic Gradient Descent,Yu-Hong Dai,
NIPS,2016,Barzilai-Borwein Step Size for Stochastic Gradient Descent,Yuqiu Qian,The University of Hong Kong
NIPS,2016,Fast learning rates with heavy-tailed losses,Vu C Dinh,Fred Hutchinson Cancer Center
NIPS,2016,Fast learning rates with heavy-tailed losses,Lam S Ho,UCLA
NIPS,2016,Fast learning rates with heavy-tailed losses,Binh Nguyen,University of Science
NIPS,2016,Fast learning rates with heavy-tailed losses,Duy Nguyen,University of Wisconsin-Madison
NIPS,2016,CliqueCNN: Deep Unsupervised Exemplar Learning,Miguel A Bautista,Heidelberg University
NIPS,2016,CliqueCNN: Deep Unsupervised Exemplar Learning,Artsiom Sanakoyeu,Heidelberg University
NIPS,2016,CliqueCNN: Deep Unsupervised Exemplar Learning,Ekaterina Tikhoncheva,Heidelberg University
NIPS,2016,CliqueCNN: Deep Unsupervised Exemplar Learning,Bjorn Ommer,Heidelberg University
NIPS,2016,Guided Policy Search via Approximate Mirror Descent,William H Montgomery,University of Washington
NIPS,2016,Guided Policy Search via Approximate Mirror Descent,Sergey Levine,University of Washington
NIPS,2016,Structured Sparse Regression via Greedy Hard Thresholding,Prateek Jain,Microsoft Research
NIPS,2016,Structured Sparse Regression via Greedy Hard Thresholding,Nikhil Rao,Amazon
NIPS,2016,Structured Sparse Regression via Greedy Hard Thresholding,Inderjit S Dhillon,University of Texas at Austin
NIPS,2016,Learning in Games: Robustness of Fast Convergence,Dylan Foster,Cornell University
NIPS,2016,Learning in Games: Robustness of Fast Convergence,zhiyuan li,Tsinghua University
NIPS,2016,Learning in Games: Robustness of Fast Convergence,Thodoris Lykouris,Cornell University
NIPS,2016,Learning in Games: Robustness of Fast Convergence,Karthik Sridharan,University of Pennsylvania
NIPS,2016,Learning in Games: Robustness of Fast Convergence,Eva Tardos,Cornell University
NIPS,2016,Measuring the reliability of MCMC inference with bidirectional Monte Carlo,Roger Grosse,University of Toronto
NIPS,2016,Measuring the reliability of MCMC inference with bidirectional Monte Carlo,Siddharth Ancha,University of Toronto
NIPS,2016,Measuring the reliability of MCMC inference with bidirectional Monte Carlo,Dan Roy,Univ of Toronto & Vector
NIPS,2016,Average-case hardness of RIP certification,Tengyao Wang,University of Cambridge
NIPS,2016,Average-case hardness of RIP certification,Quentin Berthet,University of Cambridge
NIPS,2016,Average-case hardness of RIP certification,Yaniv Plan,University of British Columbia
NIPS,2016,Provable Efficient Online Matrix Completion via Non-convex Stochastic Gradient Descent,Chi Jin,UC Berkeley
NIPS,2016,Provable Efficient Online Matrix Completion via Non-convex Stochastic Gradient Descent,Sham Kakade,University of Washington
NIPS,2016,Provable Efficient Online Matrix Completion via Non-convex Stochastic Gradient Descent,Praneeth Netrapalli,Microsoft Research
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,matt zhang,Nicta
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,Peng Lin,Data61
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,Peng Lin,Data61
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,Ting Guo,Data61
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,Yang Wang,Data61
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,Yang Wang,Data61
NIPS,2016,Infinite Hidden Semi-Markov Modulated Interaction Point Process,Fang Chen,Data61
NIPS,2016,Linear Contextual Bandits with Knapsacks,Shipra Agrawal,Columbia University
NIPS,2016,Linear Contextual Bandits with Knapsacks,Nikhil Devanur,Microsoft Research
NIPS,2016,Selective inference for group-sparse linear models,Fan Yang,University of Chicago
NIPS,2016,Selective inference for group-sparse linear models,Rina Foygel Barber,University of Chicago
NIPS,2016,Selective inference for group-sparse linear models,Prateek Jain,Microsoft Research
NIPS,2016,Selective inference for group-sparse linear models,John Lafferty,Yale University
NIPS,2016,Deep Neural Networks with Inexact Matching for Person Re-Identification,Arulkumar Subramaniam,IIT Madras
NIPS,2016,Deep Neural Networks with Inexact Matching for Person Re-Identification,Moitreya Chatterjee,IIT Madras
NIPS,2016,Deep Neural Networks with Inexact Matching for Person Re-Identification,Anurag Mittal,IIT Madras
NIPS,2016,Accelerating Stochastic Composition Optimization,Mengdi Wang,Princeton University
NIPS,2016,Accelerating Stochastic Composition Optimization,Ji Liu,"University of Rochester, Tencent AI lab"
NIPS,2016,Accelerating Stochastic Composition Optimization,Ethan Fang,Pennsylvania State University
NIPS,2016,Learning Bound for Parameter Transfer Learning,Wataru Kumagai,Kanagawa University
NIPS,2016,Can Active Memory Replace Attention?,Łukasz Kaiser,Google Brain
NIPS,2016,Can Active Memory Replace Attention?,Samy Bengio,Google Brain
NIPS,2016,Understanding the Effective Receptive Field in Deep Convolutional Neural Networks,Wenjie Luo,University of Toronto
NIPS,2016,Understanding the Effective Receptive Field in Deep Convolutional Neural Networks,Yujia Li,University of Toronto
NIPS,2016,Understanding the Effective Receptive Field in Deep Convolutional Neural Networks,Raquel Urtasun,University of Toronto
NIPS,2016,Understanding the Effective Receptive Field in Deep Convolutional Neural Networks,Richard Zemel,Vector Institute/University of Toronto
NIPS,2016,Local Similarity-Aware Deep Feature Embedding,Chen Huang,Chinese University of HongKong
NIPS,2016,Local Similarity-Aware Deep Feature Embedding,Chen Change Loy,The Chinese University of HK
NIPS,2016,Local Similarity-Aware Deep Feature Embedding,Xiaoou Tang,The Chinese University of Hong Kong
NIPS,2016,End-to-End Kernel Learning with Supervised Convolutional Kernel Networks,Julien Mairal,Inria
NIPS,2016,Single-Image Depth Perception in the Wild,Weifeng Chen,University of Michigan
NIPS,2016,Single-Image Depth Perception in the Wild,Zhao Fu,University of Michigan
NIPS,2016,Single-Image Depth Perception in the Wild,Dawei Yang,University of Michigan
NIPS,2016,Single-Image Depth Perception in the Wild,Jia Deng,University of Michigan
NIPS,2016,Without-Replacement Sampling for Stochastic Gradient Methods,Ohad Shamir,Weizmann Institute of Science
NIPS,2016,Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity,Amit Daniely,Google Brain
NIPS,2016,Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity,Roy Frostig,Stanford University
NIPS,2016,Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity,Yoram Singer,Google
NIPS,2016,R-FCN: Object Detection via Region-based Fully Convolutional Networks,jifeng dai,Microsoft
NIPS,2016,R-FCN: Object Detection via Region-based Fully Convolutional Networks,Yi Li,Tsinghua University
NIPS,2016,R-FCN: Object Detection via Region-based Fully Convolutional Networks,Kaiming He,Microsoft
NIPS,2016,R-FCN: Object Detection via Region-based Fully Convolutional Networks,Jian Sun,Microsoft
NIPS,2016,Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks,Tianfan Xue,MIT CSAIL
NIPS,2016,Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks,Jiajun Wu,MIT
NIPS,2016,Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks,Katie Bouman,MIT
NIPS,2016,Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks,Bill Freeman,MIT/Google
NIPS,2016,Learning What and Where to Draw,Scott E Reed,University of Michigan
NIPS,2016,Learning What and Where to Draw,Zeynep Akata,Max Planck Institute for Informatics
NIPS,2016,Learning What and Where to Draw,Santosh Mohan,University of MIchigan
NIPS,2016,Learning What and Where to Draw,Samuel Tenka,University of MIchigan
NIPS,2016,Learning What and Where to Draw,Bernt Schiele,Max Planck Institute for Informatics
NIPS,2016,Learning What and Where to Draw,Honglak Lee,University of Michigan
NIPS,2016,Consistent Estimation of Functions of Data Missing Non-Monotonically and Not at Random,Ilya Shpitser,Johns Hopkins University
NIPS,2016,Stochastic Online AUC Maximization,Yiming Ying,State University of New York at Albany
NIPS,2016,Stochastic Online AUC Maximization,Longyin Wen,State University of New York at Albany
NIPS,2016,Stochastic Online AUC Maximization,Siwei Lyu,State University of New York at Albany
NIPS,2016,Deep Learning without Poor Local Minima,Kenji Kawaguchi,MIT
NIPS,2016,Regularized Nonlinear Acceleration,Damien Scieur,INRIA - ENS
NIPS,2016,Regularized Nonlinear Acceleration,Alexandre d'Aspremont,CNRS - Ecole Normale Supérieure
NIPS,2016,Regularized Nonlinear Acceleration,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2016,Learning to Poke by Poking: Experiential Learning of Intuitive Physics,Pulkit Agrawal,UC Berkeley
NIPS,2016,Learning to Poke by Poking: Experiential Learning of Intuitive Physics,Ashvin Nair,UC Berkeley
NIPS,2016,Learning to Poke by Poking: Experiential Learning of Intuitive Physics,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2016,Learning to Poke by Poking: Experiential Learning of Intuitive Physics,Jitendra Malik,UC Berkeley
NIPS,2016,Learning to Poke by Poking: Experiential Learning of Intuitive Physics,Sergey Levine,University of Washington
NIPS,2016,Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks,Tim Salimans,Algoritmica
NIPS,2016,Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks,Durk Kingma,Google
NIPS,2016,Linear-Memory and Decomposition-Invariant Linearly Convergent Conditional Gradient Algorithm for Structured Polytopes,Dan Garber,Toyota Technological Institute at Chicago
NIPS,2016,Linear-Memory and Decomposition-Invariant Linearly Convergent Conditional Gradient Algorithm for Structured Polytopes,Dan Garber,Toyota Technological Institute at Chicago
NIPS,2016,Linear-Memory and Decomposition-Invariant Linearly Convergent Conditional Gradient Algorithm for Structured Polytopes,Ofer Meshi,Google
NIPS,2016,Achieving the KS threshold in the general stochastic block model with linearized acyclic belief propagation,Emmanuel Abbe,Princeton University
NIPS,2016,Achieving the KS threshold in the general stochastic block model with linearized acyclic belief propagation,Colin Sandon,Princeton University
NIPS,2016,Orthogonal Random Features,Felix Xinnan Yu,Google Research
NIPS,2016,Orthogonal Random Features,Ananda Theertha Suresh,"University of California, San Diego"
NIPS,2016,Orthogonal Random Features,Krzysztof M Choromanski,Google Brain Robotics
NIPS,2016,Orthogonal Random Features,Daniel Holtmann-Rice,Google Inc
NIPS,2016,Orthogonal Random Features,Sanjiv Kumar,Google
NIPS,2016,Universal Correspondence Network,Christopher B Choy,Stanford University
NIPS,2016,Universal Correspondence Network,Manmohan Chandraker,NEC Labs America
NIPS,2016,Universal Correspondence Network,JunYoung Gwak,Stanford University
NIPS,2016,Universal Correspondence Network,Silvio Savarese,Stanford University
NIPS,2016,The Multiscale Laplacian Graph Kernel,Risi Kondor,The University of Chicago
NIPS,2016,The Multiscale Laplacian Graph Kernel,Horace Pan,UChicago
NIPS,2016,Generalization of ERM in Stochastic Convex Optimization: The Dimension Strikes Back,Vitaly Feldman,Google Brain
NIPS,2016,Large-Scale Price Optimization via Network Flow,Shinji Ito,NEC Coorporation
NIPS,2016,Large-Scale Price Optimization via Network Flow,Ryohei Fujimaki,NEC Data Science Research Laboratories
NIPS,2016,Bayesian Optimization with Robust Bayesian Neural Networks,Jost Tobias Springenberg,University of Freiburg
NIPS,2016,Bayesian Optimization with Robust Bayesian Neural Networks,Aaron Klein,University of Freiburg
NIPS,2016,Bayesian Optimization with Robust Bayesian Neural Networks,Stefan Falkner,University of Freiburg
NIPS,2016,Bayesian Optimization with Robust Bayesian Neural Networks,Frank Hutter,University of Freiburg
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Vladimir Golkov,Technical University of Munich
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Marcin J Skwark,Vanderbilt University
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Antonij Golkov,University of Augsburg
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Alexey Dosovitskiy,University of Freiburg
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Thomas Brox,University of Freiburg
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Jens Meiler,Vanderbilt University
NIPS,2016,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,Daniel Cremers,Technical University of Munich
NIPS,2016,Supervised Word Mover's Distance,Gao Huang,Cornell University
NIPS,2016,Supervised Word Mover's Distance,Chuan Guo,Cornell University
NIPS,2016,Supervised Word Mover's Distance,Matt J Kusner,Washington University in St. Louis
NIPS,2016,Supervised Word Mover's Distance,Yu Sun,Cornell University
NIPS,2016,Supervised Word Mover's Distance,Fei Sha,University of Southern California
NIPS,2016,Supervised Word Mover's Distance,Kilian Weinberger,Cornell University
NIPS,2016,Beyond Exchangeability: The Chinese Voting Process,Moontae Lee,Cornell University
NIPS,2016,Beyond Exchangeability: The Chinese Voting Process,Seok Hyun Jin,Cornell University
NIPS,2016,Beyond Exchangeability: The Chinese Voting Process,David Mimno,Cornell University
NIPS,2016,Poisson-Gamma dynamical systems,Aaron Schein,UMass Amherst
NIPS,2016,Poisson-Gamma dynamical systems,Hanna Wallach,Microsoft Research
NIPS,2016,Poisson-Gamma dynamical systems,Mingyuan Zhou,University of Texas at Austin
NIPS,2016,Interpretable Distribution Features with Maximum Testing Power,Wittawat Jitkrittum,Gatsby Unit
NIPS,2016,Interpretable Distribution Features with Maximum Testing Power,Zoltán Szabó,École Polytechnique
NIPS,2016,Interpretable Distribution Features with Maximum Testing Power,Kacper P Chwialkowski,Gatsby Unit
NIPS,2016,Interpretable Distribution Features with Maximum Testing Power,Arthur Gretton,"Gatsby Unit, UCL"
NIPS,2016,Dense Associative Memory for Pattern Recognition,Dmitry Krotov,Institute for Advanced Study
NIPS,2016,Dense Associative Memory for Pattern Recognition,John J. Hopfield,Princeton Neuroscience Institute
NIPS,2016,Relevant sparse codes with variational information bottleneck,Matthew Chalk,IST Austria
NIPS,2016,Relevant sparse codes with variational information bottleneck,Olivier Marre,Institut de la vision
NIPS,2016,Relevant sparse codes with variational information bottleneck,Gasper Tkacik,Institute of Science and Technology Austria
NIPS,2016,"Examples are not enough, learn to criticize! Criticism for Interpretability",Been Kim,Google Brain
NIPS,2016,"Examples are not enough, learn to criticize! Criticism for Interpretability",Sanmi Koyejo,UIUC
NIPS,2016,"Examples are not enough, learn to criticize! Criticism for Interpretability",Rajiv Khanna,UT Austin
NIPS,2016,Showing versus doing: Teaching by demonstration,Mark Ho,Brown University
NIPS,2016,Showing versus doing: Teaching by demonstration,Michael Littman,Brown University
NIPS,2016,Showing versus doing: Teaching by demonstration,James MacGlashan,Brown University
NIPS,2016,Showing versus doing: Teaching by demonstration,Fiery Cushman,Harvard University
NIPS,2016,Showing versus doing: Teaching by demonstration,Joe Austerweil,University of Wisconsin-Madison
NIPS,2016,Showing versus doing: Teaching by demonstration,Joe L Austerweil,University of Wisconsin-Madison
NIPS,2017,Scalable Variational Inference for Dynamical Systems,Nico S Gorbach,Swiss Federal Institute of Technology Zurich (ETHZ)
NIPS,2017,Scalable Variational Inference for Dynamical Systems,Stefan Bauer,ETH Zürich
NIPS,2017,Scalable Variational Inference for Dynamical Systems,Joachim M Buhmann,ETH Zurich
NIPS,2017,Active Learning from Peers,Keerthiram Murugesan,Carnegie Mellon University
NIPS,2017,Active Learning from Peers,Jaime Carbonell,CMU
NIPS,2017,Consistent Multitask Learning with Nonlinear Output Relations,Carlo Ciliberto,University College London
NIPS,2017,Consistent Multitask Learning with Nonlinear Output Relations,Alessandro Rudi,INRIA
NIPS,2017,Consistent Multitask Learning with Nonlinear Output Relations,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2017,Consistent Multitask Learning with Nonlinear Output Relations,Massimiliano Pontil,IIT & UCL
NIPS,2017,Label Efficient Learning of Transferable Representations acrosss Domains and Tasks,Alan Luo,Stanford University
NIPS,2017,Label Efficient Learning of Transferable Representations acrosss Domains and Tasks,Yuliang Zou,Virginia Tech
NIPS,2017,Label Efficient Learning of Transferable Representations acrosss Domains and Tasks,Judy Hoffman,UC Berkeley
NIPS,2017,Label Efficient Learning of Transferable Representations acrosss Domains and Tasks,Li Fei-Fei,Stanford University & Google
NIPS,2017,Matching neural paths: transfer from recognition to correspondence search,Nikolay Savinov,ETH Zurich
NIPS,2017,Matching neural paths: transfer from recognition to correspondence search,Lubor Ladicky,ETH Zurich
NIPS,2017,Matching neural paths: transfer from recognition to correspondence search,Marc Pollefeys,ETH Zurich
NIPS,2017,SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability,Maithra Raghu,Cornell University and Google Brain
NIPS,2017,SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability,Justin Gilmer,Google Brain
NIPS,2017,SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability,Jason Yosinski,Uber
NIPS,2017,SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability,Jascha Sohl-Dickstein,Google Brain
NIPS,2017,PRUNE: Preserving Proximity and Global Ranking for Network Embedding,Yi-An Lai,National Taiwan University
NIPS,2017,PRUNE: Preserving Proximity and Global Ranking for Network Embedding,Chin-Chi Hsu,Academia Sinica
NIPS,2017,PRUNE: Preserving Proximity and Global Ranking for Network Embedding,Wen Hao Chen,National Taiwan University
NIPS,2017,PRUNE: Preserving Proximity and Global Ranking for Network Embedding,Mi-Yen Yeh,Academia Sinica
NIPS,2017,PRUNE: Preserving Proximity and Global Ranking for Network Embedding,Shou-De Lin,National Taiwan University
NIPS,2017,Learning Graph Representations with Embedding Propagation,Alberto Garcia Duran,NEC Europe
NIPS,2017,Learning Graph Representations with Embedding Propagation,Mathias Niepert,NEC Labs Europe
NIPS,2017,Unsupervised Sequence Classification using Sequential Output Statistics,Yu Liu,SUNY Buffalo
NIPS,2017,Unsupervised Sequence Classification using Sequential Output Statistics,Jianshu Chen,"Microsoft Research, Redmond, W"
NIPS,2017,Unsupervised Sequence Classification using Sequential Output Statistics,Li Deng,Citadel
NIPS,2017,Probabilistic Rule Realization and Selection,Haizi Yu,University of Illinois at Urbana-Champaign
NIPS,2017,Probabilistic Rule Realization and Selection,Tianxi Li,University of Michigan
NIPS,2017,Probabilistic Rule Realization and Selection,Lav Varshney,University of Illinois at Urbana-Champaign
NIPS,2017,A Minimax Optimal Algorithm for Crowdsourcing,Thomas Bonald,Telecom ParisTech
NIPS,2017,A Minimax Optimal Algorithm for Crowdsourcing,Richard Combes,Centrale-Supelec
NIPS,2017,Introspective Classification with Convolutional Nets,Long Jin,University of California San Diego
NIPS,2017,Introspective Classification with Convolutional Nets,Justin Lazarow,UC San Diego
NIPS,2017,Introspective Classification with Convolutional Nets,Zhuowen Tu,"University of California, San Diego"
NIPS,2017,Adaptive Classification for Prediction Under a Budget,Feng Nan,Boston University
NIPS,2017,Adaptive Classification for Prediction Under a Budget,Venkatesh Saligrama,Boston University
NIPS,2017,Learning with Feature Evolvable Streams,Bo-Jian Hou,LAMDA Group
NIPS,2017,Learning with Feature Evolvable Streams,Lijun Zhang,Nanjing University (NJU)
NIPS,2017,Learning with Feature Evolvable Streams,Zhi-Hua Zhou,Nanjing University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Paroma Varma,Stanford University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Bryan He,Stanford University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Payal Bajaj,Stanford University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Nishith Khandwala,Stanford University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Imon Banerjee,Stanford University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Daniel Rubin,Stanford University
NIPS,2017,Inferring Generative Model Structure with Static Analysis,Chris Ré,Stanford
NIPS,2017,Scalable Model Selection for Belief Networks,Zhao Song,Duke University
NIPS,2017,Scalable Model Selection for Belief Networks,Yusuke Muraoka,
NIPS,2017,Scalable Model Selection for Belief Networks,Ryohei Fujimaki,NEC Data Science Research Laboratories
NIPS,2017,Scalable Model Selection for Belief Networks,Lawrence Carin,Duke University
NIPS,2017,"Time-dependent spatially varying graphical models, with application to brain fMRI data analysis",Kristjan Greenewald,University of Michigan
NIPS,2017,"Time-dependent spatially varying graphical models, with application to brain fMRI data analysis",Seyoung Park,Yale University
NIPS,2017,"Time-dependent spatially varying graphical models, with application to brain fMRI data analysis",Shuheng Zhou,University of Michigan
NIPS,2017,"Time-dependent spatially varying graphical models, with application to brain fMRI data analysis",Alexander Giessing,University of Michigan
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Kris Bouchard,Lawrence Berkeley National Laboratory
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Alejandro Bujan,UC Berkeley
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Farbod Roosta-Khorasani,University of California Berkeley
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Shashanka Ubaru,University of Minnesota
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Mr. Prabhat,LBL/NERSC
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Antoine Snijders,
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Jian-Hua Mao,
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Edward Chang,
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Michael W Mahoney,UC Berkeley
NIPS,2017,Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction,Sharmodeep Bhattacharya,Oregon State University
NIPS,2017,Maxing and Ranking with Few Assumptions,Moein Falahatgar,UCSD
NIPS,2017,Maxing and Ranking with Few Assumptions,Yi Hao,UCSD
NIPS,2017,Maxing and Ranking with Few Assumptions,Alon Orlitsky,"University of California, San Diego"
NIPS,2017,Maxing and Ranking with Few Assumptions,Venkatadheeraj Pichapati,UC San Diego
NIPS,2017,Maxing and Ranking with Few Assumptions,Vaishakh Ravindrakumar,UC San Diego
NIPS,2017,Kernel functions based on triplet comparisons,Matthäus Kleindessner,University of Tübingen
NIPS,2017,Kernel functions based on triplet comparisons,Ulrike von Luxburg,University of Tübingen
NIPS,2017,Learning A Structured Optimal Bipartite Graph for Co-Clustering,Feiping Nie,University of Texas Arlington
NIPS,2017,Learning A Structured Optimal Bipartite Graph for Co-Clustering,Xiaoqian Wang,University of Pittsburgh
NIPS,2017,Learning A Structured Optimal Bipartite Graph for Co-Clustering,Cheng Deng,"School of Electronic Engineering, Xidian University, China"
NIPS,2017,Learning A Structured Optimal Bipartite Graph for Co-Clustering,Heng Huang,University of Pittsburgh
NIPS,2017,Kernel Feature Selection via Conditional Covariance Minimization,Jianbo Chen,"University of California, Berkeley"
NIPS,2017,Kernel Feature Selection via Conditional Covariance Minimization,Mitchell Stern,UC Berkeley
NIPS,2017,Kernel Feature Selection via Conditional Covariance Minimization,Martin J Wainwright,UC Berkeley
NIPS,2017,Kernel Feature Selection via Conditional Covariance Minimization,Michael Jordan,UC Berkeley
NIPS,2017,Improved Graph Laplacian via Geometric Self-Consistency,Dominique Perrault-Joncas,Google
NIPS,2017,Improved Graph Laplacian via Geometric Self-Consistency,Marina Meila,University of Washington
NIPS,2017,Improved Graph Laplacian via Geometric Self-Consistency,James McQueen,University of Washington
NIPS,2017,Mixture-Rank Matrix Approximation for Collaborative Filtering,Dongsheng Li,IBM Research - China
NIPS,2017,Mixture-Rank Matrix Approximation for Collaborative Filtering,Kehan Chen,Tongji University
NIPS,2017,Mixture-Rank Matrix Approximation for Collaborative Filtering,Wei Liu,Tencent AI Lab
NIPS,2017,Mixture-Rank Matrix Approximation for Collaborative Filtering,Tun Lu,Fudan University
NIPS,2017,Mixture-Rank Matrix Approximation for Collaborative Filtering,Ning Gu,Fudan University
NIPS,2017,Mixture-Rank Matrix Approximation for Collaborative Filtering,Stephen Chu,IBM Research - China
NIPS,2017,Hierarchical Methods of Moments,Matteo Ruffini,UPC
NIPS,2017,Hierarchical Methods of Moments,Guillaume Rabusseau,McGill University
NIPS,2017,Hierarchical Methods of Moments,Borja Balle,
NIPS,2017,Multitask Spectral Learning of Weighted Automata,Guillaume Rabusseau,McGill University
NIPS,2017,Multitask Spectral Learning of Weighted Automata,Borja Balle,
NIPS,2017,Multitask Spectral Learning of Weighted Automata,Joelle Pineau,McGill University
NIPS,2017,Principles of Riemannian Geometry  in Neural Networks,Michael Hauser,Pennsylvania State University
NIPS,2017,Principles of Riemannian Geometry  in Neural Networks,Asok Ray,Pennsylvania State University
NIPS,2017,Subset Selection and Summarization in Sequential Data,Ehsan Elhamifar,Northeastern University
NIPS,2017,Subset Selection and Summarization in Sequential Data,Clara De Paolis Kaluza,Northeastern University
NIPS,2017,On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning,Xingguo Li,University of Minnesota
NIPS,2017,On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning,Lin Yang,Johns Hopkins University
NIPS,2017,On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning,Jason Ge,Princeton University
NIPS,2017,On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning,Jarvis Haupt,University of Minnesota
NIPS,2017,On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning,Tong Zhang,Tencent AI Lab
NIPS,2017,On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning,Tuo Zhao,Georgia Tech
NIPS,2017,k-Support and Ordered Weighted Sparsity for Overlapping Groups: Hardness and Algorithms,Cong Han Lim,University of Wisconsin-Madison
NIPS,2017,k-Support and Ordered Weighted Sparsity for Overlapping Groups: Hardness and Algorithms,Stephen Wright,UW-Madison
NIPS,2017,Parametric Simplex Method for Sparse Learning,Haotian Pang,Princeton University
NIPS,2017,Parametric Simplex Method for Sparse Learning,Han Liu,Tencent AI Lab
NIPS,2017,Parametric Simplex Method for Sparse Learning,Robert J Vanderbei,Princeton University
NIPS,2017,Parametric Simplex Method for Sparse Learning,Tuo Zhao,Georgia Tech
NIPS,2017,Robust Hypothesis Test for Nonlinear Effect with Gaussian Processes,Jeremiah Liu,Harvard University
NIPS,2017,Robust Hypothesis Test for Nonlinear Effect with Gaussian Processes,Brent Coull,Harvard University
NIPS,2017,Invariance and Stability of Deep Convolutional Representations,Alberto Bietti,Inria
NIPS,2017,Invariance and Stability of Deep Convolutional Representations,Julien Mairal,Inria
NIPS,2017,An Empirical Study on The Properties of Random Bases for Kernel Methods,Maximilian Alber,TU Berlin
NIPS,2017,An Empirical Study on The Properties of Random Bases for Kernel Methods,Pieter-Jan Kindermans,Google Brain Resident
NIPS,2017,An Empirical Study on The Properties of Random Bases for Kernel Methods,Kristof Schütt,TU Berlin
NIPS,2017,An Empirical Study on The Properties of Random Bases for Kernel Methods,Klaus-Robert Müller,TU Berlin
NIPS,2017,An Empirical Study on The Properties of Random Bases for Kernel Methods,Fei Sha,University of Southern California (USC)
NIPS,2017,Max-Margin Invariant Features from Transformed Unlabelled Data,Dipan Pal,Carnegie Mellon University
NIPS,2017,Max-Margin Invariant Features from Transformed Unlabelled Data,Ashwin Kannan,Carnegie Mellon University
NIPS,2017,Max-Margin Invariant Features from Transformed Unlabelled Data,Gautam Arakalgud,Carnegie Mellon University
NIPS,2017,Max-Margin Invariant Features from Transformed Unlabelled Data,Marios Savvides,Carnegie Mellon University
NIPS,2017,SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud,Zahra Ghodsi,New York University
NIPS,2017,SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud,Tianyu Gu,NYU
NIPS,2017,SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud,Siddharth Garg,NYU
NIPS,2017,The Importance of Communities for Learning to Influence,Eric Balkanski,Harvard University
NIPS,2017,The Importance of Communities for Learning to Influence,Nicole Immorlica,Microsoft Research
NIPS,2017,The Importance of Communities for Learning to Influence,Yaron Singer,Harvard University
NIPS,2017,A Meta-Learning Perspective on Cold-Start Recommendations for Items,Manasi Vartak,Massachusetts Institute of Technology
NIPS,2017,A Meta-Learning Perspective on Cold-Start Recommendations for Items,Arvind Thiagarajan,Twitter
NIPS,2017,A Meta-Learning Perspective on Cold-Start Recommendations for Items,Conrado Miranda,
NIPS,2017,A Meta-Learning Perspective on Cold-Start Recommendations for Items,Jeshua Bratman,Twitter
NIPS,2017,A Meta-Learning Perspective on Cold-Start Recommendations for Items,Hugo Larochelle,Google Brain
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Urs Köster,Intel Corporation
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Tristan Webb,Intel / Nervana
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Xin Wang,Intel Corporation
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Marcel Nassar,Intel Corporation
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Arjun K Bansal,Intel Nervana
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,William Constable,Intel
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Oguz Elibol,Intel Nervana
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Stewart Hall,Intel
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Luke Hornof,Intel Nervana
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Amir Khosrowshahi,Intel
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Carey Kloss,Intel
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Ruby J Pai,Intel Corporation
NIPS,2017,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,Naveen Rao,Intel
NIPS,2017,Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes,Ahmed M. Alaa,UCLA
NIPS,2017,Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes,Mihaela van der Schaar,UCLA and Oxford University
NIPS,2017,Tomography of the London Underground: a Scalable Model for Origin-Destination Data,Nicolò Colombo,University College London
NIPS,2017,Tomography of the London Underground: a Scalable Model for Origin-Destination Data,Ricardo Silva,ucl.ac.uk
NIPS,2017,Tomography of the London Underground: a Scalable Model for Origin-Destination Data,Soong Moon Kang,University College London
NIPS,2017,Matching on Balanced Nonlinear Representations for Treatment Effects Estimation,Sheng Li,Adobe Research
NIPS,2017,Matching on Balanced Nonlinear Representations for Treatment Effects Estimation,Yun Fu,Northeastern University
NIPS,2017,Hiding Images in Plain Sight: Deep Steganography,Shumeet Baluja,"Google, Inc."
NIPS,2017,Unbounded cache model for online language modeling with open vocabulary,Edouard Grave,Facebook AI Research
NIPS,2017,Unbounded cache model for online language modeling with open vocabulary,Moustapha Cisse,Facebook AI Research
NIPS,2017,Unbounded cache model for online language modeling with open vocabulary,Armand Joulin,Facebook AI research
NIPS,2017,Deconvolutional Paragraph Representation Learning,Yizhe Zhang,Duke University
NIPS,2017,Deconvolutional Paragraph Representation Learning,Dinghan Shen,Duke University
NIPS,2017,Deconvolutional Paragraph Representation Learning,Guoyin Wang,Duke University
NIPS,2017,Deconvolutional Paragraph Representation Learning,Zhe Gan,Duke University
NIPS,2017,Deconvolutional Paragraph Representation Learning,Ricardo Henao,Duke University
NIPS,2017,Deconvolutional Paragraph Representation Learning,Lawrence Carin,Duke University
NIPS,2017,Teaching Machines to Describe Images with Natural Language Feedback,huan ling,university of toronto
NIPS,2017,Teaching Machines to Describe Images with Natural Language Feedback,Sanja Fidler,University of Toronto
NIPS,2017,Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks,Wei-Sheng Lai,"University of California, Merced"
NIPS,2017,Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks,Jia-Bin Huang,Virginia Tech
NIPS,2017,Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks,Ming-Hsuan Yang,UC Merced
NIPS,2017,Associative Embedding: End-to-End Learning for Joint Detection and Grouping,Alejandro Newell,University of Michigan
NIPS,2017,Associative Embedding: End-to-End Learning for Joint Detection and Grouping,Zhiao Huang,"IIIS, Tsinghua University"
NIPS,2017,Associative Embedding: End-to-End Learning for Joint Detection and Grouping,Jia Deng,University of Michigan
NIPS,2017,Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction,Dan Xu,University of Trento
NIPS,2017,Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction,Wanli Ouyang,The Chinese University of Hong Kong
NIPS,2017,Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction,Xavier Alameda-Pineda,INRIA
NIPS,2017,Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction,Elisa Ricci,
NIPS,2017,Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction,Xiaogang Wang,The Chinese University of Hong Kong
NIPS,2017,Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction,Nicu Sebe,University of Trento
NIPS,2017,Incorporating Side Information by Adaptive Convolution,Di Kang,City University of Hong Kong
NIPS,2017,Incorporating Side Information by Adaptive Convolution,Debarun Dhar,City University of Hong Kong
NIPS,2017,Incorporating Side Information by Adaptive Convolution,Antoni Chan,City University of Hong Kong
NIPS,2017,SVD-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks,Kyuhong Shim,Seoul National University
NIPS,2017,SVD-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks,Minjae Lee,Seoul National University
NIPS,2017,SVD-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks,Iksoo Choi,Seoul National University
NIPS,2017,SVD-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks,Yoonho Boo,Seoul National University
NIPS,2017,SVD-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks,Wonyong Sung,Seoul National University
NIPS,2017,A Regularized Framework for Sparse and Structured Neural Attention,Vlad Niculae,Cornell University
NIPS,2017,A Regularized Framework for Sparse and Structured Neural Attention,Mathieu Blondel,NTT
NIPS,2017,Learning Hierarchical Information Flow with Recurrent Neural Modules,Danijar Hafner,University College London
NIPS,2017,Learning Hierarchical Information Flow with Recurrent Neural Modules,Alexander Irpan,Google
NIPS,2017,Learning Hierarchical Information Flow with Recurrent Neural Modules,James Davidson,Google Brain
NIPS,2017,Learning Hierarchical Information Flow with Recurrent Neural Modules,Nicolas Heess,Google DeepMind
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Benjamin XIAO,Georgia Institute of Technology
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Mehrdad Farajtabar,Georgia Tech
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Xiaojing Ye,Georgia State University
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Junchi Yan,IBM Research - China
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Xiaokang Yang,Shanghai Jiao Tong University
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Le Song,Georgia Institute of Technology
NIPS,2017,Wasserstein Learning of Deep Generative Point Process Models,Hongyuan Zha,Georgia Tech
NIPS,2017,Neural Variational Inference and Learning in Undirected Graphical Models,Volodymyr Kuleshov,Stanford University
NIPS,2017,Neural Variational Inference and Learning in Undirected Graphical Models,Stefano Ermon,Stanford
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Yuchen Pu,Duke University
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Weiyao Wang,Duke University
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Ricardo Henao,Duke University
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Liqun Chen,Duke University
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Zhe Gan,Duke University
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Chunyuan Li,Duke University
NIPS,2017,Adversarial Symmetric Variational Autoencoder,Lawrence Carin,Duke University
NIPS,2017,Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space,Liwei Wang,Peking University
NIPS,2017,Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2017,Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space,Svetlana Lazebnik,UIUC
NIPS,2017,One-Shot Imitation Learning,Yan Duan,
NIPS,2017,One-Shot Imitation Learning,Marcin Andrychowicz,OpenAI
NIPS,2017,One-Shot Imitation Learning,Bradly Stadie,OpenAI
NIPS,2017,One-Shot Imitation Learning,OpenAI Jonathan Ho,"OpenAI, UC Berkeley"
NIPS,2017,One-Shot Imitation Learning,Jonas Schneider,OpenAI
NIPS,2017,One-Shot Imitation Learning,Ilya Sutskever,
NIPS,2017,One-Shot Imitation Learning,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2017,One-Shot Imitation Learning,Wojciech Zaremba,OpenAI
NIPS,2017,Reconstruct & Crush Network,Erinc Merdivan,Austrian Institute of Technology GmbH
NIPS,2017,Reconstruct & Crush Network,Mohammad Reza Loghmani,TU Wien
NIPS,2017,Reconstruct & Crush Network,Matthieu Geist,Université de Lorraine
NIPS,2017,Fader Networks:Manipulating Images by Sliding Attributes,Guillaume Lample,Facebook AI Research
NIPS,2017,Fader Networks:Manipulating Images by Sliding Attributes,Neil Zeghidour,Facebook A.I. Research / Ecole Normale Supérieure
NIPS,2017,Fader Networks:Manipulating Images by Sliding Attributes,Nicolas Usunier,Facebook AI Research
NIPS,2017,Fader Networks:Manipulating Images by Sliding Attributes,Antoine Bordes,Facebook AI Research
NIPS,2017,Fader Networks:Manipulating Images by Sliding Attributes,Ludovic DENOYER,Universite Pierre et Marie Curie - Paris
NIPS,2017,Fader Networks:Manipulating Images by Sliding Attributes,Marc'Aurelio Ranzato,Facebook
NIPS,2017,VAIN: Attentional Multi-agent Predictive Modeling,Yedid Hoshen,Facebook AI Research
NIPS,2017,Gated Recurrent Convolution Neural Network for OCR,Jianfeng Wang,Beijing University of Posts and Telecommunications
NIPS,2017,Gated Recurrent Convolution Neural Network for OCR,Xiaolin Hu,Tsinghua University
NIPS,2017,Learning Efficient Object Detection Models with Knowledge Distillation,Guobin Chen,University of Missouri
NIPS,2017,Learning Efficient Object Detection Models with Knowledge Distillation,Wongun Choi,NEC Laboratories
NIPS,2017,Learning Efficient Object Detection Models with Knowledge Distillation,Xiang Yu,NEC Laboratories America
NIPS,2017,Learning Efficient Object Detection Models with Knowledge Distillation,Tony Han,University of Missouri
NIPS,2017,Learning Efficient Object Detection Models with Knowledge Distillation,Manmohan Chandraker,"University of California, San Diego"
NIPS,2017,Langevin Dynamics with Continuous Tempering for Training Deep Neural Networks,Lincoln Ye,University of Cambridge
NIPS,2017,Langevin Dynamics with Continuous Tempering for Training Deep Neural Networks,Zhanxing Zhu,Peking University / Beijing Institute of Big Data Research
NIPS,2017,Langevin Dynamics with Continuous Tempering for Training Deep Neural Networks,Rafal Mantiuk,University of Cambridge
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Yingce Xia,University of Science and Technology of China
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Fei Tian,Miicrosoft Research
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Lijun Wu,Sun Yat-sen University
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Jianxin Lin,USTC
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Tao Qin,Microsoft Research
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Nenghai Yu,University of Science and Technology of China
NIPS,2017,Deliberation Networks: Sequence Generation Beyond One-Pass Decoding,Tie-Yan Liu,Microsoft Research
NIPS,2017,Neural Program Meta-Induction,Jacob Devlin,Microsoft Research
NIPS,2017,Neural Program Meta-Induction,Rudy Bunel,Oxford University
NIPS,2017,Neural Program Meta-Induction,Rishabh Singh,Microsoft Research
NIPS,2017,Neural Program Meta-Induction,Matthew Hausknecht,Microsoft Research
NIPS,2017,Neural Program Meta-Induction,Pushmeet Kohli,DeepMind
NIPS,2017,Saliency-based Sequential Image Attention with Multiset Prediction,Sean Welleck,NYU
NIPS,2017,Saliency-based Sequential Image Attention with Multiset Prediction,Jialin Mao,New York University
NIPS,2017,Saliency-based Sequential Image Attention with Multiset Prediction,Kyunghyun Cho,NYU
NIPS,2017,Saliency-based Sequential Image Attention with Multiset Prediction,Zheng Zhang,Shanghai New York Univeristy
NIPS,2017,Protein Interface Prediction using Graph Convolutional Networks,Alex Fout,Colorado State University
NIPS,2017,Protein Interface Prediction using Graph Convolutional Networks,Jonathon Byrd,Colorado State University
NIPS,2017,Protein Interface Prediction using Graph Convolutional Networks,Basir Shariat,Colorado State University
NIPS,2017,Protein Interface Prediction using Graph Convolutional Networks,Asa Ben-Hur,Colorado State University
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Jian Zhao,National University of Singapore
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Lin Xiong,Panasonic R&D Center Singapore
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Panasonic Karlekar Jayashree,"Panasonic, Singapore"
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Jianshu Li,National University of Singapore
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Fang Zhao,National University of Singapore
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Zhecan Wang,Franklin. W. Olin College of Engineering
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Panasonic Sugiri Pranata,"Panasonic, Singapore"
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Panasonic Shengmei Shen,"Panasonic, Singapore"
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Shuicheng Yan,National University of Singapore
NIPS,2017,Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis,Jiashi Feng,National University of Singapore
NIPS,2017,Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks,Arash Vahdat,D-Wave Systems Inc.
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Eirikur Agustsson,ETH Zurich
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Fabian Mentzer,ETH Zurich
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Michael Tschannen,ETH Zurich
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Lukas Cavigelli,ETH Zurich
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Radu Timofte,ETH Zurich
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Luca Benini,ETH Zurich
NIPS,2017,Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations,Luc V Gool,"Computer Vision Lab, ETH Zurich"
NIPS,2017,Selective Classification for Deep Neural Networks,Yonatan Geifman,Technion
NIPS,2017,Selective Classification for Deep Neural Networks,Ran El-Yaniv,Technion
NIPS,2017,Lower bounds on the robustness to adversarial perturbations,Jonathan Peck,Ghent University
NIPS,2017,Lower bounds on the robustness to adversarial perturbations,Joris Roels,Ghent University
NIPS,2017,Lower bounds on the robustness to adversarial perturbations,Bart Goossens,Ghent University
NIPS,2017,Lower bounds on the robustness to adversarial perturbations,Yvan Saeys,Ghent University
NIPS,2017,Sobolev Training for Neural Networks,Wojciech Czarnecki,DeepMind
NIPS,2017,Sobolev Training for Neural Networks,Simon Osindero,DeepMind
NIPS,2017,Sobolev Training for Neural Networks,Max Jaderberg,DeepMind
NIPS,2017,Sobolev Training for Neural Networks,Grzegorz Swirszcz,DeepMind @ Google
NIPS,2017,Sobolev Training for Neural Networks,Razvan Pascanu,Google DeepMind
NIPS,2017,Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice,Jeffrey Pennington,Google Brain
NIPS,2017,Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice,Sam Schoenholz,Google Brain
NIPS,2017,Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice,Surya Ganguli,Stanford
NIPS,2017,Robust Imitation of Diverse Behaviors,Ziyu Wang,Deepmind
NIPS,2017,Robust Imitation of Diverse Behaviors,Josh Merel,DeepMind
NIPS,2017,Robust Imitation of Diverse Behaviors,Scott Reed,Google DeepMind
NIPS,2017,Robust Imitation of Diverse Behaviors,Nando de Freitas,DeepMind
NIPS,2017,Robust Imitation of Diverse Behaviors,Greg Wayne,Google DeepMind
NIPS,2017,Robust Imitation of Diverse Behaviors,Nicolas Heess,Google DeepMind
NIPS,2017,Variational Laws of Visual Attention for Dynamic Scenes,Dario Zanca,"University of Florence, University of Siena"
NIPS,2017,Variational Laws of Visual Attention for Dynamic Scenes,Marco Gori,University of Siena
NIPS,2017,Flexible statistical inference for mechanistic models of neural dynamics,Jan-Matthis Lueckmann,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Flexible statistical inference for mechanistic models of neural dynamics,Pedro J Goncalves,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Flexible statistical inference for mechanistic models of neural dynamics,Giacomo Bassetto,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Flexible statistical inference for mechanistic models of neural dynamics,Kaan Öcal,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Flexible statistical inference for mechanistic models of neural dynamics,Marcel Nonnenmacher,Research center caesar
NIPS,2017,Flexible statistical inference for mechanistic models of neural dynamics,Jakob H Macke,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems,Ingmar Kanitscheider,UT Austin
NIPS,2017,Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems,Ila Fiete,
NIPS,2017,A simple model of recognition and recall memory,Nisheeth Srivastava,IIT Kanpur
NIPS,2017,A simple model of recognition and recall memory,Edward Vul,UCSD
NIPS,2017,Gaussian process based nonlinear latent structure discovery in multivariate spike train data,Anqi Wu,Princeton University
NIPS,2017,Gaussian process based nonlinear latent structure discovery in multivariate spike train data,Nicholas Roy,Princeton Neuroscience Institute
NIPS,2017,Gaussian process based nonlinear latent structure discovery in multivariate spike train data,Stephen Keeley,Princeton University
NIPS,2017,Gaussian process based nonlinear latent structure discovery in multivariate spike train data,Jonathan W Pillow,Princeton University
NIPS,2017,Reconstructing perceived faces from brain activations with deep adversarial neural decoding,Yağmur Güçlütürk,Radboud University
NIPS,2017,Reconstructing perceived faces from brain activations with deep adversarial neural decoding,Umut Güçlü,Donders Institute
NIPS,2017,Reconstructing perceived faces from brain activations with deep adversarial neural decoding,Katja Seeliger,"Donders Institute for Brain, Cognition and Behaviour"
NIPS,2017,Reconstructing perceived faces from brain activations with deep adversarial neural decoding,Sander Bosch,Radboud University
NIPS,2017,Reconstructing perceived faces from brain activations with deep adversarial neural decoding,Rob van Lier,"Donders Institute for Brain, Cognition and Behaviour, Radboud University"
NIPS,2017,Reconstructing perceived faces from brain activations with deep adversarial neural decoding,Marcel A. J. van Gerven,Radboud Universiteit
NIPS,2017,Cross-Spectral Factor Analysis,Neil Gallagher,Duke University
NIPS,2017,Cross-Spectral Factor Analysis,Kyle Ulrich,
NIPS,2017,Cross-Spectral Factor Analysis,Austin Talbot,Duke University
NIPS,2017,Cross-Spectral Factor Analysis,Kafui Dzirasa,Duke University
NIPS,2017,Cross-Spectral Factor Analysis,Lawrence Carin,Duke University
NIPS,2017,Cross-Spectral Factor Analysis,David Carlson,Duke University
NIPS,2017,Regularized Modal Regression with Applications in Cognitive Impairment Prediction,Xiaoqian Wang,University of Pittsburgh
NIPS,2017,Regularized Modal Regression with Applications in Cognitive Impairment Prediction,Hong Chen,University of Pittsburgh
NIPS,2017,Regularized Modal Regression with Applications in Cognitive Impairment Prediction,Weidong Cai,The University of Sydney
NIPS,2017,Regularized Modal Regression with Applications in Cognitive Impairment Prediction,Dinggang Shen,UNC-Chapel Hill
NIPS,2017,Regularized Modal Regression with Applications in Cognitive Impairment Prediction,Heng Huang,University of Pittsburgh
NIPS,2017,Stochastic Submodular Maximization: The Case of Coverage Functions,Mohammad Karimi,ETH Zurich
NIPS,2017,Stochastic Submodular Maximization: The Case of Coverage Functions,Mario Lucic,Google Brain (Zurich)
NIPS,2017,Stochastic Submodular Maximization: The Case of Coverage Functions,Hamed Hassani,UPenn
NIPS,2017,Stochastic Submodular Maximization: The Case of Coverage Functions,Andreas Krause,ETHZ
NIPS,2017,Gradient Methods for Submodular Maximization,Hamed Hassani,UPenn
NIPS,2017,Gradient Methods for Submodular Maximization,Mahdi Soltanolkotabi,University of Southern california
NIPS,2017,Gradient Methods for Submodular Maximization,Amin Karbasi,Yale
NIPS,2017,Non-convex Finite-Sum Optimization Via SCSG Methods,Lihua Lei,UC Berkeley
NIPS,2017,Non-convex Finite-Sum Optimization Via SCSG Methods,Cheng Ju,"University of California, Berkeley"
NIPS,2017,Non-convex Finite-Sum Optimization Via SCSG Methods,Jianbo Chen,"University of California, Berkeley"
NIPS,2017,Non-convex Finite-Sum Optimization Via SCSG Methods,Michael Jordan,UC Berkeley
NIPS,2017,Influence Maximization with $\varepsilon$-Almost Submodular Threshold Functions,Qiang Li,Institute of Computing Technol
NIPS,2017,Influence Maximization with $\varepsilon$-Almost Submodular Threshold Functions,Wei Chen,Microsoft Research
NIPS,2017,Influence Maximization with $\varepsilon$-Almost Submodular Threshold Functions,Institute of Computing Xiaoming Sun,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2017,Influence Maximization with $\varepsilon$-Almost Submodular Threshold Functions,Institute of Computing Jialin Zhang,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2017,Polynomial time algorithms for dual volume sampling,Chengtao Li,MIT
NIPS,2017,Polynomial time algorithms for dual volume sampling,Stefanie Jegelka,MIT
NIPS,2017,Polynomial time algorithms for dual volume sampling,Suvrit Sra,MIT
NIPS,2017,Lookahead  Bayesian Optimization with Inequality Constraints,Remi Lam,MIT
NIPS,2017,Lookahead  Bayesian Optimization with Inequality Constraints,Karen Willcox,MIT
NIPS,2017,Learning ReLUs via Gradient Descent,Mahdi Soltanolkotabi,University of Southern california
NIPS,2017,Stochastic Mirror Descent in Variationally Coherent Optimization Problems,Zhengyuan Zhou,Stanford University
NIPS,2017,Stochastic Mirror Descent in Variationally Coherent Optimization Problems,Panayotis Mertikopoulos,CNRS (French National Center for Scientific Research)
NIPS,2017,Stochastic Mirror Descent in Variationally Coherent Optimization Problems,Nicholas Bambos,
NIPS,2017,Stochastic Mirror Descent in Variationally Coherent Optimization Problems,Stephen Boyd,Stanford University
NIPS,2017,Stochastic Mirror Descent in Variationally Coherent Optimization Problems,Peter W Glynn,Stanford University
NIPS,2017,Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds,Yuanyuan Liu,The Chinese University of Hong Kong
NIPS,2017,Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds,Fanhua Shang,The Chinese University of Hong Kong
NIPS,2017,Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds,James Cheng,The Chinese University of Hong Kong
NIPS,2017,Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds,Hong Cheng,The Chinese University of Hong Kong
NIPS,2017,Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds,Licheng Jiao,Xidian University
NIPS,2017,On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel Methods and Neural Networks,Arturs Backurs,MIT
NIPS,2017,On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel Methods and Neural Networks,Piotr Indyk,MIT
NIPS,2017,On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel Methods and Neural Networks,Ludwig Schmidt,MIT
NIPS,2017,Large-Scale Quadratically Constrained Quadratic Program via Low-Discrepancy Sequences,Kinjal Basu,LinkedIn
NIPS,2017,Large-Scale Quadratically Constrained Quadratic Program via Low-Discrepancy Sequences,Ankan Saha,Linkedin Corporation
NIPS,2017,Large-Scale Quadratically Constrained Quadratic Program via Low-Discrepancy Sequences,Shaunak Chatterjee,
NIPS,2017,A New Alternating Direction Method for Linear Programming,Sinong Wang,The Ohio State University
NIPS,2017,A New Alternating Direction Method for Linear Programming,Ness Shroff,The Ohio State University
NIPS,2017,Smooth Primal-Dual Coordinate Descent Algorithms for Nonsmooth Convex Optimization,Ahmet Alacaoglu,EPFL
NIPS,2017,Smooth Primal-Dual Coordinate Descent Algorithms for Nonsmooth Convex Optimization,Quoc Tran Dinh,"Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, North Carolina"
NIPS,2017,Smooth Primal-Dual Coordinate Descent Algorithms for Nonsmooth Convex Optimization,Olivier Fercoq,Telecom ParisTech
NIPS,2017,Smooth Primal-Dual Coordinate Descent Algorithms for Nonsmooth Convex Optimization,Volkan Cevher,EPFL
NIPS,2017,First-Order Adaptive Sample Size Methods to Reduce Complexity of Empirical Risk Minimization,Aryan Mokhtari,University of Pennsylvania
NIPS,2017,First-Order Adaptive Sample Size Methods to Reduce Complexity of Empirical Risk Minimization,Alejandro Ribeiro,University of Pennsylvania
NIPS,2017,Accelerated consensus via Min-Sum Splitting,Patrick Rebeschini,University of Oxford
NIPS,2017,Accelerated consensus via Min-Sum Splitting,Sekhar C Tatikonda,Yale University
NIPS,2017,Integration Methods and Optimization Algorithms,Damien Scieur,INRIA - ENS
NIPS,2017,Integration Methods and Optimization Algorithms,Vincent Roulet,INRIA / ENS Ulm
NIPS,2017,Integration Methods and Optimization Algorithms,Francis Bach,Inria
NIPS,2017,Integration Methods and Optimization Algorithms,Alexandre d'Aspremont,CNRS - Ecole Normale Supérieure
NIPS,2017,Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems,Celestine Dünner,IBM Research
NIPS,2017,Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems,Thomas Parnell,IBM Research
NIPS,2017,Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems,Martin Jaggi,EPFL
NIPS,2017,A Screening Rule for l1-Regularized Ising Model Estimation,Charles Kuang,"University of Wisconsin, Madison"
NIPS,2017,A Screening Rule for l1-Regularized Ising Model Estimation,Sinong Geng,University of Wisconsin Madison
NIPS,2017,A Screening Rule for l1-Regularized Ising Model Estimation,David Page,UW-Madison
NIPS,2017,Uprooting and Rerooting Higher-Order Graphical Models,Mark Rowland,University of Cambridge
NIPS,2017,Uprooting and Rerooting Higher-Order Graphical Models,Adrian Weller,University of Cambridge
NIPS,2017,Concentration of Multilinear Functions of the Ising Model with Applications to Network Data,Constantinos Daskalakis,MIT
NIPS,2017,Concentration of Multilinear Functions of the Ising Model with Applications to Network Data,Nishanth Dikkala,MIT
NIPS,2017,Concentration of Multilinear Functions of the Ising Model with Applications to Network Data,Gautam Kamath,MIT
NIPS,2017,Dynamic Importance Sampling for Anytime Bounds of the Partition Function,Qi Lou,UCI
NIPS,2017,Dynamic Importance Sampling for Anytime Bounds of the Partition Function,Rina Dechter,UCI
NIPS,2017,Dynamic Importance Sampling for Anytime Bounds of the Partition Function,Alexander Ihler,UC Irvine
NIPS,2017,Nonbacktracking Bounds on the Influence in Independent Cascade Models,Emmanuel Abbe,Princeton University
NIPS,2017,Nonbacktracking Bounds on the Influence in Independent Cascade Models,Sanjeev Kulkarni,Princeton University
NIPS,2017,Nonbacktracking Bounds on the Influence in Independent Cascade Models,Eun Jee Lee,Princeton University
NIPS,2017,Rigorous Dynamics and Consistent Estimation in Arbitrarily Conditioned Linear Systems,Allie Fletcher,UCLA
NIPS,2017,Rigorous Dynamics and Consistent Estimation in Arbitrarily Conditioned Linear Systems,Moji Sahraee-Ardakan,UCLA
NIPS,2017,Rigorous Dynamics and Consistent Estimation in Arbitrarily Conditioned Linear Systems,Sundeep Rangan,NYU-Poly
NIPS,2017,Rigorous Dynamics and Consistent Estimation in Arbitrarily Conditioned Linear Systems,Phil Schniter,Ohio State University
NIPS,2017,Gauging Variational Inference,Sung-Soo Ahn,KAIST
NIPS,2017,Gauging Variational Inference,Michael Chertkov,Los Alamos National Laboratory
NIPS,2017,Gauging Variational Inference,Jinwoo Shin,KAIST
NIPS,2017,Variational Inference via $\chi$ Upper Bound Minimization,Adji Dieng,Columbia University
NIPS,2017,Variational Inference via $\chi$ Upper Bound Minimization,Dustin Tran,Columbia University & OpenAI
NIPS,2017,Variational Inference via $\chi$ Upper Bound Minimization,Rajesh Ranganath,Princeton University
NIPS,2017,Variational Inference via $\chi$ Upper Bound Minimization,John Paisley,
NIPS,2017,Variational Inference via $\chi$ Upper Bound Minimization,David Blei,Columbia University
NIPS,2017,Collapsed variational Bayes for Markov jump processes,Boqian Zhang,Purdue University
NIPS,2017,Collapsed variational Bayes for Markov jump processes,Jiangwei Pan,Facebook
NIPS,2017,Collapsed variational Bayes for Markov jump processes,Vinayak A Rao,Purdue University
NIPS,2017,Bayesian Dyadic Trees and Histograms for  Regression,Stéphanie van der Pas,Leiden University
NIPS,2017,Bayesian Dyadic Trees and Histograms for  Regression,Veronika Rockova,University of Chicago
NIPS,2017,When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness,Chris Russell,The Alan Turing Institute/ The University of Surrey
NIPS,2017,When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness,Matt Kusner,Alan Turing Institute
NIPS,2017,When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness,Joshua Loftus,The Alan Turing Institute
NIPS,2017,When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness,Ricardo Silva,ucl.ac.uk
NIPS,2017,Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes,Jianshu Chen,"Microsoft Research, Redmond, W"
NIPS,2017,Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes,Chong Wang,
NIPS,2017,Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes,Lin Xiao,Microsoft Research
NIPS,2017,Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes,Ji He,University Washington
NIPS,2017,Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes,Lihong Li,Google Inc.
NIPS,2017,Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes,Li Deng,Citadel
NIPS,2017,Probabilistic Models for Integration Error in the Assessment of Functional Cardiac Models,Chris Oates,Newcastle University
NIPS,2017,Probabilistic Models for Integration Error in the Assessment of Functional Cardiac Models,Steven Niederer,Kings College London
NIPS,2017,Probabilistic Models for Integration Error in the Assessment of Functional Cardiac Models,Angela Lee,King's College London
NIPS,2017,Probabilistic Models for Integration Error in the Assessment of Functional Cardiac Models,François-Xavier Briol,University of Warwick
NIPS,2017,Probabilistic Models for Integration Error in the Assessment of Functional Cardiac Models,Mark Girolami,Imperial College London
NIPS,2017,Expectation Propagation for t-Exponential Family Using q-Algebra,Futoshi Futami,University of Tokyo/RIKEN
NIPS,2017,Expectation Propagation for t-Exponential Family Using q-Algebra,Issei Sato,The University of Tokyo/RIKEN
NIPS,2017,Expectation Propagation for t-Exponential Family Using q-Algebra,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2017,A Probabilistic Framework for Nonlinearities in Stochastic Neural Networks,Qinliang Su,Duke University
NIPS,2017,A Probabilistic Framework for Nonlinearities in Stochastic Neural Networks,xuejun Liao,
NIPS,2017,A Probabilistic Framework for Nonlinearities in Stochastic Neural Networks,Lawrence Carin,Duke University
NIPS,2017,Clone MCMC: Parallel High-Dimensional Gaussian Gibbs Sampling,Andrei-Cristian Barbos,University of Bordeaux
NIPS,2017,Clone MCMC: Parallel High-Dimensional Gaussian Gibbs Sampling,Francois Caron,Oxford
NIPS,2017,Clone MCMC: Parallel High-Dimensional Gaussian Gibbs Sampling,Jean-François Giovannelli,University of Bordeaux
NIPS,2017,Clone MCMC: Parallel High-Dimensional Gaussian Gibbs Sampling,Arnaud Doucet,Oxford
NIPS,2017,Learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data,Stéphanie ALLASSONNIERE,Ecole Polytechnique
NIPS,2017,Learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data,Juliette Chevallier,"CMAP, École polytechnique"
NIPS,2017,Learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data,Stephane Oudard,HEGP
NIPS,2017,Towards Generalization and Simplicity in Continuous Control,Aravind Rajeswaran,University of Washington
NIPS,2017,Towards Generalization and Simplicity in Continuous Control,Kendall Lowrey,University of Washington
NIPS,2017,Towards Generalization and Simplicity in Continuous Control,Emanuel Todorov,University of Washington
NIPS,2017,Towards Generalization and Simplicity in Continuous Control,Sham Kakade,University of Washington
NIPS,2017,Variable Importance Using Decision Trees,Jalil Kazemitabar,"University of California, Los Angeles"
NIPS,2017,Variable Importance Using Decision Trees,Arash Amini,UCLA
NIPS,2017,Variable Importance Using Decision Trees,Adam Bloniarz,Google
NIPS,2017,Variable Importance Using Decision Trees,Ameet S Talwalkar,CMU
NIPS,2017,The Expressive Power of Neural Networks: A View from the Width,Zhou Lu,Peking University
NIPS,2017,The Expressive Power of Neural Networks: A View from the Width,Hongming Pu,Peking university
NIPS,2017,The Expressive Power of Neural Networks: A View from the Width,Feicheng Wang,Peking University
NIPS,2017,The Expressive Power of Neural Networks: A View from the Width,Zhiqiang Hu,Peking University
NIPS,2017,The Expressive Power of Neural Networks: A View from the Width,Liwei Wang,Peking University
NIPS,2017,SGD Learns the Conjugate Kernel Class of the Network,Amit Daniely,Google Research
NIPS,2017,Noise-Tolerant Interactive Learning Using Pairwise Comparisons,Yichong Xu,Carnegie Mellon University
NIPS,2017,Noise-Tolerant Interactive Learning Using Pairwise Comparisons,Hongyang Zhang,Carnegie Mellon University
NIPS,2017,Noise-Tolerant Interactive Learning Using Pairwise Comparisons,Aarti Singh,Carnegie Mellon University
NIPS,2017,Noise-Tolerant Interactive Learning Using Pairwise Comparisons,Artur Dubrawski,Carnegie Mellon University
NIPS,2017,Noise-Tolerant Interactive Learning Using Pairwise Comparisons,Kyle Miller,Carnegie Mellon University
NIPS,2017,A PAC-Bayesian Analysis of Randomized Learning with Application to Stochastic Gradient Descent,Ben London,Amazon
NIPS,2017,Revisiting Perceptron: Efficient and Label-Optimal Learning of Halfspaces,Songbai Yan,"University of California, San Diego"
NIPS,2017,Revisiting Perceptron: Efficient and Label-Optimal Learning of Halfspaces,Chicheng Zhang,University of California San Diego
NIPS,2017,Sample and Computationally Efficient Learning Algorithms under S-Concave Distributions,Maria-Florina Balcan,Carnegie Mellon University
NIPS,2017,Sample and Computationally Efficient Learning Algorithms under S-Concave Distributions,Hongyang Zhang,Carnegie Mellon University
NIPS,2017,"Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite Dimensions",Aryeh Kontorovich,Ben Gurion University
NIPS,2017,"Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite Dimensions",Sivan Sabato,Ben Gurion University
NIPS,2017,"Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite Dimensions",Roi Weiss,Weizmann institute of science
NIPS,2017,Learning Identifiable Gaussian Bayesian Networks in Polynomial Time and Sample Complexity,Asish Ghoshal,Purdue University
NIPS,2017,Learning Identifiable Gaussian Bayesian Networks in Polynomial Time and Sample Complexity,Jean Honorio,Purdue University
NIPS,2017,From which world is your graph,Cheng Li,College of William and Mary
NIPS,2017,From which world is your graph,Felix MF Wong,Google
NIPS,2017,From which world is your graph,Zhenming Liu,William and Mary
NIPS,2017,From which world is your graph,Varun Kanade,University of Oxford
NIPS,2017,Mean Field Residual Networks: On the Edge of Chaos,Ge Yang,Harvard University
NIPS,2017,Mean Field Residual Networks: On the Edge of Chaos,Sam Schoenholz,Google Brain
NIPS,2017,Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes,Anton Mallasto,University of Copenhagen
NIPS,2017,Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes,Aasa Feragen,University of Copenhagen
NIPS,2017,On the Power of Truncated SVD for General High-rank Matrix Estimation Problems,Simon Du,Carnegie Mellon University
NIPS,2017,On the Power of Truncated SVD for General High-rank Matrix Estimation Problems,Yining Wang,Carnegie Mellon University
NIPS,2017,On the Power of Truncated SVD for General High-rank Matrix Estimation Problems,Aarti Singh,Carnegie Mellon University
NIPS,2017,Phase Transitions in the Pooled Data Problem,Jonathan Scarlett,EPFL
NIPS,2017,Phase Transitions in the Pooled Data Problem,Volkan Cevher,EPFL
NIPS,2017,Coded Distributed Computing for Inverse Problems,Yaoqing Yang,Carnegie Mellon University
NIPS,2017,Coded Distributed Computing for Inverse Problems,Pulkit Grover,CMU
NIPS,2017,Coded Distributed Computing for Inverse Problems,Soummya Kar,Carnegie Mellon University
NIPS,2017,Query Complexity of Clustering with Side Information,Arya Mazumdar,University of Massachusetts Amherst
NIPS,2017,Query Complexity of Clustering with Side Information,Barna Saha,University of Massachusetts Amherst
NIPS,2017,Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU with Generalized Hamming Network,Lixin Fan,Nokia Technologies
NIPS,2017,Optimistic posterior sampling for reinforcement learning: worst-case regret bounds,Shipra Agrawal,Columbia University
NIPS,2017,Optimistic posterior sampling for reinforcement learning: worst-case regret bounds,Randy Jia,Columbia University
NIPS,2017,Monte-Carlo Tree Search by Best Arm Identification,Emilie Kaufmann,CNRS & CRIStAL (SequeL)
NIPS,2017,Monte-Carlo Tree Search by Best Arm Identification,Wouter Koolen,Centrum Wiskunde & Informatica
NIPS,2017,Minimal Exploration in Structured Stochastic Bandits,Richard Combes,Centrale-Supelec
NIPS,2017,Minimal Exploration in Structured Stochastic Bandits,Stefan Magureanu,KTH
NIPS,2017,Minimal Exploration in Structured Stochastic Bandits,Alexandre Proutiere,KTH
NIPS,2017,Regret Analysis for Continuous Dueling Bandit,Wataru Kumagai,RIKEN
NIPS,2017,Elementary Symmetric Polynomials for Optimal Experimental Design,Zelda Mariet,MIT
NIPS,2017,Elementary Symmetric Polynomials for Optimal Experimental Design,Suvrit Sra,MIT
NIPS,2017,Learning Linear Dynamical Systems via Spectral Filtering,Elad Hazan,Princeton University
NIPS,2017,Learning Linear Dynamical Systems via Spectral Filtering,Karan Singh,Princeton University
NIPS,2017,Learning Linear Dynamical Systems via Spectral Filtering,Cyril Zhang,Princeton University
NIPS,2017,Efficient and Flexible Inference for Stochastic Systems,Stefan Bauer,ETH Zürich
NIPS,2017,Efficient and Flexible Inference for Stochastic Systems,Nico S Gorbach,Swiss Federal Institute of Technology Zurich (ETHZ)
NIPS,2017,Efficient and Flexible Inference for Stochastic Systems,Djordje Miladinovic,ETH Zurich
NIPS,2017,Efficient and Flexible Inference for Stochastic Systems,Joachim M Buhmann,ETH Zurich
NIPS,2017,Group Sparse Additive Machine,Hong Chen,University of Pittsburgh
NIPS,2017,Group Sparse Additive Machine,Xiaoqian Wang,University of Pittsburgh
NIPS,2017,Group Sparse Additive Machine,Cheng Deng,"School of Electronic Engineering, Xidian University, China"
NIPS,2017,Group Sparse Additive Machine,Heng Huang,University of Pittsburgh
NIPS,2017,Bregman Divergence for Stochastic Variance Reduction: Saddle-Point and Adversarial Prediction,Zhan Shi,University of Illinois at Chicago
NIPS,2017,Bregman Divergence for Stochastic Variance Reduction: Saddle-Point and Adversarial Prediction,Xinhua Zhang,University of Illinois at Chicago (UIC)
NIPS,2017,Bregman Divergence for Stochastic Variance Reduction: Saddle-Point and Adversarial Prediction,Yaoliang Yu,University of Waterloo
NIPS,2017,Universal consistency and minimax rates for online Mondrian Forests,Jaouad Mourtada,Ecole Polytechnique
NIPS,2017,Universal consistency and minimax rates for online Mondrian Forests,Stéphane Gaïffas,Ecole polytechnique
NIPS,2017,Universal consistency and minimax rates for online Mondrian Forests,Erwan Scornet,Ecole Polytechnique
NIPS,2017,Learning from Complementary Labels,Takashi Ishida,"Sumitomo Mitsui Asset Management, The University of Tokyo, RIKEN"
NIPS,2017,Learning from Complementary Labels,Gang Niu,The University of Tokyo / RIKEN
NIPS,2017,Learning from Complementary Labels,Weihua Hu,The University of Tokyo
NIPS,2017,Learning from Complementary Labels,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2017,"Semisupervised Clustering, AND-Queries and Locally Encodable Source Coding",Arya Mazumdar,University of Massachusetts Amherst
NIPS,2017,"Semisupervised Clustering, AND-Queries and Locally Encodable Source Coding",Soumyabrata Pal,University of Massachusetts Amherst
NIPS,2017,A Learning Error Analysis for Structured Prediction with Approximate Inference,Yuanbin Wu,East China Normal University
NIPS,2017,A Learning Error Analysis for Structured Prediction with Approximate Inference,Man Lan,
NIPS,2017,A Learning Error Analysis for Structured Prediction with Approximate Inference,Shiliang Sun,East China Normal University
NIPS,2017,A Learning Error Analysis for Structured Prediction with Approximate Inference,Qi Zhang,Fudan University
NIPS,2017,A Learning Error Analysis for Structured Prediction with Approximate Inference,Xuanjing Huang,Fudan University
NIPS,2017,On Optimal Generalizability in Parametric Learning,Ahmad Beirami,Harvard University & MIT
NIPS,2017,On Optimal Generalizability in Parametric Learning,Meisam Razaviyayn,University of Southern California
NIPS,2017,On Optimal Generalizability in Parametric Learning,Shahin Shahrampour,Harvard University
NIPS,2017,On Optimal Generalizability in Parametric Learning,Vahid Tarokh,Harvard University
NIPS,2017,Multi-Objective Non-parametric Sequential Prediction,Guy Uziel,Technion
NIPS,2017,Multi-Objective Non-parametric Sequential Prediction,Ran El-Yaniv,Technion
NIPS,2017,Ranking Data with Continuous Labels through Oriented Recursive Partitions,Stéphan Clémençon,Telecom ParisTech
NIPS,2017,Ranking Data with Continuous Labels through Oriented Recursive Partitions,Mastane Achab,Télécom ParisTech
NIPS,2017,Simple strategies for recovering inner products from coarsely quantized random projections,Ping Li,Rugters University
NIPS,2017,Simple strategies for recovering inner products from coarsely quantized random projections,Martin Slawski,
NIPS,2017,Clustering Stable Instances of Euclidean k-means.,Aravindan Vijayaraghavan,Northwestern University
NIPS,2017,Clustering Stable Instances of Euclidean k-means.,Abhratanu Dutta,Northwestern University
NIPS,2017,Clustering Stable Instances of Euclidean k-means.,Alex Wang,Northwestern University
NIPS,2017,Sparse Embedded $k$-Means Clustering,Weiwei Liu,UTS
NIPS,2017,Sparse Embedded $k$-Means Clustering,Xiaobo Shen,NJUST
NIPS,2017,Sparse Embedded $k$-Means Clustering,Ivor Tsang,"University of Technology, Sydney"
NIPS,2017,"Approximation Bounds for Hierarchical Clustering: Average Linkage, Bisecting K-means, and Local Search",Benjamin Moseley,Carnegie Mellon University
NIPS,2017,"Approximation Bounds for Hierarchical Clustering: Average Linkage, Bisecting K-means, and Local Search",Joshua Wang,Stanford University
NIPS,2017,Subspace Clustering via Tangent Cones,Amin Jalali,Wisconsin Institute for Discovery
NIPS,2017,Subspace Clustering via Tangent Cones,Rebecca Willett,University of Wisconsin
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Shinji Ito,NEC Coorporation
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Daisuke Hatano,National Institute of Informatics
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Hanna Sumita,National Institute of Informatics
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Akihiro Yabe,
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Takuro Fukunaga,National Institute of Informatics
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Naonori Kakimura,
NIPS,2017,Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation,Ken-Ichi Kawarabayashi,National Institute of Informatics
NIPS,2017,Unbiased estimates for linear regression via volume sampling,Michal Derezinski,UC Santa Cruz
NIPS,2017,Unbiased estimates for linear regression via volume sampling,Manfred Warmuth,Univ. of Calif. at Santa Cruz
NIPS,2017,"On Separability of Loss Functions, and Revisiting Discriminative Vs Generative Models",Adarsh Prasad,Carnegie Mellon University
NIPS,2017,"On Separability of Loss Functions, and Revisiting Discriminative Vs Generative Models",Alexandru Niculescu-Mizil,NEC Laboratories America
NIPS,2017,"On Separability of Loss Functions, and Revisiting Discriminative Vs Generative Models",Pradeep Ravikumar,Carnegie Mellon University
NIPS,2017,Group Additive Structure Identification for Kernel Nonparametric Regression,Chao Pan,Purdue University
NIPS,2017,Group Additive Structure Identification for Kernel Nonparametric Regression,Michael Zhu,Purdue University
NIPS,2017,Learning Overcomplete HMMs,Vatsal Sharan,Stanford University
NIPS,2017,Learning Overcomplete HMMs,Sham Kakade,University of Washington
NIPS,2017,Learning Overcomplete HMMs,Percy Liang,Stanford University
NIPS,2017,Learning Overcomplete HMMs,Gregory Valiant,Stanford University
NIPS,2017,A New Theory for Matrix Completion,Guangcan Liu,Nanjing University of Information Science & Technology
NIPS,2017,A New Theory for Matrix Completion,Qingshan Liu,
NIPS,2017,A New Theory for Matrix Completion,Xiaotong Yuan,
NIPS,2017,Learning Low-Dimensional Metrics,Blake Mason,University of Wisconsin - Madison
NIPS,2017,Learning Low-Dimensional Metrics,Lalit Jain,University of Michigan
NIPS,2017,Learning Low-Dimensional Metrics,Robert Nowak,University of Wisconsion-Madison
NIPS,2017,Partial Hard Thresholding: Towards A Principled Analysis of Support Recovery,Jie Shen,Rutgers University
NIPS,2017,Partial Hard Thresholding: Towards A Principled Analysis of Support Recovery,Ping Li,Rugters University
NIPS,2017,Minimax Estimation of Bandable Precision Matrices,Addison Hu,Yale University
NIPS,2017,Minimax Estimation of Bandable Precision Matrices,Sahand Negahban,Yale University
NIPS,2017,Diffusion Approximations for Online Principal Component Estimation and Global Convergence,Chris Junchi Li,Princeton University
NIPS,2017,Diffusion Approximations for Online Principal Component Estimation and Global Convergence,Mengdi Wang,Princeton University
NIPS,2017,Diffusion Approximations for Online Principal Component Estimation and Global Convergence,Tong Zhang,Tencent AI Lab
NIPS,2017,Estimation of the covariance structure of heavy-tailed distributions,Xiaohan Wei,University of Southern California
NIPS,2017,Estimation of the covariance structure of heavy-tailed distributions,Stanislav Minsker,USC
NIPS,2017,The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings,Krzysztof Choromanski,Google Brain Robotics
NIPS,2017,The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings,Mark Rowland,University of Cambridge
NIPS,2017,The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings,Adrian Weller,University of Cambridge
NIPS,2017,Generalization Properties of Learning with Random Features,Alessandro Rudi,INRIA
NIPS,2017,Generalization Properties of Learning with Random Features,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2017,Gaussian Quadrature for Kernel Features,Tri Dao,Stanford University
NIPS,2017,Gaussian Quadrature for Kernel Features,Christopher M De Sa,Stanford
NIPS,2017,Gaussian Quadrature for Kernel Features,Chris Ré,Stanford
NIPS,2017,Convergence rates of a partition based Bayesian multivariate density estimation method,Linxi Liu,Columbia University
NIPS,2017,Convergence rates of a partition based Bayesian multivariate density estimation method,Dangna Li,Stanford University
NIPS,2017,Convergence rates of a partition based Bayesian multivariate density estimation method,Wing Hung Wong,Stanford university
NIPS,2017,The power of absolute discounting: all-dimensional distribution estimation,Moein Falahatgar,UCSD
NIPS,2017,The power of absolute discounting: all-dimensional distribution estimation,Mesrob Ohannessian,Toyota Technological Institute at Chicago
NIPS,2017,The power of absolute discounting: all-dimensional distribution estimation,Alon Orlitsky,"University of California, San Diego"
NIPS,2017,The power of absolute discounting: all-dimensional distribution estimation,Venkatadheeraj Pichapati,UC San Diego
NIPS,2017,Learning Populations of Parameters,Kevin Tian,Stanford University
NIPS,2017,Learning Populations of Parameters,Weihao Kong,Stanford University
NIPS,2017,Learning Populations of Parameters,Gregory Valiant,Stanford University
NIPS,2017,Communication-Efficient Distributed Learning of Discrete Distributions,Ilias Diakonikolas,USC
NIPS,2017,Communication-Efficient Distributed Learning of Discrete Distributions,Elena Grigorescu,Purdue University
NIPS,2017,Communication-Efficient Distributed Learning of Discrete Distributions,Jerry Li,MIT
NIPS,2017,Communication-Efficient Distributed Learning of Discrete Distributions,Abhiram Natarajan,Purdue University
NIPS,2017,Communication-Efficient Distributed Learning of Discrete Distributions,Krzysztof Onak,IBM T.J. Watson Research Center
NIPS,2017,Communication-Efficient Distributed Learning of Discrete Distributions,Ludwig Schmidt,MIT
NIPS,2017,Improved Dynamic Regret for Non-degenerate Functions,Lijun Zhang,Nanjing University (NJU)
NIPS,2017,Improved Dynamic Regret for Non-degenerate Functions,Tianbao Yang,The University of Iowa
NIPS,2017,Improved Dynamic Regret for Non-degenerate Functions,Jinfeng Yi,Tencent AI Lab/IBM TJ Watson Research Center
NIPS,2017,Improved Dynamic Regret for Non-degenerate Functions,Jing Rong,Alibaba
NIPS,2017,Improved Dynamic Regret for Non-degenerate Functions,Zhi-Hua Zhou,Nanjing University
NIPS,2017,Parameter-Free Online Learning via Model Selection,Dylan J Foster,Cornell University
NIPS,2017,Parameter-Free Online Learning via Model Selection,Satyen Kale,Google
NIPS,2017,Parameter-Free Online Learning via Model Selection,Mehryar Mohri,Courant Institute and Google
NIPS,2017,Parameter-Free Online Learning via Model Selection,Karthik Sridharan,Cornell University
NIPS,2017,Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe,Quentin Berthet,University of Cambridge
NIPS,2017,Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe,Vianney Perchet,ENS Paris-Saclay & Criteo Research
NIPS,2017,Online Learning with Transductive Regret,Scott Yang,D. E. Shaw & Co.
NIPS,2017,Online Learning with Transductive Regret,Mehryar Mohri,Courant Institute and Google
NIPS,2017,Multi-Armed Bandits with Metric Movement Costs,Tomer Koren,Google
NIPS,2017,Multi-Armed Bandits with Metric Movement Costs,Roi Livni,Princeton
NIPS,2017,Multi-Armed Bandits with Metric Movement Costs,Yishay Mansour,Tel Aviv University
NIPS,2017,Differentially Private Empirical Risk Minimization Revisited: Faster and More General,Di Wang,State University of New York at Buffalo
NIPS,2017,Differentially Private Empirical Risk Minimization Revisited: Faster and More General,Minwei Ye,University at Buffalo
NIPS,2017,Differentially Private Empirical Risk Minimization Revisited: Faster and More General,Jinhui Xu,SUNY at Buffalo
NIPS,2017,Sparse Approximate Conic Hulls,Greg Van Buskirk,UT Dallas
NIPS,2017,Sparse Approximate Conic Hulls,Benjamin Raichel,UT Dallas
NIPS,2017,Sparse Approximate Conic Hulls,Nicholas Ruozzi,UTDallas
NIPS,2017,On Tensor Train Rank Minimization : Statistical Efficiency and Scalable Algorithm,Masaaki Imaizumi,Institute of Statistical Mathematics / RIKEN
NIPS,2017,On Tensor Train Rank Minimization : Statistical Efficiency and Scalable Algorithm,Takanori Maehara,RIKEN AIP
NIPS,2017,On Tensor Train Rank Minimization : Statistical Efficiency and Scalable Algorithm,Kohei Hayashi,AIST / RIKEN
NIPS,2017,Estimating High-dimensional Non-Gaussian Multiple Index Models via Stein’s Lemma,Zhuoran Yang,Princeton University
NIPS,2017,Estimating High-dimensional Non-Gaussian Multiple Index Models via Stein’s Lemma,Krishnakumar Balasubramanian,georgia tech
NIPS,2017,Estimating High-dimensional Non-Gaussian Multiple Index Models via Stein’s Lemma,Princeton Zhaoran Wang,"Princeton, Phd student"
NIPS,2017,Estimating High-dimensional Non-Gaussian Multiple Index Models via Stein’s Lemma,Han Liu,Tencent AI Lab
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Cyrus Rashtchian,University of Washington
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Konstantin Makarychev,
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Miklos Racz,Princeton University
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Siena Ang,Microsoft
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Djordje Jevdjic,Microsoft Research
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Sergey Yekhanin,Microsoft
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Luis Ceze,University of Washington
NIPS,2017,Clustering Billions of Reads for DNA Data Storage,Karin Strauss,Microsoft Research
NIPS,2017,Decoding with Value Networks for Neural Machine Translation,Di He,Peking University
NIPS,2017,Decoding with Value Networks for Neural Machine Translation,Hanqing Lu,Zhejiang University
NIPS,2017,Decoding with Value Networks for Neural Machine Translation,Yingce Xia,University of Science and Technology of China
NIPS,2017,Decoding with Value Networks for Neural Machine Translation,Tao Qin,Microsoft Research
NIPS,2017,Decoding with Value Networks for Neural Machine Translation,Liwei Wang,Peking University
NIPS,2017,Decoding with Value Networks for Neural Machine Translation,Tie-Yan Liu,Microsoft Research
NIPS,2017,Learned in Translation: Contextualized Word Vectors,Bryan McCann,Salesforce Research
NIPS,2017,Learned in Translation: Contextualized Word Vectors,James Bradbury,Salesforce Research
NIPS,2017,Learned in Translation: Contextualized Word Vectors,Caiming Xiong,Salesforce Research
NIPS,2017,Learned in Translation: Contextualized Word Vectors,Richard Socher,MetaMind
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Andrew Gibiansky,Baidu Research
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Sercan Arik,Baidu Research
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Gregory Diamos,Baidu SVAIL
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,John Miller,Baidu Research
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Kainan Peng,Baidu Research
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Wei Ping,Baidu Research
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Jonathan Raiman,Baidu Research
NIPS,2017,Deep Voice 2: Multi-Speaker Neural Text-to-Speech,Yanqi Zhou,Baidu Research
NIPS,2017,Multimodal Learning and Reasoning for Visual Question Answering,Ilija Ilievski,National University of Singapore
NIPS,2017,Multimodal Learning and Reasoning for Visual Question Answering,Jiashi Feng,National University of Singapore
NIPS,2017,Learning to Model the Tail,Yu-Xiong Wang,Carnegie Mellon University
NIPS,2017,Learning to Model the Tail,Deva Ramanan,Carnegie Mellon University
NIPS,2017,Learning to Model the Tail,Martial Hebert,cmu
NIPS,2017,Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts,Raymond Yeh,University of Illinois at Urbana–Champaign
NIPS,2017,Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts,Jinjun Xiong,IBM Research
NIPS,2017,Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts,Wen-Mei Hwu,
NIPS,2017,Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts,Minh Do,University of Illinois
NIPS,2017,Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2017,Multiscale Quantization for Fast Similarity Search,Xiang Wu,Google
NIPS,2017,Multiscale Quantization for Fast Similarity Search,Ruiqi Guo,Google
NIPS,2017,Multiscale Quantization for Fast Similarity Search,Ananda Theertha Suresh,Google
NIPS,2017,Multiscale Quantization for Fast Similarity Search,Sanjiv Kumar,Google Research
NIPS,2017,Multiscale Quantization for Fast Similarity Search,Daniel Holtmann-Rice,Google Inc
NIPS,2017,Multiscale Quantization for Fast Similarity Search,David Simcha,Google
NIPS,2017,Multiscale Quantization for Fast Similarity Search,Felix Yu,Google Research
NIPS,2017,MaskRNN: Instance Level Video Object Segmentation,Yuan-Ting Hu,UIUC
NIPS,2017,MaskRNN: Instance Level Video Object Segmentation,Jia-Bin Huang,Virginia Tech
NIPS,2017,MaskRNN: Instance Level Video Object Segmentation,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2017,Pixels to Graphs by Associative Embedding,Alejandro Newell,University of Michigan
NIPS,2017,Pixels to Graphs by Associative Embedding,Jia Deng,University of Michigan
NIPS,2017,Temporal Coherency based Criteria for Predicting Video Frames using Deep Multi-stage Generative Adversarial Networks,Prateep Bhattacharjee,Indian Institute of Technology Madras
NIPS,2017,Temporal Coherency based Criteria for Predicting Video Frames using Deep Multi-stage Generative Adversarial Networks,S. Das,IIT Madras
NIPS,2017,Unsupervised learning of object frames by dense equivariant image labelling,James Thewlis,University of Oxford
NIPS,2017,Unsupervised learning of object frames by dense equivariant image labelling,Hakan Bilen,University of Edinburgh
NIPS,2017,Unsupervised learning of object frames by dense equivariant image labelling,Andrea Vedaldi,University of Oxford
NIPS,2017,Dynamic Routing Between Capsules,Sara Sabour,Google
NIPS,2017,Dynamic Routing Between Capsules,Nicholas Frosst,Google
NIPS,2017,Dynamic Routing Between Capsules,Geoffrey E Hinton,Google & University of Toronto
NIPS,2017,What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?,Alex Kendall,University of Cambridge
NIPS,2017,What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?,Yarin Gal,University of Oxford
NIPS,2017,Graph Matching via Multiplicative Update Algorithm,Bo Jiang,Anhui University
NIPS,2017,Graph Matching via Multiplicative Update Algorithm,Jin Tang,
NIPS,2017,Graph Matching via Multiplicative Update Algorithm,Chris Ding,University of Texas at Arlington
NIPS,2017,Graph Matching via Multiplicative Update Algorithm,Yihong Gong,
NIPS,2017,Graph Matching via Multiplicative Update Algorithm,Bin Luo,
NIPS,2017,Training Quantized Nets: A Deeper Understanding,Hao Li,"University of Maryland, College Park"
NIPS,2017,Training Quantized Nets: A Deeper Understanding,Soham De,"University of Maryland, College Park"
NIPS,2017,Training Quantized Nets: A Deeper Understanding,Zheng Xu,"University of Maryland, College Park"
NIPS,2017,Training Quantized Nets: A Deeper Understanding,Christoph Studer,Cornell University
NIPS,2017,Training Quantized Nets: A Deeper Understanding,Hanan Samet,University of Maryland at College Park
NIPS,2017,Training Quantized Nets: A Deeper Understanding,Tom Goldstein,University of Maryland
NIPS,2017,An inner-loop free solution to inverse problems using deep neural networks,Kai Fan,Duke University
NIPS,2017,An inner-loop free solution to inverse problems using deep neural networks,Qi Wei,Duke University
NIPS,2017,An inner-loop free solution to inverse problems using deep neural networks,Lawrence Carin,Duke University
NIPS,2017,An inner-loop free solution to inverse problems using deep neural networks,Katherine Heller,Duke
NIPS,2017,Towards Accurate Binary Convolutional Neural Network,Xiaofan Lin,DJI
NIPS,2017,Towards Accurate Binary Convolutional Neural Network,Cong Zhao,DJI
NIPS,2017,Towards Accurate Binary Convolutional Neural Network,Wei Pan,DJI
NIPS,2017,Runtime Neural Pruning,Ji Lin,Tsinghua University
NIPS,2017,Runtime Neural Pruning,Yongming Rao,Tsinghua University
NIPS,2017,Runtime Neural Pruning,Jiwen Lu,Tsinghua University
NIPS,2017,Runtime Neural Pruning,Jie Zhou,Tsinghua University
NIPS,2017,Poincaré Embeddings for Learning Hierarchical Representations,Maximillian Nickel,Facebook
NIPS,2017,Poincaré Embeddings for Learning Hierarchical Representations,Douwe Kiela,Facebook AI Research
NIPS,2017,Preventing Gradient Explosions in Gated Recurrent Units,Sekitoshi Kanai,NTT
NIPS,2017,Preventing Gradient Explosions in Gated Recurrent Units,Yasuhiro Fujiwara,NTT Software Innovation Center
NIPS,2017,Preventing Gradient Explosions in Gated Recurrent Units,Sotetsu Iwamura,NTT Software Innovation center
NIPS,2017,"Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",Zhen He,University College London
NIPS,2017,"Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",Shaobing Gao,Sichuan University
NIPS,2017,"Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",Liang Xiao,National University of Defense Technology
NIPS,2017,"Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",Daxue Liu,National University of Defense Technology
NIPS,2017,"Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",Hangen He,National University of Defense Technology
NIPS,2017,"Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",David Barber,University College London
NIPS,2017,Cold-Start Reinforcement Learning with Softmax Policy Gradient,Nan Ding,Google
NIPS,2017,Cold-Start Reinforcement Learning with Softmax Policy Gradient,Radu Soricut,Google
NIPS,2017,Recurrent Ladder Networks,Isabeau Prémont-Schwarz,The Curious Ai Company
NIPS,2017,Recurrent Ladder Networks,Alexander Ilin,The Curious AI company
NIPS,2017,Recurrent Ladder Networks,Hotloo Hao,The Curious AI Company
NIPS,2017,Recurrent Ladder Networks,Antti Rasmus,
NIPS,2017,Recurrent Ladder Networks,Rinu Boney,
NIPS,2017,Recurrent Ladder Networks,Harri Valpola,The Curious AI Company
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Arun Venkatraman,Carnegie Mellon University
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Nick Rhinehart,Carnegie Mellon University
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Wen Sun,Carnegie Mellon University
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Lerrel Pinto,
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Martial Hebert,cmu
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Byron Boots,Georgia Tech / Google Brain
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,Kris Kitani,Carnegie Mellon University
NIPS,2017,Predictive-State Decoders: Encoding the Future into Recurrent Networks,J. Bagnell,Carnegie Mellon University
NIPS,2017,Neural Discrete Representation Learning,Aaron van den Oord,Google Deepmind
NIPS,2017,Neural Discrete Representation Learning,Oriol Vinyals,Google DeepMind
NIPS,2017,Neural Discrete Representation Learning,koray kavukcuoglu,Google DeepMind
NIPS,2017,Variational Memory Addressing in Generative Models,Jörg Bornschein,DeepMind
NIPS,2017,Variational Memory Addressing in Generative Models,Andriy Mnih,DeepMind
NIPS,2017,Variational Memory Addressing in Generative Models,Daniel Zoran,DeepMind
NIPS,2017,Variational Memory Addressing in Generative Models,Danilo Jimenez Rezende,Google DeepMind
NIPS,2017,Cortical microcircuits as gated-recurrent neural networks,Rui Costa,University of Oxford
NIPS,2017,Cortical microcircuits as gated-recurrent neural networks,Yannis Assael,DeepMind
NIPS,2017,Cortical microcircuits as gated-recurrent neural networks,Brendan Shillingford,University of Oxford
NIPS,2017,Cortical microcircuits as gated-recurrent neural networks,Nando de Freitas,DeepMind
NIPS,2017,Cortical microcircuits as gated-recurrent neural networks,TIm Vogels,University of Oxford
NIPS,2017,Continual Learning with Deep Generative Replay,Hanul Shin,Massachusetts Institute of Technology
NIPS,2017,Continual Learning with Deep Generative Replay,Jung Kwon Lee,SK T-Brain
NIPS,2017,Continual Learning with Deep Generative Replay,Jaehong Kim,T-Brain
NIPS,2017,Continual Learning with Deep Generative Replay,Jiwon Kim,SK T-Brain
NIPS,2017,VAE Learning via Stein Variational Gradient Descent,Yuchen Pu,Duke University
NIPS,2017,VAE Learning via Stein Variational Gradient Descent,Zhe Gan,Duke University
NIPS,2017,VAE Learning via Stein Variational Gradient Descent,Ricardo Henao,Duke University
NIPS,2017,VAE Learning via Stein Variational Gradient Descent,Chunyuan Li,Duke University
NIPS,2017,VAE Learning via Stein Variational Gradient Descent,Shaobo Han,Duke University
NIPS,2017,VAE Learning via Stein Variational Gradient Descent,Lawrence Carin,Duke University
NIPS,2017,Learning to Inpaint for Image Compression,Mohammad Haris Baig,Dartmouth College
NIPS,2017,Learning to Inpaint for Image Compression,Vladlen Koltun,Intel Labs
NIPS,2017,Learning to Inpaint for Image Compression,Lorenzo Torresani,Dartmouth
NIPS,2017,Visual Interaction Networks: Learning a Physics Simulator from Video,Nick Watters,Google DeepMind
NIPS,2017,Visual Interaction Networks: Learning a Physics Simulator from Video,Daniel Zoran,DeepMind
NIPS,2017,Visual Interaction Networks: Learning a Physics Simulator from Video,Theophane Weber,DeepMind
NIPS,2017,Visual Interaction Networks: Learning a Physics Simulator from Video,Peter Battaglia,DeepMind
NIPS,2017,Visual Interaction Networks: Learning a Physics Simulator from Video,Razvan Pascanu,Google DeepMind
NIPS,2017,Visual Interaction Networks: Learning a Physics Simulator from Video,Andrea Tacchetti,MIT
NIPS,2017,Eigen-Distortions of Hierarchical Representations,Alexander Berardino,New York University
NIPS,2017,Eigen-Distortions of Hierarchical Representations,Valero Laparra,Universitat de València
NIPS,2017,Eigen-Distortions of Hierarchical Representations,Johannes Ballé,Google Inc.
NIPS,2017,Eigen-Distortions of Hierarchical Representations,Eero Simoncelli,HHMI / New York University
NIPS,2017,Learning Affinity via Spatial Propagation Networks,Sifei Liu,Nvidia
NIPS,2017,Learning Affinity via Spatial Propagation Networks,Shalini De Mello,NVIDIA
NIPS,2017,Learning Affinity via Spatial Propagation Networks,Jinwei Gu,NVIDIA Research
NIPS,2017,Learning Affinity via Spatial Propagation Networks,Guangyu Zhong,Dalian University of Technology
NIPS,2017,Learning Affinity via Spatial Propagation Networks,Ming-Hsuan Yang,UC Merced
NIPS,2017,Learning Affinity via Spatial Propagation Networks,Jan Kautz,NVIDIA
NIPS,2017,Convergent Block Coordinate Descent for Training Tikhonov Regularized Deep Neural Networks,Ziming Zhang,MERL
NIPS,2017,Convergent Block Coordinate Descent for Training Tikhonov Regularized Deep Neural Networks,Matthew Brand,Mitsubishi Electric Research Labs
NIPS,2017,How regularization affects the critical points in linear networks,Amir Taghvaei,University of Illinois at Urbana-Champaign
NIPS,2017,How regularization affects the critical points in linear networks,Jin W Kim,University of Illinois
NIPS,2017,How regularization affects the critical points in linear networks,Prashant Mehta,University of Illinois
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Xiaojie Jin,National University of Singapore Snap Research
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Huaxin Xiao,NUDT
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Xiaohui Shen,Adobe
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Jimei Yang,Adobe Research
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Zhe Lin,Adobe
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Yunpeng Chen,National University of Singapore
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Zequn Jie,Tencent AI Lab
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Jiashi Feng,National University of Singapore
NIPS,2017,Predicting Scene Parsing and Motion Dynamics in the Future,Shuicheng Yan,National University of Singapore
NIPS,2017,Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples,Moustapha Cisse,Facebook AI Research
NIPS,2017,Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples,Yossi Adi,Bar Ilan University
NIPS,2017,Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples,Natalia Neverova,Facebook AI Research
NIPS,2017,Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples,Yossi Keshet,Bar-Ilan University
NIPS,2017,Compression-aware Training of Deep Networks,Jose Alvarez,TRI
NIPS,2017,Compression-aware Training of Deep Networks,Mathieu Salzmann,EPFL
NIPS,2017,Non-parametric Structured Output Networks,Andreas Lehrmann,Disney Research
NIPS,2017,Non-parametric Structured Output Networks,Leonid Sigal,Disney Research / University of British Columbia
NIPS,2017,GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,Alex Lamb,UMontreal (MILA)
NIPS,2017,GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,devon Hjelm,MILA
NIPS,2017,GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,Yaroslav Ganin,Université de Montréal
NIPS,2017,GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,Joseph Paul Cohen,Montreal Institute for Learning Algorithms
NIPS,2017,GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,Aaron Courville,U. Montreal
NIPS,2017,GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,Yoshua Bengio,U. Montreal
NIPS,2017,Exploring Generalization in Deep Learning,Behnam Neyshabur,Institute for Advanced Study
NIPS,2017,Exploring Generalization in Deep Learning,Srinadh Bhojanapalli,Toyota Technological Institute at Chicago
NIPS,2017,Exploring Generalization in Deep Learning,David Mcallester,Toyota Tech Institute Chicago
NIPS,2017,Exploring Generalization in Deep Learning,Nati Srebro,TTI-Chicago
NIPS,2017,Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization,Hyeonwoo Noh,POSTECH
NIPS,2017,Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization,Tackgeun You,POSTECH
NIPS,2017,Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization,Jonghwan Mun,POSTECH
NIPS,2017,Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization,Bohyung Han,POSTECH
NIPS,2017,Extracting low-dimensional dynamics from multiple large-scale neural population recordings by learning to predict correlations,Marcel Nonnenmacher,Research center caesar
NIPS,2017,Extracting low-dimensional dynamics from multiple large-scale neural population recordings by learning to predict correlations,Srini C Turaga,"Janelia Research Campus, Howard Hughes Medical Institute"
NIPS,2017,Extracting low-dimensional dynamics from multiple large-scale neural population recordings by learning to predict correlations,Jakob H Macke,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Adaptive stimulus selection for optimizing neural population responses,Benjamin Cowley,Carnegie Mellon University
NIPS,2017,Adaptive stimulus selection for optimizing neural population responses,Ryan Williamson,Carnegie Mellon University
NIPS,2017,Adaptive stimulus selection for optimizing neural population responses,Katerina Clemens,University of Pittsburgh
NIPS,2017,Adaptive stimulus selection for optimizing neural population responses,Matthew Smith,University of Pittsburgh
NIPS,2017,Adaptive stimulus selection for optimizing neural population responses,Byron M Yu,Carnegie Mellon University
NIPS,2017,Detrended Partial Cross Correlation for Brain Connectivity Analysis,Jaime Ide,Yale University
NIPS,2017,Detrended Partial Cross Correlation for Brain Connectivity Analysis,Fábio Cappabianco,Federal University of Sao Paulo
NIPS,2017,Detrended Partial Cross Correlation for Brain Connectivity Analysis,Fabio Faria,Federal University of Sao Paulo
NIPS,2017,Detrended Partial Cross Correlation for Brain Connectivity Analysis,Chiang-shan R Li,Yale University
NIPS,2017,An Error Detection and Correction Framework for Connectomics,Jonathan Zung,Princeton University
NIPS,2017,An Error Detection and Correction Framework for Connectomics,Ignacio Tartavull,Princeton Universitiy
NIPS,2017,An Error Detection and Correction Framework for Connectomics,Kisuk Lee,MIT
NIPS,2017,An Error Detection and Correction Framework for Connectomics,H. Sebastian Seung,Princeton University
NIPS,2017,Mapping distinct timescales of functional interactions among brain networks,Mali Sundaresan,"Indian Institute of Science, Bangalore"
NIPS,2017,Mapping distinct timescales of functional interactions among brain networks,Arshed Nabeel,"Indian Institute of Science, Bangalore"
NIPS,2017,Mapping distinct timescales of functional interactions among brain networks,Devarajan Sridharan,"Indian Institute of Science, Bangalore"
NIPS,2017,Robust Estimation of Neural Signals in Calcium Imaging,Hakan Inan,Stanford University
NIPS,2017,Robust Estimation of Neural Signals in Calcium Imaging,Murat A Erdogdu,Microsoft Research
NIPS,2017,Robust Estimation of Neural Signals in Calcium Imaging,Mark Schnitzer,Stanford University
NIPS,2017,Decomposable Submodular Function Minimization: Discrete and Continuous,Alina Ene,University of Warwick
NIPS,2017,Decomposable Submodular Function Minimization: Discrete and Continuous,Huy Nguyen,Northeastern University
NIPS,2017,Decomposable Submodular Function Minimization: Discrete and Continuous,László A. Végh,London School of Economics
NIPS,2017,Robust Optimization for Non-Convex Objectives,Robert S Chen,Harvard University
NIPS,2017,Robust Optimization for Non-Convex Objectives,Brendan Lucier,Microsoft Research
NIPS,2017,Robust Optimization for Non-Convex Objectives,Yaron Singer,Harvard University
NIPS,2017,Robust Optimization for Non-Convex Objectives,Vasilis Syrgkanis,Microsoft Research
NIPS,2017,On the Optimization Landscape of Tensor Decompositions,Rong Ge,Duke University
NIPS,2017,On the Optimization Landscape of Tensor Decompositions,Tengyu Ma,Facebook AI Research
NIPS,2017,Gradient Descent Can Take Exponential Time to Escape Saddle Points,Simon Du,Carnegie Mellon University
NIPS,2017,Gradient Descent Can Take Exponential Time to Escape Saddle Points,Chi Jin,UC Berkeley
NIPS,2017,Gradient Descent Can Take Exponential Time to Escape Saddle Points,Jason D Lee,USC
NIPS,2017,Gradient Descent Can Take Exponential Time to Escape Saddle Points,Michael Jordan,UC Berkeley
NIPS,2017,Gradient Descent Can Take Exponential Time to Escape Saddle Points,Aarti Singh,Carnegie Mellon University
NIPS,2017,Gradient Descent Can Take Exponential Time to Escape Saddle Points,Barnabas Poczos,Carnegie Mellon University
NIPS,2017,Convolutional Phase Retrieval,Qing Qu,Columbia University
NIPS,2017,Convolutional Phase Retrieval,Yuqian Zhang,Columbia University
NIPS,2017,Convolutional Phase Retrieval,Yonina Eldar,Israel Institute of Technology
NIPS,2017,Convolutional Phase Retrieval,John Wright,Columbia University
NIPS,2017,Implicit Regularization in Matrix Factorization,Suriya Gunasekar,TTI Chicago
NIPS,2017,Implicit Regularization in Matrix Factorization,Blake Woodworth,Toyota Technological Institute at Chicago
NIPS,2017,Implicit Regularization in Matrix Factorization,Srinadh Bhojanapalli,Toyota Technological Institute at Chicago
NIPS,2017,Implicit Regularization in Matrix Factorization,Behnam Neyshabur,Institute for Advanced Study
NIPS,2017,Implicit Regularization in Matrix Factorization,Nati Srebro,TTI-Chicago
NIPS,2017,Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration,Jason Altschuler,MIT
NIPS,2017,Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration,Jon Weed,MIT
NIPS,2017,Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration,Philippe Rigollet,MIT
NIPS,2017,On Frank-Wolfe and Equilibrium Computation,Jacob D Abernethy,University of Michigan
NIPS,2017,On Frank-Wolfe and Equilibrium Computation,Jun-Kun Wang,Georgia Institute of Technology
NIPS,2017,When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent,Mert Gurbuzbalaban,Rutgers University
NIPS,2017,When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent,Asuman Ozdaglar,Massachusetts Institute of Technology
NIPS,2017,When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent,Pablo A Parrilo,Massachusetts Institute of Technology
NIPS,2017,When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent,Denizcan Vanli,Massachusetts Institute of Technology
NIPS,2017,Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2017,Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls,Elad Hazan,Princeton University
NIPS,2017,Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls,Wei Hu,Princeton University
NIPS,2017,Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls,Yuanzhi Li,Princeton University
NIPS,2017,"Adaptive Accelerated Gradient Converging Method under H\""{o}lderian Error Bound Condition",Mingrui Liu,The University of Iowa
NIPS,2017,"Adaptive Accelerated Gradient Converging Method under H\""{o}lderian Error Bound Condition",Tianbao Yang,The University of Iowa
NIPS,2017,Adaptive SVRG Methods under Error Bound Conditions with Unknown Growth Parameter,Yi Xu,The University of Iowa
NIPS,2017,Adaptive SVRG Methods under Error Bound Conditions with Unknown Growth Parameter,Qihang Lin,University of Iowa
NIPS,2017,Adaptive SVRG Methods under Error Bound Conditions with Unknown Growth Parameter,Tianbao Yang,The University of Iowa
NIPS,2017,Geometric Descent Method for Convex Composite Minimization,Shixiang Chen,The Chinese University of HongKong
NIPS,2017,Geometric Descent Method for Convex Composite Minimization,Shiqian Ma,UC Davis
NIPS,2017,Geometric Descent Method for Convex Composite Minimization,Wei Liu,Tencent AI Lab
NIPS,2017,Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for Regularized Empirical Risk Minimization,Tomoya Murata,NTT DATA Mathematical Systems Inc.
NIPS,2017,Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for Regularized Empirical Risk Minimization,Taiji Suzuki,taiji@mist.i.u-tokyo.ac.jp
NIPS,2017,Limitations on Variance-Reduction and Acceleration Schemes for Finite Sums Optimization,Yossi Arjevani,The Weizmann Institute
NIPS,2017,Nonlinear Acceleration of Stochastic Algorithms,Damien Scieur,INRIA - ENS
NIPS,2017,Nonlinear Acceleration of Stochastic Algorithms,Francis Bach,Inria
NIPS,2017,Nonlinear Acceleration of Stochastic Algorithms,Alexandre d'Aspremont,CNRS - Ecole Normale Supérieure
NIPS,2017,Acceleration and Averaging in Stochastic Descent Dynamics,Walid Krichene,Google
NIPS,2017,Acceleration and Averaging in Stochastic Descent Dynamics,Peter Bartlett,UC Berkeley
NIPS,2017,Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces,Daniel Milstein,Brown University
NIPS,2017,Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces,Jason Pacheco,Brown University
NIPS,2017,Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces,Leigh Hochberg,"Brown, MGH, VA, Harvard"
NIPS,2017,Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces,John D Simeral,Brown University
NIPS,2017,Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces,Beata Jarosiewicz,Stanford University
NIPS,2017,Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces,Erik Sudderth,"University of California, Irvine"
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Yogatheesan Varatharajah,University of Illinois at Urbana Champaign
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Min Jin Chong,University of Illinois at Urbana-Champaign
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Krishnakant Saboo,
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Brent Berry,Mayo Clinic
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Benjamin Brinkmann,Mayo Clinic
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Gregory Worrell,"Mayo Clinic, Rochester"
NIPS,2017,"EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms",Ravishankar Iyer,
NIPS,2017,Asynchronous Parallel Coordinate Minimization for MAP Inference,Ofer Meshi,Google
NIPS,2017,Asynchronous Parallel Coordinate Minimization for MAP Inference,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2017,Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization,Pan Xu,University of Virginia
NIPS,2017,Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization,Jian Ma,Carnegie Mellon University
NIPS,2017,Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization,Quanquan Gu,University of Virginia
NIPS,2017,Robust Conditional Probabilities,Yoav Wald,Hebrew University
NIPS,2017,Robust Conditional Probabilities,Amir Globerson,HUJI
NIPS,2017,Stein Variational Gradient Descent as Gradient Flow,Qiang Liu,Dartmouth College
NIPS,2017,Deep Dynamic Poisson Factorization Model,Chengyue Gong,Peking University
NIPS,2017,Deep Dynamic Poisson Factorization Model,win-bin huang,peking university
NIPS,2017,On the Model Shrinkage Effect of Gamma Process Edge Partition Models,Iku Ohama,Panasonic Corporation
NIPS,2017,On the Model Shrinkage Effect of Gamma Process Edge Partition Models,Issei Sato,The University of Tokyo/RIKEN
NIPS,2017,On the Model Shrinkage Effect of Gamma Process Edge Partition Models,Takuya Kida,Hokkaido University
NIPS,2017,On the Model Shrinkage Effect of Gamma Process Edge Partition Models,Hiroki Arimura,Hokkaido University
NIPS,2017,Identification of Gaussian Process State Space Models,Stefanos Eleftheriadis,PROWLER.io
NIPS,2017,Identification of Gaussian Process State Space Models,Tom Nicholson,PROWLER.IO
NIPS,2017,Identification of Gaussian Process State Space Models,Marc Deisenroth,Imperial College London
NIPS,2017,Identification of Gaussian Process State Space Models,James Hensman,PROWLER.io
NIPS,2017,Variational Inference for Gaussian Process Models with Linear Complexity,Ching-An Cheng,Georgia Tech
NIPS,2017,Variational Inference for Gaussian Process Models with Linear Complexity,Byron Boots,Georgia Tech / Google Brain
NIPS,2017,Non-Stationary Spectral Kernels,Sami Remes,Aalto University
NIPS,2017,Non-Stationary Spectral Kernels,Markus Heinonen,Aalto University
NIPS,2017,Non-Stationary Spectral Kernels,Samuel Kaski,Aalto University
NIPS,2017,Spectral Mixture Kernels for Multi-Output Gaussian Processes,Gabriel Parra,Universidad de Chile
NIPS,2017,Spectral Mixture Kernels for Multi-Output Gaussian Processes,Felipe Tobar,Universidad de Chile
NIPS,2017,Hindsight Experience Replay,Marcin Andrychowicz,OpenAI
NIPS,2017,Hindsight Experience Replay,Filip Wolski,Whisper.ai
NIPS,2017,Hindsight Experience Replay,Alex Ray,OpenAI
NIPS,2017,Hindsight Experience Replay,Jonas Schneider,OpenAI
NIPS,2017,Hindsight Experience Replay,rfong Fong,OpenAI
NIPS,2017,Hindsight Experience Replay,Peter Welinder,OpenAI
NIPS,2017,Hindsight Experience Replay,Bob McGrew,OpenAI
NIPS,2017,Hindsight Experience Replay,Josh Tobin,OpenAI
NIPS,2017,Hindsight Experience Replay,OpenAI Pieter Abbeel,"OpenAI, UC Berkeley"
NIPS,2017,Hindsight Experience Replay,Wojciech Zaremba,OpenAI
NIPS,2017,Finite sample analysis of the GTD Policy Evaluation Algorithms in Markov Setting,Yue Wang,Beijing Jiaotong University
NIPS,2017,Finite sample analysis of the GTD Policy Evaluation Algorithms in Markov Setting,Wei Chen,Microsoft Research
NIPS,2017,Finite sample analysis of the GTD Policy Evaluation Algorithms in Markov Setting,Yuting Liu,Beijing Jiaotong University
NIPS,2017,Finite sample analysis of the GTD Policy Evaluation Algorithms in Markov Setting,Zhi-Ming Ma,
NIPS,2017,Finite sample analysis of the GTD Policy Evaluation Algorithms in Markov Setting,Tie-Yan Liu,Microsoft Research
NIPS,2017,Inverse Filtering for Hidden Markov Models,Robert Mattila,KTH Royal Institute of Technology
NIPS,2017,Inverse Filtering for Hidden Markov Models,Cristian Rojas,KTH Royal Institute of Technology
NIPS,2017,Inverse Filtering for Hidden Markov Models,Vikram Krishnamurthy,Cornell University
NIPS,2017,Inverse Filtering for Hidden Markov Models,Bo Wahlberg,KTH Royal Inst. of Technology
NIPS,2017,Data-Efficient Reinforcement Learning in Continuous State-Action Gaussian-POMDPs,Rowan McAllister,University of Cambridge
NIPS,2017,Data-Efficient Reinforcement Learning in Continuous State-Action Gaussian-POMDPs,Carl Edward Rasmussen,University of Cambridge
NIPS,2017,Linear regression without correspondence,Daniel Hsu,Columbia University
NIPS,2017,Linear regression without correspondence,Kevin Shi,Columbia University
NIPS,2017,Linear regression without correspondence,Xiaorui Sun,Columbia University
NIPS,2017,On the Complexity of Learning Neural Networks,Le Song,Georgia Institute of Technology
NIPS,2017,On the Complexity of Learning Neural Networks,Santosh Vempala,Georgia Tech
NIPS,2017,On the Complexity of Learning Neural Networks,John Wilmes,Georgia Institute of Technology
NIPS,2017,On the Complexity of Learning Neural Networks,Bo Xie,Georgia Tech
NIPS,2017,Near Optimal Sketching of Low-Rank Tensor Regression,Xingguo Li,University of Minnesota
NIPS,2017,Near Optimal Sketching of Low-Rank Tensor Regression,Jarvis Haupt,University of Minnesota
NIPS,2017,Near Optimal Sketching of Low-Rank Tensor Regression,David Woodruff,Carnegie Mellon University
NIPS,2017,Is Input Sparsity Time Possible for Kernel Low-Rank Approximation?,Cameron Musco,Massachusetts Institute of Technology
NIPS,2017,Is Input Sparsity Time Possible for Kernel Low-Rank Approximation?,David Woodruff,Carnegie Mellon University
NIPS,2017,Higher-Order Total Variation Classes on Grids: Minimax Theory and Trend Filtering Methods,Veeranjaneyulu Sadhanala,CMU
NIPS,2017,Higher-Order Total Variation Classes on Grids: Minimax Theory and Trend Filtering Methods,Yu-Xiang Wang,CMU / Amazon AI
NIPS,2017,Higher-Order Total Variation Classes on Grids: Minimax Theory and Trend Filtering Methods,James Sharpnack,UC Davis
NIPS,2017,Higher-Order Total Variation Classes on Grids: Minimax Theory and Trend Filtering Methods,Ryan Tibshirani,Carnegie Mellon University
NIPS,2017,Alternating Estimation for Structured High-Dimensional Multi-Response Models,Sheng Chen,University of Minnesota
NIPS,2017,Alternating Estimation for Structured High-Dimensional Multi-Response Models,Arindam Banerjee,University of Minnesota
NIPS,2017,Eigenvalue Decay Implies Polynomial-Time Learnability for Neural Networks,Surbhi Goel,University of Texas at Austin
NIPS,2017,Eigenvalue Decay Implies Polynomial-Time Learnability for Neural Networks,Adam Klivans,UT Austin
NIPS,2017,Hierarchical Clustering Beyond the Worst-Case,Vincent Cohen-Addad,University of Copenhagen
NIPS,2017,Hierarchical Clustering Beyond the Worst-Case,Varun Kanade,University of Oxford
NIPS,2017,Hierarchical Clustering Beyond the Worst-Case,Frederik Mallmann-Trenn,ENS
NIPS,2017,Information-theoretic analysis of generalization capability of learning algorithms,Aolin Xu,University of Illinois at Urbana-Champaign
NIPS,2017,Information-theoretic analysis of generalization capability of learning algorithms,Maxim Raginsky,University of Illinois at Urbana-Champaign
NIPS,2017,Independence clustering (without a matrix),Daniil Ryabko,INRIA
NIPS,2017,Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication,Qian Yu,University of Southern Califor
NIPS,2017,Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication,Mohammad Maddah-Ali,Nokia Bell Labs
NIPS,2017,Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication,Salman Avestimehr,USC
NIPS,2017,Statistical Cost Sharing,Eric Balkanski,Harvard University
NIPS,2017,Statistical Cost Sharing,Umar Syed,Google Research
NIPS,2017,Statistical Cost Sharing,Sergei Vassilvitskii,Google
NIPS,2017,A Sample Complexity Measure with Applications to Learning Optimal Auctions,Vasilis Syrgkanis,Microsoft Research
NIPS,2017,"Multiplicative Weights Update with Constant Step-Size in Congestion Games:  Convergence, Limit Cycles and Chaos",Gerasimos Palaiopanos,SUTD
NIPS,2017,"Multiplicative Weights Update with Constant Step-Size in Congestion Games:  Convergence, Limit Cycles and Chaos",Ioannis Panageas,MIT
NIPS,2017,"Multiplicative Weights Update with Constant Step-Size in Congestion Games:  Convergence, Limit Cycles and Chaos",Georgios Piliouras,Singapore University of Technology and Design
NIPS,2017,Welfare Guarantees from Data,Darrell Hoy,Tremor Technologies
NIPS,2017,Welfare Guarantees from Data,Denis Nekipelov,University of Virginia
NIPS,2017,Welfare Guarantees from Data,Vasilis Syrgkanis,Microsoft Research
NIPS,2017,Safe and Nested Subgame Solving for Imperfect-Information Games,Noam Brown,Carnegie Mellon University
NIPS,2017,Safe and Nested Subgame Solving for Imperfect-Information Games,Tuomas Sandholm,Carnegie Mellon University
NIPS,2017,Multi-output Polynomial Networks and Factorization Machines,Mathieu Blondel,NTT
NIPS,2017,Multi-output Polynomial Networks and Factorization Machines,Vlad Niculae,Cornell University
NIPS,2017,Multi-output Polynomial Networks and Factorization Machines,Takuma Otsuka,NTT Communication Science Labs
NIPS,2017,Multi-output Polynomial Networks and Factorization Machines,Naonori Ueda,NTT Communication Science Laboratories/ RIKEN AIP
NIPS,2017,Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples,Haw-Shiuan Chang,"UMass, Amherst"
NIPS,2017,Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples,Erik Learned-Miller,UMass Amherst
NIPS,2017,Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples,Andrew McCallum,UMass Amherst
NIPS,2017,Deep Reinforcement Learning from Human Preferences,Paul F Christiano,OpenAI
NIPS,2017,Deep Reinforcement Learning from Human Preferences,Jan Leike,DeepMind
NIPS,2017,Deep Reinforcement Learning from Human Preferences,Tom Brown,Google Brain
NIPS,2017,Deep Reinforcement Learning from Human Preferences,Miljan Martic,DeepMind
NIPS,2017,Deep Reinforcement Learning from Human Preferences,Shane Legg,DeepMind
NIPS,2017,Deep Reinforcement Learning from Human Preferences,Dario Amodei,OpenAI
NIPS,2017,Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets,Karol Hausman,University of Southern California
NIPS,2017,Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets,Yevgen Chebotar,University of Southern California
NIPS,2017,Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets,Stefan Schaal,MPI-IS and USC
NIPS,2017,Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets,Gaurav Sukhatme,USC
NIPS,2017,Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets,Joseph J Lim,University of Southern California
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Haoran Tang,UC Berkeley
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Rein Houthooft,OpenAI
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Davis Foote,Google Brain
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Adam Stooke,UC Berkeley
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,OpenAI Xi Chen,"OpenAI, UC Berkeley"
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Yan Duan,
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,John Schulman,OpenAI
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Filip DeTurck,
NIPS,2017,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2017,Thinking Fast and Slow with Deep Learning and Tree Search,Thomas Anthony,UCL
NIPS,2017,Thinking Fast and Slow with Deep Learning and Tree Search,Zheng Tian,UCL
NIPS,2017,Thinking Fast and Slow with Deep Learning and Tree Search,David Barber,University College London
NIPS,2017,Natural Value Approximators: Learning when to Trust Past Estimates,Zhongwen Xu,DeepMind
NIPS,2017,Natural Value Approximators: Learning when to Trust Past Estimates,Joseph Modayil,Deepmind
NIPS,2017,Natural Value Approximators: Learning when to Trust Past Estimates,Hado van Hasselt,DeepMind
NIPS,2017,Natural Value Approximators: Learning when to Trust Past Estimates,Andre Barreto,DeepMind
NIPS,2017,Natural Value Approximators: Learning when to Trust Past Estimates,David Silver,DeepMind
NIPS,2017,Natural Value Approximators: Learning when to Trust Past Estimates,Tom Schaul,DeepMind
NIPS,2017,Active Exploration for Learning Symbolic Representations,Garrett Andersen,PROWLER.io
NIPS,2017,Active Exploration for Learning Symbolic Representations,George Konidaris,Brown University
NIPS,2017,State Aware Imitation Learning,Yannick Schroecker,Georgia Institute of Technology
NIPS,2017,State Aware Imitation Learning,Charles L Isbell,Georgia Tech
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,Andre Barreto,DeepMind
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,Will Dabney,DeepMind
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,Remi Munos,DeepMind
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,Jonathan Hunt,DeepMind
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,Tom Schaul,DeepMind
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,David Silver,DeepMind
NIPS,2017,Successor Features for Transfer in Reinforcement Learning,Hado van Hasselt,DeepMind
NIPS,2017,Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation,Daniel Guo,Carnegie Mellon University/Stanford
NIPS,2017,Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation,Philip S. Thomas,CMU
NIPS,2017,Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation,Emma Brunskill,Stanford University
NIPS,2017,Is the Bellman residual a bad proxy?,Matthieu Geist,Université de Lorraine
NIPS,2017,Is the Bellman residual a bad proxy?,Bilal Piot,DeepMind
NIPS,2017,Is the Bellman residual a bad proxy?,Olivier Pietquin,DeepMind
NIPS,2017,Learning Unknown Markov Decision Processes: A Thompson Sampling Approach,Yi Ouyang,"University of California, Berkeley"
NIPS,2017,Learning Unknown Markov Decision Processes: A Thompson Sampling Approach,Mukul Gagrani,University of Southern California
NIPS,2017,Learning Unknown Markov Decision Processes: A Thompson Sampling Approach,Ashutosh Nayyar,University of Southern California
NIPS,2017,Learning Unknown Markov Decision Processes: A Thompson Sampling Approach,Rahul Jain,University of Southern California
NIPS,2017,Online Reinforcement Learning in Stochastic Games,Chen-Yu Wei,Academia Sinica
NIPS,2017,Online Reinforcement Learning in Stochastic Games,Yi-Te Hong,National Taiwan University
NIPS,2017,Online Reinforcement Learning in Stochastic Games,Chi-Jen Lu,Academia Sinica
NIPS,2017,Reinforcement Learning under Model Mismatch,Aurko Roy,Google
NIPS,2017,Reinforcement Learning under Model Mismatch,Huan Xu,Georgia Inst. of Technology
NIPS,2017,Reinforcement Learning under Model Mismatch,Sebastian Pokutta,Georgia Institute of Technology
NIPS,2017,Zap Q-Learning,Adithya M Devraj,University of Florida
NIPS,2017,Zap Q-Learning,Sean Meyn,University of Florida
NIPS,2017,Ensemble Sampling,Xiuyuan Lu,Stanford University
NIPS,2017,Ensemble Sampling,Benjamin Van Roy,Stanford University
NIPS,2017,Action Centered Contextual Bandits,Kristjan Greenewald,University of Michigan
NIPS,2017,Action Centered Contextual Bandits,Ambuj Tewari,University of Michigan
NIPS,2017,Action Centered Contextual Bandits,Susan Murphy,University of Michigan
NIPS,2017,Action Centered Contextual Bandits,Predag Klasnja,
NIPS,2017,Conservative Contextual Linear Bandits,Abbas Kazerouni,Stanford University
NIPS,2017,Conservative Contextual Linear Bandits,Mohammad Ghavamzadeh,DeepMind
NIPS,2017,Conservative Contextual Linear Bandits,Yasin Abbasi,Adobe Research
NIPS,2017,Conservative Contextual Linear Bandits,Benjamin Van Roy,Stanford University
NIPS,2017,Rotting Bandits,Nir Levine,Technion - Israel Institute of Technology
NIPS,2017,Rotting Bandits,Koby Crammer,Technion
NIPS,2017,Rotting Bandits,Shie Mannor,Technion
NIPS,2017,Identifying Outlier Arms in Multi-Armed Bandit,Honglei Zhuang,University of Illinois
NIPS,2017,Identifying Outlier Arms in Multi-Armed Bandit,Chi Wang,Microsoft Research
NIPS,2017,Identifying Outlier Arms in Multi-Armed Bandit,Yifan Wang,Tsinghua University
NIPS,2017,Boltzmann Exploration Done Right,Nicolò Cesa-Bianchi,"Università degli Studi di Milano, Italy"
NIPS,2017,Boltzmann Exploration Done Right,Claudio Gentile,INRIA
NIPS,2017,Boltzmann Exploration Done Right,Gergely Neu,Universitat Pompeu Fabra
NIPS,2017,Boltzmann Exploration Done Right,Gabor Lugosi,Pompeu Fabra University
NIPS,2017,Improving the Expected Improvement Algorithm,Chao Qin,Columbia University
NIPS,2017,Improving the Expected Improvement Algorithm,Diego Klabjan,Northwestern University
NIPS,2017,Improving the Expected Improvement Algorithm,Daniel Russo,Columbia University
NIPS,2017,A KL-LUCB algorithm for Large-Scale Crowdsourcing,Ervin Tanczos,University of Wisconsin - Madison
NIPS,2017,A KL-LUCB algorithm for Large-Scale Crowdsourcing,Robert Nowak,University of Wisconsion-Madison
NIPS,2017,A KL-LUCB algorithm for Large-Scale Crowdsourcing,Bob Mankoff,Former Cartoon Editor of The New Yorker
NIPS,2017,Scalable Generalized Linear Bandits: Online Computation and Hashing,Kwang-Sung Jun,UW-Madison
NIPS,2017,Scalable Generalized Linear Bandits: Online Computation and Hashing,Aniruddha Bhargava,University of Wisconsin-Madison
NIPS,2017,Scalable Generalized Linear Bandits: Online Computation and Hashing,Robert Nowak,University of Wisconsion-Madison
NIPS,2017,Scalable Generalized Linear Bandits: Online Computation and Hashing,Rebecca Willett,University of Wisconsin
NIPS,2017,Bandits Dueling on Partially Ordered Sets,Julien Audiffren,"Exascale Infolab, Fribourg University"
NIPS,2017,Bandits Dueling on Partially Ordered Sets,Liva Ralaivola,"LIF, IUF, Aix-Marseille University, CNRS"
NIPS,2017,Position-based Multiple-play Bandit Problem with Unknown Position Bias,Junpei Komiyama,The University of Tokyo
NIPS,2017,Position-based Multiple-play Bandit Problem with Unknown Position Bias,Junya Honda,The University of Tokyo / RIKEN
NIPS,2017,Position-based Multiple-play Bandit Problem with Unknown Position Bias,Akiko Takeda,The Institute of Statistical Mathematics / RIKEN
NIPS,2017,Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback,Zheng Wen,Adobe Research
NIPS,2017,Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback,Branislav Kveton,Adobe Research
NIPS,2017,Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback,Michal Valko,Inria Lille - Nord Europe
NIPS,2017,Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback,Sharan Vaswani,University of British Columbia
NIPS,2017,A Scale Free Algorithm for Stochastic Bandits with Bounded Kurtosis,Tor Lattimore,DeepMind
NIPS,2017,Adaptive Active Hypothesis Testing under Limited Information,Fabio Cecchi,Eindhoven University of Technology
NIPS,2017,Adaptive Active Hypothesis Testing under Limited Information,Nidhi Hegde,Nokia Bell Labs
NIPS,2017,Overcoming Catastrophic Forgetting by Incremental Moment Matching,Sang-Woo Lee,Seoul National University
NIPS,2017,Overcoming Catastrophic Forgetting by Incremental Moment Matching,Jin-Hwa Kim,Seoul National University
NIPS,2017,Overcoming Catastrophic Forgetting by Incremental Moment Matching,Jaehyun Jun,Seoul National University
NIPS,2017,Overcoming Catastrophic Forgetting by Incremental Moment Matching,Jung-Woo Ha,"Clova, NAVER Corp."
NIPS,2017,Overcoming Catastrophic Forgetting by Incremental Moment Matching,Byoung-Tak Zhang,Seoul National University & Surromind Robotics
NIPS,2017,Hypothesis Transfer Learning via Transformation Functions,Simon Du,Carnegie Mellon University
NIPS,2017,Hypothesis Transfer Learning via Transformation Functions,Jayanth Koushik,Carnegie Mellon University
NIPS,2017,Hypothesis Transfer Learning via Transformation Functions,Aarti Singh,Carnegie Mellon University
NIPS,2017,Hypothesis Transfer Learning via Transformation Functions,Barnabas Poczos,Carnegie Mellon University
NIPS,2017,Learning multiple visual domains with residual adapters,Sylvestre-Alvise Rebuffi,University of Oxford
NIPS,2017,Learning multiple visual domains with residual adapters,Hakan Bilen,University of Edinburgh
NIPS,2017,Learning multiple visual domains with residual adapters,Andrea Vedaldi,University of Oxford
NIPS,2017,Self-supervised Learning of Motion Capture,Hsiao-Yu Tung,Carnegie Mellon University
NIPS,2017,Self-supervised Learning of Motion Capture,Hsiao-Wei Tung,University of Pittsburgh
NIPS,2017,Self-supervised Learning of Motion Capture,Ersin Yumer,Adobe Research
NIPS,2017,Self-supervised Learning of Motion Capture,Katerina Fragkiadaki,Carnegie Mellon University
NIPS,2017,"Information Theoretic Properties of Markov Random Fields, and their Algorithmic Applications",Linus Hamilton,MIT
NIPS,2017,"Information Theoretic Properties of Markov Random Fields, and their Algorithmic Applications",Frederic Koehler,MIT
NIPS,2017,"Information Theoretic Properties of Markov Random Fields, and their Algorithmic Applications",Ankur Moitra,
NIPS,2017,Local Aggregative Games,Vikas Garg,MIT
NIPS,2017,Local Aggregative Games,Tommi Jaakkola,MIT
NIPS,2017,An Empirical Bayes Approach to Optimizing Machine Learning Algorithms,James McInerney,Spotify Research
NIPS,2017,Learning Chordal Markov Networks via Branch and Bound,Kari Rantanen,University of Helsinki
NIPS,2017,Learning Chordal Markov Networks via Branch and Bound,Antti Hyttinen,University of Helsinki
NIPS,2017,Learning Chordal Markov Networks via Branch and Bound,Matti Järvisalo,University of Helsinki
NIPS,2017,Optimal Sample Complexity of M-wise Data for Top-K Ranking,Minje Jang,KAIST
NIPS,2017,Optimal Sample Complexity of M-wise Data for Top-K Ranking,Sunghyun Kim,ETRI
NIPS,2017,Optimal Sample Complexity of M-wise Data for Top-K Ranking,Changho Suh,KAIST
NIPS,2017,Optimal Sample Complexity of M-wise Data for Top-K Ranking,Sewoong Oh,UIUC
NIPS,2017,Translation Synchronization via Truncated Least Squares,Xiangru Huang,University of Texas at Austin
NIPS,2017,Translation Synchronization via Truncated Least Squares,Zhenxiao Liang,Tsinghua University
NIPS,2017,Translation Synchronization via Truncated Least Squares,Chandrajit Bajaj,The University of Texas at Austin
NIPS,2017,Translation Synchronization via Truncated Least Squares,Qixing Huang,The University of Texas at Austin
NIPS,2017,Online Learning for Multivariate Hawkes Processes,Yingxiang Yang,UIUC
NIPS,2017,Online Learning for Multivariate Hawkes Processes,Jalal Etesami,UIUC
NIPS,2017,Online Learning for Multivariate Hawkes Processes,Niao He,UIUC
NIPS,2017,Online Learning for Multivariate Hawkes Processes,Negar Kiyavash,UIUC
NIPS,2017,Efficient Second-Order Online Kernel Learning with Adaptive Embedding,Daniele Calandriello,INRIA Lille - Nord Europe
NIPS,2017,Efficient Second-Order Online Kernel Learning with Adaptive Embedding,Alessandro Lazaric,INRIA Lille-Nord Europe
NIPS,2017,Efficient Second-Order Online Kernel Learning with Adaptive Embedding,Michal Valko,Inria Lille - Nord Europe
NIPS,2017,"Online to Offline Conversions, Universality and Adaptive Minibatch Sizes",Kfir Levy,ETH
NIPS,2017,Nonparametric Online Regression while Learning the Metric,Ilja Kuzborskij,EPFL / Google Brain Intern
NIPS,2017,Nonparametric Online Regression while Learning the Metric,Nicolò Cesa-Bianchi,"Università degli Studi di Milano, Italy"
NIPS,2017,Stochastic and Adversarial Online Learning without Hyperparameters,Ashok Cutkosky,Stanford University
NIPS,2017,Stochastic and Adversarial Online Learning without Hyperparameters,Kwabena A Boahen,Stanford University
NIPS,2017,Affine-Invariant Online Optimization and the Low-rank Experts Problem,Tomer Koren,Google
NIPS,2017,Affine-Invariant Online Optimization and the Low-rank Experts Problem,Roi Livni,Princeton
NIPS,2017,Online Convex Optimization with Stochastic Constraints,Hao Yu,University of Southern California
NIPS,2017,Online Convex Optimization with Stochastic Constraints,Michael Neely,Univ. Southern California
NIPS,2017,Online Convex Optimization with Stochastic Constraints,Xiaohan Wei,University of Southern California
NIPS,2017,Online Learning with a Hint,Ofer Dekel,Microsoft Research
NIPS,2017,Online Learning with a Hint,arthur flajolet,MIT
NIPS,2017,Online Learning with a Hint,Nika Haghtalab,Carnegie Mellon University
NIPS,2017,Online Learning with a Hint,Patrick Jaillet,MIT
NIPS,2017,Efficient Online Linear Optimization with Approximation Algorithms,Dan Garber,Technion - Israel Institute of Technology
NIPS,2017,Random Permutation Online Isotonic Regression,Wojciech Kotlowski,Poznan University of Technology
NIPS,2017,Random Permutation Online Isotonic Regression,Wouter Koolen,Centrum Wiskunde & Informatica
NIPS,2017,Random Permutation Online Isotonic Regression,Alan Malek,MIT
NIPS,2017,Near Minimax Optimal Players for the Finite-Time 3-Expert Prediction Problem,Yasin Abbasi,Adobe Research
NIPS,2017,Near Minimax Optimal Players for the Finite-Time 3-Expert Prediction Problem,Peter Bartlett,UC Berkeley
NIPS,2017,Near Minimax Optimal Players for the Finite-Time 3-Expert Prediction Problem,Victor Gabillon,QUT - ACEMS
NIPS,2017,Online Learning of Optimal Bidding Strategy in Repeated Multi-Commodity Auctions,Sevi Baltaoglu,Cornell University
NIPS,2017,Online Learning of Optimal Bidding Strategy in Repeated Multi-Commodity Auctions,Lang Tong,Cornell University
NIPS,2017,Online Learning of Optimal Bidding Strategy in Repeated Multi-Commodity Auctions,Qing Zhao,Cornell University
NIPS,2017,Online Prediction with Selfish Experts,Tim Roughgarden,Stanford University
NIPS,2017,Online Prediction with Selfish Experts,Okke Schrijvers,Facebook Inc.
NIPS,2017,Real-Time Bidding with Side Information,arthur flajolet,MIT
NIPS,2017,Real-Time Bidding with Side Information,Patrick Jaillet,MIT
NIPS,2017,Improving Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms and Its Applications,Qinshi Wang,Princeton University
NIPS,2017,Improving Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms and Its Applications,Wei Chen,Microsoft Research
NIPS,2017,A General Framework for Robust Interactive Learning,Ehsan Emamjomeh-Zadeh,U. of Southern California
NIPS,2017,A General Framework for Robust Interactive Learning,David Kempe,U. of Southern California
NIPS,2017,Practical Locally Private Heavy Hitters,Raef Bassily,The Ohio State University
NIPS,2017,Practical Locally Private Heavy Hitters,kobbi Nissim,Georgetown University
NIPS,2017,Practical Locally Private Heavy Hitters,Uri Stemmer,Harvard University
NIPS,2017,Practical Locally Private Heavy Hitters,Abhradeep Guha Thakurta,University of California Santa Cruz
NIPS,2017,Deanonymization in the Bitcoin P2P Network,Giulia Fanti,Carnegie Mellon University
NIPS,2017,Deanonymization in the Bitcoin P2P Network,Pramod Viswanath,UIUC
NIPS,2017,Renyi Differential Privacy Mechanisms for Posterior Sampling,Joseph Geumlek,UCSD
NIPS,2017,Renyi Differential Privacy Mechanisms for Posterior Sampling,Shuang Song,UC San Diego
NIPS,2017,Renyi Differential Privacy Mechanisms for Posterior Sampling,Kamalika Chaudhuri,UCSD
NIPS,2017,Collecting Telemetry Data Privately,Bolin Ding,Microsoft
NIPS,2017,Collecting Telemetry Data Privately,Janardhan Kulkarni,Microsoft Research
NIPS,2017,Collecting Telemetry Data Privately,Sergey Yekhanin,Microsoft
NIPS,2017,Generating steganographic images via adversarial training,Jamie Hayes,University College London
NIPS,2017,Generating steganographic images via adversarial training,George Danezis,University College London
NIPS,2017,Thy Friend is My Friend: Iterative Collaborative Filtering for Sparse Matrix Estimation,Christian Borgs,Microsoft Research New England
NIPS,2017,Thy Friend is My Friend: Iterative Collaborative Filtering for Sparse Matrix Estimation,Jennifer Chayes,Microsoft Research
NIPS,2017,Thy Friend is My Friend: Iterative Collaborative Filtering for Sparse Matrix Estimation,Christina Lee,Microsoft Research
NIPS,2017,Thy Friend is My Friend: Iterative Collaborative Filtering for Sparse Matrix Estimation,Devavrat Shah,Massachusetts Institute of Technology
NIPS,2017,Fair Clustering Through Fairlets,Flavio Chierichetti,Sapienza University
NIPS,2017,Fair Clustering Through Fairlets,Ravi Kumar,Google
NIPS,2017,Fair Clustering Through Fairlets,Silvio Lattanzi,Google
NIPS,2017,Fair Clustering Through Fairlets,Sergei Vassilvitskii,Google
NIPS,2017,Avoiding Discrimination through Causal Reasoning,Niki Kilbertus,MPI Tuebingen & Cambridge
NIPS,2017,Avoiding Discrimination through Causal Reasoning,Mateo Rojas Carulla,"University of Cambridge, Max Planck for Intelligent Systems"
NIPS,2017,Avoiding Discrimination through Causal Reasoning,Giambattista Parascandolo,Max Planck Institute for Intelligent Systems and and Max Planck ETH CLS
NIPS,2017,Avoiding Discrimination through Causal Reasoning,Moritz Hardt,UC Berkeley
NIPS,2017,Avoiding Discrimination through Causal Reasoning,Dominik Janzing,MPI Tübingen
NIPS,2017,Avoiding Discrimination through Causal Reasoning,Bernhard Schölkopf,MPI for Intelligent Systems
NIPS,2017,Beyond Parity: Fairness Objectives for Collaborative Filtering,Sirui Yao,Virginia Polytechnic Institute and State University
NIPS,2017,Beyond Parity: Fairness Objectives for Collaborative Filtering,Bert Huang,Virginia Tech
NIPS,2017,Multi-view Matrix Factorization for Linear Dynamical System Estimation,Mahdi Karami,University of Alberta
NIPS,2017,Multi-view Matrix Factorization for Linear Dynamical System Estimation,Martha White,
NIPS,2017,Multi-view Matrix Factorization for Linear Dynamical System Estimation,Dale Schuurmans,Google
NIPS,2017,Multi-view Matrix Factorization for Linear Dynamical System Estimation,Csaba Szepesvari,University of Alberta
NIPS,2017,Random Projection Filter Bank for Time Series Data,Amir-massoud Farahmand,MERL
NIPS,2017,Random Projection Filter Bank for Time Series Data,Sepideh Pourazarm,MERL
NIPS,2017,Random Projection Filter Bank for Time Series Data,Daniel Nikovski,
NIPS,2017,Predicting User Activity Level In Point Processes With Mass Transport Equation,Yichen Wang,Georgia Tech
NIPS,2017,Predicting User Activity Level In Point Processes With Mass Transport Equation,Xiaojing Ye,Georgia State University
NIPS,2017,Predicting User Activity Level In Point Processes With Mass Transport Equation,Hongyuan Zha,Georgia Tech
NIPS,2017,Predicting User Activity Level In Point Processes With Mass Transport Equation,Le Song,Georgia Institute of Technology
NIPS,2017,A multi-agent reinforcement learning model of common-pool resource appropriation,Julien Pérolat,CNRS
NIPS,2017,A multi-agent reinforcement learning model of common-pool resource appropriation,Joel Leibo,DeepMind
NIPS,2017,A multi-agent reinforcement learning model of common-pool resource appropriation,Vinicius Zambaldi,Deepmind
NIPS,2017,A multi-agent reinforcement learning model of common-pool resource appropriation,Charles Beattie,DeepMind
NIPS,2017,A multi-agent reinforcement learning model of common-pool resource appropriation,Karl Tuyls,University of Liverpool
NIPS,2017,A multi-agent reinforcement learning model of common-pool resource appropriation,Thore Graepel,DeepMind
NIPS,2017,Scalable Demand-Aware Recommendation,Jinfeng Yi,Tencent AI Lab/IBM TJ Watson Research Center
NIPS,2017,Scalable Demand-Aware Recommendation,Cho-Jui Hsieh,UC Davis
NIPS,2017,Scalable Demand-Aware Recommendation,Kush Varshney,IBM Research
NIPS,2017,Scalable Demand-Aware Recommendation,Lijun Zhang,Nanjing University (NJU)
NIPS,2017,Scalable Demand-Aware Recommendation,Yao Li,"University of California, Davis"
NIPS,2017,A Greedy Approach for Budgeted Maximum Inner Product Search,Hsiang-Fu Yu,U Texas
NIPS,2017,A Greedy Approach for Budgeted Maximum Inner Product Search,Cho-Jui Hsieh,UC Davis
NIPS,2017,A Greedy Approach for Budgeted Maximum Inner Product Search,Qi Lei,"Institute for Computational Engineering and Sciences, University of Texas at Austin"
NIPS,2017,A Greedy Approach for Budgeted Maximum Inner Product Search,Inderjit S Dhillon,University of Texas at Austin
NIPS,2017,DPSCREEN: Dynamic Personalized Screening,Kartik Ahuja,"University of California, Los Angeles"
NIPS,2017,DPSCREEN: Dynamic Personalized Screening,William Zame,UCLA
NIPS,2017,DPSCREEN: Dynamic Personalized Screening,Mihaela van der Schaar,UCLA and Oxford University
NIPS,2017,Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks,Ahmed M. Alaa,UCLA
NIPS,2017,Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks,Mihaela van der Schaar,UCLA and Oxford University
NIPS,2017,Premise Selection for Theorem Proving by Deep Graph Embedding,Mingzhe Wang,University of Michigan
NIPS,2017,Premise Selection for Theorem Proving by Deep Graph Embedding,Yihe Tang,Carnegie Mellon University
NIPS,2017,Premise Selection for Theorem Proving by Deep Graph Embedding,Jian Wang,University of Michigan
NIPS,2017,Premise Selection for Theorem Proving by Deep Graph Embedding,Jia Deng,University of Michigan
NIPS,2017,Gradients of Generative Models for Improved Discriminative Analysis of Tandem Mass Spectra,John T Halloran,"University of California, Davis"
NIPS,2017,Gradients of Generative Models for Improved Discriminative Analysis of Tandem Mass Spectra,David M Rocke,"University of California, Davis"
NIPS,2017,Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols,Serhii Havrylov,University of Edinburgh
NIPS,2017,Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols,Ivan Titov,University of Edinburgh / University of Amsterdam
NIPS,2017,Approximation and Convergence Properties of Generative Adversarial Learning,Shuang Liu,"University of California, San Diego"
NIPS,2017,Approximation and Convergence Properties of Generative Adversarial Learning,Olivier Bousquet,Google
NIPS,2017,Approximation and Convergence Properties of Generative Adversarial Learning,Kamalika Chaudhuri,UCSD
NIPS,2017,Generalizing GANs: A Turing Perspective,Roderich Gross,The University of Sheffield
NIPS,2017,Generalizing GANs: A Turing Perspective,Yue Gu,The University of Sheffield
NIPS,2017,Generalizing GANs: A Turing Perspective,Wei Li,University of York
NIPS,2017,Generalizing GANs: A Turing Perspective,Melvin Gauci,Harvard University
NIPS,2017,Dualing GANs,Yujia Li,DeepMind
NIPS,2017,Dualing GANs,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2017,Dualing GANs,Kuan-Chieh Wang,University of Toronto
NIPS,2017,Dualing GANs,Richard Zemel,University of Toronto
NIPS,2017,Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference,Abhishek Kumar,IBM Research AI
NIPS,2017,Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference,Prasanna Sattigeri,IBM Research
NIPS,2017,Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference,Tom Fletcher,University of Utah
NIPS,2017,PixelGAN Autoencoders,Alireza Makhzani,University of Toronto
NIPS,2017,PixelGAN Autoencoders,Brendan J Frey,"Deep Genomics, Vector Institute, Univ. Toronto"
NIPS,2017,Controllable Invariance through Adversarial Feature Learning,Qizhe Xie,Carnegie Mellon University
NIPS,2017,Controllable Invariance through Adversarial Feature Learning,Zihang Dai,Carnegie Mellon University
NIPS,2017,Controllable Invariance through Adversarial Feature Learning,Yulun Du,Carnegie Mellon University
NIPS,2017,Controllable Invariance through Adversarial Feature Learning,Eduard Hovy,CMU
NIPS,2017,Controllable Invariance through Adversarial Feature Learning,Graham Neubig,Carnegie Mellon University
NIPS,2017,Adversarial Ranking for Language Generation,Kevin Lin,University of Washington
NIPS,2017,Adversarial Ranking for Language Generation,Dianqi Li,University of Washington
NIPS,2017,Adversarial Ranking for Language Generation,Xiaodong He,"Microsoft Research, Redmond, WA"
NIPS,2017,Adversarial Ranking for Language Generation,Ming-ting Sun,University of Washington
NIPS,2017,Adversarial Ranking for Language Generation,Zhengyou Zhang,Microsoft Research
NIPS,2017,Linear Time Computation of Moments in Sum-Product Networks,Han Zhao,Carnegie Mellon University
NIPS,2017,Linear Time Computation of Moments in Sum-Product Networks,Geoffrey Gordon,CMU
NIPS,2017,End-to-End Differentiable Proving,Tim Rocktäschel,University of Oxford
NIPS,2017,End-to-End Differentiable Proving,Sebastian Riedel,University College London
NIPS,2017,A simple neural network module for relational reasoning,Adam Santoro,DeepMind
NIPS,2017,A simple neural network module for relational reasoning,David Raposo,DeepMind
NIPS,2017,A simple neural network module for relational reasoning,David Barrett,DeepMind
NIPS,2017,A simple neural network module for relational reasoning,Mateusz Malinowski,DeepMind
NIPS,2017,A simple neural network module for relational reasoning,Razvan Pascanu,Google DeepMind
NIPS,2017,A simple neural network module for relational reasoning,Peter Battaglia,DeepMind
NIPS,2017,A simple neural network module for relational reasoning,Timothy Lillicrap,Google DeepMind
NIPS,2017,Deep Sets,Manzil Zaheer,Carnegie Mellon University
NIPS,2017,Deep Sets,Satwik Kottur,Carnegie Mellon University
NIPS,2017,Deep Sets,Siamak Ravanbakhsh,CMU/UBC
NIPS,2017,Deep Sets,Barnabas Poczos,Carnegie Mellon University
NIPS,2017,Deep Sets,Ruslan Salakhutdinov,
NIPS,2017,Deep Sets,Alex Smola,Amazon - We are hiring!
NIPS,2017,Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles,Balaji Lakshminarayanan,Google Deepmind
NIPS,2017,Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles,Alexander Pritzel,Google Deepmind
NIPS,2017,Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles,Charles Blundell,DeepMind
NIPS,2017,Self-Normalizing Neural Networks,Günter Klambauer,LIT AI Lab / University Linz
NIPS,2017,Self-Normalizing Neural Networks,Tom Unterthiner,LIT AI Lab / University Linz
NIPS,2017,Self-Normalizing Neural Networks,Andreas Mayr,LIT AI Lab / University Linz
NIPS,2017,Self-Normalizing Neural Networks,Sepp Hochreiter,LIT AI Lab / University Linz
NIPS,2017,Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models,Sergey Ioffe,Google
NIPS,2017,Nonlinear random matrix theory for deep learning,Jeffrey Pennington,Google Brain
NIPS,2017,Nonlinear random matrix theory for deep learning,Pratik Worah,Google
NIPS,2017,Distral: Robust multitask reinforcement learning,Yee Teh,DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,Victor Bapst,DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,Wojciech Czarnecki,DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,John Quan,Google DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,James Kirkpatrick,Google DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,Raia Hadsell,DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,Nicolas Heess,Google DeepMind
NIPS,2017,Distral: Robust multitask reinforcement learning,Razvan Pascanu,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Seb Racanière,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Theophane Weber,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,David Reichert,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Lars Buesing,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Arthur Guez,Google
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Danilo Jimenez Rezende,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Adrià Puigdomènech Badia,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Oriol Vinyals,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Nicolas Heess,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Yujia Li,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Razvan Pascanu,Google DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Peter Battaglia,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Demis Hassabis,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,David Silver,DeepMind
NIPS,2017,Imagination-Augmented Agents for Deep Reinforcement Learning,Daan Wierstra,DeepMind Technologies
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,Yitong Li,Duke University
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,michael Murias,Duke University
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,samantha Major,
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,geraldine Dawson,Duke University
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,Kafui Dzirasa,Duke University
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,Lawrence Carin,Duke University
NIPS,2017,Targeting EEG/LFP Synchrony with Neural Nets,David Carlson,Duke University
NIPS,2017,Fast amortized inference of neural activity from calcium imaging data with variational autoencoders,Artur Speiser,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Fast amortized inference of neural activity from calcium imaging data with variational autoencoders,Jinyao Yan,Janelia Research Campus
NIPS,2017,Fast amortized inference of neural activity from calcium imaging data with variational autoencoders,Evan Archer,
NIPS,2017,Fast amortized inference of neural activity from calcium imaging data with variational autoencoders,Lars Buesing,DeepMind
NIPS,2017,Fast amortized inference of neural activity from calcium imaging data with variational autoencoders,Srini C Turaga,"Janelia Research Campus, Howard Hughes Medical Institute"
NIPS,2017,Fast amortized inference of neural activity from calcium imaging data with variational autoencoders,Jakob H Macke,"research center caesar, an associate of the Max Planck Society"
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,Nikhil Parthasarathy,New York University
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,Eleanor Batty,Columbia University
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,William Falcon,Columbia University
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,Thomas Rutten,Columbia University
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,Mohit Rajpal,Columbia University
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,chichilnisky Chichilnisky,Stanford University
NIPS,2017,Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons,Liam Paninski,Columbia University
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Laurence Aitchison,University of Cambridge
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Lloyd Russell,University College London
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Adam Packer,University College London
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Jinyao Yan,Janelia Research Campus
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Philippe Castonguay,University of Montreal
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Michael Hausser,UCL
NIPS,2017,Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit,Srini C Turaga,"Janelia Research Campus, Howard Hughes Medical Institute"
NIPS,2017,Online Dynamic Programming,Holakou Rahmanian,University of California at Santa Cruz
NIPS,2017,Online Dynamic Programming,Manfred Warmuth,Univ. of Calif. at Santa Cruz
NIPS,2017,Interactive Submodular Bandit,Lin Chen,Yale University
NIPS,2017,Interactive Submodular Bandit,Andreas Krause,ETHZ
NIPS,2017,Interactive Submodular Bandit,Amin Karbasi,Yale
NIPS,2017,Streaming Robust Submodular Maximization: A Partitioned Thresholding Approach,Slobodan Mitrovic,EPFL
NIPS,2017,Streaming Robust Submodular Maximization: A Partitioned Thresholding Approach,Ilija Bogunovic,EPFL Lausanne
NIPS,2017,Streaming Robust Submodular Maximization: A Partitioned Thresholding Approach,Ashkan Norouzi-Fard,EPFL
NIPS,2017,Streaming Robust Submodular Maximization: A Partitioned Thresholding Approach,Jakub M Tarnawski,EPFL
NIPS,2017,Streaming Robust Submodular Maximization: A Partitioned Thresholding Approach,Volkan Cevher,EPFL
NIPS,2017,Minimizing a Submodular Function from Samples,Eric Balkanski,Harvard University
NIPS,2017,Minimizing a Submodular Function from Samples,Yaron Singer,Harvard University
NIPS,2017,The Marginal Value of Adaptive Gradient Methods in Machine Learning,Ashia C Wilson,UC Berkeley
NIPS,2017,The Marginal Value of Adaptive Gradient Methods in Machine Learning,Becca Roelofs,UC Berkeley
NIPS,2017,The Marginal Value of Adaptive Gradient Methods in Machine Learning,Mitchell Stern,UC Berkeley
NIPS,2017,The Marginal Value of Adaptive Gradient Methods in Machine Learning,Nati Srebro,TTI-Chicago
NIPS,2017,The Marginal Value of Adaptive Gradient Methods in Machine Learning,Benjamin Recht,UC Berkeley
NIPS,2017,Beyond Worst-case: A Probabilistic Analysis of Affine Policies in Dynamic Optimization,Omar El Housni,Columbia University
NIPS,2017,Beyond Worst-case: A Probabilistic Analysis of Affine Policies in Dynamic Optimization,Vineet Goyal,Columbia University
NIPS,2017,Approximate Supermodularity Bounds for Experimental Design,Luiz Chamon Chamon,University of Pennsylvania
NIPS,2017,Approximate Supermodularity Bounds for Experimental Design,Alejandro Ribeiro,University of Pennsylvania
NIPS,2017,On Blackbox Backpropagation and Jacobian Sensing,Krzysztof Choromanski,Google Brain Robotics
NIPS,2017,On Blackbox Backpropagation and Jacobian Sensing,Vikas Sindhwani,
NIPS,2017,Asynchronous Coordinate Descent under More Realistic Assumptions,Tao Sun,National university of defense technology
NIPS,2017,Asynchronous Coordinate Descent under More Realistic Assumptions,Robert Hannah,UCLA
NIPS,2017,Asynchronous Coordinate Descent under More Realistic Assumptions,Wotao Yin,"University of California, Los Angeles"
NIPS,2017,Clustering with Noisy Queries,Arya Mazumdar,University of Massachusetts Amherst
NIPS,2017,Clustering with Noisy Queries,Barna Saha,University of Massachusetts Amherst
NIPS,2017,Approximation Algorithms for $\ell_0$-Low Rank Approximation,Karl Bringmann,Saarland University
NIPS,2017,Approximation Algorithms for $\ell_0$-Low Rank Approximation,Pavel Kolev,Max-Planck-Institut für Informatik
NIPS,2017,Approximation Algorithms for $\ell_0$-Low Rank Approximation,David Woodruff,Carnegie Mellon University
NIPS,2017,Convergence Analysis of Two-layer Neural Networks with ReLU Activation,Yuanzhi Li,Princeton University
NIPS,2017,Convergence Analysis of Two-layer Neural Networks with ReLU Activation,Yang Yuan,Cornell University
NIPS,2017,Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent,Xiangru Lian,University of Rochester
NIPS,2017,Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent,Ce Zhang,ETH Zurich
NIPS,2017,Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent,Huan Zhang,
NIPS,2017,Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent,Cho-Jui Hsieh,UC Davis
NIPS,2017,Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent,Wei Zhang,IBM T.J.Watson Research Center
NIPS,2017,Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent,Ji Liu,University of Rochester
NIPS,2017,Decomposition-Invariant Conditional Gradient for General Polytopes with Line Search,Mohammad Ali Bashiri,University of Illinois at Chicago
NIPS,2017,Decomposition-Invariant Conditional Gradient for General Polytopes with Line Search,Xinhua Zhang,University of Illinois at Chicago (UIC)
NIPS,2017,Straggler Mitigation in Distributed Optimization Through Data Encoding,Can Karakus,UCLA
NIPS,2017,Straggler Mitigation in Distributed Optimization Through Data Encoding,Yifan Sun,
NIPS,2017,Straggler Mitigation in Distributed Optimization Through Data Encoding,Suhas Diggavi,UCLA
NIPS,2017,Straggler Mitigation in Distributed Optimization Through Data Encoding,Wotao Yin,"University of California, Los Angeles"
NIPS,2017,ADMM without a Fixed Penalty Parameter: Faster Convergence with New Adaptive Penalization,Yi Xu,The University of Iowa
NIPS,2017,ADMM without a Fixed Penalty Parameter: Faster Convergence with New Adaptive Penalization,Mingrui Liu,The University of Iowa
NIPS,2017,ADMM without a Fixed Penalty Parameter: Faster Convergence with New Adaptive Penalization,Qihang Lin,University of Iowa
NIPS,2017,ADMM without a Fixed Penalty Parameter: Faster Convergence with New Adaptive Penalization,Tianbao Yang,The University of Iowa
NIPS,2017,Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding Projection onto Simplex,Chaobing Song,Tsinghua University
NIPS,2017,Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding Projection onto Simplex,Shaobo Cui,Tsinghua University
NIPS,2017,Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding Projection onto Simplex,Yong Jiang,Tsinghua-Berkeley Shenzhen Institute
NIPS,2017,Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding Projection onto Simplex,Shu-Tao Xia,Tsinghua University
NIPS,2017,Safe Adaptive Importance Sampling,Sebastian Stich,EPFL
NIPS,2017,Safe Adaptive Importance Sampling,Anant Raj,Max Planck Institute for Intelligent Systems
NIPS,2017,Safe Adaptive Importance Sampling,Martin Jaggi,EPFL
NIPS,2017,"Sharpness, Restart and Acceleration",Vincent Roulet,INRIA / ENS Ulm
NIPS,2017,"Sharpness, Restart and Acceleration",Alexandre d'Aspremont,CNRS - Ecole Normale Supérieure
NIPS,2017,Min-Max Propagation,Christopher Srinivasa,University of Toronto/Borealis AI
NIPS,2017,Min-Max Propagation,Inmar Givoni,University of Toronto
NIPS,2017,Min-Max Propagation,Siamak Ravanbakhsh,CMU/UBC
NIPS,2017,Min-Max Propagation,Brendan J Frey,"Deep Genomics, Vector Institute, Univ. Toronto"
NIPS,2017,Hierarchical Implicit Models and Likelihood-Free Variational Inference,Dustin Tran,Columbia University & OpenAI
NIPS,2017,Hierarchical Implicit Models and Likelihood-Free Variational Inference,Rajesh Ranganath,Princeton University
NIPS,2017,Hierarchical Implicit Models and Likelihood-Free Variational Inference,David Blei,Columbia University
NIPS,2017,Perturbative Black Box Variational Inference,Robert Bamler,Disney Research
NIPS,2017,Perturbative Black Box Variational Inference,Cheng Zhang,Disney Research
NIPS,2017,Perturbative Black Box Variational Inference,Manfred Opper,TU Berlin
NIPS,2017,Perturbative Black Box Variational Inference,Stephan Mandt,Disney Research
NIPS,2017,Fast Black-box Variational Inference through Stochastic Trust-Region Optimization,Jeff Regier,UC Berkeley
NIPS,2017,Fast Black-box Variational Inference through Stochastic Trust-Region Optimization,Michael Jordan,UC Berkeley
NIPS,2017,Fast Black-box Variational Inference through Stochastic Trust-Region Optimization,Jon McAuliffe,UC Berkeley
NIPS,2017,Excess Risk Bounds for the Bayes Risk using Variational Inference in Latent Gaussian Models,Rishit Sheth,Tufts University
NIPS,2017,Excess Risk Bounds for the Bayes Risk using Variational Inference in Latent Gaussian Models,Roni Khardon,Tufts University
NIPS,2017,Experimental Design for Learning Causal Graphs with Latent Variables,Murat Kocaoglu,University of Texas at Austin
NIPS,2017,Experimental Design for Learning Causal Graphs with Latent Variables,Karthikeyan Shanmugam,"IBM Research, NY"
NIPS,2017,Experimental Design for Learning Causal Graphs with Latent Variables,Elias Bareinboim,Purdue
NIPS,2017,Learning Causal Structures Using Regression Invariance,AmirEmad Ghassami,University of Illinois at Urbana–Champaign
NIPS,2017,Learning Causal Structures Using Regression Invariance,Saber Salehkaleybar,University of Illinois at Urbana-Champaign
NIPS,2017,Learning Causal Structures Using Regression Invariance,Negar Kiyavash,UIUC
NIPS,2017,Learning Causal Structures Using Regression Invariance,Kun Zhang,CMU
NIPS,2017,Counterfactual Fairness,Matt Kusner,Alan Turing Institute
NIPS,2017,Counterfactual Fairness,Joshua Loftus,The Alan Turing Institute
NIPS,2017,Counterfactual Fairness,Chris Russell,The Alan Turing Institute/ The University of Surrey
NIPS,2017,Counterfactual Fairness,Ricardo Silva,ucl.ac.uk
NIPS,2017,Tractability in Structured Probability Spaces,Arthur Choi,UCLA
NIPS,2017,Tractability in Structured Probability Spaces,Yujia Shen,UCLA
NIPS,2017,Tractability in Structured Probability Spaces,Adnan Darwiche,UCLA
NIPS,2017,Adaptive Bayesian Sampling with Monte Carlo EM,Anirban Roychowdhury,Ohio State University
NIPS,2017,Adaptive Bayesian Sampling with Monte Carlo EM,Srinivasan Parthasarathy,The Ohio State University
NIPS,2017,Reliable Decision Support using Counterfactual Models,Peter Schulam,Johns Hopkins University
NIPS,2017,Reliable Decision Support using Counterfactual Models,Suchi Saria,Johns Hopkins University
NIPS,2017,Repeated Inverse Reinforcement Learning,Kareem Amin,Google Research
NIPS,2017,Repeated Inverse Reinforcement Learning,Nan Jiang,Microsoft Research
NIPS,2017,Repeated Inverse Reinforcement Learning,Satinder Singh,University of Michigan
NIPS,2017,Inverse Reward Design,Dylan Hadfield-Menell,UC Berkeley
NIPS,2017,Inverse Reward Design,Smitha Milli,UC Berkeley
NIPS,2017,Inverse Reward Design,Pieter Abbeel,OpenAI / UC Berkeley / Gradescope
NIPS,2017,Inverse Reward Design,Stuart J Russell,UC Berkeley
NIPS,2017,Inverse Reward Design,Anca Dragan,UC Berkeley
NIPS,2017,Policy Gradient With Value Function Approximation For Collective Multiagent Planning,Duc Nguyen,Singapore Management University
NIPS,2017,Policy Gradient With Value Function Approximation For Collective Multiagent Planning,Akshat Kumar,Singapore Management University
NIPS,2017,Policy Gradient With Value Function Approximation For Collective Multiagent Planning,Hoong Chuin Lau,Singapore Management University
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Marc Lanctot,DeepMind
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Vinicius Zambaldi,Deepmind
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Audrunas Gruslys,Google DeepMind
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Angeliki Lazaridou,DeepMind
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Karl Tuyls,University of Liverpool
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Julien Perolat,DeepMind
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,David Silver,DeepMind
NIPS,2017,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,Thore Graepel,DeepMind
NIPS,2017,Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learning,El Mahdi El Mhamdi,EPFL
NIPS,2017,Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learning,Rachid Guerraoui,
NIPS,2017,Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learning,Hadrien Hendrikx,EPFL
NIPS,2017,Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learning,Alexandre Maurer,EPFL
NIPS,2017,Spectrally-normalized margin bounds for neural networks,Peter Bartlett,UC Berkeley
NIPS,2017,Spectrally-normalized margin bounds for neural networks,Dylan J Foster,Cornell University
NIPS,2017,Spectrally-normalized margin bounds for neural networks,Matus Telgarsky,UIUC
NIPS,2017,Collaborative PAC Learning,Avrim Blum,Toyota Technological Institute at Chicago
NIPS,2017,Collaborative PAC Learning,Nika Haghtalab,Carnegie Mellon University
NIPS,2017,Collaborative PAC Learning,Ariel D Procaccia,Carnegie Mellon University
NIPS,2017,Collaborative PAC Learning,Mingda Qiao,"IIIS, Tsinghua University"
NIPS,2017,Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues,Noga Alon,Tel Aviv University
NIPS,2017,Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues,Moshe Babaioff,Microsoft Research
NIPS,2017,Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues,Yannai A. Gonczarowski,The Hebrew University of Jerusalem and Microsoft Research
NIPS,2017,Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues,Yishay Mansour,Tel Aviv University
NIPS,2017,Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues,Shay Moran,"IAS, Princeton"
NIPS,2017,Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues,Amir Yehudayoff,Technion - Israel institue of Technology
NIPS,2017,Discriminative State Space Models,Vitaly Kuznetsov,Google Research
NIPS,2017,Discriminative State Space Models,Mehryar Mohri,Courant Institute and Google
NIPS,2017,Countering Feedback Delays in Multi-Agent Learning,Zhengyuan Zhou,Stanford University
NIPS,2017,Countering Feedback Delays in Multi-Agent Learning,Panayotis Mertikopoulos,CNRS (French National Center for Scientific Research)
NIPS,2017,Countering Feedback Delays in Multi-Agent Learning,Nicholas Bambos,
NIPS,2017,Countering Feedback Delays in Multi-Agent Learning,Peter W Glynn,Stanford University
NIPS,2017,Countering Feedback Delays in Multi-Agent Learning,Claire Tomlin,UC Berkeley
NIPS,2017,Variance-based Regularization with Convex Objectives,Hong Namkoong,Stanford University
NIPS,2017,Variance-based Regularization with Convex Objectives,John Duchi,Stanford
NIPS,2017,Learning Mixture of Gaussians with Streaming Data,Aditi Raghunathan,Stanford University
NIPS,2017,Learning Mixture of Gaussians with Streaming Data,Prateek Jain,Microsoft Research
NIPS,2017,Learning Mixture of Gaussians with Streaming Data,Ravishankar Krishnawamy,Microsoft Research India
NIPS,2017,On the Consistency of Quick Shift,Heinrich Jiang,Google
NIPS,2017,Early stopping for kernel boosting algorithms: A general analysis with localized complexities,Yuting Wei,"University of California, Berkeley"
NIPS,2017,Early stopping for kernel boosting algorithms: A general analysis with localized complexities,Fanny Yang,"University of California, Berkeley"
NIPS,2017,Early stopping for kernel boosting algorithms: A general analysis with localized complexities,Martin Wainwright,UC Berkeley
NIPS,2017,The Scaling Limit of High-Dimensional Online Independent Component Analysis,Chuang Wang,Harvard University
NIPS,2017,The Scaling Limit of High-Dimensional Online Independent Component Analysis,Yue Lu,Harvard University
NIPS,2017,Convergence of Gradient EM on Multi-component Mixture of Gaussians,Bowei Yan,University of Texas at Austin
NIPS,2017,Convergence of Gradient EM on Multi-component Mixture of Gaussians,Mingzhang Yin,University of Texas at Austin
NIPS,2017,Convergence of Gradient EM on Multi-component Mixture of Gaussians,Purnamrita Sarkar,UT Austin
NIPS,2017,Learning with Bandit Feedback in Potential Games,Amélie Héliou,Univ. Grenoble Alpes
NIPS,2017,Learning with Bandit Feedback in Potential Games,Johanne Cohen,LRI-CNRS
NIPS,2017,Learning with Bandit Feedback in Potential Games,Panayotis Mertikopoulos,CNRS (French National Center for Scientific Research)
NIPS,2017,Fully Decentralized Policies for Multi-Agent Systems: An Information Theoretic Approach,Roel Dobbe,UC Berkeley
NIPS,2017,Fully Decentralized Policies for Multi-Agent Systems: An Information Theoretic Approach,David Fridovich-Keil,UC Berkeley
NIPS,2017,Fully Decentralized Policies for Multi-Agent Systems: An Information Theoretic Approach,Claire Tomlin,UC Berkeley
NIPS,2017,Revenue Optimization with Approximate Bid Predictions,Andres Munoz,
NIPS,2017,Revenue Optimization with Approximate Bid Predictions,Sergei Vassilvitskii,Google
NIPS,2017,A Decomposition of Forecast Error in Prediction Markets,Miro Dudik,Microsoft Research
NIPS,2017,A Decomposition of Forecast Error in Prediction Markets,Sebastien Lahaie,Google
NIPS,2017,A Decomposition of Forecast Error in Prediction Markets,Ryan M Rogers,University of Pennsylvania
NIPS,2017,A Decomposition of Forecast Error in Prediction Markets,Jenn Wortman Vaughan,Microsoft Research
NIPS,2017,Dynamic Revenue Sharing,Santiago Balseiro,Duke University
NIPS,2017,Dynamic Revenue Sharing,Max Lin,Google
NIPS,2017,Dynamic Revenue Sharing,Vahab Mirrokni,Google Research NYC
NIPS,2017,Dynamic Revenue Sharing,Renato Leme,Google Research
NIPS,2017,Dynamic Revenue Sharing,IIIS Song Zuo,"IIIS, Tsinghua University"
NIPS,2017,Multi-View Decision Processes: The Helper-AI Problem,Christos Dimitrakakis,Chalmers / Harvard / Lille / Oslo
NIPS,2017,Multi-View Decision Processes: The Helper-AI Problem,David Parkes,Harvard University
NIPS,2017,Multi-View Decision Processes: The Helper-AI Problem,Goran Radanovic,Harvard
NIPS,2017,Multi-View Decision Processes: The Helper-AI Problem,Paul Tylkin,Harvard University
NIPS,2018,e-SNLI: Natural Language Inference with Natural Language Explanations,Oana-Maria Camburu,University of Oxford
NIPS,2018,e-SNLI: Natural Language Inference with Natural Language Explanations,Tim Rocktäschel,University of Oxford
NIPS,2018,e-SNLI: Natural Language Inference with Natural Language Explanations,Thomas Lukasiewicz,University of Oxford
NIPS,2018,e-SNLI: Natural Language Inference with Natural Language Explanations,Phil Blunsom,Oxford University
NIPS,2018,Sharp Bounds for Generalized Uniformity Testing,Ilias Diakonikolas,University of Southern California
NIPS,2018,Sharp Bounds for Generalized Uniformity Testing,Daniel M. Kane,UCSD
NIPS,2018,Sharp Bounds for Generalized Uniformity Testing,Alistair Stewart,University of Southern California
NIPS,2018,Deep Neural Networks with Box Convolutions,Egor Burkov,Samsung
NIPS,2018,Deep Neural Networks with Box Convolutions,Victor Lempitsky,Samsung
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Weiyang Liu,Georgia Institute of Technology
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Rongmei Lin,Emory University
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Zhen Liu,Georgia Institute of Technology
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Lixin Liu,SCUT
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Zhiding Yu,NVIDIA
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Bo Dai,Google Brain
NIPS,2018,Learning towards Minimum Hyperspherical Energy,Le Song,Ant Financial & Georgia Institute of Technology
NIPS,2018,LF-Net: Learning Local Features from Images,Yuki Ono,SONY
NIPS,2018,LF-Net: Learning Local Features from Images,Eduard Trulls,EPFL
NIPS,2018,LF-Net: Learning Local Features from Images,Pascal Fua,"EPFL, Switzerland"
NIPS,2018,LF-Net: Learning Local Features from Images,Kwang Yi,University of Victoria
NIPS,2018,Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming,Bart van Merrienboer,"MILA, Google"
NIPS,2018,Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming,Dan Moldovan,Google
NIPS,2018,Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming,Alexander Wiltschko,Google Brain
NIPS,2018,Multi-domain Causal Structure Learning in Linear Systems,AmirEmad Ghassami,University of Illinois at Urbana–Champaign
NIPS,2018,Multi-domain Causal Structure Learning in Linear Systems,Negar Kiyavash,Georgia Tech
NIPS,2018,Multi-domain Causal Structure Learning in Linear Systems,Biwei Huang,Carnegie Mellon University
NIPS,2018,Multi-domain Causal Structure Learning in Linear Systems,Kun Zhang,CMU
NIPS,2018,Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences,Borja Balle,Amazon Research Cambridge
NIPS,2018,Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences,Gilles Barthe,IMDEA Software Institute
NIPS,2018,Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences,Marco Gaboardi,Univeristy at Buffalo
NIPS,2018,Algebraic tests of general Gaussian latent tree models,Dennis Leung,University of Southern California
NIPS,2018,Algebraic tests of general Gaussian latent tree models,Mathias Drton,University of Washington
NIPS,2018,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models,Minjia Zhang,Microsoft
NIPS,2018,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models,Wenhan Wang,Microsoft
NIPS,2018,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models,Xiaodong Liu,Microsoft
NIPS,2018,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models,Jianfeng Gao,"Microsoft Research, Redmond, WA"
NIPS,2018,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models,Yuxiong He,Microsoft
NIPS,2018,Deep Structured Prediction via Nonlinear Output Transformations,Colin Graber,University of Illinois at Urbana-Champaign
NIPS,2018,Deep Structured Prediction via Nonlinear Output Transformations,Ofer Meshi,Google
NIPS,2018,Deep Structured Prediction via Nonlinear Output Transformations,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2018,Computationally and Statistically Efficient Learning of Bayes Nets Using Path Queries,Kevin Bello,Purdue University
NIPS,2018,Computationally and Statistically Efficient Learning of Bayes Nets Using Path Queries,Jean Honorio,Purdue University
NIPS,2018,Sparse PCA from Sparse Linear Regression,Guy Bresler,MIT
NIPS,2018,Sparse PCA from Sparse Linear Regression,Sung Min Park,MIT
NIPS,2018,Sparse PCA from Sparse Linear Regression,Madalina Persu,"Two Sigma Investments, MIT"
NIPS,2018,Sequential Data Classification for Resource-constrained Devices,Don Dennis,Microsoft Research
NIPS,2018,Sequential Data Classification for Resource-constrained Devices,Chirag Pabbaraju,Microsoft Research
NIPS,2018,Sequential Data Classification for Resource-constrained Devices,Harsha Simhadri,Microsoft Research India
NIPS,2018,Sequential Data Classification for Resource-constrained Devices,Prateek Jain,Microsoft Research
NIPS,2018,The Price of Fair PCA: One Extra dimension,Samira Samadi,Georgia Tech
NIPS,2018,The Price of Fair PCA: One Extra dimension,Tao (Uthaipon) Tantipongpipat,Georgia Tech
NIPS,2018,The Price of Fair PCA: One Extra dimension,Jamie Morgenstern,Georgia Tech
NIPS,2018,The Price of Fair PCA: One Extra dimension,Mohit Singh,Georgia Tech
NIPS,2018,The Price of Fair PCA: One Extra dimension,Santosh Vempala,Georgia Tech
NIPS,2018,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking,Patrick Chen,UCLA
NIPS,2018,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking,Si Si,Google Research
NIPS,2018,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking,Yang Li,Google
NIPS,2018,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking,Ciprian Chelba,Google
NIPS,2018,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking,Cho-Jui Hsieh,"UCLA, Google Research"
NIPS,2018,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents",Nick Haber,Stanford University
NIPS,2018,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents",Damian Mrowca,Stanford University
NIPS,2018,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents",Stephanie Wang,Stanford University
NIPS,2018,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents",Li Fei-Fei,Stanford University & Google
NIPS,2018,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents",Daniel Yamins,Stanford University
NIPS,2018,Scaling provable adversarial defenses,Eric Wong,Carnegie Mellon University
NIPS,2018,Scaling provable adversarial defenses,Frank Schmidt,Robert Bosch GmbH
NIPS,2018,Scaling provable adversarial defenses,Jan Hendrik Metzen,Robert Bosch GmbH
NIPS,2018,Scaling provable adversarial defenses,J. Zico Kolter,Carnegie Mellon University / Bosch Center for AI
NIPS,2018,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images,Andrei Zanfir,Institute of Mathematics of the Romanian Academy
NIPS,2018,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images,Elisabeta Marinoiu,IMAR
NIPS,2018,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images,Mihai Zanfir,IMAR
NIPS,2018,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images,Alin-Ionut Popa,IMAR
NIPS,2018,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images,Cristian Sminchisescu,LTH
NIPS,2018,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs,Han Shao,The Chinese University of Hong Kong
NIPS,2018,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs,Xiaotian Yu,The Chinese University of Hong Kong
NIPS,2018,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs,Irwin King,Chinese University of Hong Kong
NIPS,2018,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs,Michael Lyu,CUHK
NIPS,2018,Data-dependent PAC-Bayes priors via differential privacy,Gintare Karolina Dziugaite,University of Cambridge
NIPS,2018,Data-dependent PAC-Bayes priors via differential privacy,Dan Roy,Univ of Toronto & Vector
NIPS,2018,Deep Poisson gamma dynamical systems,Dandan Guo,Xidian University
NIPS,2018,Deep Poisson gamma dynamical systems,Bo Chen,Xidian University
NIPS,2018,Deep Poisson gamma dynamical systems,Hao Zhang,Petuum Inc.
NIPS,2018,Deep Poisson gamma dynamical systems,Mingyuan Zhou,University of Texas at Austin
NIPS,2018,Continuity vs. Injectivity in Dimensionality Reduction: a Quantitative Topology View,Kry Lui,BorealisAI
NIPS,2018,Continuity vs. Injectivity in Dimensionality Reduction: a Quantitative Topology View,Gavin Weiguang Ding,Borealis AI
NIPS,2018,Continuity vs. Injectivity in Dimensionality Reduction: a Quantitative Topology View,Ruitong Huang,Borealis AI
NIPS,2018,Continuity vs. Injectivity in Dimensionality Reduction: a Quantitative Topology View,Robert McCann,University of Toronto
NIPS,2018,Teaching Inverse Reinforcement Learners via Features and Demonstrations,Luis Haug,ETH Zurich
NIPS,2018,Teaching Inverse Reinforcement Learners via Features and Demonstrations,Sebastian Tschiatschek,Microsoft Research
NIPS,2018,Teaching Inverse Reinforcement Learners via Features and Demonstrations,Adish Singla,MPI-SWS
NIPS,2018,Wasserstein Distributionally Robust Kalman Filtering,Soroosh Shafieezadeh Abadeh,EPFL
NIPS,2018,Wasserstein Distributionally Robust Kalman Filtering,Viet Anh Nguyen,Ecole Polytechnique Federale de Lausanne
NIPS,2018,Wasserstein Distributionally Robust Kalman Filtering,Daniel Kuhn,EPFL
NIPS,2018,Wasserstein Distributionally Robust Kalman Filtering,Peyman Mohajerin Esfahani,TU Delft
NIPS,2018,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization",Blake Woodworth,TTI-Chicago
NIPS,2018,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization",Jialei Wang,"Two Sigma Investments, University of Chicago"
NIPS,2018,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization",Adam Smith,Boston University
NIPS,2018,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization",Brendan McMahan,Google
NIPS,2018,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization",Nati Srebro,TTI-Chicago
NIPS,2018,Adversarial Regularizers in Inverse Problems,Sebastian Lunz,University of Cambridge
NIPS,2018,Adversarial Regularizers in Inverse Problems,Carola Schoenlieb,Cambridge University
NIPS,2018,Adversarial Regularizers in Inverse Problems,Ozan Öktem,KTH - Royal Institute of Technology
NIPS,2018,Clustering Redemption–Beyond the Impossibility of Kleinberg’s Axioms,Vincent Cohen-Addad,CNRS & Sorbonne Université
NIPS,2018,Clustering Redemption–Beyond the Impossibility of Kleinberg’s Axioms,Varun Kanade,University of Oxford
NIPS,2018,Clustering Redemption–Beyond the Impossibility of Kleinberg’s Axioms,Frederik Mallmann-Trenn,MIT
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Bo Han,RIKEN & UTS
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Quanming Yao,4Paradigm
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Xingrui Yu,University of Technology Sydney
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Gang Niu,RIKEN
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Miao Xu,RIKEN AIP
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Weihua Hu,The University of Tokyo
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Ivor Tsang,"University of Technology, Sydney"
NIPS,2018,Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2018,An Event-Based Framework for Task Specification and Control,Justin Fu,UC Berkeley
NIPS,2018,An Event-Based Framework for Task Specification and Control,Avi Singh,UC Berkeley
NIPS,2018,An Event-Based Framework for Task Specification and Control,Dibya Ghosh,UC Berkeley
NIPS,2018,An Event-Based Framework for Task Specification and Control,Larry Yang,UC Berkeley
NIPS,2018,An Event-Based Framework for Task Specification and Control,Sergey Levine,UC Berkeley
NIPS,2018,Adversarial Multiple Source Domain Adaptation,Han Zhao,Carnegie Mellon University
NIPS,2018,Adversarial Multiple Source Domain Adaptation,Shanghang Zhang,Carnegie Mellon University
NIPS,2018,Adversarial Multiple Source Domain Adaptation,Guanhang Wu,Carnegie Mellon University
NIPS,2018,Adversarial Multiple Source Domain Adaptation,José M. F. Moura,Carnegie Mellon University
NIPS,2018,Adversarial Multiple Source Domain Adaptation,Joao P Costeira,Instituto Superior Tecnico VAT- 501507930
NIPS,2018,Adversarial Multiple Source Domain Adaptation,Geoffrey Gordon,MSR Montréal & CMU
NIPS,2018,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,Arthur Jacot-Guillarmod,EPFL
NIPS,2018,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,Clement Hongler,EPFL
NIPS,2018,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,Franck Gabriel,EPFL
NIPS,2018,A statistical model for graph partitioning with high-dimensional covariates,Yash Deshpande,Massachusetts Institute of Technology
NIPS,2018,A statistical model for graph partitioning with high-dimensional covariates,Subhabrata Sen,Massachusetts Institute of Technology
NIPS,2018,A statistical model for graph partitioning with high-dimensional covariates,Andrea Montanari,Stanford
NIPS,2018,A statistical model for graph partitioning with high-dimensional covariates,Elchanan Mossel,MIT
NIPS,2018,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks,Jeffrey Chan,UC Berkeley
NIPS,2018,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks,Valerio Perrone,University of Warwick
NIPS,2018,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks,Jeffrey Spence,UC Berkeley
NIPS,2018,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks,Paul Jenkins,University of Warwick
NIPS,2018,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks,Sara Mathieson,Swarthmore College
NIPS,2018,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks,Yun Song,UC Berkeley
NIPS,2018,Randomized Prior Functions for Deep Reinforcement Learning,Ian Osband,Google Deepmind
NIPS,2018,Randomized Prior Functions for Deep Reinforcement Learning,jaslanides Aslanides,DeepMind
NIPS,2018,Randomized Prior Functions for Deep Reinforcement Learning,cassirer Cassirer,DeepMind
NIPS,2018,Compact Representation of Uncertainty In Clustering,Craig Greenberg,University of Massachusetts Amherst / NIST
NIPS,2018,Compact Representation of Uncertainty In Clustering,Nicholas Monath,University of Massachusetts Amherst
NIPS,2018,Compact Representation of Uncertainty In Clustering,Ari Kobren,UMass Amherst
NIPS,2018,Compact Representation of Uncertainty In Clustering,Patrick Flaherty,"University of Massachusetts, Amherst"
NIPS,2018,Compact Representation of Uncertainty In Clustering,Andrew McGregor,University of Massachusetts Amherst
NIPS,2018,Compact Representation of Uncertainty In Clustering,Andrew McCallum,UMass Amherst
NIPS,2018,Minimax Rates in Contextual Partial Monitoring,Alan Malek,MIT
NIPS,2018,Minimax Rates in Contextual Partial Monitoring,Dylan Foster,Cornell University
NIPS,2018,Minimax Rates in Contextual Partial Monitoring,Ali Jadbabaie,MIT
NIPS,2018,Minimax Rates in Contextual Partial Monitoring,Alexander Rakhlin,MIT
NIPS,2018,Learning without Phase: Regularized PhaseMax Achieves Optimal Sample Complexity,Fariborz Salehi,California Institute of Technology
NIPS,2018,Learning without Phase: Regularized PhaseMax Achieves Optimal Sample Complexity,Ehsan Abbasi,Caltech
NIPS,2018,Learning without Phase: Regularized PhaseMax Achieves Optimal Sample Complexity,Babak Hassibi,Caltech
NIPS,2018,Multilingual Anchoring: Interactive Topic Modeling and Alignment Across Languages,Michelle Yuan,"University of Maryland, College Park"
NIPS,2018,Multilingual Anchoring: Interactive Topic Modeling and Alignment Across Languages,Benjamin Van Durme,Johns Hopkins University
NIPS,2018,Multilingual Anchoring: Interactive Topic Modeling and Alignment Across Languages,Jordan Ying,University of Maryland
NIPS,2018,Estimators for Multivariate Information Measures in General Probability Spaces,Arman Rahimzamani,University of Washington
NIPS,2018,Estimators for Multivariate Information Measures in General Probability Spaces,Himanshu Asnani,"University of Washington, Seattle"
NIPS,2018,Estimators for Multivariate Information Measures in General Probability Spaces,Pramod Viswanath,UIUC
NIPS,2018,Estimators for Multivariate Information Measures in General Probability Spaces,Sreeram Kannan,University of Washington
NIPS,2018,DeepPINK: reproducible feature selection in deep neural networks,Yang Lu,University of Washington
NIPS,2018,DeepPINK: reproducible feature selection in deep neural networks,Yingying Fan,University of Southern California
NIPS,2018,DeepPINK: reproducible feature selection in deep neural networks,Jinchi Lv,University of Southern California
NIPS,2018,DeepPINK: reproducible feature selection in deep neural networks,William Stafford Noble,
NIPS,2018,Synthesis of Differentiable Functional Programs for Lifelong Learning,Lazar Valkov,University of Edinburgh
NIPS,2018,Synthesis of Differentiable Functional Programs for Lifelong Learning,Dipak Chaudhari,Rice University
NIPS,2018,Synthesis of Differentiable Functional Programs for Lifelong Learning,Akash Srivastava,University of Edinburgh
NIPS,2018,Synthesis of Differentiable Functional Programs for Lifelong Learning,Charles Sutton,Google
NIPS,2018,Synthesis of Differentiable Functional Programs for Lifelong Learning,Swarat Chaudhuri,Rice University
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Liang-Chieh Chen,Google Inc.
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Maxwell Collins,Google Inc.
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Yukun Zhu,Google
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,George Papandreou,Google
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Barret Zoph,Google Brain
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Florian Schroff,"Google Inc., Venice, CA"
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Hartwig Adam,Google
NIPS,2018,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,Jon Shlens,Google Research
NIPS,2018,Orthogonally Decoupled Variational Gaussian Processes,Hugh Salimbeni,Imperial College London
NIPS,2018,Orthogonally Decoupled Variational Gaussian Processes,Ching-An Cheng,Georgia Tech
NIPS,2018,Orthogonally Decoupled Variational Gaussian Processes,Byron Boots,Georgia Tech / Google Brain
NIPS,2018,Orthogonally Decoupled Variational Gaussian Processes,Marc Deisenroth,Imperial College London
NIPS,2018,Dendritic cortical microcircuits approximate the backpropagation algorithm,João Sacramento,University of Bern
NIPS,2018,Dendritic cortical microcircuits approximate the backpropagation algorithm,Rui Ponte Costa,Univeristy of Bern
NIPS,2018,Dendritic cortical microcircuits approximate the backpropagation algorithm,Yoshua Bengio,U. Montreal
NIPS,2018,Dendritic cortical microcircuits approximate the backpropagation algorithm,Walter Senn,University of Bern
NIPS,2018,Automatic differentiation in ML: Where we are and where we should be going,Bart van Merrienboer,"MILA, Google"
NIPS,2018,Automatic differentiation in ML: Where we are and where we should be going,Olivier Breuleux,MILA
NIPS,2018,Automatic differentiation in ML: Where we are and where we should be going,Arnaud Bergeron,Université de Montréal (MILA)
NIPS,2018,Automatic differentiation in ML: Where we are and where we should be going,Pascal Lamblin,Google
NIPS,2018,A Bayesian Nonparametric View on Count-Min Sketch,Diana Cai,Princeton University
NIPS,2018,A Bayesian Nonparametric View on Count-Min Sketch,Michael Mitzenmacher,Harvard University
NIPS,2018,A Bayesian Nonparametric View on Count-Min Sketch,Ryan Adams,Google Brain and Princeton University
NIPS,2018,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels,Zhilu Zhang,Cornell University
NIPS,2018,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels,Mert Sabuncu,Cornell
NIPS,2018,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs",Timur Garipov,Moscow State University
NIPS,2018,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs",Pavel Izmailov,Cornell University
NIPS,2018,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs",Dmitrii Podoprikhin,XTX markets
NIPS,2018,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs",Dmitry Vetrov,"Higher School of Economics, Samsung AI Center, Moscow"
NIPS,2018,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs",Andrew Wilson,Cornell University
NIPS,2018,Legendre Decomposition for Tensors,Mahito Sugiyama,National Institute of Informatics
NIPS,2018,Legendre Decomposition for Tensors,Hiroyuki Nakahara,RIKEN Brain Science Institute
NIPS,2018,Legendre Decomposition for Tensors,Koji Tsuda,The University of Tokyo / RIKEN
NIPS,2018,Reinforcement Learning of Theorem Proving,Cezary Kaliszyk,Innsbruck University
NIPS,2018,Reinforcement Learning of Theorem Proving,Josef Urban,Czech Technical University in Prague
NIPS,2018,Reinforcement Learning of Theorem Proving,Henryk Michalewski,"University of Warsaw, University of Oxford, deepsense.ai"
NIPS,2018,Reinforcement Learning of Theorem Proving,Miroslav Olšák,Charles University in Prague
NIPS,2018,Group Equivariant Capsule Networks,Jan Lenssen,TU Dortmund
NIPS,2018,Group Equivariant Capsule Networks,Matthias Fey,TU Dortmund
NIPS,2018,Group Equivariant Capsule Networks,Pascal Libuschewski,TU Dortmund
NIPS,2018,Stein Variational Gradient Descent as Moment Matching,Qiang Liu,UT Austin
NIPS,2018,Stein Variational Gradient Descent as Moment Matching,Dilin Wang,UT Austin
NIPS,2018,Differential Privacy for Growing Databases,Rachel Cummings,Georgia Tech
NIPS,2018,Differential Privacy for Growing Databases,Sara Krehbiel,University of Richmond
NIPS,2018,Differential Privacy for Growing Databases,Kevin A Lai,Georgia Tech
NIPS,2018,Differential Privacy for Growing Databases,Tao (Uthaipon) Tantipongpipat,Georgia Tech
NIPS,2018,Exploration in Structured Reinforcement Learning,Jungseul Ok,UIUC
NIPS,2018,Exploration in Structured Reinforcement Learning,Damianos Tranos,KTH Royal Institute of Stockholm
NIPS,2018,Exploration in Structured Reinforcement Learning,Alexandre Proutiere,KTH
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Rudrasis Chakraborty,University of Florida
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Chun-Hao Yang,University of Florida
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Xingjian Zhen,UW-Madison
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Monami Banerjee,University of Florida
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Derek Archer,University of Florida
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,David Vaillancourt,University of Florida
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Vikas Singh,UW-Madison
NIPS,2018,Statistical Recurrent Models on Manifold valued Data,Baba Vemuri,"University of Florida, USA"
NIPS,2018,Balanced Policy Evaluation and Learning,Nathan Kallus,Cornell University
NIPS,2018,Distributed Multitask Reinforcement Learning with Quadratic Convergence,Rasul Tutunov,PROWLER.io
NIPS,2018,Distributed Multitask Reinforcement Learning with Quadratic Convergence,Dongho Kim,PROWLER.io
NIPS,2018,Distributed Multitask Reinforcement Learning with Quadratic Convergence,Haitham Bou Ammar,PROWLER.io
NIPS,2018,Improving Neural Program Synthesis with Inferred Execution Traces,Richard Shin,UC Berkeley
NIPS,2018,Improving Neural Program Synthesis with Inferred Execution Traces,Illia Polosukhin,NEAR
NIPS,2018,Improving Neural Program Synthesis with Inferred Execution Traces,Dawn Song,UC Berkeley
NIPS,2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,Jung-Su Ha,KAIST
NIPS,2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,Young-Jin Park,KAIST
NIPS,2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,Hyeok-Joo Chae,KAIST
NIPS,2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,Soon-Seo Park,KAIST
NIPS,2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,Han-Lim Choi,Korea Advanced Institute of Science and Technology
NIPS,2018,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes,Andrea Tirinzoni,Politecnico di Milano
NIPS,2018,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes,Marek Petrik,University of New Hampshire
NIPS,2018,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes,Xiangli Chen,University of Illinois at Chicago
NIPS,2018,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes,Brian Ziebart,University of Illinois at Chicago
NIPS,2018,Online Learning of Quantum States,Scott Aaronson,UT Austin
NIPS,2018,Online Learning of Quantum States,Xinyi Chen,Google Brain
NIPS,2018,Online Learning of Quantum States,Elad Hazan,Princeton University
NIPS,2018,Online Learning of Quantum States,Satyen Kale,Google
NIPS,2018,Online Learning of Quantum States,Ashwin Nayak,University of Waterloo
NIPS,2018,Inferring Latent Velocities from Weather Radar Data using Gaussian Processes,Rico Angell,University of Massachusetts
NIPS,2018,Inferring Latent Velocities from Weather Radar Data using Gaussian Processes,Dan Sheldon,University of Massachusetts Amherst
NIPS,2018,A Structured Prediction Approach for Label Ranking,Anna Korba,TELECOM PARISTECH
NIPS,2018,A Structured Prediction Approach for Label Ranking,Alexandre Garcia,Telecom ParisTech
NIPS,2018,A Structured Prediction Approach for Label Ranking,Florence d'Alché-Buc,"LTCI,Télécom ParisTech, University of Paris-Saclay"
NIPS,2018,Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features,Mojmir Mutny,ETH Zurich
NIPS,2018,Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features,Andreas Krause,ETHZ
NIPS,2018,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network",Aditya Kusupati,Microsoft Research India
NIPS,2018,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network",Manish Singh,Indian Institute of Technology Delhi
NIPS,2018,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network",Kush Bhatia,UC Berkeley
NIPS,2018,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network",Ashish Kumar,UC Berkeley
NIPS,2018,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network",Prateek Jain,Microsoft Research
NIPS,2018,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network",Manik Varma,Microsoft Research India
NIPS,2018,SING: Symbol-to-Instrument Neural Generator,Alexandre Defossez,Facebook
NIPS,2018,SING: Symbol-to-Instrument Neural Generator,Neil Zeghidour,Facebook A.I. Research / Ecole Normale Supérieure
NIPS,2018,SING: Symbol-to-Instrument Neural Generator,Nicolas Usunier,Facebook AI Research
NIPS,2018,SING: Symbol-to-Instrument Neural Generator,Leon Bottou,Facebook AI Research
NIPS,2018,SING: Symbol-to-Instrument Neural Generator,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds,Xiaohan Chen,Texas A&M University
NIPS,2018,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds,Jialin Liu,"University of California, Los Angeles (UCLA)"
NIPS,2018,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds,Zhangyang Wang,TAMU
NIPS,2018,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds,Wotao Yin,"University of California, Los Angeles"
NIPS,2018,Iterative Value-Aware Model Learning,Amir-massoud Farahmand,Vector Institute
NIPS,2018,Evading the Adversary in Invariant Representation,Daniel Moyer,University of Southern California
NIPS,2018,Evading the Adversary in Invariant Representation,Shuyang Gao,ISI USC
NIPS,2018,Evading the Adversary in Invariant Representation,Rob Brekelmans,University of Southern California
NIPS,2018,Evading the Adversary in Invariant Representation,Aram Galstyan,USC Information Sciences Inst
NIPS,2018,Evading the Adversary in Invariant Representation,Greg Ver Steeg,University of Southern California
NIPS,2018,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias,Abhinav Gupta,Facebook AI Research/CMU
NIPS,2018,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias,Adithyavairavan Murali,Carnegie Mellon University Robotics Institute
NIPS,2018,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias,Dhiraj Prakashchand Gandhi,Carnegie Mellon University Robotics Institute
NIPS,2018,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias,Lerrel Pinto,Carnegie Mellon University
NIPS,2018,Transfer of Deep Reactive Policies for MDP Planning,Aniket (Nick) Bajpai,MIT
NIPS,2018,Transfer of Deep Reactive Policies for MDP Planning,Sankalp Garg,Indian Institute of Technology Delhi
NIPS,2018,Transfer of Deep Reactive Policies for MDP Planning,Mausam,IIT Dehli
NIPS,2018,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization,Ian En-Hsu Yen,Carnegie Mellon University
NIPS,2018,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization,Wei-Cheng Lee,National Taiwan University
NIPS,2018,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization,Kai Zhong,University of Texas at Austin
NIPS,2018,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization,Sung-En Chang,Northeastern University
NIPS,2018,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization,Pradeep Ravikumar,Carnegie Mellon University
NIPS,2018,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization,Shou-De Lin,National Taiwan University
NIPS,2018,Bias and Generalization in Deep Generative Models: An Empirical Study,Shengjia Zhao,Stanford University
NIPS,2018,Bias and Generalization in Deep Generative Models: An Empirical Study,Hongyu Ren,Stanford University
NIPS,2018,Bias and Generalization in Deep Generative Models: An Empirical Study,Arianna Yuan,Stanford University
NIPS,2018,Bias and Generalization in Deep Generative Models: An Empirical Study,Jiaming Song,Stanford University
NIPS,2018,Bias and Generalization in Deep Generative Models: An Empirical Study,Noah Goodman,Stanford University
NIPS,2018,Bias and Generalization in Deep Generative Models: An Empirical Study,Stefano Ermon,Stanford
NIPS,2018,Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language,Matthew D. Hoffman,Google
NIPS,2018,Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language,Matthew Johnson,Google Brain
NIPS,2018,Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language,Dustin Tran,Google Brain
NIPS,2018,Sketching Method for Large Scale Combinatorial Inference,Will Wei Sun,University of Miami Business School
NIPS,2018,Sketching Method for Large Scale Combinatorial Inference,Junwei Lu,
NIPS,2018,Sketching Method for Large Scale Combinatorial Inference,Han Liu,Tencent AI Lab
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,Zhiting Hu,Carnegie Mellon University
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,Zichao Yang,
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,Russ Salakhutdinov,Carnegie Mellon University
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,LIANHUI Qin,
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,Xiaodan Liang,Sun Yat-sen University
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,Haoye Dong,Sun Yat-sen University
NIPS,2018,Deep Generative Models with Learnable Knowledge Constraints,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Noam Shazeer,Google
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Youlong Cheng,Google
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Niki Parmar,Google
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Dustin Tran,Google Brain
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Ashish Vaswani,Google Brain
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Penporn Koanantakool,Google
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Peter Hawkins,google.com
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,HyoukJoong Lee,Google
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Mingsheng Hong,google.com
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Cliff Young,google.com
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Ryan Sepassi,Google
NIPS,2018,Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation,Blake Hechtman,Google
NIPS,2018,Context-aware Synthesis and Placement of Object Instances,Donghoon Lee,Seoul National University
NIPS,2018,Context-aware Synthesis and Placement of Object Instances,Ming-Yu Liu,NVIDIA
NIPS,2018,Context-aware Synthesis and Placement of Object Instances,Ming-Hsuan Yang,UC Merced / Google
NIPS,2018,Context-aware Synthesis and Placement of Object Instances,Sifei Liu,NVIDIA
NIPS,2018,Context-aware Synthesis and Placement of Object Instances,Jinwei Gu,NVIDIA Research
NIPS,2018,Context-aware Synthesis and Placement of Object Instances,Jan Kautz,NVIDIA
NIPS,2018,Adversarial Risk and Robustness for Discrete Distributions,Dimitrios Diochnos,University of Virginia
NIPS,2018,Adversarial Risk and Robustness for Discrete Distributions,Saeed Mahloujifar,University of Virginia
NIPS,2018,Adversarial Risk and Robustness for Discrete Distributions,Mohammad Mahmoody,University of Virginia
NIPS,2018,PCA of high dimensional stochastic processes,Joseph Antognini,Google
NIPS,2018,PCA of high dimensional stochastic processes,Jascha Sohl-Dickstein,Google Brain
NIPS,2018,Total stochastic gradient algorithms and applications in reinforcement learning,Paavo Parmas,Okinawa Institute of Science and Technology Graduate University
NIPS,2018,A Retrieve-and-Edit Framework for Predicting Structured Outputs,Tatsunori Hashimoto,Stanford
NIPS,2018,A Retrieve-and-Edit Framework for Predicting Structured Outputs,Kelvin Guu,Google
NIPS,2018,A Retrieve-and-Edit Framework for Predicting Structured Outputs,Yonatan Oren,Stanford
NIPS,2018,A Retrieve-and-Edit Framework for Predicting Structured Outputs,Percy Liang,Stanford University
NIPS,2018,Learning and Testing Causal Models with Interventions,Jayadev Acharya,Cornell University
NIPS,2018,Learning and Testing Causal Models with Interventions,Arnab Bhattacharyya,National University of Singapore & Indian Institute of Science
NIPS,2018,Learning and Testing Causal Models with Interventions,Constantinos  Daskalakis,MIT
NIPS,2018,Learning and Testing Causal Models with Interventions,Saravanan Kandasamy,Tata Institute of Fundamental Research
NIPS,2018,Identification and Estimation of Causal Effects from Dependent Data,Eli Sherman,Johns Hopkins University
NIPS,2018,Identification and Estimation of Causal Effects from Dependent Data,Ilya Shpitser,Johns Hopkins University
NIPS,2018,Learning Compressed Transforms with Low Displacement Rank,Anna Thomas,Stanford
NIPS,2018,Learning Compressed Transforms with Low Displacement Rank,Albert Gu,Stanford
NIPS,2018,Learning Compressed Transforms with Low Displacement Rank,Tri Dao,Stanford University
NIPS,2018,Learning Compressed Transforms with Low Displacement Rank,Atri Rudra,"University at Buffalo, SUNY"
NIPS,2018,Learning Compressed Transforms with Low Displacement Rank,Chris Ré,Stanford
NIPS,2018,Data Amplification: A Unified and Competitive Approach to Property Estimation,Yi HAO,"University of California, San Diego"
NIPS,2018,Data Amplification: A Unified and Competitive Approach to Property Estimation,Alon Orlitsky,"University of California, San Diego"
NIPS,2018,Data Amplification: A Unified and Competitive Approach to Property Estimation,Ananda Theertha Suresh,Google
NIPS,2018,Data Amplification: A Unified and Competitive Approach to Property Estimation,Yihong Wu,Yale University
NIPS,2018,A flexible neural representation for physics prediction,Damian Mrowca,Stanford University
NIPS,2018,A flexible neural representation for physics prediction,Chengxu Zhuang,Stanford University
NIPS,2018,A flexible neural representation for physics prediction,Elias Wang,Stanford University
NIPS,2018,A flexible neural representation for physics prediction,Nick Haber,Stanford University
NIPS,2018,A flexible neural representation for physics prediction,Li Fei-Fei,Stanford University & Google
NIPS,2018,A flexible neural representation for physics prediction,Josh Tenenbaum,MIT
NIPS,2018,A flexible neural representation for physics prediction,Daniel Yamins,Stanford University
NIPS,2018,Approximate Knowledge Compilation by Online Collapsed Importance Sampling,Tal Friedman,UCLA
NIPS,2018,Approximate Knowledge Compilation by Online Collapsed Importance Sampling,Guy Van den Broeck,UCLA
NIPS,2018,Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization,Bruno Korbar,Dartmouth Collegue
NIPS,2018,Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization,Du Tran,Facebook
NIPS,2018,Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization,Lorenzo Torresani,Dartmouth/Facebook
NIPS,2018,Adversarial Scene Editing: Automatic Object Removal from Weak Supervision,Rakshith R Shetty,Max Planck Institute for Informatics
NIPS,2018,Adversarial Scene Editing: Automatic Object Removal from Weak Supervision,Mario Fritz,CISPA Helmholtz Center i.G.
NIPS,2018,Adversarial Scene Editing: Automatic Object Removal from Weak Supervision,Bernt Schiele,Max Planck Institute for Informatics
NIPS,2018,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks,Abdullah Rashwan,University of Waterloo
NIPS,2018,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks,Agastya Kalra,University of Waterloo
NIPS,2018,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks,Pascal Poupart,University of Waterloo & RBC Borealis AI
NIPS,2018,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks,Prashant Doshi,University of Georgia
NIPS,2018,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks,George Trimponias,"Huawei Technologies Co., Ltd."
NIPS,2018,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks,Wei-Shou Hsu,University of Waterloo
NIPS,2018,CatBoost: unbiased boosting with categorical features,Liudmila Prokhorenkova,Yandex
NIPS,2018,CatBoost: unbiased boosting with categorical features,Gleb Gusev,Yandex LLC
NIPS,2018,CatBoost: unbiased boosting with categorical features,Aleksandr Vorobev,Yandex LLC
NIPS,2018,CatBoost: unbiased boosting with categorical features,Anna Veronika Dorogush,Yandex
NIPS,2018,CatBoost: unbiased boosting with categorical features,Andrey Gulin,Yandex
NIPS,2018,ResNet with one-neuron hidden layers is a Universal Approximator,Hongzhou Lin,MIT
NIPS,2018,ResNet with one-neuron hidden layers is a Universal Approximator,Stefanie Jegelka,MIT
NIPS,2018,Reparameterization Gradient for Non-differentiable Models,Wonyeol Lee,KAIST
NIPS,2018,Reparameterization Gradient for Non-differentiable Models,Hangyeol Yu,KAIST
NIPS,2018,Reparameterization Gradient for Non-differentiable Models,Hongseok Yang,KAIST
NIPS,2018,Meta-Reinforcement Learning of Structured Exploration Strategies,Abhishek Gupta,"University of California, Berkeley"
NIPS,2018,Meta-Reinforcement Learning of Structured Exploration Strategies,Russell Mendonca,UC Berkeley
NIPS,2018,Meta-Reinforcement Learning of Structured Exploration Strategies,YuXuan Liu,UC Berkeley
NIPS,2018,Meta-Reinforcement Learning of Structured Exploration Strategies,Pieter Abbeel,UC Berkeley | Gradescope | Covariant
NIPS,2018,Meta-Reinforcement Learning of Structured Exploration Strategies,Sergey Levine,UC Berkeley
NIPS,2018,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach,Wenbo Guo,Pennsylvania State University
NIPS,2018,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach,Sui Huang,Netflix
NIPS,2018,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach,Yunzhe Tao,Columbia University
NIPS,2018,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach,Xinyu (X.Y.) Xing,Penn State University
NIPS,2018,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach,Lin Lin,The Pennsylvania State University
NIPS,2018,Expanding Holographic Embeddings for Knowledge Completion,Yexiang Xue,Purdue University
NIPS,2018,Expanding Holographic Embeddings for Knowledge Completion,Yang Yuan,Cornell University
NIPS,2018,Expanding Holographic Embeddings for Knowledge Completion,Zhitian Xu,Shanghai Jiaotong University
NIPS,2018,Expanding Holographic Embeddings for Knowledge Completion,Ashish Sabharwal,Allen Institute for AI
NIPS,2018,Probabilistic Neural Programmed Networks for Scene Generation,Zhiwei Deng,Simon Fraser University
NIPS,2018,Probabilistic Neural Programmed Networks for Scene Generation,Jiacheng Chen,Simon Fraser University
NIPS,2018,Probabilistic Neural Programmed Networks for Scene Generation,YIFANG FU,Simon Fraser University
NIPS,2018,Probabilistic Neural Programmed Networks for Scene Generation,Greg Mori,Borealis AI
NIPS,2018,Stochastic Nested Variance Reduced Gradient Descent for Nonconvex Optimization,Dongruo Zhou,UCLA
NIPS,2018,Stochastic Nested Variance Reduced Gradient Descent for Nonconvex Optimization,Pan Xu,UCLA
NIPS,2018,Stochastic Nested Variance Reduced Gradient Descent for Nonconvex Optimization,Quanquan Gu,UCLA
NIPS,2018,Inferring Networks From Random Walk-Based Node Similarities,Jeremy Hoskins,Yale University
NIPS,2018,Inferring Networks From Random Walk-Based Node Similarities,Cameron Musco,Massachusetts Institute of Technology
NIPS,2018,Inferring Networks From Random Walk-Based Node Similarities,Christopher Musco,Mass. Institute of Technology
NIPS,2018,Inferring Networks From Random Walk-Based Node Similarities,Babis Tsourakakis,Boston University
NIPS,2018,Tight Bounds for Collaborative PAC Learning via Multiplicative Weights,Jiecao Chen,Indiana University Bloomington
NIPS,2018,Tight Bounds for Collaborative PAC Learning via Multiplicative Weights,Qin Zhang,Indiana University Bloomington
NIPS,2018,Tight Bounds for Collaborative PAC Learning via Multiplicative Weights,Yuan Zhou,Indiana University Bloomington
NIPS,2018,Step Size Matters in Deep Learning,Kamil Nar,"University of California, Berkeley"
NIPS,2018,Step Size Matters in Deep Learning,Shankar Sastry,"Department of EECS, UC Berkeley"
NIPS,2018,Learning to Optimize Tensor Programs,Tianqi Chen,University of Washington
NIPS,2018,Learning to Optimize Tensor Programs,Lianmin Zheng,Shanghai Jiaotong University
NIPS,2018,Learning to Optimize Tensor Programs,Eddie Yan,university of washington
NIPS,2018,Learning to Optimize Tensor Programs,Ziheng Jiang,Fudan University
NIPS,2018,Learning to Optimize Tensor Programs,Thierry Moreau,university of washington
NIPS,2018,Learning to Optimize Tensor Programs,Luis Ceze,University of Washington
NIPS,2018,Learning to Optimize Tensor Programs,Carlos Guestrin,University of Washington
NIPS,2018,Learning to Optimize Tensor Programs,Arvind Krishnamurthy,University of Washington
NIPS,2018,Training deep learning based denoisers without ground truth data,Shakarim Soltanayev,Ulsan National Institute of Science and Technology
NIPS,2018,Training deep learning based denoisers without ground truth data,Se Young Chun,UNIST
NIPS,2018,Learning latent variable structured prediction models with Gaussian perturbations,Kevin Bello,Purdue University
NIPS,2018,Learning latent variable structured prediction models with Gaussian perturbations,Jean Honorio,Purdue University
NIPS,2018,Efficiency of adaptive importance sampling,François Portier,Télécom ParisTech
NIPS,2018,Efficiency of adaptive importance sampling,Bernard Delyon,University of Rennes 1
NIPS,2018,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization,Pan Xu,UCLA
NIPS,2018,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization,Jinghui Chen,University of Virginia
NIPS,2018,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization,Difan Zou,"University of California, Los Angeles"
NIPS,2018,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization,Quanquan Gu,UCLA
NIPS,2018,Q-learning with Nearest Neighbors,Devavrat Shah,Massachusetts Institute of Technology
NIPS,2018,Q-learning with Nearest Neighbors,Qiaomin Xie,Massachusetts Institute of Technology
NIPS,2018,On Binary Classification in Extreme Regions,Hamid JALALZAI,Télécom ParisTech
NIPS,2018,On Binary Classification in Extreme Regions,Stephan Clémençon,Telecom ParisTech
NIPS,2018,On Binary Classification in Extreme Regions,Anne Sabourin,"LTCI,  Telecom ParisTech, Université Paris-Saclay"
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Stefan Webb,University of Oxford
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Adam Golinski,University of Oxford
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Rob Zinkov,University of Oxford
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Siddharth Narayanaswamy,Unversity of Oxford
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Tom Rainforth,University of Oxford
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Yee Whye Teh,"University of Oxford, DeepMind"
NIPS,2018,Faithful Inversion of Generative Models for Effective Amortized Inference,Frank Wood,University of British Columbia
NIPS,2018,Constructing Deep Neural Networks by Bayesian Network Structure Learning,Raanan Y. Rohekar,Intel Corporation
NIPS,2018,Constructing Deep Neural Networks by Bayesian Network Structure Learning,Shami Nisimov,intel
NIPS,2018,Constructing Deep Neural Networks by Bayesian Network Structure Learning,Yaniv Gurwicz,Intel AI Lab
NIPS,2018,Constructing Deep Neural Networks by Bayesian Network Structure Learning,Guy Koren,Intel
NIPS,2018,Constructing Deep Neural Networks by Bayesian Network Structure Learning,Gal Novik,Intel
NIPS,2018,On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport,Lénaïc Chizat,INRIA
NIPS,2018,On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Optimistic Optimization of a Brownian,Jean-Bastien Grill,Google DeepMind
NIPS,2018,Optimistic Optimization of a Brownian,Michal Valko,Inria Lille - Nord Europe
NIPS,2018,Optimistic Optimization of a Brownian,Remi Munos,DeepMind
NIPS,2018,Optimization over Continuous and Multi-dimensional Decisions with Observational Data,Dimitris Bertsimas,Massachusetts Institute of Technology
NIPS,2018,Optimization over Continuous and Multi-dimensional Decisions with Observational Data,Christopher McCord,MIT
NIPS,2018,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base,Daya Guo,Sun Yat-Sen University
NIPS,2018,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base,Duyu Tang,Microsoft Research
NIPS,2018,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base,Nan Duan,Microsoft Research
NIPS,2018,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base,Ming Zhou,Microsoft Research
NIPS,2018,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base,Jian Yin,Sun Yat-Sen University
NIPS,2018,Mirrored Langevin Dynamics,Ya-Ping Hsieh,EPFL
NIPS,2018,Mirrored Langevin Dynamics,Ali Kavis,EPFL
NIPS,2018,Mirrored Langevin Dynamics,Paul Rolland,EPFL
NIPS,2018,Mirrored Langevin Dynamics,Volkan Cevher,EPFL
NIPS,2018,Metric on Nonlinear Dynamical Systems with Koopman Operators,Isao Ishikawa,RIKEN AIP
NIPS,2018,Metric on Nonlinear Dynamical Systems with Koopman Operators,Keisuke Fujii,RIKEN AIP Center
NIPS,2018,Metric on Nonlinear Dynamical Systems with Koopman Operators,Masahiro Ikeda,RIKEN AIP
NIPS,2018,Metric on Nonlinear Dynamical Systems with Koopman Operators,Yuka Hashimoto,NTT Network Technology Laboratories
NIPS,2018,Metric on Nonlinear Dynamical Systems with Koopman Operators,Yoshinobu Kawahara,Osaka University / RIKEN
NIPS,2018,Empirical Risk Minimization Under Fairness Constraints,Michele Donini,Istituto Italiano di Tecnologia
NIPS,2018,Empirical Risk Minimization Under Fairness Constraints,Luca Oneto,University of Genoa
NIPS,2018,Empirical Risk Minimization Under Fairness Constraints,Shai Ben-David,Universitys of Waterloo
NIPS,2018,Empirical Risk Minimization Under Fairness Constraints,John Shawe-Taylor,UCL
NIPS,2018,Empirical Risk Minimization Under Fairness Constraints,Massimiliano Pontil,IIT & UCL
NIPS,2018,Analytic solution and stationary phase approximation for the Bayesian lasso and elastic net,Tom Michoel,University of Bergen
NIPS,2018,Paraphrasing Complex Network: Network Compression via Factor Transfer,Jangho Kim,Seoul National University
NIPS,2018,Paraphrasing Complex Network: Network Compression via Factor Transfer,Seonguk Park,Seoul National University
NIPS,2018,Paraphrasing Complex Network: Network Compression via Factor Transfer,Nojun Kwak,Seoul National University
NIPS,2018,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks,Kevin Scaman,"Noah's Ark Lab, Huawei Technologies"
NIPS,2018,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks,Sebastien Bubeck,Microsoft Research
NIPS,2018,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks,Laurent Massoulié,Inria
NIPS,2018,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks,Yin Tat Lee,UW
NIPS,2018,Learning Hierarchical Semantic Image Manipulation through Structured Representations,Seunghoon Hong,University of Michigan
NIPS,2018,Learning Hierarchical Semantic Image Manipulation through Structured Representations,Xinchen Yan,University of Michigan
NIPS,2018,Learning Hierarchical Semantic Image Manipulation through Structured Representations,Honglak Lee,Google Brain
NIPS,2018,Learning Hierarchical Semantic Image Manipulation through Structured Representations,Thomas Huang,UIUC
NIPS,2018,Minimax Statistical Learning with Wasserstein distances,Jaeho Lee,University of Illinois at Urbana-Champaign
NIPS,2018,Minimax Statistical Learning with Wasserstein distances,Maxim Raginsky,University of Illinois at Urbana-Champaign
NIPS,2018,Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering,Medhini Narasimhan,UIUC
NIPS,2018,Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering,Svetlana Lazebnik,UIUC
NIPS,2018,Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2018,Representation Learning for Treatment Effect Estimation from Observational Data,Liuyi Yao,"SUNY Buffalo, USA"
NIPS,2018,Representation Learning for Treatment Effect Estimation from Observational Data,Sheng Li,University of Georgia
NIPS,2018,Representation Learning for Treatment Effect Estimation from Observational Data,Yaliang Li,Tencent Medical AI Lab
NIPS,2018,Representation Learning for Treatment Effect Estimation from Observational Data,Mengdi Huai,State University of New York at Buffalo
NIPS,2018,Representation Learning for Treatment Effect Estimation from Observational Data,Jing Gao,University at Buffalo
NIPS,2018,Representation Learning for Treatment Effect Estimation from Observational Data,Aidong Zhang,SUNY Buffalo
NIPS,2018,Online Learning with an Unknown Fairness Metric,Stephen Gillen,University of Pennsylvania
NIPS,2018,Online Learning with an Unknown Fairness Metric,Christopher Jung,University of Pennsylvania
NIPS,2018,Online Learning with an Unknown Fairness Metric,Michael Kearns,University of Pennsylvania
NIPS,2018,Online Learning with an Unknown Fairness Metric,Aaron Roth,University of Pennsylvania
NIPS,2018,Structural Causal Bandits: Where to Intervene?,Sanghack Lee,Purdue University
NIPS,2018,Structural Causal Bandits: Where to Intervene?,Elias Bareinboim,Purdue
NIPS,2018,Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks,Hyeonseob Nam,Lunit Inc.
NIPS,2018,Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks,Hyo-Eun Kim,Lunit Inc
NIPS,2018,Active Learning for Non-Parametric Regression Using Purely Random Trees,Jack Goetz,University of Michigan
NIPS,2018,Active Learning for Non-Parametric Regression Using Purely Random Trees,Ambuj Tewari,University of Michigan
NIPS,2018,Active Learning for Non-Parametric Regression Using Purely Random Trees,Paul Zimmerman,University of Michigan
NIPS,2018,Verifiable Reinforcement Learning via Policy Extraction,Osbert Bastani,University of Pennsylvania
NIPS,2018,Verifiable Reinforcement Learning via Policy Extraction,Yewen Pu,MIT
NIPS,2018,Verifiable Reinforcement Learning via Policy Extraction,Armando Solar-Lezama,MIT
NIPS,2018,A theory on the absence of spurious optimality,Cedric Josz,UC Berkeley
NIPS,2018,A theory on the absence of spurious optimality,Yi Ouyang,Preferred Networks
NIPS,2018,A theory on the absence of spurious optimality,Richard Zhang,"University of California, Berkeley"
NIPS,2018,A theory on the absence of spurious optimality,Javad Lavaei,"University of California, Berkeley"
NIPS,2018,A theory on the absence of spurious optimality,Somayeh Sojoudi,"University of California, Berkeley"
NIPS,2018,Learning to Navigate in Cities Without a Map,Piotr Mirowski,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Matt Grimes,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Mateusz Malinowski,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Karl Moritz Hermann,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Keith Anderson,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Denis Teplyashin,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Karen Simonyan,DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,koray kavukcuoglu,Google DeepMind
NIPS,2018,Learning to Navigate in Cities Without a Map,Andrew Zisserman,DeepMind & University of Oxford
NIPS,2018,Learning to Navigate in Cities Without a Map,Raia Hadsell,DeepMind
NIPS,2018,Meta-Gradient Reinforcement Learning,Zhongwen Xu,DeepMind
NIPS,2018,Meta-Gradient Reinforcement Learning,Hado van Hasselt,DeepMind
NIPS,2018,Meta-Gradient Reinforcement Learning,David Silver,DeepMind
NIPS,2018,Local Differential Privacy for Evolving Data,Matthew  Joseph,University of Pennsylvania
NIPS,2018,Local Differential Privacy for Evolving Data,Aaron Roth,University of Pennsylvania
NIPS,2018,Local Differential Privacy for Evolving Data,Jonathan Ullman,Northeastern University
NIPS,2018,Local Differential Privacy for Evolving Data,Bo Waggoner,Penn
NIPS,2018,"Modelling sparsity, heterogeneity, reciprocity and community structure in temporal interaction data",Xenia Miscouridou,University of Oxford
NIPS,2018,"Modelling sparsity, heterogeneity, reciprocity and community structure in temporal interaction data",Francois Caron,Oxford
NIPS,2018,"Modelling sparsity, heterogeneity, reciprocity and community structure in temporal interaction data",Yee Whye Teh,"University of Oxford, DeepMind"
NIPS,2018,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization,Shusen Wang,UC Berkeley
NIPS,2018,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization,Farbod Roosta-Khorasani,University of Queensland
NIPS,2018,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization,Peng Xu,Stanford University
NIPS,2018,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization,Michael W Mahoney,UC Berkeley
NIPS,2018,Structured Local Minima in Sparse Blind Deconvolution,Yuqian Zhang,Cornell University
NIPS,2018,Structured Local Minima in Sparse Blind Deconvolution,Henry Kuo,Columbia University
NIPS,2018,Structured Local Minima in Sparse Blind Deconvolution,John Wright,Columbia University
NIPS,2018,Breaking the Span Assumption Yields Fast Finite-Sum Minimization,Robert Hannah,UCLA
NIPS,2018,Breaking the Span Assumption Yields Fast Finite-Sum Minimization,Yanli Liu,UCLA
NIPS,2018,Breaking the Span Assumption Yields Fast Finite-Sum Minimization,Daniel O'Connor,UCLA
NIPS,2018,Breaking the Span Assumption Yields Fast Finite-Sum Minimization,Wotao Yin,"University of California, Los Angeles"
NIPS,2018,Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning,Ofir Marom,University of the Witwatersrand
NIPS,2018,Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning,Benjamin Rosman,University of the Witwatersrand / CSIR
NIPS,2018,Trajectory Convolution for Action Recognition,Yue Zhao,The Chinese University of Hong Kong
NIPS,2018,Trajectory Convolution for Action Recognition,Yuanjun Xiong,Amazon
NIPS,2018,Trajectory Convolution for Action Recognition,Dahua Lin,The Chinese University of Hong Kong
NIPS,2018,MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval,Helena Peic Tukuljac,École polytechnique fédérale de Lausanne
NIPS,2018,MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval,Antoine Deleforge,Inria
NIPS,2018,MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval,Remi Gribonval,INRIA
NIPS,2018,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms,Zhihui Zhu,Johns Hopkins University
NIPS,2018,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms,Yifan Wang,University of Washington
NIPS,2018,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms,Daniel Robinson,Johns Hopkins University
NIPS,2018,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms,Daniel Naiman,Johns Hopkins University
NIPS,2018,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms,Rene Vidal,Johns Hopkins University
NIPS,2018,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms,Manolis Tsakiris,ShanghaiTech University
NIPS,2018,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning,Runsheng Yu,Xiaomi AI Lab
NIPS,2018,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning,Wenyu Liu,Peking University
NIPS,2018,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning,Yasen Zhang,Xiaomi AI Lab
NIPS,2018,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning,Zhi Qu,Xiaomi AI Lab
NIPS,2018,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning,Deli Zhao,Xiaomi AI Lab
NIPS,2018,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning,Bo Zhang,Xiaomi Corp.
NIPS,2018,Regularizing by the Variance of the Activations' Sample-Variances,Etai Littwin,Apple
NIPS,2018,Regularizing by the Variance of the Activations' Sample-Variances,Lior Wolf,Facebook AI Research
NIPS,2018,Nonparametric learning for Bayesian models via randomized objective functions,Simon Lyddon,University of Oxford
NIPS,2018,Nonparametric learning for Bayesian models via randomized objective functions,Stephen Walker,University of Texas at Austin
NIPS,2018,Nonparametric learning for Bayesian models via randomized objective functions,Chris C Holmes,University of Oxford
NIPS,2018,Learning Optimal Reserve Price against Non-myopic Bidders,Jinyan Liu,The University of Hong Kong
NIPS,2018,Learning Optimal Reserve Price against Non-myopic Bidders,Zhiyi Huang,The University of Hong Kong
NIPS,2018,Learning Optimal Reserve Price against Non-myopic Bidders,Xiangning Wang,The University of Hong Kong
NIPS,2018,Generalized Zero-Shot Learning with Deep Calibration Network,Shichen Liu,Tsinghua University
NIPS,2018,Generalized Zero-Shot Learning with Deep Calibration Network,Mingsheng Long,Tsinghua University
NIPS,2018,Generalized Zero-Shot Learning with Deep Calibration Network,Jianmin Wang,Tsinghua University
NIPS,2018,Generalized Zero-Shot Learning with Deep Calibration Network,Michael Jordan,UC Berkeley
NIPS,2018,SplineNets: Continuous Neural Decision Graphs,Cem Keskin,Google Inc.
NIPS,2018,SplineNets: Continuous Neural Decision Graphs,Shahram Izadi,Google
NIPS,2018,Pelee: A Real-Time Object Detection System on Mobile Devices,Robert Wang,Aeryon Labs
NIPS,2018,Pelee: A Real-Time Object Detection System on Mobile Devices,Tanner Bohn,Western University
NIPS,2018,Pelee: A Real-Time Object Detection System on Mobile Devices,Charles Ling,University of Western Ontario
NIPS,2018,Deep Attentive Tracking via Reciprocative Learning,Shi Pu,Beijing University of Posts and Telecommunications
NIPS,2018,Deep Attentive Tracking via Reciprocative Learning,Yibing Song,Tencent AI Lab
NIPS,2018,Deep Attentive Tracking via Reciprocative Learning,Chao Ma,Princeton University
NIPS,2018,Deep Attentive Tracking via Reciprocative Learning,Honggang Zhang,Beijing University of Posts and Telecommunications
NIPS,2018,Deep Attentive Tracking via Reciprocative Learning,Ming-Hsuan Yang,UC Merced / Google
NIPS,2018,Random Feature Stein Discrepancies,Jonathan Huggins,Massachusetts Institute of Technology
NIPS,2018,Random Feature Stein Discrepancies,Lester Mackey,Microsoft Research
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Shunyu Yao,Tsinghua University
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Harry Hsu,MIT
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Jun-Yan Zhu,MIT
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Jiajun Wu,MIT
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Antonio Torralba,MIT
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Bill Freeman,MIT/Google
NIPS,2018,3D-Aware Scene Manipulation via Inverse Graphics,Josh Tenenbaum,MIT
NIPS,2018,High Dimensional Linear Regression using Lattice Basis Reduction,Ilias Zadik,MIT
NIPS,2018,High Dimensional Linear Regression using Lattice Basis Reduction,David Gamarnik,Massachusetts Institute of Technology
NIPS,2018,Collaborative Learning for Deep Neural Networks,Guocong Song,Playground Global
NIPS,2018,Collaborative Learning for Deep Neural Networks,Wei Chai,Google Inc
NIPS,2018,Simple random search of static linear policies is competitive for reinforcement learning,Horia Mania,UC Berkeley
NIPS,2018,Simple random search of static linear policies is competitive for reinforcement learning,Aurelia Guy,UC Berkeley
NIPS,2018,Simple random search of static linear policies is competitive for reinforcement learning,Benjamin Recht,UC Berkeley
NIPS,2018,Temporal Regularization for Markov Decision Process,Pierre Thodoroff,McGill
NIPS,2018,Temporal Regularization for Markov Decision Process,Audrey Durand,McGill University
NIPS,2018,Temporal Regularization for Markov Decision Process,Joelle Pineau,McGill University
NIPS,2018,Temporal Regularization for Markov Decision Process,Doina Precup,McGill University / DeepMind Montreal
NIPS,2018,Enhancing the Accuracy and Fairness of Human Decision Making,Isabel Valera,Max Planck Institute for Intelligent Systems
NIPS,2018,Enhancing the Accuracy and Fairness of Human Decision Making,Adish Singla,MPI-SWS
NIPS,2018,Enhancing the Accuracy and Fairness of Human Decision Making,Manuel Gomez Rodriguez,Max Planck Institute for Software Systems
NIPS,2018,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning,Romain WARLOP,Inria
NIPS,2018,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning,Alessandro Lazaric,Facebook Artificial Intelligence Research
NIPS,2018,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning,Jérémie Mary,
NIPS,2018,Genetic-Gated Networks for Deep Reinforcement Learning,Simyung Chang,Seoul National University
NIPS,2018,Genetic-Gated Networks for Deep Reinforcement Learning,John Yang,Seoul National University
NIPS,2018,Genetic-Gated Networks for Deep Reinforcement Learning,Jaeseok Choi,Seoul National University
NIPS,2018,Genetic-Gated Networks for Deep Reinforcement Learning,Nojun Kwak,Seoul National University
NIPS,2018,Distilled Wasserstein Learning for Word Embedding and Topic Modeling,Hongteng Xu,Infinia ML
NIPS,2018,Distilled Wasserstein Learning for Word Embedding and Topic Modeling,Wenlin Wang,Duke University
NIPS,2018,Distilled Wasserstein Learning for Word Embedding and Topic Modeling,Wei Liu,Tencent AI Lab
NIPS,2018,Distilled Wasserstein Learning for Word Embedding and Topic Modeling,Lawrence Carin,Duke University
NIPS,2018,Video Prediction via Selective Sampling,Jingwei Xu,Shanghai Jiao Tong University
NIPS,2018,Video Prediction via Selective Sampling,Bingbing Ni,Shanghai Jiao Tong University
NIPS,2018,Video Prediction via Selective Sampling,Xiaokang Yang,Shanghai Jiao Tong University
NIPS,2018,DifNet: Semantic Segmentation by Diffusion Networks,Peng Jiang,Shandong University
NIPS,2018,DifNet: Semantic Segmentation by Diffusion Networks,Fanglin Gu,Shandong University
NIPS,2018,DifNet: Semantic Segmentation by Diffusion Networks,Yunhai Wang,Shandong University
NIPS,2018,DifNet: Semantic Segmentation by Diffusion Networks,Changhe Tu,Shandong University
NIPS,2018,DifNet: Semantic Segmentation by Diffusion Networks,Baoquan Chen,Shandong University
NIPS,2018,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization,Robert Gower,ParisTech
NIPS,2018,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization,Filip Hanzely,KAUST
NIPS,2018,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization,Peter Richtarik,KAUST
NIPS,2018,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization,Sebastian Stich,EPFL
NIPS,2018,Learning Versatile Filters for Efficient Convolutional Neural Networks,Yunhe Wang,"Noah’s Ark Laboratory, Huawei Technologies Co., Ltd."
NIPS,2018,Learning Versatile Filters for Efficient Convolutional Neural Networks,Chang Xu,The University of Sydney
NIPS,2018,Learning Versatile Filters for Efficient Convolutional Neural Networks,Chunjing XU,Huawei Technologies
NIPS,2018,Learning Versatile Filters for Efficient Convolutional Neural Networks,Chao Xu,Peking University
NIPS,2018,Learning Versatile Filters for Efficient Convolutional Neural Networks,Dacheng Tao,"University of Technology, Sydney"
NIPS,2018,Parsimonious Quantile Regression of Asymmetrically Heavy-tailed Financial Return Series,Xing Yan,The Chinese University of Hong Kong
NIPS,2018,Parsimonious Quantile Regression of Asymmetrically Heavy-tailed Financial Return Series,Weizhong Zhang,Zhejiang University
NIPS,2018,Parsimonious Quantile Regression of Asymmetrically Heavy-tailed Financial Return Series,Lin Ma,Tencent AI Lab
NIPS,2018,Parsimonious Quantile Regression of Asymmetrically Heavy-tailed Financial Return Series,Wei Liu,Tencent AI Lab
NIPS,2018,Parsimonious Quantile Regression of Asymmetrically Heavy-tailed Financial Return Series,Qi Wu,City University of Hong Kong
NIPS,2018,Bilinear Attention Networks,Jin-Hwa Kim,SK T-Brain
NIPS,2018,Bilinear Attention Networks,Jaehyun Jun,Seoul National University
NIPS,2018,Bilinear Attention Networks,Byoung-Tak Zhang,Seoul National University & Surromind Robotics
NIPS,2018,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation,Yuan Li,Duke University
NIPS,2018,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation,Xiaodan Liang,Sun Yat-sen University
NIPS,2018,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation,Zhiting Hu,Carnegie Mellon University
NIPS,2018,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,Stochastic Composite Mirror Descent: Optimal Bounds with High Probabilities,Yunwen Lei,Southern University of Science and Technology
NIPS,2018,Stochastic Composite Mirror Descent: Optimal Bounds with High Probabilities,Ke Tang,Southern University of Science and Technology
NIPS,2018,PacGAN: The power of two samples in generative adversarial networks,Zinan Lin,Carnegie Mellon University
NIPS,2018,PacGAN: The power of two samples in generative adversarial networks,Ashish Khetan,Amazon AI Labs
NIPS,2018,PacGAN: The power of two samples in generative adversarial networks,Giulia Fanti,CMU
NIPS,2018,PacGAN: The power of two samples in generative adversarial networks,Sewoong Oh,University of Washington
NIPS,2018,A loss framework for calibrated anomaly detection,Aditya Menon,Google Research
NIPS,2018,A loss framework for calibrated anomaly detection,Robert Williamson,Australian National University & Data61
NIPS,2018,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution,Longquan Dai,Nanjing University of Science and Technology
NIPS,2018,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution,Liang Tang,"CASA Environmental Technology Co., Ltd and CASA EM&EW IOT Research Center"
NIPS,2018,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution,Yuan Xie,Chinese Academy of Sciences
NIPS,2018,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution,Jinhui Tang,Nanjing University of Science and Technology
NIPS,2018,Generalizing Tree Probability Estimation via Bayesian Networks,Cheng Zhang,Fred Hutchinson Cancer Research Center
NIPS,2018,Generalizing Tree Probability Estimation via Bayesian Networks,Frederick A Matsen IV,Fred Hutchinson Cancer Research Center
NIPS,2018,On Oracle-Efficient PAC RL with Rich Observations,Christoph Dann,Carnegie Mellon University
NIPS,2018,On Oracle-Efficient PAC RL with Rich Observations,Nan Jiang,University of Illinois at Urbana-Champaign
NIPS,2018,On Oracle-Efficient PAC RL with Rich Observations,Akshay Krishnamurthy,Microsoft
NIPS,2018,On Oracle-Efficient PAC RL with Rich Observations,Alekh Agarwal,Microsoft Research
NIPS,2018,On Oracle-Efficient PAC RL with Rich Observations,John Langford,Microsoft Research New York
NIPS,2018,On Oracle-Efficient PAC RL with Rich Observations,Robert Schapire,MIcrosoft Research
NIPS,2018,Geometry Based Data Generation,Ofir Lindenbaum,Yale
NIPS,2018,Geometry Based Data Generation,Jay Stanley,Yale University
NIPS,2018,Geometry Based Data Generation,Guy Wolf,Yale University
NIPS,2018,Geometry Based Data Generation,Smita Krishnaswamy,Yale University
NIPS,2018,Regularization Learning Networks,Ira Shavitt,Weizmann Institute of Science
NIPS,2018,Regularization Learning Networks,Eran Segal,Weizmann Institute of Science
NIPS,2018,Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding,Hajin Shim,KAIST
NIPS,2018,Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding,Sung Ju Hwang,"KAIST, AItrics"
NIPS,2018,Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding,Eunho Yang,Korea Advanced Institute of Science and Technology; AItrics
NIPS,2018,FRAGE: Frequency-Agnostic Word Representation,Chengyue Gong,Peking University
NIPS,2018,FRAGE: Frequency-Agnostic Word Representation,Di He,Peking University
NIPS,2018,FRAGE: Frequency-Agnostic Word Representation,Xu Tan,Microsoft Research
NIPS,2018,FRAGE: Frequency-Agnostic Word Representation,Tao Qin,Microsoft Research
NIPS,2018,FRAGE: Frequency-Agnostic Word Representation,Liwei Wang,Peking University
NIPS,2018,FRAGE: Frequency-Agnostic Word Representation,Tie-Yan Liu,Microsoft Research Asia
NIPS,2018,Gradient Sparsification for Communication-Efficient Distributed Optimization,Jianqiao Wangni,University of Pennsylvania
NIPS,2018,Gradient Sparsification for Communication-Efficient Distributed Optimization,Jialei Wang,"Two Sigma Investments, University of Chicago"
NIPS,2018,Gradient Sparsification for Communication-Efficient Distributed Optimization,Ji Liu,"University of Rochester, Tencent AI lab"
NIPS,2018,Gradient Sparsification for Communication-Efficient Distributed Optimization,Tong Zhang,The Australian National University
NIPS,2018,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making,Hoda Heidari,ETH Zürich
NIPS,2018,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making,Claudio Ferrari,ETH Zürich
NIPS,2018,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making,Krishna Gummadi,Max Planck Institute for Software Systems
NIPS,2018,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making,Andreas Krause,ETHZ
NIPS,2018,Unsupervised Learning of View-invariant Action Representations,Junnan Li,National University of Singapore
NIPS,2018,Unsupervised Learning of View-invariant Action Representations,Yongkang Wong,National University of Singapore
NIPS,2018,Unsupervised Learning of View-invariant Action Representations,Qi Zhao,University of Minnesota
NIPS,2018,Unsupervised Learning of View-invariant Action Representations,Mohan Kankanhalli,"National University of Singapore,"
NIPS,2018,Toddler-Inspired Visual Object Learning,Sven Bambach,The Research Institute at Nationwide Children's Hospital
NIPS,2018,Toddler-Inspired Visual Object Learning,David Crandall,Indiana University
NIPS,2018,Toddler-Inspired Visual Object Learning,Linda Smith,Indiana University
NIPS,2018,Toddler-Inspired Visual Object Learning,Chen Yu,Indiana University
NIPS,2018,Evolutionary Reinforcement Learning,Shaw Khadka,Oregon State University
NIPS,2018,Evolutionary Reinforcement Learning,Kagan Tumer,Oregon State University US
NIPS,2018,Efficient nonmyopic batch active search,Shali Jiang,Washington University in St. Louis
NIPS,2018,Efficient nonmyopic batch active search,Gustavo Malkomes,Washington University in St. Louis
NIPS,2018,Efficient nonmyopic batch active search,Matthew Abbott,Washington University in St. Louis
NIPS,2018,Efficient nonmyopic batch active search,Benjamin Moseley,Carnegie Mellon University
NIPS,2018,Efficient nonmyopic batch active search,Roman Garnett,Washington University in St. Louis
NIPS,2018,$\ell_1$-regression with Heavy-tailed Distributions,Lijun Zhang,Nanjing University (NJU)
NIPS,2018,$\ell_1$-regression with Heavy-tailed Distributions,Zhi-Hua Zhou,Nanjing University
NIPS,2018,Domain-Invariant Projection Learning for Zero-Shot Recognition,An Zhao,Renmin University of China
NIPS,2018,Domain-Invariant Projection Learning for Zero-Shot Recognition,Mingyu Ding,Renmin University of China
NIPS,2018,Domain-Invariant Projection Learning for Zero-Shot Recognition,Abel Guan,Renmin University of China
NIPS,2018,Domain-Invariant Projection Learning for Zero-Shot Recognition,Zhiwu Lu,Renmin University of China
NIPS,2018,Domain-Invariant Projection Learning for Zero-Shot Recognition,Tao Xiang,"Samsung AI Centre, Cambridge"
NIPS,2018,Domain-Invariant Projection Learning for Zero-Shot Recognition,Ji-Rong Wen,Renmin University of China
NIPS,2018,Boosted Sparse and Low-Rank Tensor Regression,Lifang He,Cornell University
NIPS,2018,Boosted Sparse and Low-Rank Tensor Regression,Kun Chen,University of Connecticut
NIPS,2018,Boosted Sparse and Low-Rank Tensor Regression,Wanwan Xu,University of Connecticut
NIPS,2018,Boosted Sparse and Low-Rank Tensor Regression,Jiayu Zhou,Michigan State University
NIPS,2018,Boosted Sparse and Low-Rank Tensor Regression,Fei Wang,Cornell University
NIPS,2018,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Network,Hang Gao,Columbia University
NIPS,2018,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Network,Zheng Shou,Columbia University
NIPS,2018,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Network,Alireza Zareian,Columbia University
NIPS,2018,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Network,Hanwang Zhang,Nanyang Technological University
NIPS,2018,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Network,Shih-Fu Chang,Columbia University
NIPS,2018,A flexible model for training action localization with varying levels of supervision,Guilhem Chéron,Inria
NIPS,2018,A flexible model for training action localization with varying levels of supervision,Jean-Baptiste Alayrac,Deepmind
NIPS,2018,A flexible model for training action localization with varying levels of supervision,Ivan Laptev,INRIA
NIPS,2018,A flexible model for training action localization with varying levels of supervision,Cordelia Schmid,Inria / Google
NIPS,2018,Posterior Concentration for Sparse Deep Learning,Veronika Rockova,University of Chicago
NIPS,2018,Posterior Concentration for Sparse Deep Learning,nicholas polson,Chicago Booth
NIPS,2018,DropMax: Adaptive Variational Softmax,Hae Beom Lee,KAIST
NIPS,2018,DropMax: Adaptive Variational Softmax,Juho Lee,University of Oxford
NIPS,2018,DropMax: Adaptive Variational Softmax,Saehoon Kim,AITRICS
NIPS,2018,DropMax: Adaptive Variational Softmax,Eunho Yang,Korea Advanced Institute of Science and Technology; AItrics
NIPS,2018,DropMax: Adaptive Variational Softmax,Sung Ju Hwang,"KAIST, AItrics"
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Jay Heo,UNIST
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Hae Beom Lee,KAIST
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Saehoon Kim,AITRICS
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Juho Lee,University of Oxford
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Kwang Joon Kim,Yonsei University College of Medicine
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Eunho Yang,Korea Advanced Institute of Science and Technology; AItrics
NIPS,2018,Uncertainty-Aware Attention for Reliable Interpretation and Prediction,Sung Ju Hwang,"KAIST, AItrics"
NIPS,2018,Large Margin Deep Networks for Classification,Gamaleldin Elsayed,Google Brain
NIPS,2018,Large Margin Deep Networks for Classification,Dilip Krishnan,Google
NIPS,2018,Large Margin Deep Networks for Classification,Hossein Mobahi,Google Research
NIPS,2018,Large Margin Deep Networks for Classification,Kevin Regan,Google
NIPS,2018,Large Margin Deep Networks for Classification,Samy Bengio,Google Brain
NIPS,2018,PointCNN,Yangyan Li,Alibaba AI Labs
NIPS,2018,PointCNN,Rui Bu,Shandong University
NIPS,2018,PointCNN,Mingchao Sun,Shandong University
NIPS,2018,PointCNN,Wei Wu,Shandong University
NIPS,2018,PointCNN,XINHAN DI,Vivo Communication Technology Co.Ltd
NIPS,2018,PointCNN,Baoquan Chen,Shandong University
NIPS,2018,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN,Shupeng Su,Peking University
NIPS,2018,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN,Chao Zhang,Peking University
NIPS,2018,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN,Kai Han,"Noah's Ark Laboratory, Huawei"
NIPS,2018,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN,Yonghong Tian,Peking University
NIPS,2018,Long short-term memory and Learning-to-learn in networks of spiking neurons,Guillaume Bellec,Graz University of Technology
NIPS,2018,Long short-term memory and Learning-to-learn in networks of spiking neurons,Darjan Salaj,Graz University of Technology
NIPS,2018,Long short-term memory and Learning-to-learn in networks of spiking neurons,Anand Subramoney,Graz University of Technology
NIPS,2018,Long short-term memory and Learning-to-learn in networks of spiking neurons,Robert Legenstein,Graz University of Technology
NIPS,2018,Long short-term memory and Learning-to-learn in networks of spiking neurons,Wolfgang Maass,Graz University of Technology
NIPS,2018,FishNet: the Beauty of Feature Preservation and Refinement,Shuyang Sun,The University of Sydney
NIPS,2018,FishNet: the Beauty of Feature Preservation and Refinement,Jiangmiao Pang,Zhejiang University
NIPS,2018,FishNet: the Beauty of Feature Preservation and Refinement,Jianping Shi,Sensetime Group Limited
NIPS,2018,FishNet: the Beauty of Feature Preservation and Refinement,Shuai Yi,The Chinese University of Hong Kong
NIPS,2018,FishNet: the Beauty of Feature Preservation and Refinement,Wanli Ouyang,The University of Sydney
NIPS,2018,TADAM: Task dependent adaptive metric for improved few-shot learning,Boris Oreshkin,Element AI
NIPS,2018,TADAM: Task dependent adaptive metric for improved few-shot learning,Pau Rodríguez López,CVC UAB
NIPS,2018,TADAM: Task dependent adaptive metric for improved few-shot learning,Alexandre Lacoste,Element AI
NIPS,2018,Are GANs Created Equal? A Large-Scale Study,Mario Lucic,Google Brain
NIPS,2018,Are GANs Created Equal? A Large-Scale Study,Karol Kurach,Google Brain
NIPS,2018,Are GANs Created Equal? A Large-Scale Study,Marcin Michalski,Google
NIPS,2018,Are GANs Created Equal? A Large-Scale Study,Sylvain Gelly,Google Brain (Zurich)
NIPS,2018,Are GANs Created Equal? A Large-Scale Study,Olivier Bousquet,Google Brain (Zurich)
NIPS,2018,Dialog-based Interactive Image Retrieval,Xiaoxiao Guo,IBM Research
NIPS,2018,Dialog-based Interactive Image Retrieval,Hui Wu,IBM Research
NIPS,2018,Dialog-based Interactive Image Retrieval,Yu Cheng,Microsoft AI & Research
NIPS,2018,Dialog-based Interactive Image Retrieval,Steven Rennie,Fusemachines
NIPS,2018,Dialog-based Interactive Image Retrieval,Gerald Tesauro,IBM TJ Watson Research Center
NIPS,2018,Dialog-based Interactive Image Retrieval,Rogerio Feris,IBM Research AI
NIPS,2018,A Neural Compositional Paradigm for Image Captioning,Bo Dai,Google Brain
NIPS,2018,A Neural Compositional Paradigm for Image Captioning,Sanja Fidler,University of Toronto
NIPS,2018,A Neural Compositional Paradigm for Image Captioning,Dahua Lin,The Chinese University of Hong Kong
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Amit Dhurandhar,IBM Research
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Pin-Yu Chen,IBM Research AI
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Ronny Luss,IBM Research
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Chun-Chen Tu,University of Michigan
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Paishun Ting,University of Michigan
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Karthikeyan Shanmugam,"IBM Research, NY"
NIPS,2018,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,Payel Das,IBM Research
NIPS,2018,Are ResNets Provably Better than Linear Predictors?,Ohad Shamir,Weizmann Institute of Science
NIPS,2018,Training DNNs with Hybrid Block Floating Point,Mario Drumond,EPFL
NIPS,2018,Training DNNs with Hybrid Block Floating Point,Tao LIN,EPFL
NIPS,2018,Training DNNs with Hybrid Block Floating Point,Martin Jaggi,EPFL
NIPS,2018,Training DNNs with Hybrid Block Floating Point,Babak Falsafi,"EcoCloud, EPFL"
NIPS,2018,Implicit Reparameterization Gradients,Michael Figurnov,DeepMind
NIPS,2018,Implicit Reparameterization Gradients,Shakir Mohamed,DeepMind
NIPS,2018,Implicit Reparameterization Gradients,Andriy Mnih,DeepMind
NIPS,2018,Deep Defense: Training DNNs with Improved Adversarial Robustness,ziang Yan,"Automation Department, Tsinghua University"
NIPS,2018,Deep Defense: Training DNNs with Improved Adversarial Robustness,Yiwen Guo,Intel Labs China
NIPS,2018,Deep Defense: Training DNNs with Improved Adversarial Robustness,Changshui Zhang,Tsinghua University
NIPS,2018,On Misinformation Containment in Online Social Networks,Amo Tong,University of Delaware
NIPS,2018,On Misinformation Containment in Online Social Networks,Ding-Zhu Du,University of Texas at Dallas
NIPS,2018,On Misinformation Containment in Online Social Networks,Weili Wu,University of Texas at Dallas
NIPS,2018,Probabilistic Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC,Tolga Birdal,Technical University of Munich
NIPS,2018,Probabilistic Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC,Umut Simsekli,Telecom ParisTech
NIPS,2018,Probabilistic Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC,Mustafa Onur Eken,Technical University of Munich
NIPS,2018,Probabilistic Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC,Slobodan Ilic,Siemens AG
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Celestine Dünner,IBM Research
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Thomas Parnell,IBM Research
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Dimitrios Sarigiannis,IBM Research
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Nikolas Ioannou,IBM Research
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Andreea Anghel,IBM Research
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Gummadi Ravi,IBM Systems
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Madhusudanan Kandasamy,IBM Systems
NIPS,2018,Snap ML: A Hierarchical Framework for Machine Learning,Haris Pozidis,IBM Research
NIPS,2018,PAC-learning in the presence of adversaries,Daniel Cullina,Princeton University
NIPS,2018,PAC-learning in the presence of adversaries,Arjun Nitin Bhagoji,Princeton University
NIPS,2018,PAC-learning in the presence of adversaries,Prateek Mittal,Princeton University
NIPS,2018,Cooperative Holistic 3D Scene Understanding from a Single RGB Image,Siyuan Huang,"University of California, Los Angeles"
NIPS,2018,Cooperative Holistic 3D Scene Understanding from a Single RGB Image,Siyuan Qi,UCLA
NIPS,2018,Cooperative Holistic 3D Scene Understanding from a Single RGB Image,Yinxue Xiao,"University of California, Los Angeles"
NIPS,2018,Cooperative Holistic 3D Scene Understanding from a Single RGB Image,Yixin Zhu,"University of California, Los Angeles"
NIPS,2018,Cooperative Holistic 3D Scene Understanding from a Single RGB Image,Ying Nian Wu,"University of California, Los Angeles"
NIPS,2018,Cooperative Holistic 3D Scene Understanding from a Single RGB Image,Song-Chun Zhu,UCLA
NIPS,2018,Fast Similarity Search via Optimal Sparse Lifting,Wenye Li,"The Chinese University of Hong Kong, Shenzhen"
NIPS,2018,Fast Similarity Search via Optimal Sparse Lifting,Jingwei Mao,"The Chinese University of Hong Kong, Shenzhen"
NIPS,2018,Fast Similarity Search via Optimal Sparse Lifting,Yin Zhang,"The Chinese University of Hong Kong, Shenzhen"
NIPS,2018,Fast Similarity Search via Optimal Sparse Lifting,Shuguang Cui,"The Chinese University of Hong Kong, Shenzhen"
NIPS,2018,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution,Zhisheng Zhong,Peking University
NIPS,2018,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution,Tiancheng Shen,Peking University
NIPS,2018,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution,Yibo Yang,Peking University
NIPS,2018,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution,Zhouchen Lin,Peking University
NIPS,2018,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution,Chao Zhang,Peking University
NIPS,2018,Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning,Tyler Scott,University of Colorado Boulder
NIPS,2018,Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning,Karl Ridgeway,"University of Colorado, Boulder"
NIPS,2018,Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning,Mike Mozer,Google Brain / U. Colorado
NIPS,2018,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis,Huaibo Huang,"Institute of Automation, Chinese Academy of Science"
NIPS,2018,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis,zhihang li,"Institute of Automation, Chinese Academy of Science"
NIPS,2018,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis,Ran He,"NLPR, CASIA"
NIPS,2018,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis,Zhenan Sun,"Institute of Automation, Chinese Academy of Sciences (CASIA)"
NIPS,2018,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis,Tieniu Tan,Chinese Academy of Sciences
NIPS,2018,Kalman Normalization,Guangrun Wang,Sun Yat-sen University
NIPS,2018,Kalman Normalization,jiefeng peng,Sun Yat-sen University
NIPS,2018,Kalman Normalization,Ping Luo,The Chinese University of Hong Kong
NIPS,2018,Kalman Normalization,Xinjiang Wang,SenseTime Group Ltd.
NIPS,2018,Kalman Normalization,Liang Lin,Sun Yat-Sen University
NIPS,2018,Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Shinji Ito,NEC Corporation
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Daisuke Hatano,RIKEN AIP
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Sumita Hanna,Tokyo Metropolitan University
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Akihiro Yabe,
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Takuro Fukunaga,"RIKEN AIP, JST PRESTO"
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Naonori Kakimura,Keio University
NIPS,2018,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint,Ken-Ichi Kawarabayashi,National Institute of Informatics
NIPS,2018,Fast deep reinforcement learning using online adjustments from the past,Steven Hansen,DeepMind
NIPS,2018,Fast deep reinforcement learning using online adjustments from the past,Alexander Pritzel,Deepmind
NIPS,2018,Fast deep reinforcement learning using online adjustments from the past,Pablo Sprechmann,DeepMind
NIPS,2018,Fast deep reinforcement learning using online adjustments from the past,Andre Barreto,DeepMind
NIPS,2018,Fast deep reinforcement learning using online adjustments from the past,Charles Blundell,DeepMind
NIPS,2018,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning,Zhang-Wei Hong,National Tsing Hua University
NIPS,2018,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning,Ariel Shann,University of British Columbia
NIPS,2018,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning,Shih-Yang Su,Virginia Tech
NIPS,2018,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning,Yi-Hsiang Chang,
NIPS,2018,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning,Tsu-Jui Fu,Academia Sinica
NIPS,2018,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning,Chun-Yi Lee,National Tsing Hua University
NIPS,2018,Glow: Generative Flow with Invertible 1x1 Convolutions,Durk Kingma,Google
NIPS,2018,Glow: Generative Flow with Invertible 1x1 Convolutions,Prafulla Dhariwal,OpenAI
NIPS,2018,Learning To Learn Around A Common Mean,Giulia Denevi,IIT
NIPS,2018,Learning To Learn Around A Common Mean,Carlo Ciliberto,Imperial College London
NIPS,2018,Learning To Learn Around A Common Mean,Dimitris Stamos,University College London
NIPS,2018,Learning To Learn Around A Common Mean,Massimiliano Pontil,IIT & UCL
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Bo Dai,Google Brain
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Hanjun Dai,Georgia Tech
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Niao He,UIUC
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Weiyang Liu,Georgia Institute of Technology
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Zhen Liu,Georgia Institute of Technology
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Jianshu Chen,Tencent AI Lab
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Lin Xiao,Microsoft Research
NIPS,2018,Coupled Variational Bayes via Optimization Embedding,Le Song,Ant Financial & Georgia Institute of Technology
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Bradly Stadie,Vector Institute
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Ge Yang Yang,Berkeley
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Rein Houthooft,Happy Elements
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Peter Chen,covariant.ai
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Yan Duan,UC Berkeley
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Yuhuai Wu,University of Toronto
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Pieter Abbeel,UC Berkeley | Gradescope | Covariant
NIPS,2018,The Importance of Sampling inMeta-Reinforcement Learning,Ilya Sutskever,OpenAI
NIPS,2018,Beyond Grids: Learning Graph Representations for Visual Recognition,Yin Li,University of Wisconsin-Madison
NIPS,2018,Beyond Grids: Learning Graph Representations for Visual Recognition,Abhinav Gupta,Facebook AI Research/CMU
NIPS,2018,PAC-Bayes bounds for stable algorithms with instance-dependent priors,Omar Rivasplata,University College London
NIPS,2018,PAC-Bayes bounds for stable algorithms with instance-dependent priors,Csaba Szepesvari,University of Alberta
NIPS,2018,PAC-Bayes bounds for stable algorithms with instance-dependent priors,John Shawe-Taylor,UCL
NIPS,2018,PAC-Bayes bounds for stable algorithms with instance-dependent priors,Emilio Parrado-Hernandez,University Carlos III de Madrid
NIPS,2018,PAC-Bayes bounds for stable algorithms with instance-dependent priors,Shiliang Sun,East China Normal University
NIPS,2018,Reversible Recurrent Neural Networks,Matthew MacKay,University of Toronto
NIPS,2018,Reversible Recurrent Neural Networks,Paul Vicol,University of Toronto
NIPS,2018,Reversible Recurrent Neural Networks,Jimmy Ba,University of Toronto / Vector Institute
NIPS,2018,Reversible Recurrent Neural Networks,Roger Grosse,University of Toronto
NIPS,2018,Wavelet regression and additive models for irregularly spaced data,Asad Haris,University of Washington
NIPS,2018,Wavelet regression and additive models for irregularly spaced data,Ali Shojaie,
NIPS,2018,Wavelet regression and additive models for irregularly spaced data,Noah Simon,University of Washington
NIPS,2018,Uniform Convergence of Gradients for Non-Convex Learning and Optimization,Dylan Foster,Cornell University
NIPS,2018,Uniform Convergence of Gradients for Non-Convex Learning and Optimization,Ayush Sekhari,Cornell University
NIPS,2018,Uniform Convergence of Gradients for Non-Convex Learning and Optimization,Karthik Sridharan,Cornell University
NIPS,2018,Learning Plannable Representations with Causal InfoGAN,Thanard Kurutach,University of California Berkeley
NIPS,2018,Learning Plannable Representations with Causal InfoGAN,Aviv Tamar,UC Berkeley
NIPS,2018,Learning Plannable Representations with Causal InfoGAN,Ge Yang Yang,Berkeley
NIPS,2018,Learning Plannable Representations with Causal InfoGAN,Stuart Russell,UC Berkeley
NIPS,2018,Learning Plannable Representations with Causal InfoGAN,Pieter Abbeel,UC Berkeley | Gradescope | Covariant
NIPS,2018,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects",Adam Kosiorek,University of Oxford
NIPS,2018,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects",Hyunjik Kim,
NIPS,2018,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects",Yee Whye Teh,"University of Oxford, DeepMind"
NIPS,2018,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects",Ingmar Posner,Oxford University
NIPS,2018,Learning Conditioned Graph Structures for Interpretable Visual Question Answering,Will Norcliffe-Brown,AimBrain
NIPS,2018,Learning Conditioned Graph Structures for Interpretable Visual Question Answering,Stathis Vafeias,AimBrain
NIPS,2018,Learning Conditioned Graph Structures for Interpretable Visual Question Answering,Sarah Parisot,Huawei
NIPS,2018,Generative Adversarial Examples,Yang Song,Stanford University
NIPS,2018,Generative Adversarial Examples,Rui Shu,Stanford University
NIPS,2018,Generative Adversarial Examples,Nate Kushman,Microsoft Research Cambridge
NIPS,2018,Generative Adversarial Examples,Stefano Ermon,Stanford
NIPS,2018,The promises and pitfalls of Stochastic Gradient Langevin Dynamics,Nicolas Brosse,"Ecole Polytechnique, Palaiseau, FRANCE"
NIPS,2018,The promises and pitfalls of Stochastic Gradient Langevin Dynamics,Alain Durmus,ENS
NIPS,2018,The promises and pitfalls of Stochastic Gradient Langevin Dynamics,Eric Moulines,Ecole Polytechnique
NIPS,2018,Efficient Anomaly Detection via Matrix Sketching,Vatsal Sharan,Stanford University
NIPS,2018,Efficient Anomaly Detection via Matrix Sketching,Parikshit Gopalan,VMware Research
NIPS,2018,Efficient Anomaly Detection via Matrix Sketching,Udi Wieder,VMware Research
NIPS,2018,Stochastic Expectation Maximization with Variance Reduction,Jianfei Chen,RealAI
NIPS,2018,Stochastic Expectation Maximization with Variance Reduction,Jun Zhu,Tsinghua University
NIPS,2018,Stochastic Expectation Maximization with Variance Reduction,Yee Whye Teh,"University of Oxford, DeepMind"
NIPS,2018,Stochastic Expectation Maximization with Variance Reduction,Tong Zhang,The Australian National University
NIPS,2018,Learning Loop Invariants for Program Verification,Xujie Si,University of Pennsylvania
NIPS,2018,Learning Loop Invariants for Program Verification,Hanjun Dai,Georgia Tech
NIPS,2018,Learning Loop Invariants for Program Verification,Mukund Raghothaman,University of Pennsylvania
NIPS,2018,Learning Loop Invariants for Program Verification,Mayur Naik,University of Pennsylvania
NIPS,2018,Learning Loop Invariants for Program Verification,Le Song,Ant Financial & Georgia Institute of Technology
NIPS,2018,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples,Guanhong Tao,Purdue University
NIPS,2018,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples,Shiqing Ma,Purdue University
NIPS,2018,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples,Yingqi Liu,Purdue University
NIPS,2018,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples,Xiangyu Zhang,Purdue University
NIPS,2018,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis,Alyson Fletcher,UCLA
NIPS,2018,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis,Parthe Pandit,UCLA
NIPS,2018,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis,Sundeep Rangan,NYU
NIPS,2018,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis,Subrata Sarkar,The Ohio State University
NIPS,2018,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis,Phil Schniter,The Ohio State University
NIPS,2018,How to tell when a clustering is (approximately) correct using convex relaxations,Marina Meila,University of Washington
NIPS,2018,Bayesian Model-Agnostic Meta-Learning,Jaesik Yoon,SAP
NIPS,2018,Bayesian Model-Agnostic Meta-Learning,Taesup Kim,Université de Montréal
NIPS,2018,Bayesian Model-Agnostic Meta-Learning,Ousmane Dia,Element AI
NIPS,2018,Bayesian Model-Agnostic Meta-Learning,Sungwoong Kim,Kakao Brain
NIPS,2018,Bayesian Model-Agnostic Meta-Learning,Yoshua Bengio,U. Montreal
NIPS,2018,Bayesian Model-Agnostic Meta-Learning,Sungjin Ahn,Rutgers University
NIPS,2018,Chaining Mutual Information and Tightening Generalization Bounds,Amir Asadi,Princeton University
NIPS,2018,Chaining Mutual Information and Tightening Generalization Bounds,Emmanuel Abbe,Princeton University
NIPS,2018,Chaining Mutual Information and Tightening Generalization Bounds,Sergio Verdu,Princeton University
NIPS,2018,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks,Kimin Lee,Korea Advanced Institute of Science and Technology
NIPS,2018,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks,Kibok Lee,University of Michigan
NIPS,2018,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks,Honglak Lee,Google Brain
NIPS,2018,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks,Jinwoo Shin,KAIST; AITRICS
NIPS,2018,Model-Agnostic Private Learning,Raef Bassily,The Ohio State University
NIPS,2018,Model-Agnostic Private Learning,Abhradeep Guha Thakurta,University of California Santa Cruz
NIPS,2018,Model-Agnostic Private Learning,Om Thakkar,Boston University
NIPS,2018,Causal Inference with Noisy and Missing Covariates via Matrix Factorization,Nathan Kallus,Cornell University
NIPS,2018,Causal Inference with Noisy and Missing Covariates via Matrix Factorization,Xiaojie Mao,Cornell University
NIPS,2018,Causal Inference with Noisy and Missing Covariates via Matrix Factorization,Madeleine Udell,Cornell University
NIPS,2018,Bayesian Adversarial Learning,Lincoln Ye,University of Cambridge
NIPS,2018,Bayesian Adversarial Learning,Zhanxing Zhu,Peking University
NIPS,2018,Provable Gaussian Embedding with One Observation,Ming Yu,"The University of Chicago, Booth School of Business"
NIPS,2018,Provable Gaussian Embedding with One Observation,Zhuoran Yang,Princeton University
NIPS,2018,Provable Gaussian Embedding with One Observation,Tuo Zhao,Georgia Tech
NIPS,2018,Provable Gaussian Embedding with One Observation,Mladen Kolar,University of Chicago
NIPS,2018,Provable Gaussian Embedding with One Observation,Princeton Zhaoran Wang,"Princeton, Phd student"
NIPS,2018,Banach Wasserstein GAN,Jonas Adler,KTH - Royal Institute of Technology
NIPS,2018,Banach Wasserstein GAN,Sebastian Lunz,University of Cambridge
NIPS,2018,Neural Ordinary Differential Equations,Ricky Chen,University of Toronto
NIPS,2018,Neural Ordinary Differential Equations,Yulia Rubanova,University of Toronto
NIPS,2018,Neural Ordinary Differential Equations,Jesse Bettencourt,University of Toronto
NIPS,2018,Neural Ordinary Differential Equations,David Duvenaud,University of Toronto
NIPS,2018,Proximal SCOPE for Distributed Sparse Learning,Shenyi Zhao,Nanjing University
NIPS,2018,Proximal SCOPE for Distributed Sparse Learning,Gong-Duo Zhang,Nanjing University
NIPS,2018,Proximal SCOPE for Distributed Sparse Learning,Ming-Wei Li,Nanjing University
NIPS,2018,Proximal SCOPE for Distributed Sparse Learning,Wu-Jun Li,Nanjing University
NIPS,2018,Exponentially Weighted Imitation Learning for Batched Historical Data,Qing Wang,Tencent AI Lab
NIPS,2018,Exponentially Weighted Imitation Learning for Batched Historical Data,Jiechao Xiong,Tencent AI Lab
NIPS,2018,Exponentially Weighted Imitation Learning for Batched Historical Data,Lei Han,
NIPS,2018,Exponentially Weighted Imitation Learning for Batched Historical Data,peng sun,Tencent AI Lab
NIPS,2018,Exponentially Weighted Imitation Learning for Batched Historical Data,Han Liu,Tencent AI Lab
NIPS,2018,Exponentially Weighted Imitation Learning for Batched Historical Data,Tong Zhang,The Australian National University
NIPS,2018,Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo,Oren Mangoubi,EPFL
NIPS,2018,Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo,Nisheeth Vishnoi,EPFL
NIPS,2018,Automating Bayesian optimization with Bayesian optimization,Gustavo Malkomes,Washington University in St. Louis
NIPS,2018,Automating Bayesian optimization with Bayesian optimization,Roman Garnett,Washington University in St. Louis
NIPS,2018,A Bayes-Sard Cubature Method,Toni Karvonen,Aalto University
NIPS,2018,A Bayes-Sard Cubature Method,Chris J Oates,Newcastle University
NIPS,2018,A Bayes-Sard Cubature Method,Simo Sarkka,Aalto University
NIPS,2018,Mental Sampling in Multimodal Representations,Jianqiao Zhu,University of Warwick
NIPS,2018,Mental Sampling in Multimodal Representations,Adam Sanborn,University of Warwick
NIPS,2018,Mental Sampling in Multimodal Representations,Nick Chater,Warwick Business School
NIPS,2018,Critical initialisation for deep signal propagation in noisy rectifier neural networks,Arnu Pretorius,Stellenbosch University
NIPS,2018,Critical initialisation for deep signal propagation in noisy rectifier neural networks,Elan van Biljon,Stellenbosch University
NIPS,2018,Critical initialisation for deep signal propagation in noisy rectifier neural networks,Steve Kroon,Stellenbosch University
NIPS,2018,Critical initialisation for deep signal propagation in noisy rectifier neural networks,Herman Kamper,Stellenbosch University
NIPS,2018,Contextual Pricing for Lipschitz Buyers,Jieming Mao,Princeton University
NIPS,2018,Contextual Pricing for Lipschitz Buyers,Renato Leme,Google Research
NIPS,2018,Contextual Pricing for Lipschitz Buyers,Jon Schneider,Google
NIPS,2018,Community Exploration: From Offline Optimization to Online Learning,Xiaowei Chen,The Chinese University of Hong Kong
NIPS,2018,Community Exploration: From Offline Optimization to Online Learning,Weiran Huang,"Noah's Ark Lab, Huawei Technologies"
NIPS,2018,Community Exploration: From Offline Optimization to Online Learning,Wei Chen,Microsoft Research
NIPS,2018,Community Exploration: From Offline Optimization to Online Learning,John C. S. Lui,The Chinese University of Hong Kong
NIPS,2018,Hyperbolic Neural Networks,Octavian Ganea,ETH Zurich
NIPS,2018,Hyperbolic Neural Networks,Gary Becigneul,ETH Zürich & MPI Tübingen
NIPS,2018,Hyperbolic Neural Networks,Thomas Hofmann,ETH Zurich
NIPS,2018,Horizon-Independent Minimax Linear Regression,Alan Malek,MIT
NIPS,2018,Horizon-Independent Minimax Linear Regression,Peter Bartlett,UC Berkeley
NIPS,2018,Multi-armed Bandits with Compensation,Siwei Wang,"IIIS, Tsinghua University"
NIPS,2018,Multi-armed Bandits with Compensation,Longbo Huang,"IIIS, Tsinghua Univeristy"
NIPS,2018,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning,Tianyi Chen,University of Minnesota
NIPS,2018,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning,Georgios Giannakis,University of Minnesota
NIPS,2018,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning,Tao Sun,National university of defense technology
NIPS,2018,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning,Wotao Yin,"University of California, Los Angeles"
NIPS,2018,A Smoother Way to Train Structured Prediction Models,Krishna Pillutla,University of Washington
NIPS,2018,A Smoother Way to Train Structured Prediction Models,Vincent Roulet,UW
NIPS,2018,A Smoother Way to Train Structured Prediction Models,Sham Kakade,University of Washington
NIPS,2018,A Smoother Way to Train Structured Prediction Models,Zaid Harchaoui,University of Washington
NIPS,2018,Boolean Decision Rules via Column Generation,Sanjeeb Dash,IBM Research
NIPS,2018,Boolean Decision Rules via Column Generation,Oktay Gunluk,IBM Research
NIPS,2018,Boolean Decision Rules via Column Generation,Dennis Wei,IBM Research
NIPS,2018,Spectral Filtering for General Linear Dynamical Systems,Elad Hazan,Princeton University
NIPS,2018,Spectral Filtering for General Linear Dynamical Systems,HOLDEN LEE,Princeton
NIPS,2018,Spectral Filtering for General Linear Dynamical Systems,Karan Singh,Princeton University
NIPS,2018,Spectral Filtering for General Linear Dynamical Systems,Cyril Zhang,Princeton University
NIPS,2018,Spectral Filtering for General Linear Dynamical Systems,Yi Zhang,Princeton
NIPS,2018,Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima,Yaodong Yu,University of Virginia
NIPS,2018,Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima,Pan Xu,UCLA
NIPS,2018,Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima,Quanquan Gu,UCLA
NIPS,2018,Amortized Inference Regularization,Rui Shu,Stanford University
NIPS,2018,Amortized Inference Regularization,Hung Bui,Google DeepMind
NIPS,2018,Amortized Inference Regularization,Shengjia Zhao,Stanford University
NIPS,2018,Amortized Inference Regularization,Mykel J Kochenderfer,Stanford University
NIPS,2018,Amortized Inference Regularization,Stefano Ermon,Stanford
NIPS,2018,Bilevel Distance Metric Learning for Robust Image Recognition,Jie Xu,University of Miami
NIPS,2018,Bilevel Distance Metric Learning for Robust Image Recognition,Lei Luo,University of Pittsburgh
NIPS,2018,Bilevel Distance Metric Learning for Robust Image Recognition,Cheng Deng,Xidian University
NIPS,2018,Bilevel Distance Metric Learning for Robust Image Recognition,Heng Huang,University of Pittsburgh
NIPS,2018,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator,Sarah Dean,
NIPS,2018,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator,Horia Mania,UC Berkeley
NIPS,2018,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator,Nikolai Matni,UC Berkeley
NIPS,2018,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator,Benjamin Recht,UC Berkeley
NIPS,2018,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator,Stephen Tu,UC Berkeley
NIPS,2018,Direct Runge-Kutta Discretization Achieves Acceleration,Jingzhao Zhang,MIT
NIPS,2018,Direct Runge-Kutta Discretization Achieves Acceleration,Aryan Mokhtari,MIT
NIPS,2018,Direct Runge-Kutta Discretization Achieves Acceleration,Suvrit Sra,MIT
NIPS,2018,Direct Runge-Kutta Discretization Achieves Acceleration,Ali Jadbabaie,MIT
NIPS,2018,Leveraging the Exact Likelihood of Deep Latent Variable Models,Pierre-Alexandre Mattei,ITU Copenhagen
NIPS,2018,Leveraging the Exact Likelihood of Deep Latent Variable Models,Jes Frellsen,IT University of Copenhagen
NIPS,2018,Lipschitz regularity of deep neural networks: analysis and efficient estimation,Aladin Virmaux,Huawei
NIPS,2018,Lipschitz regularity of deep neural networks: analysis and efficient estimation,Kevin Scaman,"Noah's Ark Lab, Huawei Technologies"
NIPS,2018,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization,Tianyi Liu,Georgia Institute of Technolodgy
NIPS,2018,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization,Shiyang Li,"University of California, Santa Barbara"
NIPS,2018,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization,Jianping Shi,Sensetime Group Limited
NIPS,2018,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization,Enlu Zhou,Georgia Institute of Technology
NIPS,2018,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization,Tuo Zhao,Georgia Tech
NIPS,2018,Communication Efficient Parallel Algorithms for Optimization on Manifolds,Bayan Saparbayeva,University Notre Dame
NIPS,2018,Communication Efficient Parallel Algorithms for Optimization on Manifolds,Michael Zhang,Princeton University
NIPS,2018,Communication Efficient Parallel Algorithms for Optimization on Manifolds,Lizhen Lin,The University of Notre Dame
NIPS,2018,Recurrent Relational Networks,Rasmus Palm,Technical University Denmark
NIPS,2018,Recurrent Relational Networks,Ulrich Paquet,DeepMind
NIPS,2018,Recurrent Relational Networks,Ole Winther,Technical University of Denmark
NIPS,2018,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward,Lixing Chen,University of Miami
NIPS,2018,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward,Jie Xu,University of Miami
NIPS,2018,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward,Zhuo  Lu,University of South Florida
NIPS,2018,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces,Motoya Ohnishi,Keio University/KTH Royal Institute of Technology/RIKEN
NIPS,2018,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces,Masahiro Yukawa,Keio University
NIPS,2018,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces,Mikael Johansson,KTH - Royal Institute of Technology
NIPS,2018,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2018,Unsupervised Learning of Shape and Pose with Differentiable Point Clouds,Eldar Insafutdinov,Max Planck Institute for Informatics
NIPS,2018,Unsupervised Learning of Shape and Pose with Differentiable Point Clouds,Alexey Dosovitskiy,Intel Labs
NIPS,2018,A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication,Peng Jiang,Shandong University
NIPS,2018,A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication,Gagan Agrawal,Ohio State University
NIPS,2018,Query Complexity of Bayesian Private Learning,Kuang Xu,Stanford Graduate School of Business
NIPS,2018,The Description Length of Deep Learning models,Léonard Blier,Ecole Normale Supérieure
NIPS,2018,The Description Length of Deep Learning models,Yann Ollivier,Facebook Artificial Intelligence Research
NIPS,2018,"Overlapping Clustering, and One (class) SVM to Bind Them All",Xueyu Mao,University of Texas at Austin
NIPS,2018,"Overlapping Clustering, and One (class) SVM to Bind Them All",Purnamrita Sarkar,UT Austin
NIPS,2018,"Overlapping Clustering, and One (class) SVM to Bind Them All",Deepayan Chakrabarti,UT Austin
NIPS,2018,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning,Supasorn Suwajanakorn,VISTEC
NIPS,2018,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning,Noah Snavely,Google
NIPS,2018,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning,Jonathan Tompson,Google Brain
NIPS,2018,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning,Mohammad Norouzi,Google Brain
NIPS,2018,Sequential Context Encoding for Duplicate Removal,lu Qi,The Chinese University of Hong Kong
NIPS,2018,Sequential Context Encoding for Duplicate Removal,Shu Liu,Chinese University of Hong Kong
NIPS,2018,Sequential Context Encoding for Duplicate Removal,Jianping Shi,Sensetime Group Limited
NIPS,2018,Sequential Context Encoding for Duplicate Removal,Jiaya Jia,CUHK
NIPS,2018,Entropy and mutual information in models of deep neural networks,Marylou Gabrié,École Normale Supérieure
NIPS,2018,Entropy and mutual information in models of deep neural networks,Andre Manoel,OWKIN
NIPS,2018,Entropy and mutual information in models of deep neural networks,Clément Luneau,École Polytechnique de Lausanne
NIPS,2018,Entropy and mutual information in models of deep neural networks,jean barbier,EPFL
NIPS,2018,Entropy and mutual information in models of deep neural networks,Nicolas Macris,EPFL
NIPS,2018,Entropy and mutual information in models of deep neural networks,Florent Krzakala,École Normale Supérieure
NIPS,2018,Entropy and mutual information in models of deep neural networks,Lenka Zdeborová,CEA Saclay
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,lczhang Zhang,University of Toronto
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,Gregory Rosenblatt,University of Alabama at Birmingham
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,Ethan Fetaya,University of Toronto
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,Renjie Liao,University of Toronto
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,William Byrd,University of Alabama at Birmingham
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,Matthew Might,University of Alabama at Birmingham
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,Raquel Urtasun,University of Toronto
NIPS,2018,Neural Guided Constraint Logic Programming for Program Synthesis,Richard Zemel,Vector Institute/University of Toronto
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Yilun Du,MIT
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Zhijian Liu,MIT
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Hector Basevi,University of Birmingham
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Ales Leonardis,University of Birmingham
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Bill Freeman,MIT/Google
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Josh Tenenbaum,MIT
NIPS,2018,Learning to Exploit Stability for 3D Scene Parsing,Jiajun Wu,MIT
NIPS,2018,Neighbourhood Consensus Networks,Ignacio Rocco,Inria
NIPS,2018,Neighbourhood Consensus Networks,Mircea Cimpoi,"CIIRC, CTU Prague"
NIPS,2018,Neighbourhood Consensus Networks,Relja Arandjelović,DeepMind
NIPS,2018,Neighbourhood Consensus Networks,Akihiko Torii,"Tokyo Institute of Technology, Japan"
NIPS,2018,Neighbourhood Consensus Networks,Tomas Pajdla,Czech Technical University in Prague
NIPS,2018,Neighbourhood Consensus Networks,Josef Sivic,Inria and Czech Technical University
NIPS,2018,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners,Yuxin Chen,Caltech
NIPS,2018,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners,Adish Singla,MPI-SWS
NIPS,2018,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners,Oisin Mac Aodha,California Institute of Technology
NIPS,2018,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners,Pietro Perona,California Institute of Technology
NIPS,2018,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners,Yisong Yue,Caltech
NIPS,2018,Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior,Sid Reddy,UC Berkeley
NIPS,2018,Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior,Anca Dragan,UC Berkeley
NIPS,2018,Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior,Sergey Levine,UC Berkeley
NIPS,2018,Gradient Descent for Spiking Neural Networks,Ben Huh,MIT-IBM AI Center
NIPS,2018,Gradient Descent for Spiking Neural Networks,Terrence J Sejnowski,Salk Institute
NIPS,2018,Adaptive Online Learning in Dynamic Environments,Lijun Zhang,Nanjing University (NJU)
NIPS,2018,Adaptive Online Learning in Dynamic Environments,Shiyin Lu,Nanjing University
NIPS,2018,Adaptive Online Learning in Dynamic Environments,Zhi-Hua Zhou,Nanjing University
NIPS,2018,New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity,Pan Zhou,National University of Singapore
NIPS,2018,New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity,Xiaotong Yuan,Nanjing University of Information Science and Technology
NIPS,2018,New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity,Jiashi Feng,National University of Singapore
NIPS,2018,Video-to-Video Synthesis,Ting-Chun Wang,NVIDIA
NIPS,2018,Video-to-Video Synthesis,Ming-Yu Liu,NVIDIA
NIPS,2018,Video-to-Video Synthesis,Jun-Yan Zhu,MIT
NIPS,2018,Video-to-Video Synthesis,Guilin Guilin,NVIDIA
NIPS,2018,Video-to-Video Synthesis,Andrew Tao,Nvidia Corporation
NIPS,2018,Video-to-Video Synthesis,Jan Kautz,NVIDIA
NIPS,2018,Video-to-Video Synthesis,Bryan Catanzaro,NVIDIA
NIPS,2018,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks,Zhenhua Liu,Peking University
NIPS,2018,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks,Jizheng Xu,Bytedance Inc.
NIPS,2018,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks,Xiulian Peng,Microsoft Research
NIPS,2018,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks,Ruiqin Xiong,Peking University
NIPS,2018,Removing the Feature Correlation Effect of Multiplicative Noise,Zijun Zhang,University of Calgary
NIPS,2018,Removing the Feature Correlation Effect of Multiplicative Noise,Yining Zhang,University of Calgary
NIPS,2018,Removing the Feature Correlation Effect of Multiplicative Noise,Zongpeng Li,Wuhan University
NIPS,2018,Self-Supervised Generation of Spatial Audio for 360-degree Video,Pedro Morgado,"University of California, San Diego"
NIPS,2018,Self-Supervised Generation of Spatial Audio for 360-degree Video,Nuno Nvasconcelos,UC San Diego
NIPS,2018,Self-Supervised Generation of Spatial Audio for 360-degree Video,Timothy Langlois,Adobe Systems Inc
NIPS,2018,Self-Supervised Generation of Spatial Audio for 360-degree Video,Oliver Wang,Adobe Research
NIPS,2018,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems,Mrinmaya Sachan,Carnegie Mellon University
NIPS,2018,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems,Kumar Avinava Dubey,Carnegie Mellon University
NIPS,2018,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems,Tom Mitchell,Carnegie Mellon University
NIPS,2018,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems,Dan Roth,UPenn
NIPS,2018,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,An Off-policy Policy Gradient Theorem Using Emphatic Weightings,Ehsan Imani,University of Alberta
NIPS,2018,An Off-policy Policy Gradient Theorem Using Emphatic Weightings,Eric Graves,University of Alberta
NIPS,2018,An Off-policy Policy Gradient Theorem Using Emphatic Weightings,Martha White,University of Alberta
NIPS,2018,Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language,Seonghyeon Nam,Yonsei University
NIPS,2018,Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language,Yunji Kim,Yonsei University
NIPS,2018,Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language,Seon Joo Kim,Yonsei University
NIPS,2018,Monte-Carlo Tree Search for Constrained POMDPs,Jongmin Lee,KAIST
NIPS,2018,Monte-Carlo Tree Search for Constrained POMDPs,Geon-hyeong Kim,KAIST
NIPS,2018,Monte-Carlo Tree Search for Constrained POMDPs,Pascal Poupart,University of Waterloo & RBC Borealis AI
NIPS,2018,Monte-Carlo Tree Search for Constrained POMDPs,Kee-Eung Kim,KAIST
NIPS,2018,GILBO: One Metric to Measure Them All,Alex Alemi,Google
NIPS,2018,GILBO: One Metric to Measure Them All,Ian Fischer,Google
NIPS,2018,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses,Corinna Cortes,Google Research
NIPS,2018,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses,Vitaly Kuznetsov,Google
NIPS,2018,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses,Mehryar Mohri,Courant Inst. of Math. Sciences & Google Research
NIPS,2018,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses,Dmitry Storcheus,Google Research
NIPS,2018,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses,Scott Yang,D. E. Shaw & Co.
NIPS,2018,Unsupervised Learning of Artistic Styles with Archetypal Style Analysis,Daan Wynen,INRIA
NIPS,2018,Unsupervised Learning of Artistic Styles with Archetypal Style Analysis,Cordelia Schmid,Inria / Google
NIPS,2018,Unsupervised Learning of Artistic Styles with Archetypal Style Analysis,Julien Mairal,Inria
NIPS,2018,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient,Aaron Mishkin,University of British Columbia
NIPS,2018,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient,Frederik Kunstner,EPFL
NIPS,2018,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient,Didrik Nielsen,DTU Compute
NIPS,2018,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient,Mark Schmidt,University of British Columbia
NIPS,2018,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient,Emtiyaz Khan,"RIKEN, Tokyo"
NIPS,2018,The Convergence of Sparsified Gradient Methods,Dan Alistarh,IST Austria
NIPS,2018,The Convergence of Sparsified Gradient Methods,Torsten Hoefler,ETH Zurich
NIPS,2018,The Convergence of Sparsified Gradient Methods,Mikael Johansson,KTH - Royal Institute of Technology
NIPS,2018,The Convergence of Sparsified Gradient Methods,Nikola Konstantinov,IST Austria
NIPS,2018,The Convergence of Sparsified Gradient Methods,Sarit Khirirat,KTH Royal Institute of Technology
NIPS,2018,The Convergence of Sparsified Gradient Methods,Cedric Renggli,ETH Zurich
NIPS,2018,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance,Giulia Luise,University College London
NIPS,2018,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance,Alessandro Rudi,"INRIA, Ecole Normale Superieure"
NIPS,2018,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance,Massimiliano Pontil,IIT & UCL
NIPS,2018,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance,Carlo Ciliberto,Imperial College London
NIPS,2018,Scalable Robust Matrix Factorization with Nonconvex Loss,Quanming Yao,4Paradigm
NIPS,2018,Scalable Robust Matrix Factorization with Nonconvex Loss,James Kwok,Hong Kong University of Science and Technology
NIPS,2018,Lifelong Inverse Reinforcement Learning,Jorge Armando Mendez Mendez,University of Pennsylvania
NIPS,2018,Lifelong Inverse Reinforcement Learning,Shashank Shivkumar,University of Pennsylvania
NIPS,2018,Lifelong Inverse Reinforcement Learning,Eric Eaton,University of Pennsylvania
NIPS,2018,Flexible and accurate inference and learning for deep generative models,Eszter Vértes,"Gatsby Unit, UCL"
NIPS,2018,Flexible and accurate inference and learning for deep generative models,Maneesh Sahani,"Gatsby Unit, UCL"
NIPS,2018,A Bandit Approach to Sequential Experimental Design with False Discovery Control,Kevin Jamieson,U Washington
NIPS,2018,A Bandit Approach to Sequential Experimental Design with False Discovery Control,Lalit Jain,University of Washington
NIPS,2018,Moonshine: Distilling with Cheap Convolutions,Elliot J. Crowley,University of Edinburgh
NIPS,2018,Moonshine: Distilling with Cheap Convolutions,Gavin Gray,University of Edinburgh
NIPS,2018,Moonshine: Distilling with Cheap Convolutions,Amos Storkey,University of Edinburgh
NIPS,2018,Smoothed analysis of the low-rank approach for smooth semidefinite programs,Thomas Pumir,Princeton University
NIPS,2018,Smoothed analysis of the low-rank approach for smooth semidefinite programs,Samy Jelassi,Princeton University
NIPS,2018,Smoothed analysis of the low-rank approach for smooth semidefinite programs,Nicolas Boumal,Princeton
NIPS,2018,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search,Zhuwen Li,Intel Labs
NIPS,2018,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search,Qifeng Chen,HKUST
NIPS,2018,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search,Vladlen Koltun,Intel Labs
NIPS,2018,Structure-Aware Convolutional Neural Networks,Jianlong Chang,"National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences"
NIPS,2018,Structure-Aware Convolutional Neural Networks,Jie Gu,"National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences"
NIPS,2018,Structure-Aware Convolutional Neural Networks,Lingfeng Wang,"Institute of Automation, Chinese Academy of Sciences"
NIPS,2018,Structure-Aware Convolutional Neural Networks,GAOFENG MENG,"Institute of Automation, Chinese Academy of Sciences"
NIPS,2018,Structure-Aware Convolutional Neural Networks,SHIMING XIANG,"Chinese Academy of Sciences, China"
NIPS,2018,Structure-Aware Convolutional Neural Networks,Chunhong Pan,"Institute of Automation, Chinese Academy of Sciences"
NIPS,2018,HOGWILD!-Gibbs can be PanAccurate,Constantinos Daskalakis,MIT
NIPS,2018,HOGWILD!-Gibbs can be PanAccurate,Nishanth Dikkala,MIT
NIPS,2018,HOGWILD!-Gibbs can be PanAccurate,Siddhartha Jayanti,MIT
NIPS,2018,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences,Jeremias Knoblauch,Warwick University
NIPS,2018,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences,Jack E Jewson,University of Warwick
NIPS,2018,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences,Theo Damoulas,University of Warwick        The Alan Turing Institute
NIPS,2018,Generalized Inverse Optimization through Online Learning,Chaosheng Dong,University of Pittsburgh
NIPS,2018,Generalized Inverse Optimization through Online Learning,Yiran Chen,Duke University
NIPS,2018,Generalized Inverse Optimization through Online Learning,Bo Zeng,pitt
NIPS,2018,Supervised autoencoders: Improving generalization performance with unsupervised regularizers,Lei Le,Indiana University Bloomington
NIPS,2018,Supervised autoencoders: Improving generalization performance with unsupervised regularizers,Andy Patterson,University of Alberta
NIPS,2018,Supervised autoencoders: Improving generalization performance with unsupervised regularizers,Martha White,University of Alberta
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Jun-Yan Zhu,MIT
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Zhoutong Zhang,MIT
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Chengkai Zhang,Massachusetts Institute of Technology
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Jiajun Wu,MIT
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Antonio Torralba,MIT
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Josh Tenenbaum,MIT
NIPS,2018,Visual Object Networks: Image Generation with Disentangled 3D Representations,Bill Freeman,MIT/Google
NIPS,2018,Understanding Weight Normalized Deep Neural Networks with Rectified Linear Units,Yixi Xu,Purdue University
NIPS,2018,Understanding Weight Normalized Deep Neural Networks with Rectified Linear Units,Xiao Wang,Purdue University
NIPS,2018,Learning long-range spatial dependencies with horizontal gated recurrent units,Drew Linsley,Brown University
NIPS,2018,Learning long-range spatial dependencies with horizontal gated recurrent units,Junkyung Kim,Brown University
NIPS,2018,Learning long-range spatial dependencies with horizontal gated recurrent units,Vijay Veerabadran,"University of California, San Diego"
NIPS,2018,Learning long-range spatial dependencies with horizontal gated recurrent units,Charles Windolf,Brown University
NIPS,2018,Learning long-range spatial dependencies with horizontal gated recurrent units,Thomas Serre,Brown University
NIPS,2018,Learning Deep Disentangled Embeddings With the F-Statistic Loss,Karl Ridgeway,"University of Colorado, Boulder"
NIPS,2018,Learning Deep Disentangled Embeddings With the F-Statistic Loss,Mike Mozer,Google Brain / U. Colorado
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,Mark Rowland,University of Cambridge
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,Krzysztof Choromanski,Google Brain Robotics
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,François Chalus,Credit Suisse & University of Cambridge
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,Aldo Pacchiano,UC Berkeley
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,Tamas Sarlos,Google Research
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,Richard E Turner,University of Cambridge
NIPS,2018,Geometrically Coupled Monte Carlo Sampling,Adrian Weller,University of Cambridge
NIPS,2018,An Efficient Pruning Algorithm for Robust Isotonic Regression,Cong Han Lim,Georgia Tech
NIPS,2018,Sparse DNNs with Improved Adversarial Robustness,Yiwen Guo,Intel Labs China
NIPS,2018,Sparse DNNs with Improved Adversarial Robustness,Chao Zhang,Peking University
NIPS,2018,Sparse DNNs with Improved Adversarial Robustness,Changshui Zhang,Tsinghua University
NIPS,2018,Sparse DNNs with Improved Adversarial Robustness,Yurong Chen,Intel Labs China
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,Shice Liu,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,YU HU,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,Yiming Zeng,Institute of Computing Technology Chinese Academy of Sciences
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,Qiankun Tang,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,Beibei Jin,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,Yinhe Han,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2018,See and Think: Disentangling Semantic Scene Completion,Xiaowei Li,"Institute of Computing Technology, Chinese Academy of Sciences"
NIPS,2018,Chain of Reasoning for Visual Question Answering,Chenfei Wu,Beijing University of Posts and Telecommunications
NIPS,2018,Chain of Reasoning for Visual Question Answering,Jinlai Liu,Beijing University of Posts and Telecommunications
NIPS,2018,Chain of Reasoning for Visual Question Answering,Xiaojie Wang,The University of Melbourne
NIPS,2018,Chain of Reasoning for Visual Question Answering,Xuan Dong,Beijing University of Posts and Telecommunications
NIPS,2018,Sigsoftmax: Reanalysis of the Softmax Bottleneck,Sekitoshi Kanai,"NTT, Keio University"
NIPS,2018,Sigsoftmax: Reanalysis of the Softmax Bottleneck,Yasuhiro Fujiwara,NTT Software Innovation Center
NIPS,2018,Sigsoftmax: Reanalysis of the Softmax Bottleneck,Yuki Yamanaka,NTT Secure Platform Laboratories
NIPS,2018,Sigsoftmax: Reanalysis of the Softmax Bottleneck,Shuichi Adachi,Keio University
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Wenqi Ren,Chinese Academy of Sciences
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Jiawei Zhang,Sensetime Research
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Lin Ma,Tencent AI Lab
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Jinshan Pan,Nanjing University of Science and Technology
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Xiaochun Cao,Chinese Academy of Sciences
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Wangmeng Zuo,Harbin Institute of Technology
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Wei Liu,Tencent AI Lab
NIPS,2018,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation,Ming-Hsuan Yang,UC Merced / Google
NIPS,2018,MetaAnchor: Learning to Detect Objects with Customized Anchors,Tong Yang,"Megvii(Face++),Fudan University"
NIPS,2018,MetaAnchor: Learning to Detect Objects with Customized Anchors,Xiangyu Zhang,Purdue University
NIPS,2018,MetaAnchor: Learning to Detect Objects with Customized Anchors,Zeming Li,Megvii(Face++) Inc
NIPS,2018,MetaAnchor: Learning to Detect Objects with Customized Anchors,Wenqiang Zhang,Fudan University
NIPS,2018,MetaAnchor: Learning to Detect Objects with Customized Anchors,Jian Sun,"Megvii, Face++"
NIPS,2018,Image Inpainting via Generative Multi-column Convolutional Neural Networks,Yi Wang,Chinese University of Hong Kong
NIPS,2018,Image Inpainting via Generative Multi-column Convolutional Neural Networks,Xin Tao,CUHK
NIPS,2018,Image Inpainting via Generative Multi-column Convolutional Neural Networks,Xiaojuan Qi,CUHK
NIPS,2018,Image Inpainting via Generative Multi-column Convolutional Neural Networks,Xiaoyong Shen,CUHK
NIPS,2018,Image Inpainting via Generative Multi-column Convolutional Neural Networks,Jiaya Jia,CUHK
NIPS,2018,A^2-Nets: Double Attention Networks,Yunpeng Chen,National University of Singapore
NIPS,2018,A^2-Nets: Double Attention Networks,Yannis Kalantidis,Facebook
NIPS,2018,A^2-Nets: Double Attention Networks,Jianshu Li,National University of Singapore
NIPS,2018,A^2-Nets: Double Attention Networks,Shuicheng Yan,National University of Singapore
NIPS,2018,A^2-Nets: Double Attention Networks,Jiashi Feng,National University of Singapore
NIPS,2018,How Many Samples are Needed to Learn a Convolutional Neural Network?,Simon Du,Carnegie Mellon University
NIPS,2018,How Many Samples are Needed to Learn a Convolutional Neural Network?,Yining Wang,CMU
NIPS,2018,How Many Samples are Needed to Learn a Convolutional Neural Network?,Xiyu Zhai,MIT
NIPS,2018,How Many Samples are Needed to Learn a Convolutional Neural Network?,Sivaraman Balakrishnan,Carnegie Mellon University
NIPS,2018,How Many Samples are Needed to Learn a Convolutional Neural Network?,Russ Salakhutdinov,Carnegie Mellon University
NIPS,2018,How Many Samples are Needed to Learn a Convolutional Neural Network?,Aarti Singh,CMU
NIPS,2018,Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced,Simon Du,Carnegie Mellon University
NIPS,2018,Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced,Wei Hu,Princeton University
NIPS,2018,Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced,Jason Lee,University of Southern California
NIPS,2018,Optimization for Approximate Submodularity,Yaron Singer,Harvard University
NIPS,2018,Optimization for Approximate Submodularity,Avinatan Hassidim,Bar Ilan University
NIPS,2018,(Probably) Concave Graph Matching,Haggai Maron,Weizmann Institute of Science
NIPS,2018,(Probably) Concave Graph Matching,Yaron Lipman,Weizmann Institute of Science
NIPS,2018,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes,Junqi Tang,University of Edinburgh
NIPS,2018,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes,Mohammad Golbabaee,University of Bath
NIPS,2018,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes,Mike E davies,University of Edinburgh
NIPS,2018,A Model for Learned Bloom Filters and Optimizing by Sandwiching,Michael Mitzenmacher,Harvard University
NIPS,2018,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis,Haoye Dong,Sun Yat-sen University
NIPS,2018,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis,Xiaodan Liang,Sun Yat-sen University
NIPS,2018,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis,Ke Gong,Sun Yat-sen University
NIPS,2018,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis,Hanjiang Lai,Sun Yat-Sen university
NIPS,2018,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis,Jia Zhu,South China Normal University
NIPS,2018,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis,Jian Yin,Sun Yat-Sen University
NIPS,2018,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions,Minhyuk Sung,Stanford University
NIPS,2018,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions,Hao Su,UCSD
NIPS,2018,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions,Ronald Yu,UCSD
NIPS,2018,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions,Leonidas J Guibas,stanford.edu
NIPS,2018,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling",Yunzhe Tao,Columbia University
NIPS,2018,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling",Qi Sun,CSRC & USTC & CU
NIPS,2018,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling",Qiang Du,Columbia University
NIPS,2018,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling",Wei Liu,Tencent AI Lab
NIPS,2018,Learning to Decompose and Disentangle Representations for Video Prediction,Jun-Ting Hsieh,Stanford University
NIPS,2018,Learning to Decompose and Disentangle Representations for Video Prediction,Bingbin Liu,Stanford University
NIPS,2018,Learning to Decompose and Disentangle Representations for Video Prediction,De-An Huang,Stanford University
NIPS,2018,Learning to Decompose and Disentangle Representations for Video Prediction,Li Fei-Fei,Stanford University & Google
NIPS,2018,Learning to Decompose and Disentangle Representations for Video Prediction,Juan Carlos Niebles,Stanford University
NIPS,2018,Multi-Task Learning as Multi-Objective Optimization,Ozan Sener,Intel Labs
NIPS,2018,Multi-Task Learning as Multi-Objective Optimization,Vladlen Koltun,Intel Labs
NIPS,2018,Self-Handicapping Network for Integral Object Attention,Andrew Hou,Nankai University
NIPS,2018,Self-Handicapping Network for Integral Object Attention,PengTao Jiang,Nankai University
NIPS,2018,Self-Handicapping Network for Integral Object Attention,Yunchao Wei,UIUC
NIPS,2018,Self-Handicapping Network for Integral Object Attention,Ming-Ming Cheng,Nankai University
NIPS,2018,LinkNet: Relational Embedding for Scene Graph,Sanghyun Woo,KAIST
NIPS,2018,LinkNet: Relational Embedding for Scene Graph,Dahun Kim,KAIST
NIPS,2018,LinkNet: Relational Embedding for Scene Graph,Donghyeon Cho,KAIST
NIPS,2018,LinkNet: Relational Embedding for Scene Graph,In So Kweon,KAIST
NIPS,2018,BourGAN: Generative Networks with Metric Embeddings,Chang Xiao,Columbia University
NIPS,2018,BourGAN: Generative Networks with Metric Embeddings,Peilin Zhong,Columbia University
NIPS,2018,BourGAN: Generative Networks with Metric Embeddings,Changxi Zheng,Columbia University
NIPS,2018,Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate,Mikhail Belkin,Ohio State University
NIPS,2018,Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate,Daniel Hsu,Columbia University
NIPS,2018,Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate,Partha Mitra,Cold Spring Harbor Laboratory
NIPS,2018,Non-monotone Submodular Maximization in Exponentially Fewer Iterations,Eric Balkanski,Harvard University
NIPS,2018,Non-monotone Submodular Maximization in Exponentially Fewer Iterations,Adam Breuer,Harvard University
NIPS,2018,Non-monotone Submodular Maximization in Exponentially Fewer Iterations,Yaron Singer,Harvard University
NIPS,2018,MetaGAN: An Adversarial Approach to Few-Shot Learning,Ruixiang ZHANG,MILA
NIPS,2018,MetaGAN: An Adversarial Approach to Few-Shot Learning,Tong Che,MILA
NIPS,2018,MetaGAN: An Adversarial Approach to Few-Shot Learning,Zoubin Ghahramani,Uber and University of Cambridge
NIPS,2018,MetaGAN: An Adversarial Approach to Few-Shot Learning,Yoshua Bengio,U. Montreal
NIPS,2018,MetaGAN: An Adversarial Approach to Few-Shot Learning,Yangqiu Song,Hong Kong University of Science and Technology
NIPS,2018,Gaussian Process Conditional Density Estimation,Vincent Dutordoir,PROWLER.io
NIPS,2018,Gaussian Process Conditional Density Estimation,Hugh Salimbeni,Imperial College London
NIPS,2018,Gaussian Process Conditional Density Estimation,James Hensman,PROWLER.io
NIPS,2018,Gaussian Process Conditional Density Estimation,Marc Deisenroth,Imperial College London
NIPS,2018,Modular Networks: Learning to Decompose Neural Computation,Louis Kirsch,University College London & IDSIA
NIPS,2018,Modular Networks: Learning to Decompose Neural Computation,Julius Kunze,University College London
NIPS,2018,Modular Networks: Learning to Decompose Neural Computation,David Barber,University College London
NIPS,2018,Recurrent World Models Facilitate Policy Evolution,David Ha,Google Brain
NIPS,2018,Recurrent World Models Facilitate Policy Evolution,Jürgen Schmidhuber,"Swiss AI Lab, IDSIA (USI & SUPSI) - NNAISENSE"
NIPS,2018,Ridge Regression and Provable Deterministic Ridge Leverage Score Sampling,Shannon McCurdy,Ancestry
NIPS,2018,Wasserstein Variational Inference,Luca Ambrogioni,Donders Institute
NIPS,2018,Wasserstein Variational Inference,Umut Güçlü,"Donders Institute for Brain, Cognition and Behaviour, Radboud University"
NIPS,2018,Wasserstein Variational Inference,Yağmur Güçlütürk,"Donders Institute for Brain, Cognition and Behaviour, Radboud University"
NIPS,2018,Wasserstein Variational Inference,Max Hinne,University of Amsterdam
NIPS,2018,Wasserstein Variational Inference,Marcel A. J. van Gerven,Radboud Universiteit
NIPS,2018,Wasserstein Variational Inference,Eric Maris,Donders Institute
NIPS,2018,"How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",Shibani Santurkar,MIT
NIPS,2018,"How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",Dimitris Tsipras,MIT
NIPS,2018,"How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",Andrew Ilyas,MIT
NIPS,2018,"How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",Aleksander Madry,MIT
NIPS,2018,Leveraged volume sampling for linear regression,Michal Derezinski,UC Berkeley
NIPS,2018,Leveraged volume sampling for linear regression,Manfred Warmuth,Univ. of Calif. at Santa Cruz
NIPS,2018,Leveraged volume sampling for linear regression,Daniel Hsu,Columbia University
NIPS,2018,Supervised Local Modeling for Interpretability,Gregory Plumb,CMU
NIPS,2018,Supervised Local Modeling for Interpretability,Denali Molitor,"University of California, Los Angeles"
NIPS,2018,Supervised Local Modeling for Interpretability,Ameet Talwalkar,CMU
NIPS,2018,Tree-to-tree Neural Networks for Program Translation,Xinyun Chen,UC Berkeley
NIPS,2018,Tree-to-tree Neural Networks for Program Translation,Chang Liu,Citadel
NIPS,2018,Tree-to-tree Neural Networks for Program Translation,Dawn Song,UC Berkeley
NIPS,2018,Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog,Sang-Woo Lee,Naver Corp.
NIPS,2018,Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog,Yu-Jung Heo,Seoul National University
NIPS,2018,Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog,Byoung-Tak Zhang,Seoul National University & Surromind Robotics
NIPS,2018,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation,Alexander H. Liu,National Taiwan University
NIPS,2018,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation,Yen-Cheng Liu,Georgia Tech
NIPS,2018,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation,Yu-Ying Yeh,"University of California, San Diego"
NIPS,2018,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation,Yu-Chiang Frank Wang,National Taiwan University
NIPS,2018,Isolating Sources of Disentanglement in Variational Autoencoders,Ricky Chen,University of Toronto
NIPS,2018,Isolating Sources of Disentanglement in Variational Autoencoders,Xuechen Li,University of Toronto
NIPS,2018,Isolating Sources of Disentanglement in Variational Autoencoders,Roger Grosse,University of Toronto
NIPS,2018,Isolating Sources of Disentanglement in Variational Autoencoders,David Duvenaud,University of Toronto
NIPS,2018,Contextual bandits with surrogate losses: Margin bounds and efficient algorithms,Dylan Foster,Cornell University
NIPS,2018,Contextual bandits with surrogate losses: Margin bounds and efficient algorithms,Akshay Krishnamurthy,Microsoft
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Yao Liu,Stanford University
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Omer Gottesman,Harvard University
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Aniruddh Raghu,Massachusetts Institute of Technology
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Matthieu Komorowski,Imperial College London / MIT
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Aldo A Faisal,Imperial College London
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Finale Doshi-Velez,Harvard
NIPS,2018,Representation Balancing MDPs for Off-policy Policy Evaluation,Emma Brunskill,Stanford University
NIPS,2018,Causal Inference on Discrete Data using Hidden Compact Representation,Ruichu Cai,Guangdong University of Technology
NIPS,2018,Causal Inference on Discrete Data using Hidden Compact Representation,Jie Qiao,Guangdong University of Technology
NIPS,2018,Causal Inference on Discrete Data using Hidden Compact Representation,Kun Zhang,CMU
NIPS,2018,Causal Inference on Discrete Data using Hidden Compact Representation,Zhenjie Zhang,"Singapore R&D, Yitu Technology Ltd.,"
NIPS,2018,Causal Inference on Discrete Data using Hidden Compact Representation,Zhifeng Hao,Guangdong University of Technology
NIPS,2018,Natasha 2: Faster Non-Convex Optimization Than SGD,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2018,Provable Variational Inference for Constrained Log-Submodular Models,Josip Djolonga,Google Brain
NIPS,2018,Provable Variational Inference for Constrained Log-Submodular Models,Stefanie Jegelka,MIT
NIPS,2018,Provable Variational Inference for Constrained Log-Submodular Models,Andreas Krause,ETHZ
NIPS,2018,Processing of missing data by neural networks,Marek Śmieja,Jagiellonian University
NIPS,2018,Processing of missing data by neural networks,Łukasz Struski,Jagiellonian University
NIPS,2018,Processing of missing data by neural networks,Jacek Tabor,Jagiellonian University
NIPS,2018,Processing of missing data by neural networks,Bartosz Zieliński,Jagiellonian University
NIPS,2018,Processing of missing data by neural networks,Przemysław Spurek,Jagiellonian University
NIPS,2018,Safe Active Learning for Time-Series Modeling with Gaussian Processes,Christoph Zimmer,Bosch Center for Artificial Intelligence
NIPS,2018,Safe Active Learning for Time-Series Modeling with Gaussian Processes,Mona Meister,Robert Bosch GmbH
NIPS,2018,Safe Active Learning for Time-Series Modeling with Gaussian Processes,Duy Nguyen-Tuong,Bosch Center for AI
NIPS,2018,Computing Higher Order Derivatives of Matrix and Tensor Expressions,Soeren Laue,Universitaet Jena
NIPS,2018,Computing Higher Order Derivatives of Matrix and Tensor Expressions,Matthias Mitterreiter,Friedrich Schiller University Jena
NIPS,2018,Computing Higher Order Derivatives of Matrix and Tensor Expressions,Joachim Giesen,Friedrich-Schiller-Universitat Jena
NIPS,2018,Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation,Chaitanya Ryali,UC San Diego
NIPS,2018,Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation,Gautam Reddy,"University of California, San Diego"
NIPS,2018,Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation,Angela J Yu,UC San Diego
NIPS,2018,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach,Xiaohan Wei,USC
NIPS,2018,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach,Hao Yu,Alibaba Group (US) Inc
NIPS,2018,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach,Qing Ling,Sun Yat-Sen University
NIPS,2018,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach,Michael Neely,USC
NIPS,2018,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks,Joshua Fromm,University of Washington
NIPS,2018,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks,Shwetak Patel,University of Washington
NIPS,2018,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks,Matthai Philipose,Microsoft Research
NIPS,2018,Unsupervised Learning of Object Landmarks through Conditional Image Generation,Tomas Jakab,University of Oxford
NIPS,2018,Unsupervised Learning of Object Landmarks through Conditional Image Generation,Ankush Gupta,University of Oxford
NIPS,2018,Unsupervised Learning of Object Landmarks through Conditional Image Generation,Hakan Bilen,University of Edinburgh
NIPS,2018,Unsupervised Learning of Object Landmarks through Conditional Image Generation,Andrea Vedaldi,University of Oxford and Facebook
NIPS,2018,The streaming rollout of deep networks - towards fully model-parallel execution,Volker Fischer,"Robert Bosch GmbH, Bosch Center for Artificial Intelligence"
NIPS,2018,The streaming rollout of deep networks - towards fully model-parallel execution,Jan Koehler,Robert Bosch GmbH
NIPS,2018,The streaming rollout of deep networks - towards fully model-parallel execution,Thomas Pfeil,Robert Bosch GmbH
NIPS,2018,KONG: Kernels for ordered-neighborhood graphs,Moez Draief,"Noah's Ark Labs, Huawei Research"
NIPS,2018,KONG: Kernels for ordered-neighborhood graphs,Konstantin Kutzkov,London School of Economics
NIPS,2018,KONG: Kernels for ordered-neighborhood graphs,Kevin Scaman,"Noah's Ark Lab, Huawei Technologies"
NIPS,2018,KONG: Kernels for ordered-neighborhood graphs,Milan Vojnovic,London School of Economics (LSE)
NIPS,2018,GumBolt: Extending Gumbel trick to Boltzmann priors,Amir Khoshaman,D-Wave Systems Inc
NIPS,2018,GumBolt: Extending Gumbel trick to Boltzmann priors,Mohammad Amin,D-Wave Systems Inc
NIPS,2018,Neural Networks Trained to Solve Differential Equations Learn General Representations,Martin Magill,University of Ontario Institute of Technology
NIPS,2018,Neural Networks Trained to Solve Differential Equations Learn General Representations,Faisal Qureshi,"University of Ontario Institute of Technology, Canada"
NIPS,2018,Neural Networks Trained to Solve Differential Equations Learn General Representations,Hendrick de Haan,University of Ontario Institute of Technology
NIPS,2018,Beauty-in-averageness and its contextual modulations: A Bayesian statistical account,Chaitanya Ryali,UC San Diego
NIPS,2018,Beauty-in-averageness and its contextual modulations: A Bayesian statistical account,Angela J Yu,UC San Diego
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Patrick McClure,NIH
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Charles Zheng,National Institute of Mental Health
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Jakub Kaczmarzyk,MIT
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,John Rogers-Lee,NIMH
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Satra Ghosh,MIT
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Dylan Nielson,NIMH
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Peter A Bandettini,National Institute of Mental Health
NIPS,2018,Distributed Weight Consolidation: A Brain Segmentation Case Study,Francisco Pereira,National Institute of Mental Health
NIPS,2018,Efficient Projection onto the Perfect Phylogeny Model,Bei Jia,ITG
NIPS,2018,Efficient Projection onto the Perfect Phylogeny Model,Surjyendu Ray,Boston College
NIPS,2018,Efficient Projection onto the Perfect Phylogeny Model,Sam Safavi,Boston College
NIPS,2018,Efficient Projection onto the Perfect Phylogeny Model,José Bento,Boston College
NIPS,2018,TETRIS: TilE-matching the TRemendous Irregular Sparsity,Yu Ji,Tsinghua University
NIPS,2018,TETRIS: TilE-matching the TRemendous Irregular Sparsity,Ling Liang,UCSB
NIPS,2018,TETRIS: TilE-matching the TRemendous Irregular Sparsity,Lei Deng,"University of California, Santa Barbara"
NIPS,2018,TETRIS: TilE-matching the TRemendous Irregular Sparsity,Youyang Zhang,Tsinghua University
NIPS,2018,TETRIS: TilE-matching the TRemendous Irregular Sparsity,Youhui Zhang,Tsinghua University
NIPS,2018,TETRIS: TilE-matching the TRemendous Irregular Sparsity,Yuan Xie,Chinese Academy of Sciences
NIPS,2018,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification,Harsh Shrivastava,Georgia Institute of Technology
NIPS,2018,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification,Eugene Bart,Palo Alto Research Center
NIPS,2018,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification,Bob Price,PARC
NIPS,2018,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification,Hanjun Dai,Georgia Tech
NIPS,2018,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification,Bo Dai,Google Brain
NIPS,2018,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification,Srinivas Aluru,Georgia Institute of Technology
NIPS,2018,Differentially Private Robust PCA,Raman Arora,Johns Hopkins University
NIPS,2018,Differentially Private Robust PCA,Vladimir braverman,Johns Hopkins University
NIPS,2018,Differentially Private Robust PCA,Jalaj Upadhyay,Johns Hopkins University
NIPS,2018,Meta-Learning MCMC Proposals,Tongzhou Wang,Facebook AI Research
NIPS,2018,Meta-Learning MCMC Proposals,YI WU,UC Berkeley
NIPS,2018,Meta-Learning MCMC Proposals,Dave Moore,Google
NIPS,2018,Meta-Learning MCMC Proposals,Stuart Russell,UC Berkeley
NIPS,2018,An Information-Theoretic Analysis of Thompson Sampling for Large Action Spaces,Shi Dong,Stanford University
NIPS,2018,An Information-Theoretic Analysis of Thompson Sampling for Large Action Spaces,Benjamin Van Roy,Stanford University
NIPS,2018,The Price of Privacy for Low-rank Factorization,Jalaj Upadhyay,Johns Hopkins University
NIPS,2018,Differentially Private Uniformly Most Powerful Tests for Binomial Data,Jordan Awan,Penn State University
NIPS,2018,Differentially Private Uniformly Most Powerful Tests for Binomial Data,Aleksandra Slavković,Pennsylvania State University
NIPS,2018,Scalable Coordinated Exploration in Concurrent Reinforcement Learning,Maria Dimakopoulou,Stanford University
NIPS,2018,Scalable Coordinated Exploration in Concurrent Reinforcement Learning,Ian Osband,Google Deepmind
NIPS,2018,Scalable Coordinated Exploration in Concurrent Reinforcement Learning,Benjamin Van Roy,Stanford University
NIPS,2018,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models,Amir Dezfouli,"UNSW, Sydney"
NIPS,2018,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models,Richard Morris,U Sydney
NIPS,2018,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models,Fabio Ramos,University of Sydney
NIPS,2018,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models,Peter Dayan,"Gatsby Unit, UCL"
NIPS,2018,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models,Bernard Balleine,UNSW
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Songtao Wang,Tsinghua University
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Dan Li,Tsinghua University
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Yang Cheng,Tsinghua University
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Jinkun Geng,Tsinghua University
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Yanshu Wang,Tsinghua Univeristy
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Shuai Wang,Tsinghua University
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Shu-Tao Xia,Tsinghua University
NIPS,2018,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training",Jianping Wu,Tsinghua University
NIPS,2018,Inexact trust-region algorithm on Riemannian manifolds,Hiroyuki Kasai,UEC
NIPS,2018,Inexact trust-region algorithm on Riemannian manifolds,Bamdev Mishra,Microsoft
NIPS,2018,Can We Gain More from Orthogonality Regularizations in Training Deep Networks?,Nitin Bansal,Texas A&M University
NIPS,2018,Can We Gain More from Orthogonality Regularizations in Training Deep Networks?,Xiaohan Chen,Texas A&M University
NIPS,2018,Can We Gain More from Orthogonality Regularizations in Training Deep Networks?,Zhangyang Wang,TAMU
NIPS,2018,Binary Rating Estimation with Graph Side Information,Kwangjun Ahn,Korean Augmentation To the United States Army (KATUSA)
NIPS,2018,Binary Rating Estimation with Graph Side Information,Kangwook Lee,EE at KAIST
NIPS,2018,Binary Rating Estimation with Graph Side Information,Hyunseung Cha,Kakao Brain
NIPS,2018,Binary Rating Estimation with Graph Side Information,Changho Suh,KAIST
NIPS,2018,SimplE Embedding for Link Prediction in Knowledge Graphs,Seyed Mehran Kazemi,University of British Columbia
NIPS,2018,SimplE Embedding for Link Prediction in Knowledge Graphs,David Poole,University of British Columbia
NIPS,2018,Differentially Private Contextual Linear Bandits,Roshan Shariff,University of Alberta
NIPS,2018,Differentially Private Contextual Linear Bandits,Or Sheffet,University of Alberta
NIPS,2018,"Submodular Field Grammars: Representation, Inference, and Application to Image Parsing",Abe L Friesen,University of Washington
NIPS,2018,"Submodular Field Grammars: Representation, Inference, and Application to Image Parsing",Pedro Domingos,University of Washington
NIPS,2018,A Bridging Framework for Model Optimization and Deep Propagation,Risheng Liu,Dalian University of Technology
NIPS,2018,A Bridging Framework for Model Optimization and Deep Propagation,Shichao Cheng,Dalian University of Technology
NIPS,2018,A Bridging Framework for Model Optimization and Deep Propagation,xiaokun liu,DUT
NIPS,2018,A Bridging Framework for Model Optimization and Deep Propagation,Long Ma,"School of Software Technology, Dalian University of Technology"
NIPS,2018,A Bridging Framework for Model Optimization and Deep Propagation,Xin Fan,Dalian University of Technology
NIPS,2018,A Bridging Framework for Model Optimization and Deep Propagation,Zhongxuan Luo,DALIAN UNIVERSITY OF TECHNOLOGY
NIPS,2018,Completing State Representations using Spectral Learning,Nan Jiang,University of Illinois at Urbana-Champaign
NIPS,2018,Completing State Representations using Spectral Learning,Alex Kulesza,Google
NIPS,2018,Completing State Representations using Spectral Learning,Satinder Singh,University of Michigan
NIPS,2018,Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates,Yining Wang,CMU
NIPS,2018,Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates,Sivaraman Balakrishnan,Carnegie Mellon University
NIPS,2018,Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates,Aarti Singh,CMU
NIPS,2018,Adding One Neuron Can Eliminate All Bad Local Minima,SHIYU LIANG,UIUC
NIPS,2018,Adding One Neuron Can Eliminate All Bad Local Minima,Ruoyu Sun,University of Illinois at Urbana-Champaign
NIPS,2018,Adding One Neuron Can Eliminate All Bad Local Minima,Jason Lee,University of Southern California
NIPS,2018,Adding One Neuron Can Eliminate All Bad Local Minima,R. Srikant,University of Illinois at Urbana-Champaign
NIPS,2018,Mean-field theory of graph neural networks in graph partitioning,Tatsuro Kawamoto,National Institute of Advanced Industrial Science and Technology
NIPS,2018,Mean-field theory of graph neural networks in graph partitioning,Masashi Tsubaki,National Institute of Advanced Industrial Science and Technology (AIST)
NIPS,2018,Mean-field theory of graph neural networks in graph partitioning,Tomoyuki Obuchi,Tokyo Institute of Technology
NIPS,2018,The Physical Systems Behind Optimization Algorithms,Lin Yang,Princeton University
NIPS,2018,The Physical Systems Behind Optimization Algorithms,Raman Arora,Johns Hopkins University
NIPS,2018,The Physical Systems Behind Optimization Algorithms,Vladimir braverman,Johns Hopkins University
NIPS,2018,The Physical Systems Behind Optimization Algorithms,Tuo Zhao,Georgia Tech
NIPS,2018,Top-k lists: Models and Algorithms,Flavio Chierichetti,Sapienza University
NIPS,2018,Top-k lists: Models and Algorithms,Anirban Dasgupta,IIT Gandhinagar
NIPS,2018,Top-k lists: Models and Algorithms,Shahrzad Haddadan,"Sapienza University, Rome, Italy"
NIPS,2018,Top-k lists: Models and Algorithms,Ravi Kumar,Google
NIPS,2018,Top-k lists: Models and Algorithms,Silvio Lattanzi,Google Research
NIPS,2018,Maximum Causal Tsallis Entropy Imitation Learning,Kyungjae Lee,Seoul National University
NIPS,2018,Maximum Causal Tsallis Entropy Imitation Learning,Sungjoon Choi,Disney Research
NIPS,2018,Maximum Causal Tsallis Entropy Imitation Learning,Songhwai Oh,Seoul National University
NIPS,2018,Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives,Song Zhou,Cornell University
NIPS,2018,Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives,Swati Gupta,Georgia Institute of Technology
NIPS,2018,Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives,Madeleine Udell,Cornell University
NIPS,2018,Semi-Supervised Learning with Declaratively Specified Entropy Constraints,Haitian Sun,Carnegie Mellon University
NIPS,2018,Semi-Supervised Learning with Declaratively Specified Entropy Constraints,William Cohen,Google AI
NIPS,2018,Semi-Supervised Learning with Declaratively Specified Entropy Constraints,Lidong Bing,Tencent AI Lab
NIPS,2018,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,Linfeng Zhang,Princeton University
NIPS,2018,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,Jiequn Han,Princeton University
NIPS,2018,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,Han Wang,Institute of Applied Physics and Computational Mathematics
NIPS,2018,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,Wissam  Saidi,University of Pittsburgh
NIPS,2018,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,Roberto Car,Princeton University
NIPS,2018,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,Weinan E,Princeton University
NIPS,2018,Sparsified SGD with Memory,Sebastian Stich,EPFL
NIPS,2018,Sparsified SGD with Memory,Jean-Baptiste Cordonnier,EPFL
NIPS,2018,Sparsified SGD with Memory,Martin Jaggi,EPFL
NIPS,2018,Exponentiated Strongly Rayleigh Distributions,Zelda Mariet,MIT
NIPS,2018,Exponentiated Strongly Rayleigh Distributions,Suvrit Sra,MIT
NIPS,2018,Exponentiated Strongly Rayleigh Distributions,Stefanie Jegelka,MIT
NIPS,2018,Importance Weighting and Varational Inference,Justin Domke,"University of Massachusetts, Amherst"
NIPS,2018,Importance Weighting and Varational Inference,Dan Sheldon,University of Massachusetts Amherst
NIPS,2018,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,Ye Jia,Google
NIPS,2018,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,Yu Zhang,
NIPS,2018,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,Ron Weiss,"Google, Inc."
NIPS,2018,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,Jonathan Shen,Google
NIPS,2018,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,Yonghui Wu,Google
NIPS,2018,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,ZF Chen,Google Brain
NIPS,2018,COLA: Decentralized Linear Learning,Lie He,EPFL
NIPS,2018,COLA: Decentralized Linear Learning,An Bian,ETH Zurich
NIPS,2018,COLA: Decentralized Linear Learning,Martin Jaggi,EPFL
NIPS,2018,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare,Edward Choi,Georgia Institute of Technology
NIPS,2018,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare,Cao Xiao,IBM Research
NIPS,2018,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare,Walter  Stewart,No Affiliation
NIPS,2018,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare,Jimeng Sun,Georgia Tech
NIPS,2018,Adaptive Sampling Towards Fast Graph Representation Learning,Wenbing Huang,Tencent AI Lab
NIPS,2018,Adaptive Sampling Towards Fast Graph Representation Learning,Tong Zhang,The Australian National University
NIPS,2018,Adaptive Sampling Towards Fast Graph Representation Learning,Yu Rong,Tencent AI Lab
NIPS,2018,Adaptive Sampling Towards Fast Graph Representation Learning,Junzhou Huang,University of Texas at Arlington / Tencent AI Lab
NIPS,2018,Hunting for Discriminatory Proxies in Linear Regression Models,Samuel Yeom,Carnegie Mellon University
NIPS,2018,Hunting for Discriminatory Proxies in Linear Regression Models,Anupam Datta,Carnegie Mellon University
NIPS,2018,Hunting for Discriminatory Proxies in Linear Regression Models,Matt Fredrikson,CMU
NIPS,2018,Towards Robust Detection of Adversarial Examples,Tianyu Pang,Tsinghua University
NIPS,2018,Towards Robust Detection of Adversarial Examples,Chao Du,Tsinghua University
NIPS,2018,Towards Robust Detection of Adversarial Examples,Yinpeng Dong,Tsinghua University
NIPS,2018,Towards Robust Detection of Adversarial Examples,Jun Zhu,Tsinghua University
NIPS,2018,Active Matting,Xin Yang,Dalian University of Technology
NIPS,2018,Active Matting,Ke Xu,Dalian University of Technology;City University of Hong Kong
NIPS,2018,Active Matting,Shaozhe Chen,Dalian University of Technology
NIPS,2018,Active Matting,Shengfeng He,South China University of Technology
NIPS,2018,Active Matting,Baocai Yin Yin,Dalian University of Technology
NIPS,2018,Active Matting,Rynson Lau,City University of Hong Kong
NIPS,2018,Learning filter widths of spectral decompositions with wavelets,Haidar Khan,Rensselaer Polytechnic Institute
NIPS,2018,Learning filter widths of spectral decompositions with wavelets,Bulent Yener,Rensselaer Polytechnic Institute (RPI)
NIPS,2018,Optimal Byzantine-Resilient Stochastic Gradient Descent,Dan Alistarh,IST Austria
NIPS,2018,Optimal Byzantine-Resilient Stochastic Gradient Descent,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2018,Optimal Byzantine-Resilient Stochastic Gradient Descent,Jerry Li,Berkeley
NIPS,2018,PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits,Bianca Dumitrascu,Princeton University
NIPS,2018,PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits,Karen Feng,Princeton University
NIPS,2018,PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits,Barbara Engelhardt,Princeton University
NIPS,2018,On Learning Intrinsic Rewards for Policy Gradient Methods,Zeyu Zheng,University of Michigan
NIPS,2018,On Learning Intrinsic Rewards for Policy Gradient Methods,Junhyuk Oh,DeepMind
NIPS,2018,On Learning Intrinsic Rewards for Policy Gradient Methods,Satinder Singh,University of Michigan
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Liqun Chen,Duke University
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Shuyang Dai,Duke University
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Chenyang Tao,Duke University
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Haichao Zhang,Baidu Research
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Zhe Gan,Microsoft
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Dinghan Shen,Duke University
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Yizhe Zhang,Microsoft Research
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Guoyin Wang,Duke University
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Ruiyi Zhang,Duke University
NIPS,2018,Adversarial Text Generation via Feature-Mover's Distance,Lawrence Carin,Duke University
NIPS,2018,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions,Mingrui Liu,The University of Iowa
NIPS,2018,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions,Xiaoxuan Zhang,University of Iowa
NIPS,2018,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions,Lijun Zhang,Nanjing University (NJU)
NIPS,2018,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions,Jing Rong,Alibaba
NIPS,2018,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions,Tianbao Yang,The University of Iowa
NIPS,2018,Learning Bounds for Greedy Approximation with Multiple Explicit Feature Maps,Shahin Shahrampour,Texas A&M University
NIPS,2018,Learning Bounds for Greedy Approximation with Multiple Explicit Feature Maps,Vahid Tarokh,Duke University
NIPS,2018,A Mathematical Model For Optimal Decisions In A Representative Democracy,Malik Magdon-Ismail,Rensselaer
NIPS,2018,A Mathematical Model For Optimal Decisions In A Representative Democracy,Lirong Xia,RPI
NIPS,2018,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making,Nishant Desai,UC Berkeley
NIPS,2018,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making,Andrew Critch,UC Berkeley
NIPS,2018,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making,Stuart J Russell,UC Berkeley
NIPS,2018,Non-metric Similarity Graphs for Maximum Inner Product Search,Stanislav Morozov,Yandex
NIPS,2018,Non-metric Similarity Graphs for Maximum Inner Product Search,Artem Babenko,MIPT/Yandex
NIPS,2018,Recurrently Controlled Recurrent Networks,Yi Tay,Nanyang Technological University
NIPS,2018,Recurrently Controlled Recurrent Networks,Anh Tuan Luu,Institute for Infocomm Research
NIPS,2018,Recurrently Controlled Recurrent Networks,Siu Cheung Hui,Nanyang Technological University
NIPS,2018,Fast greedy algorithms for dictionary selection with generalized sparsity constraints,Kaito Fujii,university of Tokyo
NIPS,2018,Fast greedy algorithms for dictionary selection with generalized sparsity constraints,Tasuku Soma,University of Tokyo
NIPS,2018,Data-Efficient Model-based Reinforcement Learning with Deep Probabilistic Dynamics Models,Kurtland Chua,UC Berkeley
NIPS,2018,Data-Efficient Model-based Reinforcement Learning with Deep Probabilistic Dynamics Models,Roberto Calandra,UC Berkeley
NIPS,2018,Data-Efficient Model-based Reinforcement Learning with Deep Probabilistic Dynamics Models,Rowan McAllister,UC Berkeley
NIPS,2018,Data-Efficient Model-based Reinforcement Learning with Deep Probabilistic Dynamics Models,Sergey Levine,UC Berkeley
NIPS,2018,Context-dependent upper-confidence bounds for directed exploration,Raksha Kumaraswamy,University of Alberta
NIPS,2018,Context-dependent upper-confidence bounds for directed exploration,Matthew Schlegel,University of Alberta
NIPS,2018,Context-dependent upper-confidence bounds for directed exploration,Adam White,University of Alberta; DeepMind
NIPS,2018,Context-dependent upper-confidence bounds for directed exploration,Martha White,University of Alberta
NIPS,2018,A Unified View of Piecewise Linear Neural Network Verification,Rudy Bunel,Oxford University
NIPS,2018,A Unified View of Piecewise Linear Neural Network Verification,Ilker Turkaslan,University of Oxford
NIPS,2018,A Unified View of Piecewise Linear Neural Network Verification,Philip Torr,University of Oxford
NIPS,2018,A Unified View of Piecewise Linear Neural Network Verification,Pushmeet Kohli,DeepMind
NIPS,2018,A Unified View of Piecewise Linear Neural Network Verification,Pawan K Mudigonda,University of Oxford
NIPS,2018,Hierarchical Graph Representation Learning with Differentiable Pooling,Rex Ying,Stanford University
NIPS,2018,Hierarchical Graph Representation Learning with Differentiable Pooling,Jiaxuan You,Stanford University
NIPS,2018,Hierarchical Graph Representation Learning with Differentiable Pooling,Christopher Morris,TU Dortmund University
NIPS,2018,Hierarchical Graph Representation Learning with Differentiable Pooling,Xiang Ren,University of Southern California
NIPS,2018,Hierarchical Graph Representation Learning with Differentiable Pooling,Will Hamilton,McGill University / FAIR
NIPS,2018,Hierarchical Graph Representation Learning with Differentiable Pooling,Jure Leskovec,Stanford University and Pinterest
NIPS,2018,Non-Ergodic Alternating Proximal  Augmented Lagrangian Algorithms with Optimal Rates,Quoc Tran Dinh,"Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, North Carolina"
NIPS,2018,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces,Boyla Mainsah,Duke University
NIPS,2018,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces,Dmitry Kalika,Johns Hopkins Applied Physics Laboratory
NIPS,2018,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces,Leslie Collins,Duke University
NIPS,2018,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces,Siyuan Liu,Duke University
NIPS,2018,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces,Chandra  Throckmorton,Duke University
NIPS,2018,Porcupine Neural Networks: Approximating Neural Network Landscapes,Soheil Feizi,"University of Maryland, College Park"
NIPS,2018,Porcupine Neural Networks: Approximating Neural Network Landscapes,Hamid Javadi,Stanford University
NIPS,2018,Porcupine Neural Networks: Approximating Neural Network Landscapes,Jesse Zhang,Stanford University
NIPS,2018,Porcupine Neural Networks: Approximating Neural Network Landscapes,David Tse,Stanford University
NIPS,2018,Fairness Through Computationally-Bounded Awareness,Michael Kim,Stanford University
NIPS,2018,Fairness Through Computationally-Bounded Awareness,Omer Reingold,Stanford University
NIPS,2018,Fairness Through Computationally-Bounded Awareness,Guy Rothblum,Weizmann Institute of Science
NIPS,2018,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization,Mingrui Liu,The University of Iowa
NIPS,2018,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization,Zhe Li,The university of Iowa
NIPS,2018,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization,Xiaoyu Wang,NEC Labs America
NIPS,2018,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization,Jinfeng Yi,JD AI Research
NIPS,2018,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization,Tianbao Yang,The University of Iowa
NIPS,2018,Is Q-Learning Provably Efficient?,Chi Jin,"University of California, Berkeley"
NIPS,2018,Is Q-Learning Provably Efficient?,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2018,Is Q-Learning Provably Efficient?,Sebastien Bubeck,Microsoft Research
NIPS,2018,Is Q-Learning Provably Efficient?,Michael Jordan,UC Berkeley
NIPS,2018,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections",Xin Zhang,Massachusetts Institute of Technology
NIPS,2018,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections",Armando Solar-Lezama,MIT
NIPS,2018,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections",Rishabh Singh,Google Brain
NIPS,2018,Measures of distortion for machine learning,Leena Chennuru Vankadara,"Max Planck Institute for Intelligent Systems, Tuebingen"
NIPS,2018,Measures of distortion for machine learning,Ulrike von Luxburg,University of Tübingen
NIPS,2018,On the Local Minima of the Empirical Risk,Chi Jin,"University of California, Berkeley"
NIPS,2018,On the Local Minima of the Empirical Risk,Lydia T. Liu,"University of California, Berk"
NIPS,2018,On the Local Minima of the Empirical Risk,Rong Ge,Duke University
NIPS,2018,On the Local Minima of the Empirical Risk,Michael Jordan,UC Berkeley
NIPS,2018,Densely Connected Attention Propagation for Reading Comprehension,Yi Tay,Nanyang Technological University
NIPS,2018,Densely Connected Attention Propagation for Reading Comprehension,Anh Tuan Luu,Institute for Infocomm Research
NIPS,2018,Densely Connected Attention Propagation for Reading Comprehension,Siu Cheung Hui,Nanyang Technological University
NIPS,2018,Densely Connected Attention Propagation for Reading Comprehension,Jian Su,"I2R, Singapore"
NIPS,2018,Bandit Learning with Positive Externalities,Virag Shah,Stanford
NIPS,2018,Bandit Learning with Positive Externalities,Jose Blanchet,Stanford University
NIPS,2018,Bandit Learning with Positive Externalities,Ramesh  Johari,Stanford University
NIPS,2018,Learning Confidence Sets using Support Vector Machines,Wenbo Wang,Binghamton University
NIPS,2018,Learning Confidence Sets using Support Vector Machines,Xingye Qiao,Binghamton University
NIPS,2018,Efficient Neural Network Robustness Certification with General Activation Functions,Huan Zhang,UCLA
NIPS,2018,Efficient Neural Network Robustness Certification with General Activation Functions,Lily Weng,MIT
NIPS,2018,Efficient Neural Network Robustness Certification with General Activation Functions,Pin-Yu Chen,IBM Research AI
NIPS,2018,Efficient Neural Network Robustness Certification with General Activation Functions,Cho-Jui Hsieh,"UCLA, Google Research"
NIPS,2018,Efficient Neural Network Robustness Certification with General Activation Functions,Luca Daniel,MIT
NIPS,2018,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries,Zhewei Yao,UC Berkeley
NIPS,2018,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries,Amir Gholami,"University of California, Berkeley"
NIPS,2018,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries,Kurt Keutzer,"EECS, UC Berkeley"
NIPS,2018,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries,Michael W Mahoney,UC Berkeley
NIPS,2018,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries,Qi Lei,"Institute for Computational Engineering and Sciences, University of Texas at Austin"
NIPS,2018,Neural Edit Operations for Biological Sequences,Satoshi Koide,Toyota Central R&D Labs.
NIPS,2018,Neural Edit Operations for Biological Sequences,Keisuke Kawano,"Toyota Central R&D Labs., Inc"
NIPS,2018,Neural Edit Operations for Biological Sequences,Takuro Kutsuna,Toyota Central R&D Labs. Inc.
NIPS,2018,Objective and efficient inference for couplings in neuronal networks,Yu Terada,RIKEN
NIPS,2018,Objective and efficient inference for couplings in neuronal networks,Tomoyuki Obuchi,Tokyo Institute of Technology
NIPS,2018,Objective and efficient inference for couplings in neuronal networks,Takuya Isomura,RIKEN Brain Science Institute
NIPS,2018,Objective and efficient inference for couplings in neuronal networks,Yoshiyuki Kabashima,Tokyo Institute of Technology
NIPS,2018,Learning from Group Comparisons: Exploiting Higher Order Interactions,Yao Li,"University of California, Davis"
NIPS,2018,Learning from Group Comparisons: Exploiting Higher Order Interactions,Minhao Cheng,"University of California, Davis"
NIPS,2018,Learning from Group Comparisons: Exploiting Higher Order Interactions,Kevin Fujii,UC Davis Department of Statistics
NIPS,2018,Learning from Group Comparisons: Exploiting Higher Order Interactions,Fushing Hsieh,UC Davis Department of Statistics
NIPS,2018,Learning from Group Comparisons: Exploiting Higher Order Interactions,Cho-Jui Hsieh,"UCLA, Google Research"
NIPS,2018,Supervising Unsupervised Learning,Vikas Garg,MIT
NIPS,2018,Supervising Unsupervised Learning,Adam Kalai,Microsoft Research New England (-(-_(-_-)_-)-)
NIPS,2018,Nonparametric Bayesian Lomax delegate racing for survival analysis with competing risks,Quan Zhang,"McCombs School of Business, University of Texas at Austin"
NIPS,2018,Nonparametric Bayesian Lomax delegate racing for survival analysis with competing risks,Mingyuan Zhou,University of Texas at Austin
NIPS,2018,Adversarially Robust Generalization Requires More Data,Ludwig Schmidt,MIT
NIPS,2018,Adversarially Robust Generalization Requires More Data,Shibani Santurkar,MIT
NIPS,2018,Adversarially Robust Generalization Requires More Data,Dimitris Tsipras,MIT
NIPS,2018,Adversarially Robust Generalization Requires More Data,Kunal Talwar,Google
NIPS,2018,Adversarially Robust Generalization Requires More Data,Aleksander Madry,MIT
NIPS,2018,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents,Edoardo Conti,Facebook AML
NIPS,2018,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents,Vashisht Madhavan,Uber
NIPS,2018,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents,Felipe Petroski Such,Uber AI Labs
NIPS,2018,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents,Joel Lehman,Uber AI Labs
NIPS,2018,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents,Kenneth Stanley,Uber AI Labs and University of Central Florida
NIPS,2018,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents,Jeff Clune,Uber AI Labs
NIPS,2018,Practical exact algorithm for trembling-hand equilibrium refinements in games,Gabriele Farina,Carnegie Mellon University
NIPS,2018,Practical exact algorithm for trembling-hand equilibrium refinements in games,Nicola Gatti,Politecnico di Milano
NIPS,2018,Practical exact algorithm for trembling-hand equilibrium refinements in games,Tuomas Sandholm,Carnegie Mellon University
NIPS,2018,Power-law efficient neural codes provide general link between perceptual bias and discriminability,Michael Morais,Princeton University
NIPS,2018,Power-law efficient neural codes provide general link between perceptual bias and discriminability,Jonathan W Pillow,Princeton University
NIPS,2018,Active Geometry-Aware Visual Recognition in Cluttered Scenes,Ricson Cheng,Carnegie Mellon University
NIPS,2018,Active Geometry-Aware Visual Recognition in Cluttered Scenes,Ziyan Wang,Carnegie Mellon University
NIPS,2018,Active Geometry-Aware Visual Recognition in Cluttered Scenes,Katerina Fragkiadaki,Carnegie Mellon University
NIPS,2018,Unsupervised Adversarial Invariance,Ayush Jaiswal,USC Information Sciences Institute
NIPS,2018,Unsupervised Adversarial Invariance,Rex Yue Wu,USC ISI
NIPS,2018,Unsupervised Adversarial Invariance,Wael Abd-Almageed,Information Sciences Institute
NIPS,2018,Unsupervised Adversarial Invariance,Prem Natarajan,USC ISI
NIPS,2018,Content preserving text generation with attribute controls,Lajanugen Logeswaran,University of Michigan
NIPS,2018,Content preserving text generation with attribute controls,Honglak Lee,Google Brain
NIPS,2018,Content preserving text generation with attribute controls,Samy Bengio,Google Brain
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Mingchao Yu,University of Southern California
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Zhifeng Lin,University of Southern California
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Krishna Narra,University Of Southern California
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Songze Li,University of Southern California
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Youjie Li,UIUC
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Nam Sung Kim,University of Illinois at Urbana-Champaign
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Murali Annavaram,University of Southern California
NIPS,2018,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,Salman Avestimehr,University of Southern California
NIPS,2018,Multi-agent Online Learning with Asynchronous Feedback Loss,Zhengyuan Zhou,Stanford University
NIPS,2018,Multi-agent Online Learning with Asynchronous Feedback Loss,Panayotis Mertikopoulos,CNRS (French National Center for Scientific Research)
NIPS,2018,Multi-agent Online Learning with Asynchronous Feedback Loss,Susan Athey,Stanford University
NIPS,2018,Multi-agent Online Learning with Asynchronous Feedback Loss,Nicholas Bambos,
NIPS,2018,Multi-agent Online Learning with Asynchronous Feedback Loss,Peter W Glynn,Stanford University
NIPS,2018,Multi-agent Online Learning with Asynchronous Feedback Loss,Yinyu Ye,
NIPS,2018,Scalable methods for 8-bit training of neural networks,Ron Banner,Intel - Artificial Intelligence Products Group (AIPG)
NIPS,2018,Scalable methods for 8-bit training of neural networks,Itay Hubara,Technion
NIPS,2018,Scalable methods for 8-bit training of neural networks,Elad Hoffer,Technion
NIPS,2018,Scalable methods for 8-bit training of neural networks,Daniel Soudry,Technion
NIPS,2018,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization,Zhihui Zhu,Johns Hopkins University
NIPS,2018,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization,Xiao Li,The Chinese University of Hong Kong
NIPS,2018,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization,Kai Liu,Colorado School of Mines
NIPS,2018,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization,Qiuwei Li,Colorado School of Mines
NIPS,2018,Link Prediction Based on Graph Neural Networks,Muhan Zhang,Washington University in St. Louis
NIPS,2018,Link Prediction Based on Graph Neural Networks,Yixin Chen,Washington University in St. Louis
NIPS,2018,Why so gloomy? A Bayesian explanation of human pessimism bias in the multi-armed bandit task,Dalin Guo,UC San Diego
NIPS,2018,Why so gloomy? A Bayesian explanation of human pessimism bias in the multi-armed bandit task,Angela J Yu,UC San Diego
NIPS,2018,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model,Aaron Sidford,Stanford
NIPS,2018,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model,Mengdi Wang,Princeton University
NIPS,2018,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model,Xian Wu,Stanford University
NIPS,2018,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model,Lin Yang,Princeton University
NIPS,2018,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model,Yinyu  Ye,Standord
NIPS,2018,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions,Hongyang Gao,Texas A&M University
NIPS,2018,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions,Zhengyang Wang,Texas A&M University
NIPS,2018,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions,Shuiwang Ji,Texas A&M University
NIPS,2018,Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models,Shoubo Hu,The Chinese University of Hong Kong
NIPS,2018,Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models,Zhitang Chen,"Noah's Ark Lab,Huawei Tech. Investment Co. Ltd."
NIPS,2018,Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models,Vahid Partovi Nia,Huawei Technologies
NIPS,2018,Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models,Laiwan CHAN,"Department of Computer Science and Engineering, Chinese University of Hong Kong"
NIPS,2018,Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models,Yanhui Geng,Huawei Montreal Research Centre
NIPS,2018,Contour location via entropy reduction leveraging multiple information sources,Alexandre Marques,Massachusetts Institute of Technology
NIPS,2018,Contour location via entropy reduction leveraging multiple information sources,Remi Lam,MIT
NIPS,2018,Contour location via entropy reduction leveraging multiple information sources,Karen Willcox,MIT
NIPS,2018,Assessing Generative Models via Precision and Recall,Mehdi S. M. Sajjadi,Max Planck Institute for Intelligent Systems and ETH Center for Learning Systems
NIPS,2018,Assessing Generative Models via Precision and Recall,Olivier Bachem,Google AI (Brain team)
NIPS,2018,Assessing Generative Models via Precision and Recall,Mario Lucic,Google Brain
NIPS,2018,Assessing Generative Models via Precision and Recall,Olivier Bousquet,Google Brain (Zurich)
NIPS,2018,Assessing Generative Models via Precision and Recall,Sylvain Gelly,Google Brain (Zurich)
NIPS,2018,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning,Yonathan Efroni,Technion
NIPS,2018,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning,Gal Dalal,Technion
NIPS,2018,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning,Bruno Scherrer,INRIA
NIPS,2018,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning,Shie Mannor,Technion
NIPS,2018,A Convex Duality Framework for GANs,Farzan Farnia,Stanford University
NIPS,2018,A Convex Duality Framework for GANs,David Tse,Stanford University
NIPS,2018,Exploiting Numerical Sparsity for Efficient Learning : Faster Eigenvector Computation and Regression,Neha Gupta,Stanford University
NIPS,2018,Exploiting Numerical Sparsity for Efficient Learning : Faster Eigenvector Computation and Regression,Aaron Sidford,Stanford
NIPS,2018,Experimental Design for Cost-Aware Learning of Causal Graphs,Erik Lindgren,University of Texas at Austin
NIPS,2018,Experimental Design for Cost-Aware Learning of Causal Graphs,Murat Kocaoglu,IBM Research
NIPS,2018,Experimental Design for Cost-Aware Learning of Causal Graphs,Alex Dimakis,"University of Texas, Austin"
NIPS,2018,Experimental Design for Cost-Aware Learning of Causal Graphs,Sriram Vishwanath,University of Texas at Austin
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,Aran Nayebi,Stanford University
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,Daniel Bear,Stanford University
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,Jonas Kubilius,Massachusetts Institute of Technology
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,Kohitij Kar,MIT
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,Surya Ganguli,Stanford
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,David Sussillo,Google Inc.
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,James J DiCarlo,Massachusetts Institute of Technology
NIPS,2018,Task-Driven Convolutional Recurrent Models of the Visual System,Daniel Yamins,Stanford University
NIPS,2018,Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation,Tomoya Murata,NTT DATA Mathematical Systems Inc.
NIPS,2018,Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation,Taiji Suzuki,The University of Tokyo/JST-PRESTO/RIKEN
NIPS,2018,Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance,Neal Jean,Stanford University
NIPS,2018,Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance,Sang Michael Xie,Stanford University
NIPS,2018,Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance,Stefano Ermon,Stanford
NIPS,2018,Generalizing to Unseen Domains via Adversarial Data Augmentation,Riccardo Volpi,Istituto Italiano di Tecnologia
NIPS,2018,Generalizing to Unseen Domains via Adversarial Data Augmentation,Hong Namkoong,Stanford University
NIPS,2018,Generalizing to Unseen Domains via Adversarial Data Augmentation,Ozan Sener,Intel Labs
NIPS,2018,Generalizing to Unseen Domains via Adversarial Data Augmentation,John Duchi,Stanford
NIPS,2018,Generalizing to Unseen Domains via Adversarial Data Augmentation,Vittorio Murino,Istituto Italiano di Tecnologia
NIPS,2018,Generalizing to Unseen Domains via Adversarial Data Augmentation,Silvio Savarese,Stanford University
NIPS,2018,Breaking the Curse of Horizon: Infinite-Horizon Off-policy Estimation,Qiang Liu,UT Austin
NIPS,2018,Breaking the Curse of Horizon: Infinite-Horizon Off-policy Estimation,Lihong Li,Google Inc.
NIPS,2018,Breaking the Curse of Horizon: Infinite-Horizon Off-policy Estimation,Ziyang Tang,The University of Texas at Austin
NIPS,2018,Breaking the Curse of Horizon: Infinite-Horizon Off-policy Estimation,Denny Zhou,Google
NIPS,2018,Learning Task Specifications from Demonstrations,Marcell Vazquez-Chanlatte,"University of California, Berkeley"
NIPS,2018,Learning Task Specifications from Demonstrations,Susmit Jha,SRI International
NIPS,2018,Learning Task Specifications from Demonstrations,Ashish Tiwari,SRI International
NIPS,2018,Learning Task Specifications from Demonstrations,Mark Ho,UC Berkeley
NIPS,2018,Learning Task Specifications from Demonstrations,Sanjit Seshia,UC Berkeley
NIPS,2018,Learning an olfactory topography from neural activity in piriform cortex,Anqi Wu,Princeton University
NIPS,2018,Learning an olfactory topography from neural activity in piriform cortex,Stan Pashkovski,harvard university
NIPS,2018,Learning an olfactory topography from neural activity in piriform cortex,Sandeep Datta,harvard university
NIPS,2018,Learning an olfactory topography from neural activity in piriform cortex,Jonathan W Pillow,Princeton University
NIPS,2018,Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization,Yuanxiang Gao,University of Toronto
NIPS,2018,Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization,Li Chen,University of Louisiana at Lafayette
NIPS,2018,Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization,Baochun Li,University of Toronto
NIPS,2018,Dynamic Network Model from Partial Observations,Elahe Ghalebi,TU Wien
NIPS,2018,Dynamic Network Model from Partial Observations,Baharan Mirzasoleiman,Stanford University
NIPS,2018,Dynamic Network Model from Partial Observations,Radu Grosu,TU Wien
NIPS,2018,Dynamic Network Model from Partial Observations,Jure Leskovec,Stanford University and Pinterest
NIPS,2018,Theoretical guarantees for EM under misspecified Gaussian mixture models,Raaz Dwivedi,UC Berkeley
NIPS,2018,Theoretical guarantees for EM under misspecified Gaussian mixture models,nhật Hồ,"University of California, Berkeley"
NIPS,2018,Theoretical guarantees for EM under misspecified Gaussian mixture models,Koulik Khamaru,University Of California Berkeley
NIPS,2018,Theoretical guarantees for EM under misspecified Gaussian mixture models,Martin Wainwright,UC Berkeley
NIPS,2018,Theoretical guarantees for EM under misspecified Gaussian mixture models,Michael Jordan,UC Berkeley
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,Zhilin Yang,Carnegie Mellon University
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,Jake Zhao,New York University / Facebook
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,Bhuwan Dhingra,Carnegie Mellon University
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,Kaiming He,Facebook AI Research
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,William Cohen,Google AI
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,Russ Salakhutdinov,Carnegie Mellon University
NIPS,2018,Unsupervisedly Learned Latent Graphs as Transferable Representations,Yann LeCun,Facebook AI Research and New York University
NIPS,2018,A convex program for bilinear inversion of sparse vectors,Alireza Aghasi,Institute for Insight
NIPS,2018,A convex program for bilinear inversion of sparse vectors,Ali Ahmed,Information Technology University
NIPS,2018,A convex program for bilinear inversion of sparse vectors,Paul Hand,Northeastern University
NIPS,2018,A convex program for bilinear inversion of sparse vectors,Babhru Joshi,Rice University
NIPS,2018,Generalisation of structural knowledge in the Hippocampal-Entorhinal system,James Whittington,University of Oxford
NIPS,2018,Generalisation of structural knowledge in the Hippocampal-Entorhinal system,Timothy Muller,University of Oxford
NIPS,2018,Generalisation of structural knowledge in the Hippocampal-Entorhinal system,Shirely Mark,University College London
NIPS,2018,Generalisation of structural knowledge in the Hippocampal-Entorhinal system,Caswell Barry,University College London
NIPS,2018,Generalisation of structural knowledge in the Hippocampal-Entorhinal system,Tim Behrens,University of Oxford
NIPS,2018,Bandit Learning with Implicit Feedback,Yi Qi,Tsinghua University
NIPS,2018,Bandit Learning with Implicit Feedback,Qingyun Wu,University of Virginia
NIPS,2018,Bandit Learning with Implicit Feedback,Hongning Wang,University of Virginia
NIPS,2018,Bandit Learning with Implicit Feedback,Jie Tang,Tsinghua University
NIPS,2018,Bandit Learning with Implicit Feedback,Maosong Sun,
NIPS,2018,Fully Understanding The Hashing Trick,Lior Kamma,Aarhus University
NIPS,2018,Fully Understanding The Hashing Trick,Casper B. Freksen,Aarhus University
NIPS,2018,Fully Understanding The Hashing Trick,Kasper Green Larsen,"Aarhus University, MADALGO"
NIPS,2018,Evolved Policy Gradients,Rein Houthooft,Happy Elements
NIPS,2018,Evolved Policy Gradients,Richard Chen,Happy Elements Inc.
NIPS,2018,Evolved Policy Gradients,Phillip Isola,OpenAI
NIPS,2018,Evolved Policy Gradients,Bradly Stadie,Vector Institute
NIPS,2018,Evolved Policy Gradients,Filip Wolski,OpenAI
NIPS,2018,Evolved Policy Gradients,OpenAI Jonathan Ho,"OpenAI, UC Berkeley"
NIPS,2018,Evolved Policy Gradients,Pieter Abbeel,UC Berkeley | Gradescope | Covariant
NIPS,2018,The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network,Jeffrey Pennington,Google Brain
NIPS,2018,The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network,Pratik Worah,Google
NIPS,2018,Learning Concave Conditional Likelihood Models for Improved Analysis of Tandem Mass Spectra,John T Halloran,"University of California, Davis"
NIPS,2018,Learning Concave Conditional Likelihood Models for Improved Analysis of Tandem Mass Spectra,David M Rocke,"University of California, Davis"
NIPS,2018,Differentially Private k-Means with Constant Multiplicative Error,Uri Stemmer,Ben-Gurion University
NIPS,2018,Differentially Private k-Means with Constant Multiplicative Error,Haim Kaplan,
NIPS,2018,Policy Optimization via Importance Sampling,Alberto Maria Metelli,Politecnico di Milano
NIPS,2018,Policy Optimization via Importance Sampling,Matteo Papini,Politecnico di Milano
NIPS,2018,Policy Optimization via Importance Sampling,Francesco Faccio,"Politecnico di Milano -                 The Swiss AI Lab, IDSIA (USI & SUPSI)"
NIPS,2018,Policy Optimization via Importance Sampling,Marcello Restelli,Politecnico di Milano
NIPS,2018,Adversarial Logit Pairing,Harini Kannan,Google Brain
NIPS,2018,Adversarial Logit Pairing,Ian Goodfellow,Google
NIPS,2018,Adversarial Logit Pairing,Alexey Kurakin,Google Brain
NIPS,2018,Estimating Learnability in the Sublinear Data Regime,Weihao Kong,Stanford University
NIPS,2018,Estimating Learnability in the Sublinear Data Regime,Gregory Valiant,Stanford University
NIPS,2018,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation,Shiva Gopakumar,Deakin University
NIPS,2018,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation,Sunil Gupta,Deakin University
NIPS,2018,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation,Santu Rana,Deakin University
NIPS,2018,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation,Vu Nguyen,Deakin University
NIPS,2018,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation,Svetha Venkatesh,Deakin University
NIPS,2018,A Dual Framework for Low-rank Tensor Completion,Madhav Nimishakavi,Indian Institute of Science
NIPS,2018,A Dual Framework for Low-rank Tensor Completion,Pratik Kumar Jawanpuria,Microsoft
NIPS,2018,A Dual Framework for Low-rank Tensor Completion,Bamdev Mishra,Microsoft
NIPS,2018,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames,Geneviève Robin,École Polytechnique
NIPS,2018,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames,Hoi-To Wai,The Chinese University of Hong Kong
NIPS,2018,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames,Julie Josse,École Polytechnique
NIPS,2018,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames,Olga Klopp,Université Paris Ouest
NIPS,2018,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames,Eric Moulines,Ecole Polytechnique
NIPS,2018,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing,Zehong Hu,Alibaba Group
NIPS,2018,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing,Yitao Liang,UCLA
NIPS,2018,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing,Jie Zhang,Nanyang Technological University
NIPS,2018,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing,Zhao Li,Alibaba Group
NIPS,2018,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing,Yang Liu,Harvard University
NIPS,2018,Middle-Out Decoding,Shikib Mehri,Carnegie Mellon University
NIPS,2018,Middle-Out Decoding,Leonid Sigal,University of British Columbia
NIPS,2018,First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time,Yi Xu,The University of Iowa
NIPS,2018,First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time,Jing Rong,Alibaba
NIPS,2018,First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time,Tianbao Yang,The University of Iowa
NIPS,2018,To Trust Or Not To Trust A Classifier,Heinrich Jiang,Google Research
NIPS,2018,To Trust Or Not To Trust A Classifier,Been Kim,Google
NIPS,2018,To Trust Or Not To Trust A Classifier,Melody Guan,Stanford University
NIPS,2018,To Trust Or Not To Trust A Classifier,Maya Gupta,Google
NIPS,2018,A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization,Zhize Li,Tsinghua University
NIPS,2018,A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization,Jian Li,Tsinghua University
NIPS,2018,Multimodal Generative Models for Scalable Weakly-Supervised Learning,Mike Wu,Stanford University
NIPS,2018,Multimodal Generative Models for Scalable Weakly-Supervised Learning,Noah Goodman,Stanford University
NIPS,2018,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?,Richard Zhang,"University of California, Berkeley"
NIPS,2018,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?,Cedric Josz,UC Berkeley
NIPS,2018,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?,Somayeh Sojoudi,"University of California, Berkeley"
NIPS,2018,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?,Javad Lavaei,"University of California, Berkeley"
NIPS,2018,Impossibility of deducing preferences and rationality from human policy,Stuart Armstrong,Oxford University
NIPS,2018,Impossibility of deducing preferences and rationality from human policy,Sören Mindermann,Vector Institute
NIPS,2018,Manifold Structured Prediction,Alessandro Rudi,"INRIA, Ecole Normale Superieure"
NIPS,2018,Manifold Structured Prediction,Carlo Ciliberto,Imperial College London
NIPS,2018,Manifold Structured Prediction,GianMaria Marconi,Italian Institute of Technology
NIPS,2018,Manifold Structured Prediction,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2018,Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity,Laming Chen,Hulu LLC
NIPS,2018,Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity,Guoxin Zhang,Kwai Inc.
NIPS,2018,Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity,Eric Zhou,Facebook
NIPS,2018,Learning Others' Intentional Models in Multi-Agent Settings Using Interactive POMDPs,Yanlin Han,University of Illinois at Chicago
NIPS,2018,Learning Others' Intentional Models in Multi-Agent Settings Using Interactive POMDPs,Piotr Gmytrasiewicz,UIC
NIPS,2018,Online Improper Learning with an Approximation Oracle,Elad Hazan,Princeton University
NIPS,2018,Online Improper Learning with an Approximation Oracle,Wei Hu,Princeton University
NIPS,2018,Online Improper Learning with an Approximation Oracle,Yuanzhi Li,Princeton University
NIPS,2018,Online Improper Learning with an Approximation Oracle,Zhiyuan Li,Princeton University
NIPS,2018,Bandit Learning in Concave N-Person Games,Mario Bravo,"University of Santiago, Chile"
NIPS,2018,Bandit Learning in Concave N-Person Games,David Leslie,Lancaster University and PROWLER.io
NIPS,2018,Bandit Learning in Concave N-Person Games,Panayotis Mertikopoulos,CNRS (French National Center for Scientific Research)
NIPS,2018,On Fast Leverage Score Sampling and Optimal Learning,Alessandro Rudi,"INRIA, Ecole Normale Superieure"
NIPS,2018,On Fast Leverage Score Sampling and Optimal Learning,Daniele Calandriello,LCSL IIT/MIT
NIPS,2018,On Fast Leverage Score Sampling and Optimal Learning,Luigi Carratino,University of Genoa
NIPS,2018,On Fast Leverage Score Sampling and Optimal Learning,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2018,Unsupervised Video Object Segmentation for Deep Reinforcement Learning,Vik Goel,University of Waterloo
NIPS,2018,Unsupervised Video Object Segmentation for Deep Reinforcement Learning,Jameson Weng,University of Waterloo
NIPS,2018,Unsupervised Video Object Segmentation for Deep Reinforcement Learning,Pascal Poupart,University of Waterloo & RBC Borealis AI
NIPS,2018,Efficient inference for time-varying behavior during learning,Nicholas Roy,Princeton Neuroscience Institute
NIPS,2018,Efficient inference for time-varying behavior during learning,Ji Hyun Bak,KIAS
NIPS,2018,Efficient inference for time-varying behavior during learning,Athena Akrami,Princeton University
NIPS,2018,Efficient inference for time-varying behavior during learning,Carlos Brody,Princeton University
NIPS,2018,Efficient inference for time-varying behavior during learning,Jonathan W Pillow,Princeton University
NIPS,2018,Learning convex polytopes with margin,Lee-Ad Gottlieb,Ariel University
NIPS,2018,Learning convex polytopes with margin,Eran Kaufman,Ariel University
NIPS,2018,Learning convex polytopes with margin,Aryeh Kontorovich,Ben Gurion University
NIPS,2018,Learning convex polytopes with margin,Gabriel Nivasch,Ariel University
NIPS,2018,Insights on representational similarity in neural networks with canonical correlation,Ari Morcos,Facebook AI Research
NIPS,2018,Insights on representational similarity in neural networks with canonical correlation,Maithra Raghu,Cornell University and Google Brain
NIPS,2018,Insights on representational similarity in neural networks with canonical correlation,Samy Bengio,Google Brain
NIPS,2018,Variational Inference with Tail Adapted f-Divergence,Dilin Wang,UT Austin
NIPS,2018,Variational Inference with Tail Adapted f-Divergence,Hao Liu,UESTC
NIPS,2018,Variational Inference with Tail Adapted f-Divergence,Qiang Liu,UT Austin
NIPS,2018,Adversarially Robust Optimization with Gaussian Processes,Ilija Bogunovic,EPFL Lausanne
NIPS,2018,Adversarially Robust Optimization with Gaussian Processes,Jonathan Scarlett,National University of Singapore
NIPS,2018,Adversarially Robust Optimization with Gaussian Processes,Stefanie Jegelka,MIT
NIPS,2018,Adversarially Robust Optimization with Gaussian Processes,Volkan Cevher,EPFL
NIPS,2018,Learning to Multitask,Yu Zhang,
NIPS,2018,Learning to Multitask,Ying Wei,Tencent AI Lab
NIPS,2018,Learning to Multitask,Qiang Yang,Hong Kong University of Science and Technology
NIPS,2018,Loss Functions for Multiset Prediction,Sean Welleck,NYU
NIPS,2018,Loss Functions for Multiset Prediction,Zixin Yao,New York University
NIPS,2018,Loss Functions for Multiset Prediction,Yu Gai,New York University
NIPS,2018,Loss Functions for Multiset Prediction,Jialin Mao,New York University
NIPS,2018,Loss Functions for Multiset Prediction,Zheng Zhang,Shanghai New York Univeristy
NIPS,2018,Loss Functions for Multiset Prediction,Kyunghyun Cho,NYU
NIPS,2018,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs,Gennaro Auricchio,University of Pavia
NIPS,2018,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs,Federico Bassetti,Politecnico di Milano
NIPS,2018,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs,Stefano Gualandi,University of Pavia
NIPS,2018,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs,Marco Veneroni,University of Pavia
NIPS,2018,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability,Michael Tsang,University of Southern California
NIPS,2018,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability,Hanpeng Liu,University of Southern California
NIPS,2018,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability,Sanjay Purushotham,University of Maryland Baltimore County
NIPS,2018,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability,Pavankumar Murali,IBM
NIPS,2018,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability,Yan Liu,DiDi AI Labs
NIPS,2018,CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces,Liheng Zhang,University of Central Florida
NIPS,2018,CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces,Marzieh Edraki,University of Central Florida
NIPS,2018,CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces,Guo-Jun Qi,"Futurewei Technologies, Inc."
NIPS,2018,Gamma-Poisson Dynamic Matrix Factorization Embedded with Metadata Influence,Trong Dinh Thac Do,University of Technology Sydney
NIPS,2018,Gamma-Poisson Dynamic Matrix Factorization Embedded with Metadata Influence,Longbing Cao,University of Technology Sydney
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Bo Han,RIKEN & UTS
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Jiangchao Yao,Shanghai Jiao Tong University
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Gang Niu,RIKEN
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Mingyuan Zhou,University of Texas at Austin
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Ivor Tsang,"University of Technology, Sydney"
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Ya Zhang,"Cooperative Medianet Innovation Center, Shang hai Jiao Tong University"
NIPS,2018,Masking: A New Perspective of Noisy Supervision,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2018,On GANs and GMMs,Eitan Richardson,The Hebrew University of Jerusalem
NIPS,2018,On GANs and GMMs,Yair Weiss,Hebrew University
NIPS,2018,Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching,Stepan Tulyakov,École polytechnique fédérale de Lausanne (EPFL)
NIPS,2018,Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching,Anton Ivanov,EPFL
NIPS,2018,Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching,François Fleuret,Idiap Research Institute
NIPS,2018,Dual Swap Disentangling,Zunlei Feng,Zhejiang University
NIPS,2018,Dual Swap Disentangling,Xinchao Wang,Stevens Institute of Technology
NIPS,2018,Dual Swap Disentangling,Chenglong Ke,Zhejiang University
NIPS,2018,Dual Swap Disentangling,An-Xiang Zeng,Alibaba
NIPS,2018,Dual Swap Disentangling,Dacheng Tao,"University of Technology, Sydney"
NIPS,2018,Dual Swap Disentangling,Mingli Song,Zhejiang University
NIPS,2018,Diverse Ensemble Evolution: Curriculum based Data-Model Marriage,Tianyi Zhou,"University of Washington, Seattle"
NIPS,2018,Diverse Ensemble Evolution: Curriculum based Data-Model Marriage,Shengjie Wang,"""University of Washington, Seattle"""
NIPS,2018,Diverse Ensemble Evolution: Curriculum based Data-Model Marriage,Jeff Bilmes,"University of Washington, Seattle"
NIPS,2018,Binary Classification from Positive-Confidence Data,Takashi Ishida,"The University of Tokyo, RIKEN, SMAM"
NIPS,2018,Binary Classification from Positive-Confidence Data,Gang Niu,RIKEN
NIPS,2018,Binary Classification from Positive-Confidence Data,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2018,Deep Generative Models for Distribution-Preserving Lossy Compression,Michael Tschannen,ETH Zurich
NIPS,2018,Deep Generative Models for Distribution-Preserving Lossy Compression,Eirikur Agustsson,ETH Zurich
NIPS,2018,Deep Generative Models for Distribution-Preserving Lossy Compression,Mario Lucic,Google Brain
NIPS,2018,Exact natural gradient in deep linear networks and its application to the nonlinear case,Alberto Bernacchia,University of Cambridge
NIPS,2018,Exact natural gradient in deep linear networks and its application to the nonlinear case,Mate Lengyel,University of Cambridge
NIPS,2018,Exact natural gradient in deep linear networks and its application to the nonlinear case,Guillaume Hennequin,Cambridge
NIPS,2018,Constructing Fast Network through Deconstruction of Convolution,Yunho Jeon,KAIST
NIPS,2018,Constructing Fast Network through Deconstruction of Convolution,Junmo Kim,KAIST
NIPS,2018,Memory Replay GANs: Learning to Generate New Categories without Forgetting,Chenshen Wu,Computer Vision Center
NIPS,2018,Memory Replay GANs: Learning to Generate New Categories without Forgetting,Luis Herranz,Computer Vision Center
NIPS,2018,Memory Replay GANs: Learning to Generate New Categories without Forgetting,Xialei Liu,Computer Vision Center
NIPS,2018,Memory Replay GANs: Learning to Generate New Categories without Forgetting,yaxing wang,Centre de Visió per Computador (CVC)
NIPS,2018,Memory Replay GANs: Learning to Generate New Categories without Forgetting,Joost van de Weijer,Computer Vision Center Barcelona
NIPS,2018,Memory Replay GANs: Learning to Generate New Categories without Forgetting,Bogdan Raducanu,Computer Vision Center
NIPS,2018,Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling,Emilie Kaufmann,CNRS & CRIStAL (SequeL)
NIPS,2018,Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling,Wouter Koolen,"Centrum Wiskunde & Informatica, Amsterdam"
NIPS,2018,Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling,Aurélien Garivier,ENS Lyon
NIPS,2018,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization,Bargav Jayaraman,University of Virginia
NIPS,2018,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization,Lingxiao Wang,"University of California, Los Angeles"
NIPS,2018,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization,David Evans,University of Virginia
NIPS,2018,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization,Quanquan Gu,UCLA
NIPS,2018,A no-regret generalization of hierarchical softmax to extreme multi-label classification,Marek Wydmuch,Poznan University of Technology
NIPS,2018,A no-regret generalization of hierarchical softmax to extreme multi-label classification,Kalina Jasinska,Poznan Univeristy of Technology
NIPS,2018,A no-regret generalization of hierarchical softmax to extreme multi-label classification,Mikhail Kuznetsov,Yahoo! Research
NIPS,2018,A no-regret generalization of hierarchical softmax to extreme multi-label classification,Róbert Busa-Fekete,Yahoo! Research
NIPS,2018,A no-regret generalization of hierarchical softmax to extreme multi-label classification,Krzysztof Dembczynski,Poznan University of Technology
NIPS,2018,Efficient Formal Safety Analysis of Neural Networks,Shiqi Wang,Columbia University
NIPS,2018,Efficient Formal Safety Analysis of Neural Networks,Kexin Pei,Columbia University
NIPS,2018,Efficient Formal Safety Analysis of Neural Networks,Justin Whitehouse,Columbia University
NIPS,2018,Efficient Formal Safety Analysis of Neural Networks,Junfeng Yang,Columbia University
NIPS,2018,Efficient Formal Safety Analysis of Neural Networks,Suman Jana,Columbia University
NIPS,2018,Bayesian Distributed Stochastic Gradient Descent,Michael Teng,University of Oxford (visiting at University of British Columbia)
NIPS,2018,Bayesian Distributed Stochastic Gradient Descent,Frank Wood,University of British Columbia
NIPS,2018,Visualizing the Loss Landscape of Neural Nets,Hao Li,Zhejiang University
NIPS,2018,Visualizing the Loss Landscape of Neural Nets,Zheng Xu,"University of Maryland, College Park"
NIPS,2018,Visualizing the Loss Landscape of Neural Nets,Gavin Taylor,US Naval Academy
NIPS,2018,Visualizing the Loss Landscape of Neural Nets,Christoph Studer,Cornell University
NIPS,2018,Visualizing the Loss Landscape of Neural Nets,Tom Goldstein,University of Maryland
NIPS,2018,The Limits of Post-Selection Generalization,Jonathan Ullman,Northeastern University
NIPS,2018,The Limits of Post-Selection Generalization,Adam Smith,Boston University
NIPS,2018,The Limits of Post-Selection Generalization,kobbi Nissim,Georgetown University
NIPS,2018,The Limits of Post-Selection Generalization,Uri Stemmer,Ben-Gurion University
NIPS,2018,The Limits of Post-Selection Generalization,Thomas Steinke,IBM Research - Almaden
NIPS,2018,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation,Jiaxuan You,Stanford University
NIPS,2018,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation,Bowen Liu,Stanford University
NIPS,2018,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation,Rex Ying,Stanford University
NIPS,2018,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation,Vijay Pande,Stanford
NIPS,2018,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation,Jure Leskovec,Stanford University and Pinterest
NIPS,2018,On Controllable Sparse Alternatives to Softmax,Anirban Laha,IBM Research
NIPS,2018,On Controllable Sparse Alternatives to Softmax,Saneem Ahmed Chemmengath,IBM Research AI
NIPS,2018,On Controllable Sparse Alternatives to Softmax,Priyanka Agrawal,IBM Research AI
NIPS,2018,On Controllable Sparse Alternatives to Softmax,Mitesh Khapra,IIT Madras
NIPS,2018,On Controllable Sparse Alternatives to Softmax,Karthik Sankaranarayanan,IBM Research
NIPS,2018,On Controllable Sparse Alternatives to Softmax,Harish Ramaswamy,IIT Madras
NIPS,2018,L4: Practical loss-based stepsize adaptation for deep learning,Michal Rolinek,Max Planck Institute for Intelligent Systems
NIPS,2018,L4: Practical loss-based stepsize adaptation for deep learning,Georg Martius,MPI for Intelligent Systems
NIPS,2018,Learning Latent Subspaces in Variational Autoencoders,Jack Klys,University of Toronto
NIPS,2018,Learning Latent Subspaces in Variational Autoencoders,Jake Snell,"University of Toronto, Vector Institute"
NIPS,2018,Learning Latent Subspaces in Variational Autoencoders,Richard Zemel,Vector Institute/University of Toronto
NIPS,2018,Turbo Learning for Captionbot and Drawingbot,Qiuyuan Huang,Microsoft Research AI
NIPS,2018,Turbo Learning for Captionbot and Drawingbot,Pengchuan Zhang,Microsoft Research
NIPS,2018,Turbo Learning for Captionbot and Drawingbot,Dapeng Wu,University of Florida
NIPS,2018,Turbo Learning for Captionbot and Drawingbot,Lei Zhang,Microsoft Research
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Lijun Wu,Sun Yat-sen University
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Fei Tian,Miicrosoft Research
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Yingce Xia,Microsoft Research
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Yang Fan,University of Science and Technology of China
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Tao Qin,Microsoft Research
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Lai Jian-Huang,Sun Yat-sen University
NIPS,2018,Learning to Teach with Dynamic Loss Functions,Tie-Yan Liu,Microsoft Research Asia
NIPS,2018,Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation,Edward Smith,McGill University
NIPS,2018,Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation,Scott Fujimoto,McGill University
NIPS,2018,Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation,David Meger,University of British Columbia
NIPS,2018,Size-Noise Tradeoffs in Generative Networks,Bolton Bailey,University of Illinois Urbana-Champaign
NIPS,2018,Size-Noise Tradeoffs in Generative Networks,Matus Telgarsky,UIUC
NIPS,2018,"Online Adaptive Methods, Universality and Acceleration",Yehuda Kfir Levy,ETH
NIPS,2018,"Online Adaptive Methods, Universality and Acceleration",Alp Yurtsever,EPFL
NIPS,2018,"Online Adaptive Methods, Universality and Acceleration",Volkan Cevher,EPFL
NIPS,2018,Compact Generalized Non-local Network,Kaiyu Yue,Baidu Inc.
NIPS,2018,Compact Generalized Non-local Network,Ming Sun,baidu
NIPS,2018,Compact Generalized Non-local Network,Yuchen Yuan,Baidu Inc.
NIPS,2018,Compact Generalized Non-local Network,Feng Zhou,Carnegie Mellon University
NIPS,2018,Compact Generalized Non-local Network,Errui Ding,Baidu Inc.
NIPS,2018,Compact Generalized Non-local Network,Fuxin Xu,Central South University
NIPS,2018,On the Local Hessian in Back-propagation,Huishuai Zhang,Microsoft Research Asia
NIPS,2018,On the Local Hessian in Back-propagation,Wei Chen,Microsoft Research
NIPS,2018,On the Local Hessian in Back-propagation,Tie-Yan Liu,Microsoft Research Asia
NIPS,2018,The Everlasting Database: Statistical Validity at a Fair Price,Blake Woodworth,TTI-Chicago
NIPS,2018,The Everlasting Database: Statistical Validity at a Fair Price,Vitaly Feldman,Google Brain
NIPS,2018,The Everlasting Database: Statistical Validity at a Fair Price,Saharon Rosset,Technion
NIPS,2018,The Everlasting Database: Statistical Validity at a Fair Price,Nati Srebro,TTI-Chicago
NIPS,2018,Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks,Yusuke Tsuzuku,The University of Tokyo
NIPS,2018,Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks,Issei Sato,The University of Tokyo/RIKEN
NIPS,2018,Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2018,On Coresets for Logistic Regression,Alexander Munteanu,TU Dortmund
NIPS,2018,On Coresets for Logistic Regression,Chris Schwiegelshohn,"Sapienza, University of Rome"
NIPS,2018,On Coresets for Logistic Regression,Christian Sohler,TU Dortmund
NIPS,2018,On Coresets for Logistic Regression,David Woodruff,Carnegie Mellon University
NIPS,2018,Approximating Real-Time Recurrent Learning with Random Kronecker Factors,Asier Mujika,ETH Zurich
NIPS,2018,Approximating Real-Time Recurrent Learning with Random Kronecker Factors,Florian Meier,ETH Zurich
NIPS,2018,Approximating Real-Time Recurrent Learning with Random Kronecker Factors,Angelika Steger,ETH Zurich
NIPS,2018,Contamination Attacks in Multi-Party Machine Learning,Jamie Hayes,University College London
NIPS,2018,Contamination Attacks in Multi-Party Machine Learning,Olga Ohrimenko,Microsoft Research
NIPS,2018,An Improved Analysis of Alternating Minimization for Structured Multi-Response Regression,Sheng Chen,University of Minnesota
NIPS,2018,An Improved Analysis of Alternating Minimization for Structured Multi-Response Regression,Arindam Banerjee,Voleon
NIPS,2018,Incorporating Context into Language Encoding Models for fMRI,Shailee Jain,The University of Texas at Austin
NIPS,2018,Incorporating Context into Language Encoding Models for fMRI,Alexander Huth,The University of Texas at Austin
NIPS,2018,Query K-means Clustering and the Double Dixie Cup Problem,Eli Chien,UIUC
NIPS,2018,Query K-means Clustering and the Double Dixie Cup Problem,Chao Pan,University of Illinois Urbana-Champaign
NIPS,2018,Query K-means Clustering and the Double Dixie Cup Problem,Olgica Milenkovic,University of Illinois at Urbana-Champaign
NIPS,2018,Training Neural Networks Using Features Replay,Zhouyuan Huo,University of Pittsburgh
NIPS,2018,Training Neural Networks Using Features Replay,Bin Gu,Pittsburgh University
NIPS,2018,Training Neural Networks Using Features Replay,Heng Huang,University of Pittsburgh
NIPS,2018,Modeling Dynamic Missingness of Implicit Feedback for Recommendation,Menghan Wang,Zhejiang University
NIPS,2018,Modeling Dynamic Missingness of Implicit Feedback for Recommendation,Mingming Gong,University of Pittsburgh
NIPS,2018,Modeling Dynamic Missingness of Implicit Feedback for Recommendation,Xiaolin Zheng,Zhejiang University
NIPS,2018,Modeling Dynamic Missingness of Implicit Feedback for Recommendation,Kun Zhang,CMU
NIPS,2018,Representation Learning of Compositional Data,Marta Avalos,"INRIA, INSERM U1219, University of Bordeaux"
NIPS,2018,Representation Learning of Compositional Data,Richard Nock,"Data61, the Australian National University and the University of Sydney"
NIPS,2018,Representation Learning of Compositional Data,Cheng Soon Ong,Data61 and ANU
NIPS,2018,Representation Learning of Compositional Data,Julien Rouar,University of Bordeaux
NIPS,2018,Representation Learning of Compositional Data,Ke Sun,"Data61, CSIRO"
NIPS,2018,Model-based targeted dimensionality reduction for neuronal population data,Mikio Aoi,Princeton University
NIPS,2018,Model-based targeted dimensionality reduction for neuronal population data,Jonathan W Pillow,Princeton University
NIPS,2018,On gradient regularizers for MMD GANs,Michael Arbel,UCL
NIPS,2018,On gradient regularizers for MMD GANs,Dougal Sutherland,"Gatsby Unit, UCL"
NIPS,2018,On gradient regularizers for MMD GANs,Mikołaj Bińkowski,Imperial College London
NIPS,2018,On gradient regularizers for MMD GANs,Arthur Gretton,"Gatsby Unit, UCL"
NIPS,2018,Heterogeneous Multi-output Gaussian Process Prediction,Pablo Moreno-Muñoz,Universidad Carlos III de Madrid
NIPS,2018,Heterogeneous Multi-output Gaussian Process Prediction,Antonio Artés,Universidad Carlos III de Madrid
NIPS,2018,Heterogeneous Multi-output Gaussian Process Prediction,Mauricio Álvarez,University of Sheffield
NIPS,2018,Large-Scale Stochastic Sampling from the Probability Simplex,Jack Baker,Lancaster University
NIPS,2018,Large-Scale Stochastic Sampling from the Probability Simplex,Paul Fearnhead,Lancaster University
NIPS,2018,Large-Scale Stochastic Sampling from the Probability Simplex,Emily Fox,University of Washington
NIPS,2018,Large-Scale Stochastic Sampling from the Probability Simplex,Chris Nemeth,Lancaster University
NIPS,2018,Policy Regret in Repeated Games,Raman Arora,Johns Hopkins University
NIPS,2018,Policy Regret in Repeated Games,Michael Dinitz,JHU
NIPS,2018,Policy Regret in Repeated Games,Teodor Vanislavov Marinov,Johns Hopkins University
NIPS,2018,Policy Regret in Repeated Games,Mehryar Mohri,Courant Inst. of Math. Sciences & Google Research
NIPS,2018,A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice,Hendrik Fichtenberger,TU Dortmund
NIPS,2018,A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice,Dennis Rohde,TU Dortmund
NIPS,2018,BRITS: Bidirectional Recurrent Imputation for Time Series,Wei Cao,Tsinghua University
NIPS,2018,BRITS: Bidirectional Recurrent Imputation for Time Series,Dong Wang,Duke University
NIPS,2018,BRITS: Bidirectional Recurrent Imputation for Time Series,Jian Li,Tsinghua University
NIPS,2018,BRITS: Bidirectional Recurrent Imputation for Time Series,Hao Zhou,Bytedance AI Lab
NIPS,2018,BRITS: Bidirectional Recurrent Imputation for Time Series,Lei Li,ByteDance AI Lab
NIPS,2018,BRITS: Bidirectional Recurrent Imputation for Time Series,Yitan Li,ByteDance.Inc
NIPS,2018,M-Walk: Learning to Walk in Graph  with Monte Carlo Tree Search,Yelong Shen,"Microsoft Research, Redmond, WA"
NIPS,2018,M-Walk: Learning to Walk in Graph  with Monte Carlo Tree Search,Jianshu Chen,Tencent AI Lab
NIPS,2018,M-Walk: Learning to Walk in Graph  with Monte Carlo Tree Search,Po-Sen Huang,Google DeepMind
NIPS,2018,M-Walk: Learning to Walk in Graph  with Monte Carlo Tree Search,Yuqing Guo,Microsoft Research
NIPS,2018,M-Walk: Learning to Walk in Graph  with Monte Carlo Tree Search,Jianfeng Gao,"Microsoft Research, Redmond, WA"
NIPS,2018,Extracting Relationships by Multi-Domain Matching,Yitong Li,Duke University
NIPS,2018,Extracting Relationships by Multi-Domain Matching,michael Murias,Duke University
NIPS,2018,Extracting Relationships by Multi-Domain Matching,geraldine Dawson,Duke University
NIPS,2018,Extracting Relationships by Multi-Domain Matching,David Carlson,Duke University
NIPS,2018,Generative Probabilistic Novelty Detection with Adversarial Autoencoders,Stanislav Pidhorskyi,Lane Department of Computer Science and Electrical Engineering of West Virginia University
NIPS,2018,Generative Probabilistic Novelty Detection with Adversarial Autoencoders,Ranya Almohsen,West Virginia University
NIPS,2018,Generative Probabilistic Novelty Detection with Adversarial Autoencoders,Gianfranco Doretto,West Virginia University
NIPS,2018,Diminishing Returns Shape Constraints for Interpretability and Regularization,Maya Gupta,Google
NIPS,2018,Diminishing Returns Shape Constraints for Interpretability and Regularization,Dara Bahri,Google AI
NIPS,2018,Diminishing Returns Shape Constraints for Interpretability and Regularization,Andy Cotter,Google
NIPS,2018,Diminishing Returns Shape Constraints for Interpretability and Regularization,Kevin Canini,Google
NIPS,2018,Scalable Hyperparameter Transfer Learning,Valerio Perrone,University of Warwick
NIPS,2018,Scalable Hyperparameter Transfer Learning,Rodolphe Jenatton,Amazon Research
NIPS,2018,Scalable Hyperparameter Transfer Learning,Matthias W Seeger,Amazon Development Center
NIPS,2018,Scalable Hyperparameter Transfer Learning,Cedric Archambeau,Amazon
NIPS,2018,Stochastic Nonparametric Event-Tensor Decomposition,Shandian Zhe,University of Utah
NIPS,2018,Stochastic Nonparametric Event-Tensor Decomposition,Yishuai Du,University of Utah
NIPS,2018,Scaling Gaussian Process Regression with Derivatives,David Eriksson,Cornell University
NIPS,2018,Scaling Gaussian Process Regression with Derivatives,Kun Dong,Cornell University
NIPS,2018,Scaling Gaussian Process Regression with Derivatives,Eric Lee,Cornell University
NIPS,2018,Scaling Gaussian Process Regression with Derivatives,David Bindel,Cornell University
NIPS,2018,Scaling Gaussian Process Regression with Derivatives,Andrew Wilson,Cornell University
NIPS,2018,Differentially Private Testing of Identity and Closeness of Discrete Distributions,Jayadev Acharya,Cornell University
NIPS,2018,Differentially Private Testing of Identity and Closeness of Discrete Distributions,Ziteng Sun,Cornell University
NIPS,2018,Differentially Private Testing of Identity and Closeness of Discrete Distributions,Huanyu Zhang,Cornell University
NIPS,2018,Efficient Convex Completion of Coupled Tensors using Coupled Nuclear Norms,Kishan Wimalawarne,Kyoto University
NIPS,2018,Efficient Convex Completion of Coupled Tensors using Coupled Nuclear Norms,Hiroshi Mamitsuka,Kyoto University
NIPS,2018,Maximizing Induced Cardinality Under a Determinantal Point Process,Jennifer Gillenwater,Google
NIPS,2018,Maximizing Induced Cardinality Under a Determinantal Point Process,Alex Kulesza,Google
NIPS,2018,Maximizing Induced Cardinality Under a Determinantal Point Process,Sergei Vassilvitskii,Google
NIPS,2018,Maximizing Induced Cardinality Under a Determinantal Point Process,Zelda Mariet,MIT
NIPS,2018,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions,Mathieu Fehr,École Normale Supérieure
NIPS,2018,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions,Olivier Buffet,INRIA / LORIA
NIPS,2018,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions,Vincent Thomas,LORIA / INRIA
NIPS,2018,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions,Jilles Dibangoye,"INRIA, INSA Lyon"
NIPS,2018,Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on Zero-One Loss,Stephen Mussmann,Stanford University
NIPS,2018,Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on Zero-One Loss,Percy Liang,Stanford University
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Simon Kohl,German Cancer Research Center (DKFZ)
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Bernardino Romera-Paredes,DeepMind
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Clemens Meyer,DeepMind
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Jeffrey De Fauw,DeepMind
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Joseph R. Ledsam,DeepMind
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Klaus Maier-Hein,German Cancer Research Center
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Ali Eslami,DeepMind
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Danilo Jimenez Rezende,Google DeepMind
NIPS,2018,A Probabilistic U-Net for Segmentation of Ambiguous Images,Olaf Ronneberger,DeepMind
NIPS,2018,Unorganized Malicious Attacks Detection,Ming Pang,Nanjing University
NIPS,2018,Unorganized Malicious Attacks Detection,Wei Gao,Nanjing University
NIPS,2018,Unorganized Malicious Attacks Detection,Min Tao,Nanjing University
NIPS,2018,Unorganized Malicious Attacks Detection,Zhi-Hua Zhou,Nanjing University
NIPS,2018,Causal Inference via Kernel Deviance Measures,Jovana Mitrovic,University of Oxford
NIPS,2018,Causal Inference via Kernel Deviance Measures,Dino Sejdinovic,University of Oxford
NIPS,2018,Causal Inference via Kernel Deviance Measures,Yee Whye Teh,"University of Oxford, DeepMind"
NIPS,2018,Bayesian Alignments of Warped Multi-Output Gaussian Processes,Markus Kaiser,Technical University Munich
NIPS,2018,Bayesian Alignments of Warped Multi-Output Gaussian Processes,Clemens Otte,Siemens
NIPS,2018,Bayesian Alignments of Warped Multi-Output Gaussian Processes,Thomas Runkler,Technical University of Munich
NIPS,2018,Bayesian Alignments of Warped Multi-Output Gaussian Processes,Carl Henrik Ek,University of Bristol
NIPS,2018,Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks,Yingyezhe Jin,Facebook Inc
NIPS,2018,Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks,Wenrui Zhang,Texas A&M University
NIPS,2018,Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks,Peng Li,Texas A&M University
NIPS,2018,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation,Kush Bhatia,UC Berkeley
NIPS,2018,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation,Aldo Pacchiano,UC Berkeley
NIPS,2018,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation,Nicolas Flammarion,UC Berkeley
NIPS,2018,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation,Peter Bartlett,UC Berkeley
NIPS,2018,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation,Michael Jordan,UC Berkeley
NIPS,2018,Efficient online algorithms for fast-rate regret bounds under sparsity,Pierre Gaillard,"INRIA Paris, DI ENS"
NIPS,2018,Efficient online algorithms for fast-rate regret bounds under sparsity,Olivier Wintenberger,
NIPS,2018,Predictive Uncertainty Estimation via Prior Networks,Andrey Malinin,University of Cambridge
NIPS,2018,Predictive Uncertainty Estimation via Prior Networks,Mark Gales,University of Cambridge
NIPS,2018,Dual Policy Iteration,Wen Sun,Carnegie Mellon University
NIPS,2018,Dual Policy Iteration,Geoffrey Gordon,MSR Montréal & CMU
NIPS,2018,Dual Policy Iteration,Byron Boots,Georgia Tech / Google Brain
NIPS,2018,Dual Policy Iteration,J. Bagnell,Carnegie Mellon University
NIPS,2018,A probabilistic population code based on neural samples,Sabyasachi Shivkumar,University of Rochester
NIPS,2018,A probabilistic population code based on neural samples,Richard Lange,University of Rochester
NIPS,2018,A probabilistic population code based on neural samples,Ankani Chattoraj,University of Rochester
NIPS,2018,A probabilistic population code based on neural samples,Ralf Haefner,"Brain & Cognitive Sciences, University of Rochester"
NIPS,2018,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks,Anirvan Sengupta,Rutgers University
NIPS,2018,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks,Cengiz Pehlevan,Flatiron Institute
NIPS,2018,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks,Mariano Tepper,Intel Labs
NIPS,2018,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks,Alexander Genkin,"Neuroscience Institute, NYU Langone Health"
NIPS,2018,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks,Dmitri Chklovskii,"Flatiron Institute, Simons Foundation"
NIPS,2018,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport,Maziar Sanjabi,University of Southern California
NIPS,2018,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport,Jimmy Ba,University of Toronto / Vector Institute
NIPS,2018,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport,Meisam Razaviyayn,University of Southern California
NIPS,2018,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport,Jason Lee,University of Southern California
NIPS,2018,Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders,Tengfei Ma,IBM Research
NIPS,2018,Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders,Jie Chen,IBM Research
NIPS,2018,Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders,Cao Xiao,IBM Research
NIPS,2018,Provably Correct Automatic Sub-Differentiation for Qualified Programs,Sham Kakade,University of Washington
NIPS,2018,Provably Correct Automatic Sub-Differentiation for Qualified Programs,Jason Lee,University of Southern California
NIPS,2018,"Deep Homogeneous Mixture Models: Representation, Separation, and Approximation",Priyank Jaini,University of Waterloo
NIPS,2018,"Deep Homogeneous Mixture Models: Representation, Separation, and Approximation",Pascal Poupart,University of Waterloo & RBC Borealis AI
NIPS,2018,"Deep Homogeneous Mixture Models: Representation, Separation, and Approximation",Yaoliang Yu,University of Waterloo
NIPS,2018,"Parameters as interacting particles: asymptotic scaling, convexity, and error of neural networks",Grant Rotskoff,New York University
NIPS,2018,"Parameters as interacting particles: asymptotic scaling, convexity, and error of neural networks",Eric Vanden-Eijnden,New York University
NIPS,2018,Multitask Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies,Sungryull Sohn,University of Michigan
NIPS,2018,Multitask Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies,Junhyuk Oh,DeepMind
NIPS,2018,Multitask Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies,Honglak Lee,Google Brain
NIPS,2018,End-to-End Differentiable Physics for Learning and Control,Filipe de Avila Belbute-Peres,Carnegie Mellon University
NIPS,2018,End-to-End Differentiable Physics for Learning and Control,Kevin Smith,MIT
NIPS,2018,End-to-End Differentiable Physics for Learning and Control,Kelsey Allen,MIT
NIPS,2018,End-to-End Differentiable Physics for Learning and Control,Josh Tenenbaum,MIT
NIPS,2018,End-to-End Differentiable Physics for Learning and Control,J. Zico Kolter,Carnegie Mellon University / Bosch Center for AI
NIPS,2018,BRUNO: A Deep Recurrent Model for Exchangeable Data,Iryna Korshunova,Ghent University
NIPS,2018,BRUNO: A Deep Recurrent Model for Exchangeable Data,Jonas Degrave,Deepmind
NIPS,2018,BRUNO: A Deep Recurrent Model for Exchangeable Data,Ferenc Huszar,Twitter
NIPS,2018,BRUNO: A Deep Recurrent Model for Exchangeable Data,Yarin Gal,University of OXford
NIPS,2018,BRUNO: A Deep Recurrent Model for Exchangeable Data,Arthur Gretton,"Gatsby Unit, UCL"
NIPS,2018,BRUNO: A Deep Recurrent Model for Exchangeable Data,Joni Dambre,Ghent University
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,fabee Sinz,University Tübingen
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Alexander Ecker,University of Tuebingen
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Paul Fahey,Bayl
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Edgar Walker,Baylor College of Medicine
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Erick Cobos,Baylor College of Medicine
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Emmanouil Froudarakis,Baylor College of Medicine
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Dimitri Yatsenko,Baylor College of Medicine
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Zachary Pitkow,BCM/Rice
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Jacob Reimer,Baylor College of Medicine
NIPS,2018,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video,Andreas Tolias,Baylor College of Medicine
NIPS,2018,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction,Roei Herzig,Tel Aviv University
NIPS,2018,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction,Moshiko Raboh,Tel Aviv University
NIPS,2018,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction,Gal Chechik,"Google, BIU"
NIPS,2018,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction,Jonathan Berant,Tel Aviv University
NIPS,2018,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction,Amir Globerson,"Tel Aviv University, Google"
NIPS,2018,Distributed Multi-Player Bandits - a Game of Thrones Approach,Ilai Bistritz,Stanford
NIPS,2018,Distributed Multi-Player Bandits - a Game of Thrones Approach,Amir Leshem,Bar-Ilan University
NIPS,2018,Efficient Loss-Based Decoding On Graphs For Extreme Classification,Itay Evron,Technion
NIPS,2018,Efficient Loss-Based Decoding On Graphs For Extreme Classification,Edward Moroshko,Technion
NIPS,2018,Efficient Loss-Based Decoding On Graphs For Extreme Classification,Koby Crammer,Technion
NIPS,2018,Implicit Probabilistic Integrators for ODEs,Onur Teymur,Imperial College London
NIPS,2018,Implicit Probabilistic Integrators for ODEs,Han Lie,Freie Universität Berlin
NIPS,2018,Implicit Probabilistic Integrators for ODEs,Tim Sullivan,Free University of Berlin
NIPS,2018,Implicit Probabilistic Integrators for ODEs,Ben Calderhead,Imperial College
NIPS,2018,Learning Attentional Communication for Multi-Agent Cooperation,Jiechuan Jiang,Peking University
NIPS,2018,Learning Attentional Communication for Multi-Agent Cooperation,Zongqing Lu,Peking University
NIPS,2018,"Training Deep Models Faster with Robust, Approximate Importance Sampling",Tyler Johnson,University of Washington
NIPS,2018,"Training Deep Models Faster with Robust, Approximate Importance Sampling",Carlos Guestrin,University of Washington
NIPS,2018,Unsupervised Text Style Transfer using Language Models as Discriminators,Zichao  Yang,
NIPS,2018,Unsupervised Text Style Transfer using Language Models as Discriminators,Zhiting Hu,Carnegie Mellon University
NIPS,2018,Unsupervised Text Style Transfer using Language Models as Discriminators,Chris Dyer,DeepMind
NIPS,2018,Unsupervised Text Style Transfer using Language Models as Discriminators,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,Unsupervised Text Style Transfer using Language Models as Discriminators,Taylor Berg-Kirkpatrick,Carnegie Mellon University
NIPS,2018,Relational recurrent neural networks,Adam Santoro,DeepMind
NIPS,2018,Relational recurrent neural networks,Ryan Faulkner,Deepmind
NIPS,2018,Relational recurrent neural networks,David Raposo,DeepMind
NIPS,2018,Relational recurrent neural networks,Jack Rae,"DeepMind, UCL"
NIPS,2018,Relational recurrent neural networks,Mike Chrzanowski,DeepMind
NIPS,2018,Relational recurrent neural networks,Theophane Weber,DeepMind
NIPS,2018,Relational recurrent neural networks,Daan Wierstra,DeepMind Technologies
NIPS,2018,Relational recurrent neural networks,Oriol Vinyals,Google DeepMind
NIPS,2018,Relational recurrent neural networks,Razvan Pascanu,Google DeepMind
NIPS,2018,Relational recurrent neural networks,Timothy Lillicrap,Google DeepMind
NIPS,2018,Streaming~Kernel~PCA~with~$\tilde{O}(\sqrt{n})$~Random~Features,Enayat Ullah,Johns Hopkins University
NIPS,2018,Streaming~Kernel~PCA~with~$\tilde{O}(\sqrt{n})$~Random~Features,Poorya Mianjy,Johns Hopkins University
NIPS,2018,Streaming~Kernel~PCA~with~$\tilde{O}(\sqrt{n})$~Random~Features,Teodor Vanislavov Marinov,Johns Hopkins University
NIPS,2018,Streaming~Kernel~PCA~with~$\tilde{O}(\sqrt{n})$~Random~Features,Raman Arora,Johns Hopkins University
NIPS,2018,Exploring Sparse Features in Deep Reinforcement Learning towards Fast Disease Diagnosis,Yu-Shao Peng,HTC Research
NIPS,2018,Exploring Sparse Features in Deep Reinforcement Learning towards Fast Disease Diagnosis,Kai-Fu Tang,HTC Research
NIPS,2018,Exploring Sparse Features in Deep Reinforcement Learning towards Fast Disease Diagnosis,Hsuan-Tien Lin,Appier/National Taiwan University
NIPS,2018,Exploring Sparse Features in Deep Reinforcement Learning towards Fast Disease Diagnosis,Edward Chang,
NIPS,2018,Disconnected Manifold Learning for Generative  Adversarial Networks,Mahyar Khayatkhoei,Rutgers University
NIPS,2018,Disconnected Manifold Learning for Generative  Adversarial Networks,Maneesh K. Singh,Verisk Analytics
NIPS,2018,Disconnected Manifold Learning for Generative  Adversarial Networks,Ahmed Elgammal,Rutgers University
NIPS,2018,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces,Yu-An Chung,Massachusetts Institute of Technology
NIPS,2018,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces,Wei-Hung Weng,Massachusetts Institute of Technology
NIPS,2018,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces,Schrasing Tong,MIT CSAIL
NIPS,2018,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces,Jim Glass,Massachusetts Institute of Technology
NIPS,2018,Learning Signed Determinantal Point Processes through the Principal Minor Assignment Problem,Victor-Emmanuel Brunel,ENSAE
NIPS,2018,Out-of-Distribution Detection using Multiple Semantic Label Representations,Gabi Shalev,"Dept. of Computer Science, Bar-Ilan University"
NIPS,2018,Out-of-Distribution Detection using Multiple Semantic Label Representations,Yossi Adi,Bar Ilan University
NIPS,2018,Out-of-Distribution Detection using Multiple Semantic Label Representations,Yossi Keshet,Bar-Ilan University
NIPS,2018,Stochastic Chebyshev Gradient Descent for Spectral Optimization,Insu Han,KAIST
NIPS,2018,Stochastic Chebyshev Gradient Descent for Spectral Optimization,Haim Avron,Tel Aviv University
NIPS,2018,Stochastic Chebyshev Gradient Descent for Spectral Optimization,Jinwoo Shin,KAIST; AITRICS
NIPS,2018,"Revisiting $(\epsilon, \gamma, \tau)$-similarity learning for domain adaptation",Sofiane Dhouib,CREATIS UMR CNRS 5220
NIPS,2018,"Revisiting $(\epsilon, \gamma, \tau)$-similarity learning for domain adaptation",Ievgen Redko,Hubert Curien laboratory
NIPS,2018,"Constant Regret, Generalized Mixability, and Mirror Descent",Zakaria Mhammedi,The Australian National University
NIPS,2018,"Constant Regret, Generalized Mixability, and Mirror Descent",Robert Williamson,Australian National University & Data61
NIPS,2018,A Bayesian Approach to Generative Adversarial Imitation Learning,Wonseok Jeon,KAIST
NIPS,2018,A Bayesian Approach to Generative Adversarial Imitation Learning,Seokin Seo,KAIST
NIPS,2018,A Bayesian Approach to Generative Adversarial Imitation Learning,Kee-Eung Kim,KAIST
NIPS,2018,Constrained Cross-Entropy Method for Safe Reinforcement Learning,Min Wen,University of Pennsylvania
NIPS,2018,Constrained Cross-Entropy Method for Safe Reinforcement Learning,Ufuk Topcu,The University of Texas at Austin
NIPS,2018,Multi-Agent Generative Adversarial Imitation Learning,Jiaming Song,Stanford University
NIPS,2018,Multi-Agent Generative Adversarial Imitation Learning,Hongyu Ren,Stanford University
NIPS,2018,Multi-Agent Generative Adversarial Imitation Learning,Dorsa Sadigh,Stanford
NIPS,2018,Multi-Agent Generative Adversarial Imitation Learning,Stefano Ermon,Stanford
NIPS,2018,Adaptive Learning with Unknown Information Flows,Yonatan Gur,Stanford University
NIPS,2018,Adaptive Learning with Unknown Information Flows,Ahmad Momeni,Stanford University
NIPS,2018,Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks,Bryan Lim,University of Oxford
NIPS,2018,Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks,Ahmed M. Alaa,UCLA
NIPS,2018,Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks,Mihaela van der Schaar,UCLA and Oxford University
NIPS,2018,Generative modeling for protein structures,Namrata Anand,Stanford University
NIPS,2018,Generative modeling for protein structures,Possu Huang,Stanford University
NIPS,2018,Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo,Marton Havasi,University of Cambridge
NIPS,2018,Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo,Jose Miguel Hernández-Lobato,University of Cambridge
NIPS,2018,Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo,Juan José Murillo-Fuentes,Universidad de Sevilla
NIPS,2018,Knowledge Distillation by On-the-Fly Native Ensemble,xu lan,"Queen Mary, University of London"
NIPS,2018,Knowledge Distillation by On-the-Fly Native Ensemble,Xiatian Zhu,"Queen Mary University, London, UK"
NIPS,2018,Knowledge Distillation by On-the-Fly Native Ensemble,Shaogang Gong,Queen Mary University of London
NIPS,2018,Non-Adversarial Mapping with VAEs,Yedid Hoshen,Facebook AI Research
NIPS,2018,Generalisation in humans and deep neural networks,Robert Geirhos,University of Tübingen
NIPS,2018,Generalisation in humans and deep neural networks,Carlos R. M. Temme,University of Tübingen
NIPS,2018,Generalisation in humans and deep neural networks,Jonas Rauber,University of Tübingen
NIPS,2018,Generalisation in humans and deep neural networks,Heiko H. Schütt,University of Tübingen
NIPS,2018,Generalisation in humans and deep neural networks,Matthias Bethge,University of Tübingen
NIPS,2018,Generalisation in humans and deep neural networks,Felix A. Wichmann,University of Tübingen
NIPS,2018,Towards Text Generation with Adversarially Learned Neural Outlines,Sandeep Subramanian,University of Montreal
NIPS,2018,Towards Text Generation with Adversarially Learned Neural Outlines,Sai Rajeswar Mudumba,University of Montreal
NIPS,2018,Towards Text Generation with Adversarially Learned Neural Outlines,Alessandro Sordoni,Microsoft Research Montreal
NIPS,2018,Towards Text Generation with Adversarially Learned Neural Outlines,Adam Trischler,Microsoft
NIPS,2018,Towards Text Generation with Adversarially Learned Neural Outlines,Aaron Courville,U. Montreal
NIPS,2018,Towards Text Generation with Adversarially Learned Neural Outlines,Chris Pal,"MILA, Polytechnique Montréal, Element AI"
NIPS,2018,cpSGD: Communication-efficient and differentially-private distributed SGD,Naman Agarwal,princeton
NIPS,2018,cpSGD: Communication-efficient and differentially-private distributed SGD,Ananda Theertha Suresh,Google
NIPS,2018,cpSGD: Communication-efficient and differentially-private distributed SGD,Felix Xinnan Yu,Google Research
NIPS,2018,cpSGD: Communication-efficient and differentially-private distributed SGD,Sanjiv Kumar,Google Research
NIPS,2018,cpSGD: Communication-efficient and differentially-private distributed SGD,Brendan McMahan,Google
NIPS,2018,Blackbox Matrix×Matrix Gaussian Process Inference,Jacob Gardner,Cornell University
NIPS,2018,Blackbox Matrix×Matrix Gaussian Process Inference,Geoff Pleiss,Cornell University
NIPS,2018,Blackbox Matrix×Matrix Gaussian Process Inference,Kilian Weinberger,Cornell University
NIPS,2018,Blackbox Matrix×Matrix Gaussian Process Inference,David Bindel,Cornell University
NIPS,2018,Blackbox Matrix×Matrix Gaussian Process Inference,Andrew Wilson,Cornell University
NIPS,2018,Diffusion Maps for Textual Network Embedding,Xinyuan Zhang,Duke University
NIPS,2018,Diffusion Maps for Textual Network Embedding,Yitong Li,Duke University
NIPS,2018,Diffusion Maps for Textual Network Embedding,Dinghan Shen,Duke University
NIPS,2018,Diffusion Maps for Textual Network Embedding,Lawrence Carin,Duke University
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Dustin Tran,Google Brain
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Matthew Hoffman,Google
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Dave Moore,Google
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Christopher Suter,"Google, Inc"
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Srinivas Vasudevan,Google
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Alexey Radul,Google
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Matthew Johnson,Google Brain
NIPS,2018,"Edward2: Simple, Dynamic, Accelerated",Rif A. Saurous,Google
NIPS,2018,VideoCapsuleNet: A Simplified Network for Action Detection,Kevin Duarte,University of Central Florida
NIPS,2018,VideoCapsuleNet: A Simplified Network for Action Detection,Yogesh Rawat,University of Central Florida
NIPS,2018,VideoCapsuleNet: A Simplified Network for Action Detection,Mubarak Shah,University of Central Florida
NIPS,2018,Rectangular Bounding Process,Xuhui Fan,University of New South Wales
NIPS,2018,Rectangular Bounding Process,Bin Li,Fudan University
NIPS,2018,Rectangular Bounding Process,Scott SIsson,
NIPS,2018,Improved Algorithms for Collaborative PAC Learning,Huy Nguyen,Princeton
NIPS,2018,Improved Algorithms for Collaborative PAC Learning,Lydia Zakynthinou,Northeastern University
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Nan Ke,"MILA, University of Montreal"
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Anirudh Goyal ALIAS PARTH GOYAL,Université de Montréal
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Olexa Bilaniuk,University of Montreal
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Jonathan Binas,"MILA, Montreal"
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Mike Mozer,Google Brain / U. Colorado
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Chris Pal,"MILA, Polytechnique Montréal, Element AI"
NIPS,2018,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding,Yoshua Bengio,U. Montreal
NIPS,2018,Communication Compression for Decentralized Training,Hanlin Tang,University of Rochester
NIPS,2018,Communication Compression for Decentralized Training,Shaoduo Gan,ETH Zurich
NIPS,2018,Communication Compression for Decentralized Training,Ce Zhang,ETH Zurich
NIPS,2018,Communication Compression for Decentralized Training,Tong Zhang,The Australian National University
NIPS,2018,Communication Compression for Decentralized Training,Ji Liu,"University of Rochester, Tencent AI lab"
NIPS,2018,Depth-Limited Solving for Imperfect-Information Games,Noam Brown,Carnegie Mellon University
NIPS,2018,Depth-Limited Solving for Imperfect-Information Games,Tuomas Sandholm,Carnegie Mellon University
NIPS,2018,Depth-Limited Solving for Imperfect-Information Games,Brandon Amos,Carnegie Mellon University
NIPS,2018,Training Deep Neural Networks with 8-bit Floating Point Numbers,Naigang Wang,IBM T. J. Watson Research Center
NIPS,2018,Training Deep Neural Networks with 8-bit Floating Point Numbers,Jungwook Choi,IBM Research
NIPS,2018,Training Deep Neural Networks with 8-bit Floating Point Numbers,Daniel Brand,IBM Research
NIPS,2018,Training Deep Neural Networks with 8-bit Floating Point Numbers,Chia-Yu Chen,IBM research
NIPS,2018,Training Deep Neural Networks with 8-bit Floating Point Numbers,Kailash Gopalakrishnan,IBM Research
NIPS,2018,Scalar Posterior Sampling with Applications,Georgios Theocharous,Adobe Research
NIPS,2018,Scalar Posterior Sampling with Applications,Zheng Wen,Adobe Research
NIPS,2018,Scalar Posterior Sampling with Applications,Yasin Abbasi,Adobe Research
NIPS,2018,Scalar Posterior Sampling with Applications,Nikos Vlassis,Netflix
NIPS,2018,Understanding Batch Normalization,Nils Bjorck,Cornell
NIPS,2018,Understanding Batch Normalization,Carla P Gomes,Cornell University
NIPS,2018,Understanding Batch Normalization,Bart Selman,Cornell University
NIPS,2018,Understanding Batch Normalization,Kilian Weinberger,Cornell University
NIPS,2018,On Neuronal Capacity,Pierre Baldi,UC Irvine
NIPS,2018,On Neuronal Capacity,Roman Vershynin,UCI
NIPS,2018,Breaking the Activation Function Bottleneck through Adaptive Parameterization,Sebastian Flennerhag,Alan Turing Institute
NIPS,2018,Towards Robust Interpretability with Self-Explaining Neural Networks,David Alvarez Melis,MIT
NIPS,2018,Towards Robust Interpretability with Self-Explaining Neural Networks,Tommi Jaakkola,MIT
NIPS,2018,Deep State Space Models for Time Series Forecasting,Syama Sundar Rangapuram,Amazon Research
NIPS,2018,Deep State Space Models for Time Series Forecasting,Matthias W Seeger,Amazon Development Center
NIPS,2018,Deep State Space Models for Time Series Forecasting,Jan Gasthaus,Amazon.com
NIPS,2018,Deep State Space Models for Time Series Forecasting,Lorenzo Stella,Amazon
NIPS,2018,Deep State Space Models for Time Series Forecasting,Bernie Wang,AWS AI Labs
NIPS,2018,Deep State Space Models for Time Series Forecasting,Tim Januschowski,Amazon
NIPS,2018,Constrained Graph Variational Autoencoders for Molecule Design,Qi Liu,Facebook AI Research
NIPS,2018,Constrained Graph Variational Autoencoders for Molecule Design,Miltiadis Allamanis,Microsoft Research
NIPS,2018,Constrained Graph Variational Autoencoders for Molecule Design,Marc Brockschmidt,Microsoft Research
NIPS,2018,Constrained Graph Variational Autoencoders for Molecule Design,Alexander Gaunt,Microsoft Research
NIPS,2018,Learning Libraries of Subroutines for Neurally–Guided Bayesian Program Learning,Kevin Ellis,MIT
NIPS,2018,Learning Libraries of Subroutines for Neurally–Guided Bayesian Program Learning,Lucas Morales,MIT
NIPS,2018,Learning Libraries of Subroutines for Neurally–Guided Bayesian Program Learning,Mathias Sablé-Meyer,MIT
NIPS,2018,Learning Libraries of Subroutines for Neurally–Guided Bayesian Program Learning,Armando Solar-Lezama,MIT
NIPS,2018,Learning Libraries of Subroutines for Neurally–Guided Bayesian Program Learning,Josh Tenenbaum,MIT
NIPS,2018,Neural Architecture Optimization,Renqian Luo,University of Science and Technology of China
NIPS,2018,Neural Architecture Optimization,Fei Tian,Miicrosoft Research
NIPS,2018,Neural Architecture Optimization,Tao Qin,Microsoft Research
NIPS,2018,Neural Architecture Optimization,Enhong Chen,University of Science and Technology of China
NIPS,2018,Neural Architecture Optimization,Tie-Yan Liu,Microsoft Research Asia
NIPS,2018,Preference Based Adaptation for Learning Objectives,Yao-Xiang Ding,Nanjing University
NIPS,2018,Preference Based Adaptation for Learning Objectives,Zhi-Hua Zhou,Nanjing University
NIPS,2018,Distributed $k$-Clustering for Data with Heavy Noise,Shi Li,University at Buffalo
NIPS,2018,Distributed $k$-Clustering for Data with Heavy Noise,Xiangyu Guo,State University of New York at Buffalo
NIPS,2018,Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo,HOLDEN LEE,Princeton
NIPS,2018,Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo,Andrej Risteski,MIT
NIPS,2018,Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo,Rong Ge,Duke University
NIPS,2018,A General Method for Amortizing Variational Filtering,Joe Marino,California Institute of Technology
NIPS,2018,A General Method for Amortizing Variational Filtering,Milan Cvitkovic,California Institute of Technology
NIPS,2018,A General Method for Amortizing Variational Filtering,Yisong Yue,Caltech
NIPS,2018,A Reduction for Efficient LDA Topic Reconstruction,Matteo Almanza,Sapienza University of Rome
NIPS,2018,A Reduction for Efficient LDA Topic Reconstruction,Flavio Chierichetti,Sapienza University
NIPS,2018,A Reduction for Efficient LDA Topic Reconstruction,Alessandro Panconesi,"Sapienza, University of Rome"
NIPS,2018,A Reduction for Efficient LDA Topic Reconstruction,Andrea Vattani,UC San Diego
NIPS,2018,Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data,Dominik Linzner,TU Darmstadt
NIPS,2018,Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data,Heinz Koeppl,Technische Universität Darmstadt
NIPS,2018,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes,Thu H Nguyen-Phuoc,University of Bath
NIPS,2018,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes,Chuan Li,"Lambda Labs, Inc."
NIPS,2018,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes,Stephen Balaban,Lambda
NIPS,2018,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes,Yongliang Yang,University of Bath
NIPS,2018,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets,RUI GAO,GEORGIA TECH
NIPS,2018,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets,Liyan Xie,Georgia Institute of Technology
NIPS,2018,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets,Yao Xie,Georgia Institute of Technology
NIPS,2018,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets,Huan Xu,Georgia Inst. of Technology
NIPS,2018,Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks,Zhihao Zheng,Brandeis University
NIPS,2018,Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks,Pengyu Hong,Brandeis University
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,Jacob Harer,Boston University
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,Onur Ozdemir,Draper
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,Tomo Lazovich,Lightmatter
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,Christopher Reale,Draper
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,Rebecca Russell,Draper
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,Louis Kim,Draper
NIPS,2018,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks,peter chin,boston university
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Tianyu He,University of Science and Technology of China
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Xu Tan,Microsoft Research
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Yingce Xia,Microsoft Research
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Di He,Peking University
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Tao Qin,Microsoft Research
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Zhibo Chen,University of Science and Technology of China
NIPS,2018,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,Tie-Yan Liu,Microsoft Research Asia
NIPS,2018,Dirichlet belief networks as structured topic prior,He Zhao,"Monash University, Australia"
NIPS,2018,Dirichlet belief networks as structured topic prior,Lan Du,Monash University
NIPS,2018,Dirichlet belief networks as structured topic prior,Wray Buntine,Monash University
NIPS,2018,Dirichlet belief networks as structured topic prior,Mingyuan Zhou,University of Texas at Austin
NIPS,2018,Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions,Wenruo Bai,University of Washington
NIPS,2018,Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions,William Stafford Noble,
NIPS,2018,Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions,Jeff Bilmes,"University of Washington, Seattle"
NIPS,2018,The challenge of realistic music generation: modelling raw audio at scale,Sander Dieleman,DeepMind
NIPS,2018,The challenge of realistic music generation: modelling raw audio at scale,Aaron van den Oord,Google Deepmind
NIPS,2018,The challenge of realistic music generation: modelling raw audio at scale,Karen Simonyan,DeepMind
NIPS,2018,Spectral Signatures in Backdoor Attacks on Deep Nets,Brandon Tran,Massachusetts Institute of Technology
NIPS,2018,Spectral Signatures in Backdoor Attacks on Deep Nets,Jerry Li,Berkeley
NIPS,2018,Spectral Signatures in Backdoor Attacks on Deep Nets,Aleksander Madry,MIT
NIPS,2018,Reward learning from human preferences and demonstrations in Atari,Jan Leike,DeepMind
NIPS,2018,Reward learning from human preferences and demonstrations in Atari,Borja Ibarz,DeepMind
NIPS,2018,Reward learning from human preferences and demonstrations in Atari,Dario Amodei,OpenAI
NIPS,2018,Reward learning from human preferences and demonstrations in Atari,Geoffrey Irving,OpenAI
NIPS,2018,Reward learning from human preferences and demonstrations in Atari,Shane Legg,DeepMind
NIPS,2018,Neural Arithmetic Logic Units,Andrew Trask,DeepMind
NIPS,2018,Neural Arithmetic Logic Units,Felix Hill,Deepmind
NIPS,2018,Neural Arithmetic Logic Units,Scott Reed,Google DeepMind
NIPS,2018,Neural Arithmetic Logic Units,Jack Rae,"DeepMind, UCL"
NIPS,2018,Neural Arithmetic Logic Units,Chris Dyer,DeepMind
NIPS,2018,Neural Arithmetic Logic Units,Phil Blunsom,Oxford University
NIPS,2018,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,Youjie Li,UIUC
NIPS,2018,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,Mingchao Yu,University of Southern California
NIPS,2018,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,Songze Li,University of Southern California
NIPS,2018,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,Salman Avestimehr,University of Southern California
NIPS,2018,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,Nam Sung Kim,University of Illinois at Urbana-Champaign
NIPS,2018,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,Alex Schwing,University of Illinois at Urbana-Champaign
NIPS,2018,Improved Expressivity Through Dendritic Neural Networks,Xundong Wu,Hangzhou Dianzi University
NIPS,2018,Improved Expressivity Through Dendritic Neural Networks,Xiangwen Liu,Hangzhou Dianzi University
NIPS,2018,Improved Expressivity Through Dendritic Neural Networks,wei li,Hangzhou Dianzi University
NIPS,2018,Improved Expressivity Through Dendritic Neural Networks,qing wu,Hangzhou Dianzi University
NIPS,2018,How to Start Training: The Effect of Initialization and Architecture,Boris Hanin,Texas A&M
NIPS,2018,How to Start Training: The Effect of Initialization and Architecture,David Rolnick,University of Pennsylvania
NIPS,2018,Which Neural Net Architectures Give Rise to Exploding and Vanishing Gradients?,Boris Hanin,Texas A&M
NIPS,2018,HitNet: Hybrid Ternary Recurrent Neural Network,Peiqi Wang,Tsinghua University
NIPS,2018,HitNet: Hybrid Ternary Recurrent Neural Network,Xinfeng Xie,UCSB
NIPS,2018,HitNet: Hybrid Ternary Recurrent Neural Network,Lei Deng,"University of California, Santa Barbara"
NIPS,2018,HitNet: Hybrid Ternary Recurrent Neural Network,Guoqi Li,Tsinghua University
NIPS,2018,HitNet: Hybrid Ternary Recurrent Neural Network,Dongsheng Wang,Tsinghua University
NIPS,2018,HitNet: Hybrid Ternary Recurrent Neural Network,Yuan Xie,Chinese Academy of Sciences
NIPS,2018,A Unified Framework for Extensive-Form Game Abstraction with Bounds,Christian Kroer,"Faceook, Core Data Science"
NIPS,2018,A Unified Framework for Extensive-Form Game Abstraction with Bounds,Tuomas Sandholm,Carnegie Mellon University
NIPS,2018,Maximum-Entropy Fine Grained Classification,Abhimanyu Dubey,MIT
NIPS,2018,Maximum-Entropy Fine Grained Classification,Otkrist Gupta,MIT
NIPS,2018,Maximum-Entropy Fine Grained Classification,Ramesh Raskar,MIT
NIPS,2018,Maximum-Entropy Fine Grained Classification,Nikhil Naik,Massachusetts Institute of Technology
NIPS,2018,On Learning Markov Chains,Yi HAO,"University of California, San Diego"
NIPS,2018,On Learning Markov Chains,Alon Orlitsky,"University of California, San Diego"
NIPS,2018,On Learning Markov Chains,Venkatadheeraj Pichapati,UC San Diego
NIPS,2018,Quantifying Learning Guarantees for Convex but Inconsistent Surrogates,Kirill Struminsky,NRU HSE
NIPS,2018,Quantifying Learning Guarantees for Convex but Inconsistent Surrogates,Simon Lacoste-Julien,"MILA, Université de Montréal"
NIPS,2018,Quantifying Learning Guarantees for Convex but Inconsistent Surrogates,Anton Osokin,"CS HSE, Moscow, Russia"
NIPS,2018,Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator,Cong Fang,Peking University
NIPS,2018,Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator,Chris Junchi Li,Tencent AI Lab
NIPS,2018,Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator,Zhouchen Lin,Peking University
NIPS,2018,Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator,Tong Zhang,The Australian National University
NIPS,2018,Learning Disentangled Joint Continuous and Discrete Representations,Emilien Dupont,Oxford University
NIPS,2018,"Do Less, Get More: Streaming Submodular Maximization with Subsampling",Moran Feldman,Open University of Israel
NIPS,2018,"Do Less, Get More: Streaming Submodular Maximization with Subsampling",Amin Karbasi,Yale
NIPS,2018,"Do Less, Get More: Streaming Submodular Maximization with Subsampling",Ehsan Kazemi,"Yale Institute for Network Science, Yale"
NIPS,2018,Sparse Covariance Modeling in High Dimensions with Gaussian Processes,Rui Li,Rochester Institute of Technology
NIPS,2018,Sparse Covariance Modeling in High Dimensions with Gaussian Processes,Kishan KC,Rochester Institute of Technology
NIPS,2018,Sparse Covariance Modeling in High Dimensions with Gaussian Processes,Feng Cui,Rochester Institute of Technology
NIPS,2018,Sparse Covariance Modeling in High Dimensions with Gaussian Processes,Justin Domke,"University of Massachusetts, Amherst"
NIPS,2018,Sparse Covariance Modeling in High Dimensions with Gaussian Processes,Anne Haake,Rochester Institute of Technology
NIPS,2018,Image-to-image translation for cross-domain disentanglement,Abel Gonzalez-Garcia,Computer Vision Center
NIPS,2018,Image-to-image translation for cross-domain disentanglement,Joost van de Weijer,Computer Vision Center Barcelona
NIPS,2018,Image-to-image translation for cross-domain disentanglement,Yoshua Bengio,U. Montreal
NIPS,2018,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection,Taylor Mordan,"Sorbonne Université, LIP6"
NIPS,2018,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection,Nicolas THOME,Cnam
NIPS,2018,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection,Gilles Henaff,Thales Optronique S.A.S.
NIPS,2018,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection,Matthieu Cord,Sorbonne University
NIPS,2018,Generative Neural Machine Translation,Harshil Shah,UCL
NIPS,2018,Generative Neural Machine Translation,David Barber,University College London
NIPS,2018,Found Graph Data and Planted Vertex Covers,Austin Benson,Cornell University
NIPS,2018,Found Graph Data and Planted Vertex Covers,Jon Kleinberg,Cornell University
NIPS,2018,Multitask Boosting for Survival Analysis with Competing Risks,Alexis Bellot,University of Oxford
NIPS,2018,Multitask Boosting for Survival Analysis with Competing Risks,Mihaela van der Schaar,UCLA and Oxford University
NIPS,2018,SLAYER: Spike Layer Error Reassignment in Time,Sumit Bam Shrestha,Temasek Laboratories @ National University of Singapore
NIPS,2018,SLAYER: Spike Layer Error Reassignment in Time,Garrick Orchard,National University of Singapore
NIPS,2018,Variational Memory Encoder-Decoder,Hung Le,Deakin University
NIPS,2018,Variational Memory Encoder-Decoder,Truyen Tran,Deakin University
NIPS,2018,Variational Memory Encoder-Decoder,Thin Nguyen,Deakin University
NIPS,2018,Variational Memory Encoder-Decoder,Svetha Venkatesh,Deakin University
NIPS,2018,Overcoming Language Priors in Visual Question Answering with Adversarial Regularization,Sainandan Ramakrishnan,Georgia Institute of Technology
NIPS,2018,Overcoming Language Priors in Visual Question Answering with Adversarial Regularization,Aishwarya Agrawal,Georgia Institute of Technology
NIPS,2018,Overcoming Language Priors in Visual Question Answering with Adversarial Regularization,Stefan Lee,Georgia Institute of Technology
NIPS,2018,Hybrid Knowledge Routed Modules for Large-scale Object Detection,ChenHan Jiang,Sun Yat-sen University
NIPS,2018,Hybrid Knowledge Routed Modules for Large-scale Object Detection,Hang Xu,Huawei Noah's Ark Lab
NIPS,2018,Hybrid Knowledge Routed Modules for Large-scale Object Detection,Xiaodan Liang,Sun Yat-sen University
NIPS,2018,Hybrid Knowledge Routed Modules for Large-scale Object Detection,Liang Lin,Sun Yat-Sen University
NIPS,2018,Multi-Class Learning: From Theory to Algorithm,Jian Li,Tsinghua University
NIPS,2018,Multi-Class Learning: From Theory to Algorithm,Yong Liu,"Institute of Information Engineering, CAS"
NIPS,2018,Multi-Class Learning: From Theory to Algorithm,Rong Yin,"School of Cyber Security, University of Chinese Academy of Sciences"
NIPS,2018,Multi-Class Learning: From Theory to Algorithm,Hua Zhang,"Institute of Information Engineering,Chinese Academy of Sciences"
NIPS,2018,Multi-Class Learning: From Theory to Algorithm,Lizhong Ding,KAUST
NIPS,2018,Multi-Class Learning: From Theory to Algorithm,Weiping Wang,"Institute of Information Engineering, CAS, China"
NIPS,2018,Multivariate Time Series Imputation with Generative Adversarial Networks,Yonghong Luo,Nankai University
NIPS,2018,Multivariate Time Series Imputation with Generative Adversarial Networks,Xiangrui Cai,Nankai University
NIPS,2018,Multivariate Time Series Imputation with Generative Adversarial Networks,Ying ZHANG,Nankai Univeristy
NIPS,2018,Multivariate Time Series Imputation with Generative Adversarial Networks,Jun Xu,Renmin University of China
NIPS,2018,Multivariate Time Series Imputation with Generative Adversarial Networks,Yuan xiaojie,Nankai Univeristy
NIPS,2018,Conditional Adversarial Domain Adaptation,Mingsheng Long,Tsinghua University
NIPS,2018,Conditional Adversarial Domain Adaptation,Tsinghua University CAO,Stanford University
NIPS,2018,Conditional Adversarial Domain Adaptation,Jianmin Wang,Tsinghua University
NIPS,2018,Conditional Adversarial Domain Adaptation,Michael Jordan,UC Berkeley
NIPS,2018,Relating Leverage Scores and Density using Regularized Christoffel Functions,Edouard Pauwels,IRIT
NIPS,2018,Relating Leverage Scores and Density using Regularized Christoffel Functions,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Relating Leverage Scores and Density using Regularized Christoffel Functions,Jean-Philippe Vert,Google
NIPS,2018,Non-Local Recurrent Network for Image Restoration,Ding Liu,Bytedance AI Lab
NIPS,2018,Non-Local Recurrent Network for Image Restoration,Bihan Wen,University of Illinois at Urbana-Champaign
NIPS,2018,Non-Local Recurrent Network for Image Restoration,Yuchen Fan,"Image Formation and Processing (IFP) Group, University of Illinois at Urbana-Champaign"
NIPS,2018,Non-Local Recurrent Network for Image Restoration,Chen Change Loy,Nanyang Technological University
NIPS,2018,Non-Local Recurrent Network for Image Restoration,Thomas Huang,UIUC
NIPS,2018,Bayesian Semi-supervised Learning with Graph Gaussian Processes,Yin Cheng Ng,University College London
NIPS,2018,Bayesian Semi-supervised Learning with Graph Gaussian Processes,Nicolò Colombo,University College London
NIPS,2018,Bayesian Semi-supervised Learning with Graph Gaussian Processes,Ricardo Silva,University College London
NIPS,2018,Foreground Clustering for Joint Segmentation and Localization in Videos and Images,Abhishek Sharma,Navinfo Europe Reseach
NIPS,2018,The Pessimistic Limits and Possibilities of Margin-based Losses in Semi-supervised Learning,Jesse Krijthe,Radboud University Nijmegen
NIPS,2018,The Pessimistic Limits and Possibilities of Margin-based Losses in Semi-supervised Learning,Marco Loog,Delft University of Technology
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Yizhe Zhang,Microsoft Research
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Michel Galley,Microsoft Research
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Jianfeng Gao,"Microsoft Research, Redmond, WA"
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Zhe Gan,Microsoft
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Xiujun Li,Microsoft Research Redmond
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Chris Brockett,Microsoft Research AI
NIPS,2018,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization,Bill Dolan,Microsoft
NIPS,2018,Symbolic Graph Reasoning Meets Convolutions,Xiaodan Liang,Sun Yat-sen University
NIPS,2018,Symbolic Graph Reasoning Meets Convolutions,Zhiting Hu,Carnegie Mellon University
NIPS,2018,Symbolic Graph Reasoning Meets Convolutions,Hao Zhang,Petuum Inc.
NIPS,2018,Symbolic Graph Reasoning Meets Convolutions,Liang Lin,Sun Yat-Sen University
NIPS,2018,Symbolic Graph Reasoning Meets Convolutions,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors,Arash Vahdat,Quadrant.ai (D-Wave)
NIPS,2018,DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors,Evgeny Andriyash,D-Wave
NIPS,2018,DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors,William Macready,D-Wave
NIPS,2018,Partially-Supervised Image Captioning,Peter Anderson,Georgia Tech
NIPS,2018,Partially-Supervised Image Captioning,Stephen Gould,ANU
NIPS,2018,Partially-Supervised Image Captioning,Mark Johnson,Macquarie University
NIPS,2018,Distributed Stochastic Optimization via Adaptive SGD,Ashok Cutkosky,Google
NIPS,2018,Distributed Stochastic Optimization via Adaptive SGD,Róbert Busa-Fekete,Yahoo! Research
NIPS,2018,Precision and Recall for Time Series,Nesime Tatbul,Intel Labs and MIT
NIPS,2018,Precision and Recall for Time Series,Tae Jun Lee,Microsoft
NIPS,2018,Precision and Recall for Time Series,Stan Zdonik,Brown University
NIPS,2018,Precision and Recall for Time Series,Mejbah Alam,Intel Labs
NIPS,2018,Precision and Recall for Time Series,Justin Gottschlich,Intel Labs
NIPS,2018,Virtual Class Enhanced Discriminative Embedding Learning,Binghui Chen,Beijing University of Posts and Telecommunications
NIPS,2018,Virtual Class Enhanced Discriminative Embedding Learning,Weihong Deng,Beijing University of Posts and Telecommunications
NIPS,2018,Virtual Class Enhanced Discriminative Embedding Learning,Haifeng Shen,"AI Labs, Didi Chuxing"
NIPS,2018,Attention in Convolutional LSTM for Gesture Recognition,Liang Zhang,"School of Computer Science and Technology, Xidian University, China"
NIPS,2018,Attention in Convolutional LSTM for Gesture Recognition,Guangming Zhu,Xidian University
NIPS,2018,Attention in Convolutional LSTM for Gesture Recognition,Lin Mei,"The Third Research Institute of Ministry of Public Security, China"
NIPS,2018,Attention in Convolutional LSTM for Gesture Recognition,Peiyi Shen,"School of Software, Xidian University, China"
NIPS,2018,Attention in Convolutional LSTM for Gesture Recognition,Syed Afaq Ali  Shah,"Department of Computer Science and Software Engineering, The University of Western Australia"
NIPS,2018,Attention in Convolutional LSTM for Gesture Recognition,Mohammed Bennamoun,University of Western Australia
NIPS,2018,Universal Growth in Production Economies,Simina Branzei,Purdue University
NIPS,2018,Universal Growth in Production Economies,Ruta Mehta,UIUC
NIPS,2018,Universal Growth in Production Economies,Noam Nisan,Hebrew University of Jerusalem and Microsoft Research
NIPS,2018,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors,Fei Jiang,The University of Hong Kong
NIPS,2018,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors,Guosheng Yin,University of Hong Kong
NIPS,2018,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors,Francesca Dominici,Harvard University
NIPS,2018,Efficient Stochastic Gradient Hard Thresholding,Pan Zhou,National University of Singapore
NIPS,2018,Efficient Stochastic Gradient Hard Thresholding,Xiaotong Yuan,Nanjing University of Information Science and Technology
NIPS,2018,Efficient Stochastic Gradient Hard Thresholding,Jiashi Feng,National University of Singapore
NIPS,2018,Neural Architecture Search with Bayesian Optimisation and Optimal Transport,Kirthevasan Kandasamy,Carnegie Mellon University
NIPS,2018,Neural Architecture Search with Bayesian Optimisation and Optimal Transport,Willie Neiswanger,Carnegie Mellon University
NIPS,2018,Neural Architecture Search with Bayesian Optimisation and Optimal Transport,Jeff Schneider,CMU
NIPS,2018,Neural Architecture Search with Bayesian Optimisation and Optimal Transport,Barnabas Poczos,Carnegie Mellon University
NIPS,2018,Neural Architecture Search with Bayesian Optimisation and Optimal Transport,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,Embedding Logical Queries on Knowledge Graphs,Will Hamilton,McGill University / FAIR
NIPS,2018,Embedding Logical Queries on Knowledge Graphs,Payal Bajaj,Stanford University
NIPS,2018,Embedding Logical Queries on Knowledge Graphs,Marinka Zitnik,Stanford University
NIPS,2018,Embedding Logical Queries on Knowledge Graphs,Dan Jurafsky,Stanford University
NIPS,2018,Embedding Logical Queries on Knowledge Graphs,Jure Leskovec,Stanford University and Pinterest
NIPS,2018,SEGA: Variance Reduction via Gradient Sketching,Filip Hanzely,KAUST
NIPS,2018,SEGA: Variance Reduction via Gradient Sketching,Konstantin Mishchenko,KAUST
NIPS,2018,SEGA: Variance Reduction via Gradient Sketching,Peter Richtarik,KAUST
NIPS,2018,Automatic Program Synthesis of Long Programs with a Learned Garbage Collector,Amit Zohar,Tel Aviv Universtiy
NIPS,2018,Automatic Program Synthesis of Long Programs with a Learned Garbage Collector,Lior Wolf,Facebook AI Research
NIPS,2018,One-Shot Unsupervised Cross Domain Translation,Sagie Benaim,Tel Aviv University
NIPS,2018,One-Shot Unsupervised Cross Domain Translation,Lior Wolf,Facebook AI Research
NIPS,2018,Algorithmic Linearly Constrained Gaussian Processes,Markus Lange-Hegermann,Hochschule Ostwestfalen-Lippe
NIPS,2018,Norm matters: efficient and accurate normalization schemes in deep networks,Elad Hoffer,Technion
NIPS,2018,Norm matters: efficient and accurate normalization schemes in deep networks,Ron Banner,Intel - Artificial Intelligence Products Group (AIPG)
NIPS,2018,Norm matters: efficient and accurate normalization schemes in deep networks,Itay Golan,Technion
NIPS,2018,Norm matters: efficient and accurate normalization schemes in deep networks,Daniel Soudry,Technion
NIPS,2018,Mixture Matrix Completion,Daniel Pimentel-Alarcon,Georgia State University
NIPS,2018,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem,Sampath Kannan,University of Pennsylvania
NIPS,2018,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem,Jamie Morgenstern,Georgia Tech
NIPS,2018,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem,Aaron Roth,University of Pennsylvania
NIPS,2018,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem,Bo Waggoner,Penn
NIPS,2018,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem,Zhiwei  Steven Wu,University of Minnesota
NIPS,2018,Revisiting Decomposable Submodular Function Minimization with Incidence Relations,Pan Li,University of Illinois Urbana-Champaign
NIPS,2018,Revisiting Decomposable Submodular Function Minimization with Incidence Relations,Olgica Milenkovic,University of Illinois at Urbana-Champaign
NIPS,2018,A Practical Algorithm for Distributed Clustering and Outlier Detection,Jiecao Chen,Indiana University Bloomington
NIPS,2018,A Practical Algorithm for Distributed Clustering and Outlier Detection,Erfan Sadeqi Azer,Indiana University
NIPS,2018,A Practical Algorithm for Distributed Clustering and Outlier Detection,Qin Zhang,Indiana University Bloomington
NIPS,2018,Learning to Reconstruct Shapes from Unseen Categories,Xiuming Zhang,MIT CSAIL
NIPS,2018,Learning to Reconstruct Shapes from Unseen Categories,Zhoutong Zhang,MIT
NIPS,2018,Learning to Reconstruct Shapes from Unseen Categories,Chengkai Zhang,Massachusetts Institute of Technology
NIPS,2018,Learning to Reconstruct Shapes from Unseen Categories,Josh Tenenbaum,MIT
NIPS,2018,Learning to Reconstruct Shapes from Unseen Categories,Bill Freeman,MIT/Google
NIPS,2018,Learning to Reconstruct Shapes from Unseen Categories,Jiajun Wu,MIT
NIPS,2018,Gradient Descent Meets Shift-and-Invert Preconditioning for Eigenvector Computation,Zhiqiang Xu,KAUST
NIPS,2018,Factored Bandits,Julian Zimmert,University of Copenhagen
NIPS,2018,Factored Bandits,Yevgeny Seldin,University of Copenhagen
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Eli Schwartz,IBM-Research
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Leonid Karlinsky,IBM-Research
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Joseph Shtok,IBM-Reseach
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Sivan Harary,IBM-Research
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Mattias Marder,IBM-Research
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Abhishek Kumar,IBM Research AI
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Rogerio Feris,IBM Research AI
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Raja Giryes,Tel Aviv University
NIPS,2018,Delta-encoder: an effective sample synthesis method for few-shot object recognition,Alex Bronstein,Technion
NIPS,2018,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization,Jie Cao,"Center for Research on Intelligent Perception and Computing (CRIPAC) at Institute of Automation, Chinese Academy of Sciences."
NIPS,2018,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization,Yibo Hu,"Institute of Automation, Chinese Academy of Sciences"
NIPS,2018,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization,Hongwen Zhang,CASIA
NIPS,2018,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization,Ran He,"NLPR, CASIA"
NIPS,2018,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization,Zhenan Sun,"Institute of Automation, Chinese Academy of Sciences (CASIA)"
NIPS,2018,Stochastic Cubic Regularization for Fast Nonconvex Optimization,Nilesh Tripuraneni,UC Berkeley
NIPS,2018,Stochastic Cubic Regularization for Fast Nonconvex Optimization,Mitchell Stern,UC Berkeley
NIPS,2018,Stochastic Cubic Regularization for Fast Nonconvex Optimization,Chi Jin,"University of California, Berkeley"
NIPS,2018,Stochastic Cubic Regularization for Fast Nonconvex Optimization,Jeff Regier,UC Berkeley
NIPS,2018,Stochastic Cubic Regularization for Fast Nonconvex Optimization,Michael Jordan,UC Berkeley
NIPS,2018,Adaptation to Easy Data in Prediction with Limited Advice,Tobias Thune,University of Copenhagen
NIPS,2018,Adaptation to Easy Data in Prediction with Limited Advice,Yevgeny Seldin,University of Copenhagen
NIPS,2018,Differentially Private Bayesian Inference for Exponential Families,Garrett Bernstein,University of Massachusetts Amherst
NIPS,2018,Differentially Private Bayesian Inference for Exponential Families,Dan Sheldon,University of Massachusetts Amherst
NIPS,2018,Playing hard exploration games by watching YouTube,Yusuf Aytar,DeepMind
NIPS,2018,Playing hard exploration games by watching YouTube,Tobias Pfaff,DeepMind
NIPS,2018,Playing hard exploration games by watching YouTube,David Budden,DeepMind
NIPS,2018,Playing hard exploration games by watching YouTube,Thomas Paine,DeepMind
NIPS,2018,Playing hard exploration games by watching YouTube,Ziyu Wang,Deepmind
NIPS,2018,Playing hard exploration games by watching YouTube,Nando de Freitas,DeepMind
NIPS,2018,Norm-Ranging LSH for Maximum Inner Product Search,Xiao Yan,The Chinese University of Hong Kong
NIPS,2018,Norm-Ranging LSH for Maximum Inner Product Search,Jinfeng Li,The Chinese University of Hong Kong
NIPS,2018,Norm-Ranging LSH for Maximum Inner Product Search,Xinyan Dai,The Chinese University of Hong Kong
NIPS,2018,Norm-Ranging LSH for Maximum Inner Product Search,Hongzhi Chen,CUHK
NIPS,2018,Norm-Ranging LSH for Maximum Inner Product Search,James Cheng,The Chinese University of Hong Kong
NIPS,2018,Fast Estimation of Causal Interactions using Wold Processes,Flavio Figueiredo,Universidade Federal de Minas Gerais
NIPS,2018,Fast Estimation of Causal Interactions using Wold Processes,Guilherme Resende Borges,Universidade Federal de Minas Gerais
NIPS,2018,Fast Estimation of Causal Interactions using Wold Processes,Pedro O.S. Vaz de Melo,"Universidade Federal de Minas Gerais, Brazil"
NIPS,2018,Fast Estimation of Causal Interactions using Wold Processes,Renato Assunção,UFMG
NIPS,2018,When do random forests fail?,Cheng Tang,George Washington University
NIPS,2018,When do random forests fail?,Damien Garreau,Max Planck Institute
NIPS,2018,When do random forests fail?,Ulrike von Luxburg,University of Tübingen
NIPS,2018,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes,Ronan Fruit,Inria Lille
NIPS,2018,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes,Matteo Pirotta,INRIA Lille-Nord Europe
NIPS,2018,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes,Alessandro Lazaric,Facebook Artificial Intelligence Research
NIPS,2018,Practical Methods for Graph Two-Sample Testing,Debarghya Ghoshdastidar,University of Tübingen
NIPS,2018,Practical Methods for Graph Two-Sample Testing,Ulrike von Luxburg,University of Tübingen
NIPS,2018,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations,Marco Ciccone,Politecnico di Milano
NIPS,2018,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations,Marco Gallieri,NNAISENSE
NIPS,2018,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations,Jonathan Masci,NNAISENSE
NIPS,2018,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations,Christian Osendorfer,NNAISENSE
NIPS,2018,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations,Faustino Gomez,NNAISENSE
NIPS,2018,Weakly Supervised Dense Event Captioning in Videos,Xuguang Duan,Tsinghua University
NIPS,2018,Weakly Supervised Dense Event Captioning in Videos,Wenbing Huang,Tencent AI Lab
NIPS,2018,Weakly Supervised Dense Event Captioning in Videos,Chuang Gan,MIT-IBM Watson AI Lab
NIPS,2018,Weakly Supervised Dense Event Captioning in Videos,Jingdong Wang,"Microsoft Research,"
NIPS,2018,Weakly Supervised Dense Event Captioning in Videos,Wenwu Zhu,Tsinghua University
NIPS,2018,Weakly Supervised Dense Event Captioning in Videos,Junzhou Huang,University of Texas at Arlington / Tencent AI Lab
NIPS,2018,From Stochastic Planning to Marginal MAP,Hao Cui,Tufts University
NIPS,2018,From Stochastic Planning to Marginal MAP,Radu Marinescu,IBM Research
NIPS,2018,From Stochastic Planning to Marginal MAP,Roni Khardon,"Indiana University, Bloomington"
NIPS,2018,Near-Optimal Policies for Dynamic Multinomial Logit Assortment Selection Models,Yining Wang,CMU
NIPS,2018,Near-Optimal Policies for Dynamic Multinomial Logit Assortment Selection Models,Xi Chen,NYU
NIPS,2018,Near-Optimal Policies for Dynamic Multinomial Logit Assortment Selection Models,Yuan Zhou,Indiana University Bloomington
NIPS,2018,The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal,Jiantao Jiao,"University of California, Berkeley"
NIPS,2018,The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal,Weihao Gao,UIUC
NIPS,2018,The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal,Yanjun Han,Stanford University
NIPS,2018,Deep Reinforcement Learning of Marked Temporal Point Processes,Utkarsh Upadhyay,Max Plank Institute for Software Systems
NIPS,2018,Deep Reinforcement Learning of Marked Temporal Point Processes,Abir De,Max Planck Insitute for Software Systems
NIPS,2018,Deep Reinforcement Learning of Marked Temporal Point Processes,Manuel Gomez Rodriguez,Max Planck Institute for Software Systems
NIPS,2018,Evidential Deep Learning to Quantify Classification Uncertainty,Murat Sensoy,Ozyegin University
NIPS,2018,Evidential Deep Learning to Quantify Classification Uncertainty,Lance Kaplan,U.S. Army Research Laboratory
NIPS,2018,Evidential Deep Learning to Quantify Classification Uncertainty,Melih Kandemir,Bosch Center for Artificial Intelligence (BCAI)
NIPS,2018,Parsimonious Bayesian deep networks,Mingyuan Zhou,University of Texas at Austin
NIPS,2018,Single-Agent Policy Tree Search With Guarantees,Laurent Orseau,DeepMind
NIPS,2018,Single-Agent Policy Tree Search With Guarantees,Levi Lelis,Universidade Federal de Viçosa
NIPS,2018,Single-Agent Policy Tree Search With Guarantees,Tor Lattimore,DeepMind
NIPS,2018,Single-Agent Policy Tree Search With Guarantees,Theophane Weber,DeepMind
NIPS,2018,Semi-crowdsourced Clustering with Deep Generative Models,Yucen Luo,Tsinghua University
NIPS,2018,Semi-crowdsourced Clustering with Deep Generative Models,TIAN TIAN,Tsinghua University
NIPS,2018,Semi-crowdsourced Clustering with Deep Generative Models,Jiaxin Shi,Tsinghua University
NIPS,2018,Semi-crowdsourced Clustering with Deep Generative Models,Jun Zhu,Tsinghua University
NIPS,2018,Semi-crowdsourced Clustering with Deep Generative Models,Bo Zhang,Xiaomi Corp.
NIPS,2018,The committee machine: Computational to statistical gaps in learning a two-layers neural network,Benjamin Aubin,Ipht Saclay
NIPS,2018,The committee machine: Computational to statistical gaps in learning a two-layers neural network,Antoine Maillard,Ecole Normale Supérieure
NIPS,2018,The committee machine: Computational to statistical gaps in learning a two-layers neural network,jean barbier,EPFL
NIPS,2018,The committee machine: Computational to statistical gaps in learning a two-layers neural network,Florent Krzakala,École Normale Supérieure
NIPS,2018,The committee machine: Computational to statistical gaps in learning a two-layers neural network,Nicolas Macris,EPFL
NIPS,2018,The committee machine: Computational to statistical gaps in learning a two-layers neural network,Lenka Zdeborová,CEA Saclay
NIPS,2018,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,Avital Oliver,Google Brain
NIPS,2018,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,Augustus Odena,Google Brain
NIPS,2018,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,Colin A Raffel,Google Brain Resident
NIPS,2018,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,Dogus Cubuk,Google Brain
NIPS,2018,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,Ian Goodfellow,Google
NIPS,2018,Re-evaluating evaluation,David Balduzzi,DeepMind
NIPS,2018,Re-evaluating evaluation,Karl Tuyls,DeepMind
NIPS,2018,Re-evaluating evaluation,Julien Perolat,DeepMind
NIPS,2018,Re-evaluating evaluation,Thore Graepel,DeepMind
NIPS,2018,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres",Oisín Moran,Inscribe.ai
NIPS,2018,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres",Piergiorgio Caramazza,University of Glasgow
NIPS,2018,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres",Daniele Faccio,University of Glasgow
NIPS,2018,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres",Rod Murray-Smith,University of Glasgow
NIPS,2018,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals,Tom Dupré la Tour,Télécom ParisTech
NIPS,2018,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals,Thomas Moreau,Inria
NIPS,2018,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals,Mainak Jas,Télécom ParisTech
NIPS,2018,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals,Alexandre Gramfort,"INRIA, Université Paris-Saclay"
NIPS,2018,Data-Efficient Hierarchical Reinforcement Learning,Ofir Nachum,Google Brain
NIPS,2018,Data-Efficient Hierarchical Reinforcement Learning,Shixiang (Shane) Gu,"Google Brain, University of Cambridge"
NIPS,2018,Data-Efficient Hierarchical Reinforcement Learning,Honglak Lee,Google Brain
NIPS,2018,Data-Efficient Hierarchical Reinforcement Learning,Sergey Levine,UC Berkeley
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Daniel Fried,UC Berkeley
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Ronghang Hu,"University of California, Berkeley"
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Volkan Cirik,Carnegie Mellon University
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Anna Rohrbach,UC Berkeley
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Jacob Andreas,UC Berkeley
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,LP Morency,Carnegie Mellon University
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Taylor Berg-Kirkpatrick,Carnegie Mellon University
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Kate Saenko,Boston University
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Dan Klein,UC Berkeley
NIPS,2018,Speaker-Follower Models for Vision-and-Language Navigation,Prof. Darrell,UC Berkeley
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Edward Hughes,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Joel Leibo,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Matthew Phillips,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Karl Tuyls,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Edgar Dueñez-Guzman,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Antonio García Castañeda,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Iain Dunning,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Tina Zhu,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Kevin McKee,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Raphael Koster,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Heather Roff,DeepMind
NIPS,2018,Inequity aversion improves cooperation in intertemporal social dilemmas,Thore Graepel,DeepMind
NIPS,2018,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds,David Reeb,Bosch Center for Artificial Intelligence (BCAI)
NIPS,2018,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds,Andreas Doerr,"BCAI, MPI-IS AMD"
NIPS,2018,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds,Sebastian Gerwinn,Bosch Center for Artificial Intelligence
NIPS,2018,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds,Barbara Rakitsch,Bosch Center for Artificial Intelligence
NIPS,2018,High-dimensional Bayesian optimization via collaborative filtering,Nicolo Fusi,Microsoft Research
NIPS,2018,High-dimensional Bayesian optimization via collaborative filtering,Rishit Sheth,Microsoft Research New England
NIPS,2018,High-dimensional Bayesian optimization via collaborative filtering,Melih Elibol,UC Berkeley
NIPS,2018,Stochastic Spectral and Conjugate Descent Methods,Dmitry Kovalev,KAUST
NIPS,2018,Stochastic Spectral and Conjugate Descent Methods,Peter Richtarik,KAUST
NIPS,2018,Stochastic Spectral and Conjugate Descent Methods,Eduard Gorbunov,Moscow Institute of Physics and Technology
NIPS,2018,Stochastic Spectral and Conjugate Descent Methods,Elnur Gasanov,MIPT
NIPS,2018,But How Does It Work in Theory? Linear SVM with Random Features,Yitong Sun,University of Michigan
NIPS,2018,But How Does It Work in Theory? Linear SVM with Random Features,Anna Gilbert,University of Michigan
NIPS,2018,But How Does It Work in Theory? Linear SVM with Random Features,Ambuj Tewari,University of Michigan
NIPS,2018,Boosting Black Box Variational Inference,Francesco Locatello,MPI Tübingen - ETH Zürich
NIPS,2018,Boosting Black Box Variational Inference,Gideon Dresdner,ETH Zürich
NIPS,2018,Boosting Black Box Variational Inference,Rajiv Khanna,University of Texas at Austin
NIPS,2018,Boosting Black Box Variational Inference,Isabel Valera,Max Planck Institute for Intelligent Systems
NIPS,2018,Boosting Black Box Variational Inference,Gunnar Raetsch,ETHZ
NIPS,2018,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,Hassan Ashtiani,McMaster University
NIPS,2018,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,Shai Ben-David,Universitys of Waterloo
NIPS,2018,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,Nick Harvey,University of British Columbia
NIPS,2018,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,Christopher Liaw,University of British Columbia
NIPS,2018,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,Abbas Mehrabian,Mcgill University
NIPS,2018,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,Yaniv Plan,University of British Columbia
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Marc Lanctot,DeepMind
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Sriram Srinivasan,Google
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Vinicius Zambaldi,Deepmind
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Julien Perolat,DeepMind
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Karl Tuyls,DeepMind
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Remi Munos,DeepMind
NIPS,2018,Actor-Critic Policy Optimization in PartiallyObservable Multiagent Environments,Michael Bowling,DeepMind / University of Alberta
NIPS,2018,Derivative Estimation in Random Design,Yu Liu,Iowa State University
NIPS,2018,Derivative Estimation in Random Design,Kris De Brabanter,ISU
NIPS,2018,Zeroth-order (Non)-Convex Stochastic Optimization via Conditional Gradient and Gradient Updates,Krishnakumar Balasubramanian,"University of California, Davis"
NIPS,2018,Zeroth-order (Non)-Convex Stochastic Optimization via Conditional Gradient and Gradient Updates,Saeed Ghadimi,Princeton University
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Daniel Johnson,Harvey Mudd College
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Daniel Gorelik,Harvey Mudd College
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Ross E Mawhorter,Harvey Mudd College
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Kyle Suver,Harvey Mudd College
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Weiqing Gu,Harvey Mudd College
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Steven Xing,Intel Corporation
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Cody Gabriel,Intel Corporation
NIPS,2018,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments,Peter Sankhagowit,Intel Corporation
NIPS,2018,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation,Jing LI,"University of Nantes, LS2N lab"
NIPS,2018,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation,Rafal Mantiuk,University of Cambridge
NIPS,2018,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation,Junle Wang,Tencent
NIPS,2018,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation,Suiyi Ling,université de nantes
NIPS,2018,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation,Patrick Le Callet,"""Universite de Nantes, France"""
NIPS,2018,Infinite-Horizon Gaussian Processes,Arno Solin,Aalto University
NIPS,2018,Infinite-Horizon Gaussian Processes,James Hensman,PROWLER.io
NIPS,2018,Infinite-Horizon Gaussian Processes,Richard E Turner,University of Cambridge
NIPS,2018,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization,Minshuo Chen,Georgia Tech
NIPS,2018,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization,Lin Yang,Princeton University
NIPS,2018,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization,Mengdi Wang,Princeton University
NIPS,2018,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization,Tuo Zhao,Georgia Tech
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Zijun Wei,Stony Brook University
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Boyu Wang,Stony Brook University
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Minh Hoai Nguyen,Stony Brook University
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Jianming Zhang,Adobe Research
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Zhe Lin,Adobe Research
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Xiaohui Shen,ByteDance AI Lab
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Radomir Mech,Adobe Systems Incorporated
NIPS,2018,Sequence-to-Segment Networks for Segment Detection,Dimitris Samaras,Stony Brook University
NIPS,2018,Scaling the Poisson GLM to massive neural datasets through polynomial approximations,David Zoltowski,Princeton University
NIPS,2018,Scaling the Poisson GLM to massive neural datasets through polynomial approximations,Jonathan W Pillow,Princeton University
NIPS,2018,Multiplicative Weights Updates with Constant Step-Size in Graphical Constant-Sum Games,Yun Kuen Cheung,Singapore University of Technology and Design
NIPS,2018,Why Is My Classifier Discriminatory?,Irene Chen,MIT
NIPS,2018,Why Is My Classifier Discriminatory?,Fredrik Johansson,MIT
NIPS,2018,Why Is My Classifier Discriminatory?,David Sontag,MIT
NIPS,2018,Multi-Layered Gradient Boosting Decision Trees,Ji Feng,Nanjing University & Sinovation Ventures AI Institute
NIPS,2018,Multi-Layered Gradient Boosting Decision Trees,Yang Yu,Nanjing University
NIPS,2018,Multi-Layered Gradient Boosting Decision Trees,Zhi-Hua Zhou,Nanjing University
NIPS,2018,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning,Tom Zahavy,Technion
NIPS,2018,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning,Matan Haroush,Technion
NIPS,2018,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning,Nadav Merlis,Technion
NIPS,2018,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning,Daniel J Mankowitz,Technion
NIPS,2018,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning,Shie Mannor,Technion
NIPS,2018,Neural Code Comprehension: A Learnable Representation of Code Semantics,Tal Ben-Nun,ETH Zurich
NIPS,2018,Neural Code Comprehension: A Learnable Representation of Code Semantics,Alice Shoshana Jakobovits,ETH Zurich
NIPS,2018,Neural Code Comprehension: A Learnable Representation of Code Semantics,Torsten Hoefler,ETH Zurich
NIPS,2018,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN,Maciej Zieba,"Wroclaw University of Science and Technology, Tooploox"
NIPS,2018,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN,Piotr Semberecki,"Wrocław University of Science and Technology, Tooploox"
NIPS,2018,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN,Tarek El-Gaaly,Voyage
NIPS,2018,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN,Tomasz Trzcinski,Tooploox / Warsaw University of Technology
NIPS,2018,Modern Neural Networks Generalize on Small Data Sets,Matthew Olson,University of Pennsylvania
NIPS,2018,Modern Neural Networks Generalize on Small Data Sets,Adi Wyner,University of Pennsylvania
NIPS,2018,Modern Neural Networks Generalize on Small Data Sets,Richard Berk,
NIPS,2018,Escaping Saddle Points in Constrained Optimization,Aryan Mokhtari,MIT
NIPS,2018,Escaping Saddle Points in Constrained Optimization,Asuman Ozdaglar,Massachusetts Institute of Technology
NIPS,2018,Escaping Saddle Points in Constrained Optimization,Ali Jadbabaie,MIT
NIPS,2018,Adversarial Attacks on Stochastic Bandits,Kwang-Sung Jun,UW-Madison
NIPS,2018,Adversarial Attacks on Stochastic Bandits,Lihong Li,Google Inc.
NIPS,2018,Adversarial Attacks on Stochastic Bandits,Yuzhe Ma,University of Wisconsin-Madison
NIPS,2018,Adversarial Attacks on Stochastic Bandits,Jerry Zhu,University of Wisconsin-Madison
NIPS,2018,Optimal Subsampling with Influence Functions,Daniel Ting,Tableau Software
NIPS,2018,Optimal Subsampling with Influence Functions,Eric Brochu,Tableau Software
NIPS,2018,Equality of Opportunity in Classification: A Causal Approach,Junzhe Zhang,Purdue University
NIPS,2018,Equality of Opportunity in Classification: A Causal Approach,Elias Bareinboim,Purdue
NIPS,2018,Unsupervised Attention-guided Image-to-Image Translation,Youssef Alami Mejjati,University of Bath
NIPS,2018,Unsupervised Attention-guided Image-to-Image Translation,Christian Richardt,University of Bath
NIPS,2018,Unsupervised Attention-guided Image-to-Image Translation,James Tompkin,Brown University
NIPS,2018,Unsupervised Attention-guided Image-to-Image Translation,Darren Cosker,University of Bath
NIPS,2018,Unsupervised Attention-guided Image-to-Image Translation,Kwang In Kim,University of Bath
NIPS,2018,NEON 2: Finding Local Minima via First-Order Oracles,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2018,NEON 2: Finding Local Minima via First-Order Oracles,Yuanzhi Li,Princeton University
NIPS,2018,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization,Sijia Liu,"MIT-IBM Watson AI Lab, IBM Research AI"
NIPS,2018,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization,Bhavya Kailkhura,Lawrence Livermore National Lab
NIPS,2018,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization,Pin-Yu Chen,IBM Research AI
NIPS,2018,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization,Paishun Ting,University of Michigan
NIPS,2018,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization,Shiyu Chang,IBM T.J. Watson Research Center
NIPS,2018,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization,Lisa Amini,IBM Research
NIPS,2018,Online Structured Laplace Approximations For Overcoming Catastrophic Forgetting,Hippolyt Ritter,University College London
NIPS,2018,Online Structured Laplace Approximations For Overcoming Catastrophic Forgetting,Alex Botev,University College London
NIPS,2018,Online Structured Laplace Approximations For Overcoming Catastrophic Forgetting,David Barber,University College London
NIPS,2018,DeepProbLog:  Neural Probabilistic Logic Programming,Robin Manhaeve,KU Leuven
NIPS,2018,DeepProbLog:  Neural Probabilistic Logic Programming,Sebastijan Dumancic,KU LEUVEN
NIPS,2018,DeepProbLog:  Neural Probabilistic Logic Programming,Angelika Kimmig,Cardiff University
NIPS,2018,DeepProbLog:  Neural Probabilistic Logic Programming,Thomas Demeester,Ghent University
NIPS,2018,DeepProbLog:  Neural Probabilistic Logic Programming,Luc De Raedt,KU Leuven
NIPS,2018,Convergence of Cubic Regularization for Nonconvex Optimization under KL Property,Yi Zhou,The Ohio State University
NIPS,2018,Convergence of Cubic Regularization for Nonconvex Optimization under KL Property,Zhe Wang,Ohio State University
NIPS,2018,Convergence of Cubic Regularization for Nonconvex Optimization under KL Property,Yingbin Liang,The Ohio State University
NIPS,2018,Direct Estimation of Differences in Causal Graphs,Yuhao Wang,MIT
NIPS,2018,Direct Estimation of Differences in Causal Graphs,Chandler Squires,Massachusetts Institute of Technology
NIPS,2018,Direct Estimation of Differences in Causal Graphs,Anastasiya Belyaeva,MIT
NIPS,2018,Direct Estimation of Differences in Causal Graphs,Caroline Uhler,Massachusetts Institute of Technology
NIPS,2018,Sublinear Time Low-Rank Approximation of Distance Matrices,Ainesh Bakshi,Carnegie Mellon University
NIPS,2018,Sublinear Time Low-Rank Approximation of Distance Matrices,David Woodruff,Carnegie Mellon University
NIPS,2018,Variational PDEs for Acceleration on Manifolds and Application to Diffeomorphisms,Ganesh Sundaramoorthi,UTRC
NIPS,2018,Variational PDEs for Acceleration on Manifolds and Application to Diffeomorphisms,Anthony Yezzi,Georgia Tech
NIPS,2018,Bayesian Inference of Temporal Task Specifications from Demonstrations,Ankit Shah,Massachusetts Institute of Technology
NIPS,2018,Bayesian Inference of Temporal Task Specifications from Demonstrations,Pritish Kamath,MIT
NIPS,2018,Bayesian Inference of Temporal Task Specifications from Demonstrations,Julie A Shah,MIT
NIPS,2018,Bayesian Inference of Temporal Task Specifications from Demonstrations,Shen Li,MIT
NIPS,2018,Data center cooling using model-predictive control,Nevena Lazic,Google
NIPS,2018,Data center cooling using model-predictive control,Craig Boutilier,Google
NIPS,2018,Data center cooling using model-predictive control,Tyler Lu,Google
NIPS,2018,Data center cooling using model-predictive control,Eehern Wong,Google
NIPS,2018,Data center cooling using model-predictive control,Binz Roy,Google
NIPS,2018,Data center cooling using model-predictive control,MK Ryu,Google
NIPS,2018,Data center cooling using model-predictive control,Greg Imwalle,Google
NIPS,2018,Acceleration through Optimistic No-Regret Dynamics,Jun-Kun Wang,Georgia Institute of Technology
NIPS,2018,Acceleration through Optimistic No-Regret Dynamics,Jacob Abernethy,Georgia Institute of Technolog
NIPS,2018,Minimax Estimation of Neural Net Distance,Kaiyi Ji,The Ohio State University
NIPS,2018,Minimax Estimation of Neural Net Distance,Yingbin Liang,The Ohio State University
NIPS,2018,Bipartite Stochastic Block Models with Tiny Clusters,Stefan Neumann,University of Vienna
NIPS,2018,Learning sparse neural networks via sensitivity-driven regularization,Enzo Tartaglione,Politecnico di Torino
NIPS,2018,Learning sparse neural networks via sensitivity-driven regularization,Skjalg  Lepsøy,Telecom Italia
NIPS,2018,Learning sparse neural networks via sensitivity-driven regularization,Attilio Fiandrotti,POLITO
NIPS,2018,Learning sparse neural networks via sensitivity-driven regularization,Gianluca Francini,Telecom Italia
NIPS,2018,Faster Online Learning of Optimal Threshold for  Consistent F-measure Optimization,Xiaoxuan Zhang,University of Iowa
NIPS,2018,Faster Online Learning of Optimal Threshold for  Consistent F-measure Optimization,Mingrui Liu,The University of Iowa
NIPS,2018,Faster Online Learning of Optimal Threshold for  Consistent F-measure Optimization,Xun Zhou,University of Iowa
NIPS,2018,Faster Online Learning of Optimal Threshold for  Consistent F-measure Optimization,Tianbao Yang,The University of Iowa
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Gamaleldin Elsayed,Google Brain
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Shreya Shankar,Stanford University
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Brian Cheung,UC Berkeley
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Nicolas Papernot,Google Brain
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Alexey Kurakin,Google Brain
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Ian Goodfellow,Google
NIPS,2018,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,Jascha Sohl-Dickstein,Google Brain
NIPS,2018,Faster Neural Networks Straight from JPEG,Lionel Gueguen,UBER
NIPS,2018,Faster Neural Networks Straight from JPEG,Alex Sergeev,"Uber Technologies Inc,"
NIPS,2018,Faster Neural Networks Straight from JPEG,Ben Kadlec,Uber
NIPS,2018,Faster Neural Networks Straight from JPEG,Rosanne Liu,Uber AI Labs
NIPS,2018,Faster Neural Networks Straight from JPEG,Jason Yosinski,Uber AI Labs; Recursion
NIPS,2018,TopRank: A practical algorithm for online stochastic ranking,Tor Lattimore,DeepMind
NIPS,2018,TopRank: A practical algorithm for online stochastic ranking,Branislav Kveton,Google
NIPS,2018,TopRank: A practical algorithm for online stochastic ranking,Shuai Li,The Chinese University of Hong Kong
NIPS,2018,TopRank: A practical algorithm for online stochastic ranking,Csaba Szepesvari,University of Alberta
NIPS,2018,Learning from discriminative feature feedback,Sanjoy Dasgupta,UC San Diego
NIPS,2018,Learning from discriminative feature feedback,Sivan Sabato,Ben-Gurion University of the Negev
NIPS,2018,Learning from discriminative feature feedback,Nick Roberts,UC San Diego
NIPS,2018,Learning from discriminative feature feedback,Akansha Dey,UCSD
NIPS,2018,RetGK: Graph Kernels based on Return Probabilities of Random Walks,Zhen Zhang,WASHINGTON UNIVERSITY IN ST.LOUIS
NIPS,2018,RetGK: Graph Kernels based on Return Probabilities of Random Walks,Mianzhi Wang,Washington University in St. Louis
NIPS,2018,RetGK: Graph Kernels based on Return Probabilities of Random Walks,Yijian Xiang,Washington University in St. Louis
NIPS,2018,RetGK: Graph Kernels based on Return Probabilities of Random Walks,Yan Huang,Washington University in St. Louis
NIPS,2018,RetGK: Graph Kernels based on Return Probabilities of Random Walks,Arye Nehorai,WASHINGTON UNIVERSITY IN ST.LOUIS
NIPS,2018,Deep Generative Markov State Models,Hao Wu,Freie Universität Berlin
NIPS,2018,Deep Generative Markov State Models,Andreas Mardt,
NIPS,2018,Deep Generative Markov State Models,Luca Pasquali,Freie Universitat Berlin
NIPS,2018,Deep Generative Markov State Models,Frank Noe,FU Berlin
NIPS,2018,Early Stopping for Nonparametric Testing,Meimei Liu,Duke University
NIPS,2018,Early Stopping for Nonparametric Testing,Guang Cheng,Purdue University
NIPS,2018,Learning to Specialize with Knowledge Distillation for Visual Question Answering,Jonghwan Mun,POSTECH
NIPS,2018,Learning to Specialize with Knowledge Distillation for Visual Question Answering,Kimin Lee,Korea Advanced Institute of Science and Technology
NIPS,2018,Learning to Specialize with Knowledge Distillation for Visual Question Answering,Jinwoo Shin,KAIST; AITRICS
NIPS,2018,Learning to Specialize with Knowledge Distillation for Visual Question Answering,Bohyung Han,Seoul National University
NIPS,2018,A Lyapunov-based Approach to Safe Reinforcement Learning,Yinlam Chow,DeepMind
NIPS,2018,A Lyapunov-based Approach to Safe Reinforcement Learning,Ofir Nachum,Google Brain
NIPS,2018,A Lyapunov-based Approach to Safe Reinforcement Learning,Edgar Duenez-Guzman,DeepMind
NIPS,2018,A Lyapunov-based Approach to Safe Reinforcement Learning,Mohammad Ghavamzadeh,FaceBook FAIR
NIPS,2018,Credit Assignment For Collective Multiagent RL With Global Rewards,Duc Nguyen,Singapore Management University
NIPS,2018,Credit Assignment For Collective Multiagent RL With Global Rewards,Akshat Kumar,Singapore Management University
NIPS,2018,Credit Assignment For Collective Multiagent RL With Global Rewards,Hoong Chuin Lau,Singapore Management University
NIPS,2018,Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes,Loucas Pillaud-Vivien,INRIA - Ecole Normale Supérieure
NIPS,2018,Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes,Alessandro Rudi,"INRIA, Ecole Normale Superieure"
NIPS,2018,Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes,Francis Bach,INRIA - Ecole Normale Superieure
NIPS,2018,Does mitigating ML's impact disparity require treatment disparity?,Zachary  Lipton,Carnegie Mellon University
NIPS,2018,Does mitigating ML's impact disparity require treatment disparity?,Julian McAuley,UCSD
NIPS,2018,Does mitigating ML's impact disparity require treatment disparity?,Alexandra Chouldechova,CMU
NIPS,2018,Proximal Graphical Event Models,Debarun Bhattacharjya,IBM Research
NIPS,2018,Proximal Graphical Event Models,Shankar Subramanian,IBM Research
NIPS,2018,Proximal Graphical Event Models,Tian Gao,IBM Research AI
NIPS,2018,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments,Mahdi Imani,Texas A&M University
NIPS,2018,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments,Seyede Fatemeh Ghoreishi,Texas A&M University
NIPS,2018,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments,Ulisses M. Braga-Neto,Texas A&M University
NIPS,2018,Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data,Yuanzhi Li,Princeton University
NIPS,2018,Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data,Yingyu Liang,University of Wisconsin Madison
NIPS,2018,Hamiltonian Variational Auto-Encoder,Anthony L Caterini,University of Oxford
NIPS,2018,Hamiltonian Variational Auto-Encoder,Arnaud Doucet,Oxford
NIPS,2018,Hamiltonian Variational Auto-Encoder,Dino Sejdinovic,University of Oxford
NIPS,2018,Modelling and unsupervised learning of symmetric deformable object categories,James Thewlis,University of Oxford
NIPS,2018,Modelling and unsupervised learning of symmetric deformable object categories,Hakan Bilen,University of Edinburgh
NIPS,2018,Modelling and unsupervised learning of symmetric deformable object categories,Andrea Vedaldi,University of Oxford and Facebook
NIPS,2018,Sequential Monte Carlo for probabilistic graphical models via twisted targets,Fredrik Lindsten,Uppsala University
NIPS,2018,Sequential Monte Carlo for probabilistic graphical models via twisted targets,Jouni Helske,Linköping University
NIPS,2018,Sequential Monte Carlo for probabilistic graphical models via twisted targets,Matti Vihola,University of Jyväskylä
NIPS,2018,Statistical mechanics of low-rank tensor decomposition,Jonathan Kadmon,Stanford University
NIPS,2018,Statistical mechanics of low-rank tensor decomposition,Surya Ganguli,Stanford
NIPS,2018,Variational Bayesian Monte Carlo,Luigi Acerbi,University of Geneva
NIPS,2018,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion,Jacob Buckman,Johns Hopkins University
NIPS,2018,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion,Danijar Hafner,Google Brain & UCL
NIPS,2018,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion,George Tucker,Google Brain
NIPS,2018,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion,Eugene Brevdo,Google
NIPS,2018,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion,Honglak Lee,Google Brain
NIPS,2018,Efficient Online Portfolio with Logarithmic Regret,Haipeng Luo,University of Southern California
NIPS,2018,Efficient Online Portfolio with Logarithmic Regret,Chen-Yu Wei,University of Southern California
NIPS,2018,Efficient Online Portfolio with Logarithmic Regret,Kai Zheng,Peking University
NIPS,2018,Algorithms and Theory for Multiple-Source Adaptation,Judy Hoffman,FAIR and Georgia Tech
NIPS,2018,Algorithms and Theory for Multiple-Source Adaptation,Mehryar Mohri,Courant Inst. of Math. Sciences & Google Research
NIPS,2018,Algorithms and Theory for Multiple-Source Adaptation,Ningshan Zhang,NYU
NIPS,2018,Online Reciprocal Recommendation with Theoretical Performance Guarantees,Claudio Gentile,INRIA
NIPS,2018,Online Reciprocal Recommendation with Theoretical Performance Guarantees,Nikos Parotsidis,University of Rome Tor Vergata
NIPS,2018,Online Reciprocal Recommendation with Theoretical Performance Guarantees,Fabio Vitale,Sapienza University of Rome
NIPS,2018,How SGD selects the global minima in over-parameterized learning: A stability perspective,Lei Wu,Peking University
NIPS,2018,How SGD selects the global minima in over-parameterized learning: A stability perspective,Chao Ma,Princeton University
NIPS,2018,How SGD selects the global minima in over-parameterized learning: A stability perspective,Weinan E,Princeton University
NIPS,2018,Differentiable MPC for End-to-end Planning and Control,Brandon Amos,Carnegie Mellon University
NIPS,2018,Differentiable MPC for End-to-end Planning and Control,Ivan Jimenez,Georgia Tech
NIPS,2018,Differentiable MPC for End-to-end Planning and Control,Jacob Sacks,Georgia Institute of Technology
NIPS,2018,Differentiable MPC for End-to-end Planning and Control,Byron Boots,Georgia Tech / Google Brain
NIPS,2018,Differentiable MPC for End-to-end Planning and Control,J. Zico Kolter,Carnegie Mellon University / Bosch Center for AI
NIPS,2018,Bilevel learning of the Group Lasso structure,Jordan Frecon,Istituto Italiano di Tecnologia
NIPS,2018,Bilevel learning of the Group Lasso structure,Saverio Salzo,Istituto Italiano di Tecnologia
NIPS,2018,Bilevel learning of the Group Lasso structure,Massimiliano Pontil,IIT & UCL
NIPS,2018,Information-theoretic Limits for Community Detection in Network Models,Chuyang Ke,Purdue University
NIPS,2018,Information-theoretic Limits for Community Detection in Network Models,Jean Honorio,Purdue University
NIPS,2018,Distributionally Robust Graphical Models,Rizal Fathony,University of Illinois at Chicago
NIPS,2018,Distributionally Robust Graphical Models,Ashkan Rezaei,University of Illinois at Chicago
NIPS,2018,Distributionally Robust Graphical Models,Mohammad Ali Bashiri,University of Illinois at Chicago
NIPS,2018,Distributionally Robust Graphical Models,Xinhua Zhang,UIC
NIPS,2018,Distributionally Robust Graphical Models,Brian Ziebart,University of Illinois at Chicago
NIPS,2018,Transfer Learning with Neural AutoML,Catherine Wong,MIT
NIPS,2018,Transfer Learning with Neural AutoML,Neil Houlsby,Google
NIPS,2018,Transfer Learning with Neural AutoML,Yifeng Lu,
NIPS,2018,Transfer Learning with Neural AutoML,Andrea Gesmundo,Google
NIPS,2018,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity,Conghui Tan,The Chinese University of Hong Kong
NIPS,2018,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity,Tong Zhang,The Australian National University
NIPS,2018,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity,Shiqian Ma,
NIPS,2018,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity,Ji Liu,"University of Rochester, Tencent AI lab"
NIPS,2018,On preserving non-discrimination when combining expert advice,Avrim Blum,Toyota Technological Institute at Chicago
NIPS,2018,On preserving non-discrimination when combining expert advice,Suriya Gunasekar,TTI Chicago
NIPS,2018,On preserving non-discrimination when combining expert advice,Thodoris Lykouris,Cornell University
NIPS,2018,On preserving non-discrimination when combining expert advice,Nati Srebro,TTI-Chicago
NIPS,2018,Learning safe policies with expert guidance,Jessie Huang,McGill University
NIPS,2018,Learning safe policies with expert guidance,Fa Wu,McGill
NIPS,2018,Learning safe policies with expert guidance,Doina Precup,McGill University / DeepMind Montreal
NIPS,2018,Learning safe policies with expert guidance,Yang Cai,McGill University
NIPS,2018,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data,Ehsan Hajiramezanali,Texas A&M University
NIPS,2018,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data,Siamak  Zamani Dadaneh,Texas A&M University
NIPS,2018,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data,Alireza Karbalayghareh,Texas A&M University
NIPS,2018,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data,Mingyuan Zhou,University of Texas at Austin
NIPS,2018,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data,Xiaoning Qian,Texas A&M
NIPS,2018,Learning SMaLL Predictors,Vikas Garg,MIT
NIPS,2018,Learning SMaLL Predictors,Ofer Dekel,Microsoft Research
NIPS,2018,Learning SMaLL Predictors,Lin Xiao,Microsoft Research
NIPS,2018,Phase Retrieval Under a Generative Prior,Paul Hand,Northeastern University
NIPS,2018,Phase Retrieval Under a Generative Prior,Oscar Leong,Rice University
NIPS,2018,Phase Retrieval Under a Generative Prior,Vlad Voroninski,Helm.ai
NIPS,2018,Quadrature-based features for kernel approximation,Marina Munkhoeva,Skoltech / Skolkovo Institute of Science and Technology
NIPS,2018,Quadrature-based features for kernel approximation,Yermek Kapushev,Skolkovo Institute of Science and Technology
NIPS,2018,Quadrature-based features for kernel approximation,Evgeny Burnaev,Skoltech
NIPS,2018,Quadrature-based features for kernel approximation,Ivan Oseledets,Skoltech
NIPS,2018,Reducing Network Agnostophobia,Akshay Raj Dhamija,University of Colorado Colorado Springs
NIPS,2018,Reducing Network Agnostophobia,Manuel Günther,Vision and Security Technology Lab (VaST)
NIPS,2018,Reducing Network Agnostophobia,Terrance Boult,University of Colorado Colorado Springs
NIPS,2018,A Stein variational Newton method,Gianluca Detommaso,University of Bath / The Alan Turing Institute
NIPS,2018,A Stein variational Newton method,Tiangang Cui,Monash University
NIPS,2018,A Stein variational Newton method,Youssef Marzouk,Massachusetts Institute of Technology
NIPS,2018,A Stein variational Newton method,Alessio Spantini,MIT
NIPS,2018,A Stein variational Newton method,Robert Scheichl,Heidelberg University
NIPS,2018,Watch Your Step: Learning Node Embeddings via Graph Attention,Sami Abu-El-Haija,Information Sciences Institute @ USC
NIPS,2018,Watch Your Step: Learning Node Embeddings via Graph Attention,Bryan Perozzi,Google AI
NIPS,2018,Watch Your Step: Learning Node Embeddings via Graph Attention,Rami Al-Rfou,Google Research
NIPS,2018,Watch Your Step: Learning Node Embeddings via Graph Attention,Alex Alemi,Google
NIPS,2018,Visual Goal-Conditioned Reinforcement Learning by Representation Learning,Ashvin Nair,UC Berkeley
NIPS,2018,Visual Goal-Conditioned Reinforcement Learning by Representation Learning,Vitchyr Pong,UC Berkeley
NIPS,2018,Visual Goal-Conditioned Reinforcement Learning by Representation Learning,Murtaza Dalal,"University of California, Berkeley"
NIPS,2018,Visual Goal-Conditioned Reinforcement Learning by Representation Learning,Shikhar Bahl,UC Berkeley
NIPS,2018,Visual Goal-Conditioned Reinforcement Learning by Representation Learning,Steven Lin,UC Berkeley
NIPS,2018,Visual Goal-Conditioned Reinforcement Learning by Representation Learning,Sergey Levine,UC Berkeley
NIPS,2018,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition,Kuan Han,Purdue University
NIPS,2018,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition,Haiguang Wen,Purdue University
NIPS,2018,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition,Yizhen Zhang,Purdue University
NIPS,2018,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition,Di Fu,Purdue University
NIPS,2018,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition,Eugenio Culurciello,FWDNXT
NIPS,2018,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition,Zhongming Liu,Purdue University
NIPS,2018,The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization,Constantinos Daskalakis,MIT
NIPS,2018,The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization,Ioannis Panageas,Singapore University of Technology and Design
NIPS,2018,Coordinate Descent with Bandit Sampling,Farnood Salehi,EPFL
NIPS,2018,Coordinate Descent with Bandit Sampling,Patrick Thiran,
NIPS,2018,Coordinate Descent with Bandit Sampling,ecelis Celis,EPFL
NIPS,2018,Deep Dynamical Modeling and Control of Unsteady Fluid Flows,Jeremy Morton,Stanford University
NIPS,2018,Deep Dynamical Modeling and Control of Unsteady Fluid Flows,Antony Jameson,Texas A&M University
NIPS,2018,Deep Dynamical Modeling and Control of Unsteady Fluid Flows,Mykel J Kochenderfer,Stanford University
NIPS,2018,Deep Dynamical Modeling and Control of Unsteady Fluid Flows,Freddie Witherden,Imperial College London
NIPS,2018,Confounding-Robust Policy Improvement,Nathan Kallus,Cornell University
NIPS,2018,Confounding-Robust Policy Improvement,Angela Zhou,Cornell University
NIPS,2018,Representer Point Selection for Explaining Deep Neural Networks,Chih-Kuan Yeh,Carnegie Mellon University
NIPS,2018,Representer Point Selection for Explaining Deep Neural Networks,Joon Kim,Carnegie Mellon University
NIPS,2018,Representer Point Selection for Explaining Deep Neural Networks,Ian En-Hsu Yen,Carnegie Mellon University
NIPS,2018,Representer Point Selection for Explaining Deep Neural Networks,Pradeep Ravikumar,Carnegie Mellon University
NIPS,2018,The Effect of Network Width on the Performance of  Large-batch Training,Lingjiao Chen,University of Wisconsin-Madison
NIPS,2018,The Effect of Network Width on the Performance of  Large-batch Training,Hongyi Wang,University of Wisconsin-Madison
NIPS,2018,The Effect of Network Width on the Performance of  Large-batch Training,Jinman Zhao,University of Wisconsin-Madison
NIPS,2018,The Effect of Network Width on the Performance of  Large-batch Training,Dimitrios Papailiopoulos,UW-Madison
NIPS,2018,The Effect of Network Width on the Performance of  Large-batch Training,Paraschos Koutris,University of Wisconsin-Madison
NIPS,2018,SNIPER: Efficient Multi-Scale Training,Bharat Singh,"University of Maryland, College Park"
NIPS,2018,SNIPER: Efficient Multi-Scale Training,Mahyar Najibi,University of Maryland
NIPS,2018,SNIPER: Efficient Multi-Scale Training,Larry Davis,University of Maryland
NIPS,2018,Sample Complexity of Nonparametric Semi-Supervised Learning,Chen Dan,Carnegie Mellon University
NIPS,2018,Sample Complexity of Nonparametric Semi-Supervised Learning,Liu Leqi,Carnegie Mellon University
NIPS,2018,Sample Complexity of Nonparametric Semi-Supervised Learning,Bryon Aragam,Carnegie Mellon University
NIPS,2018,Sample Complexity of Nonparametric Semi-Supervised Learning,Pradeep Ravikumar,Carnegie Mellon University
NIPS,2018,Sample Complexity of Nonparametric Semi-Supervised Learning,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,Hardware Conditioned Policies for Multi-Robot Transfer Learning,Tao Chen,Carnegie Mellon University
NIPS,2018,Hardware Conditioned Policies for Multi-Robot Transfer Learning,Adithyavairavan Murali,Carnegie Mellon University Robotics Institute
NIPS,2018,Hardware Conditioned Policies for Multi-Robot Transfer Learning,Abhinav Gupta,Facebook AI Research/CMU
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Abhishek Kumar,IBM Research AI
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Prasanna Sattigeri,IBM Research
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Kahini Wadhawan,IBM Research
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Leonid Karlinsky,IBM-Research
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Rogerio Feris,IBM Research AI
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Bill Freeman,MIT/Google
NIPS,2018,Co-regularized Alignment for Unsupervised Domain Adaptation,Gregory Wornell,MIT
NIPS,2018,Statistical and Computational Trade-Offs in Kernel K-Means,Daniele Calandriello,LCSL IIT/MIT
NIPS,2018,Statistical and Computational Trade-Offs in Kernel K-Means,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2018,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,Sergey Bartunov,DeepMind
NIPS,2018,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,Adam Santoro,DeepMind
NIPS,2018,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,Blake Richards,University of Toronto
NIPS,2018,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,Luke Marris,DeepMind
NIPS,2018,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,Geoffrey E Hinton,Google & University of Toronto
NIPS,2018,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,Timothy Lillicrap,Google DeepMind
NIPS,2018,Learning Attractor Dynamics for Generative Memory,Yan Wu,DeepMind
NIPS,2018,Learning Attractor Dynamics for Generative Memory,Greg Wayne,Google DeepMind
NIPS,2018,Learning Attractor Dynamics for Generative Memory,Karol Gregor,DeepMind
NIPS,2018,Learning Attractor Dynamics for Generative Memory,Timothy Lillicrap,Google DeepMind
NIPS,2018,The emergence of multiple retinal cell types through efficient coding of natural movies,Stephane Deny,Stanford
NIPS,2018,The emergence of multiple retinal cell types through efficient coding of natural movies,Jack Lindsey,Stanford University
NIPS,2018,The emergence of multiple retinal cell types through efficient coding of natural movies,Surya Ganguli,Stanford
NIPS,2018,The emergence of multiple retinal cell types through efficient coding of natural movies,Samuel Ocko,Stanford
NIPS,2018,Gather-Excite: Exploiting feature context in ConvNets,Jie Hu,Momenta
NIPS,2018,Gather-Excite: Exploiting feature context in ConvNets,Li Shen,University of Oxford
NIPS,2018,Gather-Excite: Exploiting feature context in ConvNets,Samuel Albanie,Oxford University
NIPS,2018,Gather-Excite: Exploiting feature context in ConvNets,Gang Sun,Momenta
NIPS,2018,Gather-Excite: Exploiting feature context in ConvNets,Andrea Vedaldi,University of Oxford and Facebook
NIPS,2018,Quantifying Linguistic Shifts: The Global Anchor Method and Its Applications,Zi Yin,Stanford University
NIPS,2018,Quantifying Linguistic Shifts: The Global Anchor Method and Its Applications,Vinayak Sachidananda,Stanford University
NIPS,2018,Quantifying Linguistic Shifts: The Global Anchor Method and Its Applications,Balaji Prabhakar,Stanford Univeristy
NIPS,2018,Deepcode: Feedback Codes via Deep Learning,Hyeji Kim,Samsung AI Center Cambridge
NIPS,2018,Deepcode: Feedback Codes via Deep Learning,Yihan Jiang,University of Washington Seattle
NIPS,2018,Deepcode: Feedback Codes via Deep Learning,Sreeram Kannan,University of Washington
NIPS,2018,Deepcode: Feedback Codes via Deep Learning,Sewoong Oh,University of Washington
NIPS,2018,Deepcode: Feedback Codes via Deep Learning,Pramod Viswanath,UIUC
NIPS,2018,Implicit Bias of Gradient Descent on Linear Convolutional Networks,Suriya Gunasekar,TTI Chicago
NIPS,2018,Implicit Bias of Gradient Descent on Linear Convolutional Networks,Jason Lee,University of Southern California
NIPS,2018,Implicit Bias of Gradient Descent on Linear Convolutional Networks,Daniel Soudry,Technion
NIPS,2018,Implicit Bias of Gradient Descent on Linear Convolutional Networks,Nati Srebro,TTI-Chicago
NIPS,2018,DAGs with NO TEARS: Continuous Optimization for Structure Learning,Xun Zheng,Carnegie Mellon University
NIPS,2018,DAGs with NO TEARS: Continuous Optimization for Structure Learning,Bryon Aragam,Carnegie Mellon University
NIPS,2018,DAGs with NO TEARS: Continuous Optimization for Structure Learning,Pradeep Ravikumar,Carnegie Mellon University
NIPS,2018,DAGs with NO TEARS: Continuous Optimization for Structure Learning,Eric Xing,Petuum Inc. /  Carnegie Mellon University
NIPS,2018,PAC-Bayes Tree: weighted subtrees with guarantees,Stan D Nguyen,MIT
NIPS,2018,PAC-Bayes Tree: weighted subtrees with guarantees,Samory Kpotufe,Princeton University
NIPS,2018,Multi-objective Maximization of Monotone Submodular Functions with Cardinality Constraint,Rajan Udwani,MIT
NIPS,2018,Sanity Checks for Saliency Maps,Julius Adebayo,Google
NIPS,2018,Sanity Checks for Saliency Maps,Justin Gilmer,Google Brain
NIPS,2018,Sanity Checks for Saliency Maps,Michael Muelly,Google
NIPS,2018,Sanity Checks for Saliency Maps,Ian Goodfellow,Google
NIPS,2018,Sanity Checks for Saliency Maps,Moritz Hardt,Google Brain
NIPS,2018,Sanity Checks for Saliency Maps,Been Kim,Google
NIPS,2018,Probabilistic Model-Agnostic Meta-Learning,Chelsea Finn,UC Berkeley
NIPS,2018,Probabilistic Model-Agnostic Meta-Learning,Kelvin Xu,UC Berkeley
NIPS,2018,Probabilistic Model-Agnostic Meta-Learning,Sergey Levine,UC Berkeley
NIPS,2018,Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach,Mike Gimelfarb,University of Toronto
NIPS,2018,Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach,Scott Sanner,University of Toronto
NIPS,2018,Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach,Chi-Guhn Lee,University of Toronto
NIPS,2018,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis,Thomas George,"MILA, Université de Montréal"
NIPS,2018,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis,César Laurent,Mila - Université de Montréal
NIPS,2018,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis,Xavier Bouthillier,Université de Montréal
NIPS,2018,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis,Nicolas Ballas,Facebook FAIR
NIPS,2018,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis,Pascal Vincent,Facebook and U. Montreal
NIPS,2018,Learning convex bounds for linear quadratic control policy synthesis,Jack Umenberger,Uppsala University
NIPS,2018,Learning convex bounds for linear quadratic control policy synthesis,Thomas Schön,Uppsala University
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,Morteza Mardani,Stanford University
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,Qingyun Sun,Stanford university
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,David Donoho,Stanford University
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,Vardan Papyan,Stanford University
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,Hatef Monajemi,Stanford University
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,Shreyas Vasanawala,Stanford University
NIPS,2018,Neural Proximal Gradient Descent for Compressive Imaging,John Pauly,Stanford University
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,Liwei Wang,Peking University
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,Lunjia Hu,Stanford University
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,Jiayuan Gu,"University of California, San Diego"
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,Zhiqiang Hu,Peking University
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,Yue Wu,Peking University
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,Kun He,Hua Zhong University of Science and Technology
NIPS,2018,To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach,John Hopcroft,Cornell University
NIPS,2018,Optimal Algorithms for Continuous   Non-monotone Submodular and DR-Submodular Maximization,Rad Niazadeh,Stanford University
NIPS,2018,Optimal Algorithms for Continuous   Non-monotone Submodular and DR-Submodular Maximization,Tim Roughgarden,Stanford University
NIPS,2018,Optimal Algorithms for Continuous   Non-monotone Submodular and DR-Submodular Maximization,Joshua Wang,Google
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Rosanne Liu,Uber AI Labs
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Joel Lehman,Uber AI Labs
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Piero Molino,Uber AI Labs
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Felipe Petroski Such,Uber AI Labs
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Eric Frank Frank,Uber AI Labs
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Alex Sergeev,"Uber Technologies Inc,"
NIPS,2018,An intriguing failing of convolutional neural networks and the CoordConv solution,Jason Yosinski,Uber AI Labs; Recursion
NIPS,2018,Trading robust representations for sample complexity through self-supervised visual experience,Andrea Tacchetti,DeepMind
NIPS,2018,Trading robust representations for sample complexity through self-supervised visual experience,Stephen Voinea,MIT
NIPS,2018,Trading robust representations for sample complexity through self-supervised visual experience,Georgios Evangelopoulos,"X, Alphabet Inc."
NIPS,2018,Invertibility of Convolutional Generative Networks from Partial Measurements,Fangchang Ma,MIT
NIPS,2018,Invertibility of Convolutional Generative Networks from Partial Measurements,Ulas Ayaz,Massachusetts Institute of Technology / Lyft
NIPS,2018,Invertibility of Convolutional Generative Networks from Partial Measurements,Sertac Karaman,MIT
NIPS,2018,Ex ante coordination and collusion in zero-sum multi-player extensive-form games,Gabriele Farina,Carnegie Mellon University
NIPS,2018,Ex ante coordination and collusion in zero-sum multi-player extensive-form games,Andrea Celli,Politecnico di Milano
NIPS,2018,Ex ante coordination and collusion in zero-sum multi-player extensive-form games,Nicola Gatti,Politecnico di Milano
NIPS,2018,Ex ante coordination and collusion in zero-sum multi-player extensive-form games,Tuomas Sandholm,Carnegie Mellon University
NIPS,2018,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization,Hoi-To Wai,The Chinese University of Hong Kong
NIPS,2018,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization,Zhuoran Yang,Princeton University
NIPS,2018,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization,Princeton Zhaoran Wang,"Princeton, Phd student"
NIPS,2018,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization,Mingyi Hong,University of Minnesota
NIPS,2018,Improving Online Algorithms via ML Predictions,Manish Purohit,Google
NIPS,2018,Improving Online Algorithms via ML Predictions,Zoya Svitkina,Google
NIPS,2018,Improving Online Algorithms via ML Predictions,Ravi Kumar,Google
NIPS,2018,Non-convex Optimization with Discretized Diffusions,Murat A Erdogdu,University of Toronto
NIPS,2018,Non-convex Optimization with Discretized Diffusions,Lester Mackey,Microsoft Research
NIPS,2018,Non-convex Optimization with Discretized Diffusions,Ohad Shamir,Weizmann Institute of Science
NIPS,2018,Improving Explorability in Variational Inference with Annealed Variational Objectives,Chin-Wei Huang,MILA
NIPS,2018,Improving Explorability in Variational Inference with Annealed Variational Objectives,Shawn Tan,Mila
NIPS,2018,Improving Explorability in Variational Inference with Annealed Variational Objectives,Alexandre Lacoste,Element AI
NIPS,2018,Improving Explorability in Variational Inference with Annealed Variational Objectives,Aaron Courville,U. Montreal
NIPS,2018,Latent Alignment and Variational Attention,Yuntian Deng,Harvard University
NIPS,2018,Latent Alignment and Variational Attention,Yoon Kim,Harvard University
NIPS,2018,Latent Alignment and Variational Attention,Justin Chiu,Harvard University
NIPS,2018,Latent Alignment and Variational Attention,Demi Guo,Harvard
NIPS,2018,Latent Alignment and Variational Attention,Alexander Rush,Harvard
NIPS,2018,Towards Deep Conversational Recommendations,Raymond Li,Polytechnique Montréal
NIPS,2018,Towards Deep Conversational Recommendations,Samira Ebrahimi Kahou,Microsoft
NIPS,2018,Towards Deep Conversational Recommendations,Hannes Schulz,"Microsoft Research, Montreal"
NIPS,2018,Towards Deep Conversational Recommendations,Vincent Michalski,Université de Montréal
NIPS,2018,Towards Deep Conversational Recommendations,Laurent Charlin,MILA / U.Montreal
NIPS,2018,Towards Deep Conversational Recommendations,Chris Pal,"MILA, Polytechnique Montréal, Element AI"
NIPS,2018,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement",Joel Moniz,Carnegie Mellon University
NIPS,2018,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement",Christopher Beckham,MILA
NIPS,2018,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement",Simon Rajotte,Polytechnique Montréal
NIPS,2018,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement",Sina Honari,University of Montreal
NIPS,2018,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement",Chris Pal,"MILA, Polytechnique Montréal, Element AI"
NIPS,2018,Generalization Bounds for Uniformly Stable Algorithms,Vitaly Feldman,Google Brain
NIPS,2018,Generalization Bounds for Uniformly Stable Algorithms,Jan Vondrak,Stanford University
NIPS,2018,Deep Anomaly Detection Using Geometric Transformations,Izhak Golan,Technion
NIPS,2018,Deep Anomaly Detection Using Geometric Transformations,Ran El-Yaniv,Technion
NIPS,2018,Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport,Theo Lacombe,Inria Saclay
NIPS,2018,Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport,Marco Cuturi,"Université Paris-Saclay, CREST - ENSAE"
NIPS,2018,Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport,Steve OUDOT,inria
NIPS,2018,Entropy Rate Estimation for Markov Chains with Large State Space,Yanjun Han,Stanford University
NIPS,2018,Entropy Rate Estimation for Markov Chains with Large State Space,Jiantao Jiao,"University of California, Berkeley"
NIPS,2018,Entropy Rate Estimation for Markov Chains with Large State Space,Chuan-Zheng Lee,Stanford University
NIPS,2018,Entropy Rate Estimation for Markov Chains with Large State Space,Tsachy Weissman,Stanford University
NIPS,2018,Entropy Rate Estimation for Markov Chains with Large State Space,Yihong Wu,Yale University
NIPS,2018,Entropy Rate Estimation for Markov Chains with Large State Space,Tiancheng Yu,Tsinghua University
NIPS,2018,Adaptive Methods for Nonconvex Optimization,Manzil Zaheer,Google
NIPS,2018,Adaptive Methods for Nonconvex Optimization,Sashank Reddi,Google
NIPS,2018,Adaptive Methods for Nonconvex Optimization,Devendra Sachan,CMU
NIPS,2018,Adaptive Methods for Nonconvex Optimization,Satyen Kale,Google
NIPS,2018,Adaptive Methods for Nonconvex Optimization,Sanjiv Kumar,Google Research
NIPS,2018,Object-Oriented Dynamics Predictor,Guangxiang Zhu,Tsinghua university
NIPS,2018,Object-Oriented Dynamics Predictor,Zhiao Huang,"IIIS, Tsinghua University"
NIPS,2018,Object-Oriented Dynamics Predictor,Chongjie Zhang,Tsinghua University
NIPS,2018,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models,Alexander Neitz,Max Planck Institute for Intelligent Systems
NIPS,2018,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models,Giambattista Parascandolo,Max Planck Insitute for Intelligent Systems & ETH
NIPS,2018,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models,Stefan Bauer,MPI for Intelligent Systems
NIPS,2018,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models,Bernhard Schölkopf,MPI for Intelligent Systems
NIPS,2018,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,Matthew O'Kelly,University of Pennsylvania
NIPS,2018,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,Aman Sinha,Stanford University
NIPS,2018,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,Hong Namkoong,Stanford University
NIPS,2018,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,Russ Tedrake,MIT
NIPS,2018,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,John Duchi,Stanford
NIPS,2018,Reinforcement Learning for Solving the Vehicle Routing Problem,MohammadReza Nazari,Lehigh University
NIPS,2018,Reinforcement Learning for Solving the Vehicle Routing Problem,Afshin Oroojlooy,Lehigh University
NIPS,2018,Reinforcement Learning for Solving the Vehicle Routing Problem,Lawrence Snyder,Lehigh University
NIPS,2018,Reinforcement Learning for Solving the Vehicle Routing Problem,Martin Takac,Lehigh University
NIPS,2018,ATOMO: Communication-efficient Learning via Atomic Sparsification,Hongyi Wang,University of Wisconsin-Madison
NIPS,2018,ATOMO: Communication-efficient Learning via Atomic Sparsification,Scott Sievert,University of Wisconsin-Madison
NIPS,2018,ATOMO: Communication-efficient Learning via Atomic Sparsification,Shengchao Liu,UW-Madison
NIPS,2018,ATOMO: Communication-efficient Learning via Atomic Sparsification,Micky Charles,University of Wisconsin-Madison
NIPS,2018,ATOMO: Communication-efficient Learning via Atomic Sparsification,Dimitrios Papailiopoulos,UW-Madison
NIPS,2018,ATOMO: Communication-efficient Learning via Atomic Sparsification,Stephen Wright,UW-Madison
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Alessandro Achille,UCLA
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Tom Eccles,DeepMind
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Loic Matthey,DeepMind
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Chris Burgess,DeepMind
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Nick Watters,Google DeepMind
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Alexander Lerchner,DeepMind
NIPS,2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Irina Higgins,DeepMind
NIPS,2018,Maximizing acquisition functions for Bayesian optimization,James Wilson,Imperial College of London
NIPS,2018,Maximizing acquisition functions for Bayesian optimization,Frank Hutter,University of Freiburg
NIPS,2018,Maximizing acquisition functions for Bayesian optimization,Marc Deisenroth,Imperial College London
NIPS,2018,On Markov Chain Gradient Descent,Tao Sun,National university of defense technology
NIPS,2018,On Markov Chain Gradient Descent,Yuejiao Sun,UCLA
NIPS,2018,On Markov Chain Gradient Descent,Wotao Yin,"University of California, Los Angeles"
NIPS,2018,Variance-Reduced Stochastic Gradient Descent on Streaming Data,Ellango Jothimurugesan,CMU
NIPS,2018,Variance-Reduced Stochastic Gradient Descent on Streaming Data,Ashraf Tahmasbi,Iowa State University
NIPS,2018,Variance-Reduced Stochastic Gradient Descent on Streaming Data,Phillip Gibbons,CMU
NIPS,2018,Variance-Reduced Stochastic Gradient Descent on Streaming Data,Srikanta Tirthapura,Iowa State University
NIPS,2018,Online Robust Policy Learning in the Presence of Unknown Adversaries,Aaron Havens,University of Illinois Urbana-Champaign
NIPS,2018,Online Robust Policy Learning in the Presence of Unknown Adversaries,Zhanhong Jiang,Iowa State University
NIPS,2018,Online Robust Policy Learning in the Presence of Unknown Adversaries,Soumik Sarkar,Iowa State University
NIPS,2018,Uplift Modeling from Separate Labels,Ikko Yamane,The University of Tokyo/RIKEN
NIPS,2018,Uplift Modeling from Separate Labels,Florian Yger,Université Paris-Dauphine
NIPS,2018,Uplift Modeling from Separate Labels,Jamal Atif,Université Paris-Dauphine
NIPS,2018,Uplift Modeling from Separate Labels,Masashi Sugiyama,RIKEN / University of Tokyo
NIPS,2018,Learning Invariances using the Marginal Likelihood,Mark van der Wilk,PROWLER.io
NIPS,2018,Learning Invariances using the Marginal Likelihood,Matthias Bauer,Max Planck Institute for Intelligent Systems
NIPS,2018,Learning Invariances using the Marginal Likelihood,Ti John,PROWLER.io
NIPS,2018,Learning Invariances using the Marginal Likelihood,James Hensman,PROWLER.io
NIPS,2018,Non-delusional Q-learning and Value-iteration,Tyler Lu,Google
NIPS,2018,Non-delusional Q-learning and Value-iteration,Dale Schuurmans,Google Inc.
NIPS,2018,Non-delusional Q-learning and Value-iteration,Craig Boutilier,Google
NIPS,2018,Using Large Ensembles of Control Variates for Variational Inference,Tomas Geffner,"University of Massachusetts, Amherst"
NIPS,2018,Using Large Ensembles of Control Variates for Variational Inference,Justin Domke,"University of Massachusetts, Amherst"
NIPS,2018,Learning to Reason with Third Order Tensor Products,Imanol Schlag,IDSIA
NIPS,2018,Learning to Reason with Third Order Tensor Products,Jürgen Schmidhuber,"Swiss AI Lab, IDSIA (USI & SUPSI) - NNAISENSE"
NIPS,2018,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing,Chen Liang,Google Brain
NIPS,2018,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing,Mohammad Norouzi,Google Brain
NIPS,2018,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing,Jonathan Berant,Tel Aviv University
NIPS,2018,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing,Quoc V Le,Google
NIPS,2018,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing,Ni Lao,Mosaix.ai
NIPS,2018,Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence Diagrams,Tam Le,RIKEN AIP
NIPS,2018,Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence Diagrams,Makoto Yamada,Kyoto University / RIKEN AIP
NIPS,2018,Neural Voice Cloning with a Few Samples,Sercan Arik,Google
NIPS,2018,Neural Voice Cloning with a Few Samples,Jitong Chen,ByteDance
NIPS,2018,Neural Voice Cloning with a Few Samples,Kainan Peng,Baidu Research
NIPS,2018,Neural Voice Cloning with a Few Samples,Wei Ping,Baidu Silicon Valley AI Lab
NIPS,2018,Neural Voice Cloning with a Few Samples,Yanqi Zhou,Baidu Research
NIPS,2018,Blind Deconvolutional Phase Retrieval via Convex Programming,Ali Ahmed,Information Technology University
NIPS,2018,Blind Deconvolutional Phase Retrieval via Convex Programming,Alireza Aghasi,Institute for Insight
NIPS,2018,Blind Deconvolutional Phase Retrieval via Convex Programming,Paul Hand,Northeastern University
NIPS,2018,Scalable Laplacian K-modes,Imtiaz Ziko,Ecole de technologie superieure (ETS)
NIPS,2018,Scalable Laplacian K-modes,Eric Granger,"École de technologie supérieure, Université du Québec"
NIPS,2018,Scalable Laplacian K-modes,Ismail Ben Ayed,ETS Montreal
NIPS,2018,Testing for Families of Distributions via the Fourier Transform,Alistair Stewart,University of Southern California
NIPS,2018,Testing for Families of Distributions via the Fourier Transform,Ilias Diakonikolas,University of Southern California
NIPS,2018,Testing for Families of Distributions via the Fourier Transform,Clement Canonne,Stanford University
NIPS,2018,Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform,Mitali Bafna,Harvard University
NIPS,2018,Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform,Jack Murtagh,Harvard University
NIPS,2018,Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform,Nikhil Vyas,MIT
NIPS,2018,Blockwise Parallel Decoding for Deep Autoregressive Models,Mitchell Stern,UC Berkeley
NIPS,2018,Blockwise Parallel Decoding for Deep Autoregressive Models,Noam Shazeer,Google
NIPS,2018,Blockwise Parallel Decoding for Deep Autoregressive Models,Jakob Uszkoreit,Google
NIPS,2018,Low-rank Tucker decomposition of large tensors using TensorSketch,Osman Malik,University of Colorado Boulder
NIPS,2018,Low-rank Tucker decomposition of large tensors using TensorSketch,Stephen Becker,University of Colorado
NIPS,2018,A Simple Cache Model for Image Recognition,Emin Orhan,BCM & Rice
NIPS,2018,Clebsch–Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network,Risi Kondor,U. Chicago
NIPS,2018,Clebsch–Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network,Zhen Lin,The University of Chicago
NIPS,2018,Clebsch–Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network,Shubhendu Trivedi,Brown University
NIPS,2018,Bayesian Nonparametric Spectral Estimation,Felipe Tobar,Universidad de Chile
NIPS,2018,A Spectral View of Adversarially Robust Features,Shivam Garg,Stanford University
NIPS,2018,A Spectral View of Adversarially Robust Features,Vatsal Sharan,Stanford University
NIPS,2018,A Spectral View of Adversarially Robust Features,Brian Zhang,Stanford University
NIPS,2018,A Spectral View of Adversarially Robust Features,Gregory Valiant,Stanford University
NIPS,2018,Synaptic Strength For Convolutional Neural Network,CHEN LIN,Sun Yat-sen University
NIPS,2018,Synaptic Strength For Convolutional Neural Network,Zhao Zhong,CASIA (Institute of Automation Chinese Academy of Sciences)
NIPS,2018,Synaptic Strength For Convolutional Neural Network,Wu Wei,Sensetime
NIPS,2018,Synaptic Strength For Convolutional Neural Network,Junjie Yan,Sensetime Group Limited
NIPS,2018,Human-in-the-Loop Interpretability Prior,Isaac Lage,Harvard
NIPS,2018,Human-in-the-Loop Interpretability Prior,Andrew Ross,Harvard University
NIPS,2018,Human-in-the-Loop Interpretability Prior,Samuel J Gershman,Harvard University
NIPS,2018,Human-in-the-Loop Interpretability Prior,Been Kim,Google
NIPS,2018,Human-in-the-Loop Interpretability Prior,Finale Doshi-Velez,Harvard
NIPS,2018,Backpropagation with Callbacks: Towards Efficient and Expressive Differentiable Programming,Fei Wang,Cornell University
NIPS,2018,Backpropagation with Callbacks: Towards Efficient and Expressive Differentiable Programming,James Decker,Purdue University
NIPS,2018,Backpropagation with Callbacks: Towards Efficient and Expressive Differentiable Programming,Xilun Wu,Purdue University
NIPS,2018,Backpropagation with Callbacks: Towards Efficient and Expressive Differentiable Programming,Gregory Essertel,Purdue University
NIPS,2018,Backpropagation with Callbacks: Towards Efficient and Expressive Differentiable Programming,Tiark Rompf,Purdue University
NIPS,2018,Learning with SGD and Random Features,Luigi Carratino,University of Genoa
NIPS,2018,Learning with SGD and Random Features,Alessandro Rudi,"INRIA, Ecole Normale Superieure"
NIPS,2018,Learning with SGD and Random Features,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2018,Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions,Boris Muzellec,ENSAE ParisTech
NIPS,2018,Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions,Marco Cuturi,"Université Paris-Saclay, CREST - ENSAE"
NIPS,2018,Learning to Share and Hide Intentions using Information Regularization,DJ Strouse,Princeton University
NIPS,2018,Learning to Share and Hide Intentions using Information Regularization,Max Kleiman-Weiner,Harvard
NIPS,2018,Learning to Share and Hide Intentions using Information Regularization,Josh Tenenbaum,MIT
NIPS,2018,Learning to Share and Hide Intentions using Information Regularization,Matt Botvinick,Google DeepMind / University College London
NIPS,2018,Learning to Share and Hide Intentions using Information Regularization,David Schwab,"ITS, CUNY Graduate Center"
NIPS,2018,Predictive Approximate Bayesian Computation via Saddle Points,Yingxiang Yang,University of Illinois at Urbana Champaign
NIPS,2018,Predictive Approximate Bayesian Computation via Saddle Points,Bo Dai,Google Brain
NIPS,2018,Predictive Approximate Bayesian Computation via Saddle Points,Negar Kiyavash,Georgia Tech
NIPS,2018,Predictive Approximate Bayesian Computation via Saddle Points,Niao He,UIUC
NIPS,2018,Learning conditional GAN using noisy labels,Kiran Thekumparampil,Univ. of Illinois at Urbana-Champaign
NIPS,2018,Learning conditional GAN using noisy labels,Ashish Khetan,Amazon AI Labs
NIPS,2018,Learning conditional GAN using noisy labels,Zinan Lin,Carnegie Mellon University
NIPS,2018,Learning conditional GAN using noisy labels,Sewoong Oh,University of Washington
NIPS,2018,Robust Learning of Fixed-Structure Bayesian Networks,Yu Cheng,Microsoft AI & Research
NIPS,2018,Robust Learning of Fixed-Structure Bayesian Networks,Ilias Diakonikolas,University of Southern California
NIPS,2018,Robust Learning of Fixed-Structure Bayesian Networks,Daniel Kane,UCSD
NIPS,2018,Robust Learning of Fixed-Structure Bayesian Networks,Alistair Stewart,University of Southern California
NIPS,2018,Improving Simple Models with Confidence Profiles,Amit Dhurandhar,IBM Research
NIPS,2018,Improving Simple Models with Confidence Profiles,Karthikeyan Shanmugam,"IBM Research, NY"
NIPS,2018,Improving Simple Models with Confidence Profiles,Ronny Luss,IBM Research
NIPS,2018,Improving Simple Models with Confidence Profiles,Peder A Olsen,IBM
NIPS,2018,Learning to solve SMT formulas,Mislav Balunovic,ETH Zurich
NIPS,2018,Learning to solve SMT formulas,Pavol Bielik,ETH Zurich
NIPS,2018,Learning to solve SMT formulas,Martin Vechev,"DeepCode and ETH Zurich, Switzerland"
NIPS,2018,Lifted Weighted Mini-Bucket,Nicholas Gallo,UC Irvine
NIPS,2018,Lifted Weighted Mini-Bucket,Alexander Ihler,UC Irvine
NIPS,2018,Using Quantum Graphical Models to Perform Inference in Hilbert Space,Siddarth Srinivasan,Georgia Institute of Technology
NIPS,2018,Using Quantum Graphical Models to Perform Inference in Hilbert Space,Carlton Downey,Carnegie Mellon University
NIPS,2018,Using Quantum Graphical Models to Perform Inference in Hilbert Space,Byron Boots,Georgia Tech / Google Brain
NIPS,2018,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound,Hadi Kazemi,WVU
NIPS,2018,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound,Sobhan Soleymani,West Virginia University
NIPS,2018,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound,Fariborz Taherkhani,West Virginia University
NIPS,2018,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound,Seyed Iranmanesh,West Virginia University
NIPS,2018,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound,Nasser Nasrabadi,WVU
NIPS,2018,Gaussian Process Prior Variational Autoencoders,Francesco Paolo Casale,Microsoft Research
NIPS,2018,Gaussian Process Prior Variational Autoencoders,Adrian Dalca,MIT
NIPS,2018,Gaussian Process Prior Variational Autoencoders,Luca Saglietti,"Microsoft Research New England (visitor)  Italian Institute for Genomic Medicine, Torino, Italy"
NIPS,2018,Gaussian Process Prior Variational Autoencoders,Jennifer Listgarten,UC Berkeley
NIPS,2018,Gaussian Process Prior Variational Autoencoders,Nicolo Fusi,Microsoft Research
NIPS,2018,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,Maurice Weiler,University of Amsterdam
NIPS,2018,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,Wouter Boomsma,University of Copenhagen
NIPS,2018,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,Mario Geiger,EPFL
NIPS,2018,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,Max Welling,University of Amsterdam / Qualcomm AI Research
NIPS,2018,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,Taco Cohen,University of Amsterdam
NIPS,2018,Convex Elicitation of Continuous Properties,Jessie Finocchiaro,University of Colorado Boulder
NIPS,2018,Convex Elicitation of Continuous Properties,Rafael Frongillo,CU Boulder
NIPS,2018,Learning Abstract Options,Matthew Riemer,IBM Research AI
NIPS,2018,Learning Abstract Options,Miao Liu,IBM
NIPS,2018,Learning Abstract Options,Gerald Tesauro,IBM TJ Watson Research Center
NIPS,2018,Bounded-Loss Private Prediction Markets,Rafael Frongillo,CU Boulder
NIPS,2018,Bounded-Loss Private Prediction Markets,Bo Waggoner,Penn
NIPS,2018,Temporal alignment and latent Gaussian process factor inference in population spike trains,Lea Duncker,"Gatsby Unit, UCL"
NIPS,2018,Temporal alignment and latent Gaussian process factor inference in population spike trains,Maneesh Sahani,"Gatsby Unit, UCL"
NIPS,2018,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise,Dan Hendrycks,UC Berkeley
NIPS,2018,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise,Mantas Mazeika,University of Chicago
NIPS,2018,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise,Duncan Wilson,Leap Motion
NIPS,2018,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise,Kevin Gimpel,
NIPS,2018,Discretely Relaxing Continuous Variables for tractable Variational Inference,Trefor Evans,University of Toronto
NIPS,2018,Discretely Relaxing Continuous Variables for tractable Variational Inference,Prasanth Nair,University of Toronto
NIPS,2018,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior,Zi Wang,MIT
NIPS,2018,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior,Beomjoon Kim,MIT
NIPS,2018,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior,Leslie Kaelbling,MIT
NIPS,2018,The Sparse Manifold Transform,Yubei Chen,"EECS, UC Berkeley"
NIPS,2018,The Sparse Manifold Transform,Dylan Paiton,"University of California, Berkeley"
NIPS,2018,The Sparse Manifold Transform,Bruno Olshausen,Redwood Center/UC Berkeley
NIPS,2018,Bayesian Structure Learning by Recursive Bootstrap,Raanan Y. Rohekar,Intel Corporation
NIPS,2018,Bayesian Structure Learning by Recursive Bootstrap,Yaniv Gurwicz,Intel AI Lab
NIPS,2018,Bayesian Structure Learning by Recursive Bootstrap,Shami Nisimov,intel
NIPS,2018,Bayesian Structure Learning by Recursive Bootstrap,Guy Koren,Intel
NIPS,2018,Bayesian Structure Learning by Recursive Bootstrap,Gal Novik,Intel
NIPS,2018,Gated Complex Recurrent Neural Networks,Moritz Wolter,University of Bonn
NIPS,2018,Gated Complex Recurrent Neural Networks,Angela Yao,University of Bonn
NIPS,2018,Learning a Warping Distance from Unlabeled Time Series Using Sequence Autoencoders,Abubakar Abid,Stanford
NIPS,2018,Learning a Warping Distance from Unlabeled Time Series Using Sequence Autoencoders,James Zou,Stanford University
NIPS,2018,Streamlining constraints for random k-SAT,Aditya Grover,Stanford University
NIPS,2018,Streamlining constraints for random k-SAT,Tudor Achim,Helm.ai
NIPS,2018,Streamlining constraints for random k-SAT,Stefano Ermon,Stanford
NIPS,2018,Improved Network Robustness with Adversary Critic,Alexander Matyasko,Nanyang Technological University
NIPS,2018,Improved Network Robustness with Adversary Critic,Lap-Pui Chau,Nanyang Technological University
NIPS,2018,Connecting Optimization and Regularization Paths,Arun Suggala,Carnegie Mellon University
NIPS,2018,Connecting Optimization and Regularization Paths,Adarsh Prasad,Carnegie Mellon University
NIPS,2018,Connecting Optimization and Regularization Paths,Pradeep Ravikumar,Carnegie Mellon University
NIPS,2018,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices,Jinhwan Park,Seoul National University
NIPS,2018,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices,Yoonho Boo,Seoul National University
NIPS,2018,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices,Iksoo Choi,Seoul National University
NIPS,2018,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices,Sungho Shin,Seoul National University
NIPS,2018,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices,Wonyong Sung,Seoul National University
NIPS,2018,Understanding Regularized Spectral Clustering via Graph Conductance,Yilin Zhang,University of Wisconsin-Madison
NIPS,2018,Understanding Regularized Spectral Clustering via Graph Conductance,Karl Rohe,UW-Madison
NIPS,2018,Data-Driven Clustering via Parameterized Lloyd's Families,Maria-Florina Balcan,Carnegie Mellon University
NIPS,2018,Data-Driven Clustering via Parameterized Lloyd's Families,Travis Dick,Carnegie Mellon University
NIPS,2018,Data-Driven Clustering via Parameterized Lloyd's Families,Colin White,Carnegie Mellon University
NIPS,2018,Learning Beam Search Policies via Imitation Learning,Renato Negrinho,Carnegie Mellon University
NIPS,2018,Learning Beam Search Policies via Imitation Learning,Matt Gormley,Carnegie Mellon University
NIPS,2018,Learning Beam Search Policies via Imitation Learning,Geoffrey Gordon,MSR Montréal & CMU
NIPS,2018,Benefits of overparameterization with EM,Ji Xu,Columbia University
NIPS,2018,Benefits of overparameterization with EM,Daniel Hsu,Columbia University
NIPS,2018,Benefits of overparameterization with EM,Arian Maleki,Columbia University
NIPS,2018,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning,Rui Luo,University College London
NIPS,2018,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning,Jianhong Wang,UCL
NIPS,2018,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning,Yaodong Yang,University College London
NIPS,2018,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning,Jun WANG,UCL
NIPS,2018,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning,Zhanxing Zhu,Peking University
NIPS,2018,Robust Subspace Approximation in a Stream,Roie Levin,Carnegie Mellon University
NIPS,2018,Robust Subspace Approximation in a Stream,Anish Sevekari Sevekari,Carnegie Mellon University
NIPS,2018,Robust Subspace Approximation in a Stream,David Woodruff,Carnegie Mellon University
NIPS,2018,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues,Soumendu Sundar Mukherjee,"University of California, Berkeley"
NIPS,2018,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues,Purnamrita Sarkar,UT Austin
NIPS,2018,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues,Y. X. Rachel Wang,University of Sydney
NIPS,2018,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues,Bowei Yan,Jump Trading
NIPS,2018,Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems,Yair Carmon,Stanford
NIPS,2018,Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems,John Duchi,Stanford
NIPS,2018,DropBlock: A regularization method for convolutional networks,Golnaz Ghiasi,Google
NIPS,2018,DropBlock: A regularization method for convolutional networks,Tsung-Yi Lin,Google Brain
NIPS,2018,DropBlock: A regularization method for convolutional networks,Quoc V Le,Google
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Gabriel Synnaeve,Facebook
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Zeming Lin,Facebook AI Research
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Jonas Gehring,Facebook AI Research
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Dan Gant,Facebook AI Research
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Vegard Mella,Facebook AI Research
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Vasil Khalidov,Facebook AI Research
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Nicolas Carion,Facebook AI Research Paris
NIPS,2018,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,Nicolas Usunier,Facebook AI Research
NIPS,2018,"With Friends Like These, Who Needs Adversaries?",Saumya Jetley,University of Oxford
NIPS,2018,"With Friends Like These, Who Needs Adversaries?",Nick Lord,University of Oxford/FiveAI
NIPS,2018,"With Friends Like These, Who Needs Adversaries?",Philip  Torr,University of Oxford
NIPS,2018,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters,Pavel Dvurechenskii,WIAS im Forschungsverbund Berlin e. V.
NIPS,2018,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters,Darina Dvinskikh,WIAS im Forschungsverbund Berlin e. V.
NIPS,2018,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters,Alexander Gasnikov,SkolTech
NIPS,2018,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters,Cesar Uribe,Massachusetts Institute of Technology
NIPS,2018,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters,Angelia Nedich,Arizona State University
NIPS,2018,Joint Autoregressive and Hierarchical Priors for Learned Image Compression,David Minnen,Google
NIPS,2018,Joint Autoregressive and Hierarchical Priors for Learned Image Compression,Johannes Ballé,Google
NIPS,2018,Joint Autoregressive and Hierarchical Priors for Learned Image Compression,George D Toderici,Google
NIPS,2018,Learning Temporal Point Processes via Reinforcement Learning,Shuang Li,Georgia Institute of Technology
NIPS,2018,Learning Temporal Point Processes via Reinforcement Learning,Benjamin XIAO,Ant Financial
NIPS,2018,Learning Temporal Point Processes via Reinforcement Learning,Woody Zhu Zhu,Georgia Institute of Technology
NIPS,2018,Learning Temporal Point Processes via Reinforcement Learning,Nan Du,Google Brain
NIPS,2018,Learning Temporal Point Processes via Reinforcement Learning,Yao Xie,Georgia Institute of Technology
NIPS,2018,Learning Temporal Point Processes via Reinforcement Learning,Le Song,Ant Financial & Georgia Institute of Technology
NIPS,2018,Fast and Effective Robustness Certification,Gagandeep Singh,ETH Zurich
NIPS,2018,Fast and Effective Robustness Certification,Timon Gehr,ETH Zurich
NIPS,2018,Fast and Effective Robustness Certification,Matthew Mirman,ETH Zurich
NIPS,2018,Fast and Effective Robustness Certification,Markus Püschel,ETH Zurich
NIPS,2018,Fast and Effective Robustness Certification,Martin Vechev,"DeepCode and ETH Zurich, Switzerland"
NIPS,2018,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds,Raghav Somani,Microsoft Research Lab - India
NIPS,2018,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds,Chirag Gupta,Carnegie Mellon University
NIPS,2018,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds,Prateek Jain,Microsoft Research
NIPS,2018,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds,Praneeth Netrapalli,Microsoft Research
NIPS,2018,Differentially Private Change-Point Detection,Sara Krehbiel,University of Richmond
NIPS,2018,Differentially Private Change-Point Detection,Rachel Cummings,Georgia Tech
NIPS,2018,Differentially Private Change-Point Detection,Wanrong Zhang,Georgia Institute of Technology
NIPS,2018,Differentially Private Change-Point Detection,Yajun Mei,Georgia Institute of Technology
NIPS,2018,Differentially Private Change-Point Detection,Rui Tuo,Texas A&M University
NIPS,2018,Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations,Tong Wang,University of Iowa
NIPS,2018,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions,Sara Magliacane,IBM Research AI
NIPS,2018,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions,Thijs van Ommen,University of Amsterdam
NIPS,2018,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions,Tom Claassen,Radboud University Nijmegen
NIPS,2018,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions,Stephan Bongers,University of Amsterdam
NIPS,2018,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions,Philip Versteeg,University of Amsterdam
NIPS,2018,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions,Joris M Mooij,University of Amsterdam
NIPS,2018,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,Nima Anari,Stanford University
NIPS,2018,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,Constantinos Daskalakis,MIT
NIPS,2018,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,Wolfgang Maass,Graz University of Technology
NIPS,2018,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,Christos Papadimitriou,Columbia University
NIPS,2018,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,Amin Saberi,Stanford University
NIPS,2018,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,Santosh Vempala,Georgia Tech
NIPS,2018,Semidefinite relaxations for certifying robustness to adversarial examples,Aditi Raghunathan,Stanford University
NIPS,2018,Semidefinite relaxations for certifying robustness to adversarial examples,Jacob Steinhardt,UC Berkeley
NIPS,2018,Semidefinite relaxations for certifying robustness to adversarial examples,Percy Liang,Stanford University
NIPS,2018,Removing Hidden Confounding by Experimental Grounding,Nathan Kallus,Cornell University
NIPS,2018,Removing Hidden Confounding by Experimental Grounding,Aahlad Manas Puli,NYU
NIPS,2018,Removing Hidden Confounding by Experimental Grounding,Uri Shalit,Technion
NIPS,2018,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements,Ankush Mandal,Georgia Institute of Technology
NIPS,2018,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements,He Jiang,Rice University
NIPS,2018,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements,ANSHUMALI Shrivastava,Rice University
NIPS,2018,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements,Vivek Sarkar,Georgia Institute of Technology
NIPS,2018,Contrastive Learning from Pairwise Measurements,Yi Chen,Northwestern University
NIPS,2018,Contrastive Learning from Pairwise Measurements,Zhuoran Yang,Princeton University
NIPS,2018,Contrastive Learning from Pairwise Measurements,Yuchen Xie,Northwestern University
NIPS,2018,Contrastive Learning from Pairwise Measurements,Princeton Zhaoran Wang,"Princeton, Phd student"
NIPS,2018,Point process latent variable models of freely swimming larval zebrafish,Anuj Sharma,Columbia University
NIPS,2018,Point process latent variable models of freely swimming larval zebrafish,Scott Linderman,Columbia University
NIPS,2018,Point process latent variable models of freely swimming larval zebrafish,Robert Johnson,Harvard University
NIPS,2018,Point process latent variable models of freely swimming larval zebrafish,Florian Engert,Harvard University
NIPS,2018,Deep Neural Nets with Interpolating Function as Output Activation,Bao Wang,UCLA
NIPS,2018,Deep Neural Nets with Interpolating Function as Output Activation,Xiyang Luo,Google
NIPS,2018,Deep Neural Nets with Interpolating Function as Output Activation,Zhen Li,Hong Kong University of Science & Technology
NIPS,2018,Deep Neural Nets with Interpolating Function as Output Activation,Wei Zhu,Duke University
NIPS,2018,Deep Neural Nets with Interpolating Function as Output Activation,Zuoqiang  Shi,zqshi@mail.tsinghua.edu.cn
NIPS,2018,Deep Neural Nets with Interpolating Function as Output Activation,Stanley Osher,UCLA
NIPS,2018,Visual Memory for Robust Path Following,Ashish Kumar,UC Berkeley
NIPS,2018,Visual Memory for Robust Path Following,Saurabh Gupta,UC Berkeley / FAIR / UIUC
NIPS,2018,Visual Memory for Robust Path Following,David Fouhey,UC Berkeley
NIPS,2018,Visual Memory for Robust Path Following,Sergey Levine,UC Berkeley
NIPS,2018,Visual Memory for Robust Path Following,Jitendra Malik,University of California at Berkley
NIPS,2018,Distilling Knowledge with Adversarial Networks,Xiaojie Wang,The University of Melbourne
NIPS,2018,Distilling Knowledge with Adversarial Networks,Rui Zhang,""" University of Melbourne, Australia"""
NIPS,2018,Distilling Knowledge with Adversarial Networks,Yu Sun,Twitter Inc.
NIPS,2018,Distilling Knowledge with Adversarial Networks,Jianzhong Qi,The University of Melbourne
NIPS,2018,Informative Features for Model Comparison,Wittawat Jitkrittum,Max Planck Institute for Intelligent Systems
NIPS,2018,Informative Features for Model Comparison,Heishiro Kanagawa,"Gatsby Unit, University College London"
NIPS,2018,Informative Features for Model Comparison,Patsorn Sangkloy,Georgia Institute of Technology
NIPS,2018,Informative Features for Model Comparison,James Hays,"Georgia Institute of Technology, USA"
NIPS,2018,Informative Features for Model Comparison,Bernhard Schölkopf,MPI for Intelligent Systems
NIPS,2018,Informative Features for Model Comparison,Arthur Gretton,"Gatsby Unit, UCL"
NIPS,2018,Connectionist Temporal Classification with Maximum Entropy Regularization,Hu Liu,Tsinghua University
NIPS,2018,Connectionist Temporal Classification with Maximum Entropy Regularization,Sheng Jin,Tsinghua University
NIPS,2018,Connectionist Temporal Classification with Maximum Entropy Regularization,Changshui Zhang,Tsinghua University
NIPS,2018,Generalizing Graph Matching beyond Quadratic Assignment Model,Tianshu Yu,Arizona State University
NIPS,2018,Generalizing Graph Matching beyond Quadratic Assignment Model,Junchi Yan,Shanghai Jiao Tong University
NIPS,2018,Generalizing Graph Matching beyond Quadratic Assignment Model,Yilin Wang,Adobe
NIPS,2018,Generalizing Graph Matching beyond Quadratic Assignment Model,Wei Liu,Tencent AI Lab
NIPS,2018,Generalizing Graph Matching beyond Quadratic Assignment Model,baoxin Li,Arizona State University
NIPS,2018,Solving Large Sequential Games with the Excessive Gap Technique,Christian Kroer,"Faceook, Core Data Science"
NIPS,2018,Solving Large Sequential Games with the Excessive Gap Technique,Gabriele Farina,Carnegie Mellon University
NIPS,2018,Solving Large Sequential Games with the Excessive Gap Technique,Tuomas Sandholm,Carnegie Mellon University
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Zhuangwei Zhuang,SCUT
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Mingkui Tan,South China University of Technology
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Bohan  Zhuang,The University of Adelaide
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Jing Liu,South China University of Technology
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Yong  Guo,South China University of Technology
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Qingyao Wu,South China University of Technology
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Junzhou Huang,University of Texas at Arlington / Tencent AI Lab
NIPS,2018,Discrimination-aware Channel Pruning for Deep Neural Networks,Jinhui Zhu,SCUT
NIPS,2018,On Word Embedding Dimensionality,Zi Yin,Stanford University
NIPS,2018,On Word Embedding Dimensionality,Ana Shen,Microsoft & Stanford University
NIPS,2018,Reinforced Continual Learning,Ju Xu,Peking University
NIPS,2018,Reinforced Continual Learning,Zhanxing Zhu,Peking University
NIPS,2018,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents,YAN ZHENG,Tianjin University
NIPS,2018,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents,Zhaopeng Meng,"School of Computer Software, Tianjin University"
NIPS,2018,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents,Jianye Hao,Tianjin University
NIPS,2018,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents,Zongzhang Zhang,Soochow University
NIPS,2018,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents,Tianpei Yang,Tianjin University
NIPS,2018,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents,Changjie Fan,Netease
NIPS,2018,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited,Di Wang,State University of New York at Buffalo
NIPS,2018,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited,Marco Gaboardi,Univeristy at Buffalo
NIPS,2018,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited,Jinhui Xu,SUNY at Buffalo
NIPS,2018,Learning semantic similarity in a continuous space,Michel Deudon,Ecole Polytechnique
NIPS,2018,MetaReg: Towards Domain Generalization using Meta-Regularization,Yogesh Balaji,University of Maryland
NIPS,2018,MetaReg: Towards Domain Generalization using Meta-Regularization,Swami Sankaranarayanan,Butterfly Network inc.
NIPS,2018,MetaReg: Towards Domain Generalization using Meta-Regularization,Rama Chellappa,University of Maryland College Park
NIPS,2018,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding,Kexin Yi,"Harvard University, MIT CSAIL"
NIPS,2018,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding,Jiajun Wu,MIT
NIPS,2018,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding,Chuang Gan,MIT-IBM Watson AI Lab
NIPS,2018,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding,Antonio Torralba,MIT
NIPS,2018,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding,Pushmeet Kohli,DeepMind
NIPS,2018,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding,Josh Tenenbaum,MIT
NIPS,2018,Quadratic Decomposable Submodular Function Minimization,Pan Li,University of Illinois Urbana-Champaign
NIPS,2018,Quadratic Decomposable Submodular Function Minimization,Niao He,UIUC
NIPS,2018,Quadratic Decomposable Submodular Function Minimization,Olgica Milenkovic,University of Illinois at Urbana-Champaign
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Tengyang Xie,University of Massachusetts Amherst
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Bo Liu,Auburn University
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Yangyang Xu,Rensselaer Polytechnic Institute
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Mohammad Ghavamzadeh,FaceBook FAIR
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Yinlam Chow,DeepMind
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Daoming Lyu,Auburn University
NIPS,2018,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization,Daesub Yoon,ETRI
NIPS,2018,Neural Nearest Neighbors Networks,Tobias Plötz,TU Darmstadt
NIPS,2018,Neural Nearest Neighbors Networks,Stefan Roth,TU Darmstadt
NIPS,2018,A Game-Theoretic Approach to Recommendation Systems with Strategic Content Providers,Omer Ben Porat,Technion – Israel Institute of Technology
NIPS,2018,A Game-Theoretic Approach to Recommendation Systems with Strategic Content Providers,Moshe Tennenholtz,Technion--Israel Institute of Technology
NIPS,2018,Interactive Structure Learning with Structural Query-by-Committee,Christopher Tosh,Columbia University
NIPS,2018,Interactive Structure Learning with Structural Query-by-Committee,Sanjoy Dasgupta,UC San Diego
NIPS,2018,Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere,Yanjun Li,UIUC
NIPS,2018,Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere,Yoram Bresler,Illinois
NIPS,2018,How To Make the Gradients Small Stochastically,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2018,Synthesize Policies for Transfer and Adaptation across Environments and Tasks,Hexiang Hu,University of Southern California
NIPS,2018,Synthesize Policies for Transfer and Adaptation across Environments and Tasks,Liyu CHEN,University of Southern California
NIPS,2018,Synthesize Policies for Transfer and Adaptation across Environments and Tasks,Boqing Gong,Tencent AI Lab
NIPS,2018,Synthesize Policies for Transfer and Adaptation across Environments and Tasks,Fei Sha,University of Southern California (USC)
NIPS,2018,Adversarial vulnerability for any classifier,Alhussein Fawzi,DeepMind
NIPS,2018,Adversarial vulnerability for any classifier,Hamza Fawzi,University of Cambridge
NIPS,2018,Adversarial vulnerability for any classifier,Omar Fawzi,ENS Lyon
NIPS,2018,"Alternating optimization of decision trees, with application to learning sparse oblique trees",Miguel A. Carreira-Perpinan,"University of California, Merced"
NIPS,2018,"Alternating optimization of decision trees, with application to learning sparse oblique trees",Pooya Tavallali,UC Merced
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,Yixiao Ge,The Chinese University of Hong Kong
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,Zhuowan Li,Johns Hopkins University
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,Haiyu Zhao,The Chinese University of Hong Kong
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,Guojun Yin,University of Science and Technology of China
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,Shuai Yi,The Chinese University of Hong Kong
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,Xiaogang Wang,The Chinese University of Hong Kong
NIPS,2018,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification,hongsheng Li,cuhk
NIPS,2018,The Lingering of Gradients: How to Reuse Gradients Over Time,Zeyuan Allen-Zhu,Microsoft Research
NIPS,2018,The Lingering of Gradients: How to Reuse Gradients Over Time,Xinshang Wang,MIT
NIPS,2018,The Lingering of Gradients: How to Reuse Gradients Over Time,David Simchi-Levi,MIT
NIPS,2018,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks,Qilong Wang,Tianjin University
NIPS,2018,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks,Zilin Gao,Dalian University of Technology
NIPS,2018,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks,Jiangtao Xie,Dalian University of Technology
NIPS,2018,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks,Wangmeng Zuo,Harbin Institute of Technology
NIPS,2018,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks,Peihua Li,Dalian University of Technology
NIPS,2018,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning,yunlong yu,Tianjin University
NIPS,2018,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning,Zhong Ji,Tianjin University
NIPS,2018,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning,yanwei Fu,"Fudan University, Shanghai;  AItrics Inc.  Seoul"
NIPS,2018,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning,Jichang Guo,Tianjin University
NIPS,2018,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning,Yanwei Pang,Tianjin University
NIPS,2018,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning,Zhongfei (Mark) Zhang,Binghamton University
NIPS,2018,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification,Dimitrios Milios,EURECOM
NIPS,2018,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification,Raffaello Camoriano,Istituto Italiano di Tecnologia
NIPS,2018,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification,Pietro Michiardi,EURECOM
NIPS,2018,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification,Lorenzo Rosasco,University of Genova- MIT - IIT
NIPS,2018,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification,Maurizio Filippone,EURECOM
NIPS,2018,Multi-Task Zipping via Layer-wise Neuron Sharing,Xiaoxi He,ETH Zürich
NIPS,2018,Multi-Task Zipping via Layer-wise Neuron Sharing,Zimu Zhou,ETH Zurich
NIPS,2018,Multi-Task Zipping via Layer-wise Neuron Sharing,Lothar Thiele,ETH Zürich
NIPS,2018,Approximation algorithms for stochastic clustering,David Harris,University of Maryland
NIPS,2018,Approximation algorithms for stochastic clustering,Shi Li,University at Buffalo
NIPS,2018,Approximation algorithms for stochastic clustering,Aravind Srinivasan,University of Maryland College Park
NIPS,2018,Approximation algorithms for stochastic clustering,Khoa Trinh,
NIPS,2018,Approximation algorithms for stochastic clustering,Thomas Pensyl,
NIPS,2018,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks,Xiaodong Cui,IBM T. J. Watson Research Center
NIPS,2018,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks,Wei Zhang,IBM T.J.Watson Research Center
NIPS,2018,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks,Zoltán Tüske,IBM T. J. Watson Research Center
NIPS,2018,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks,Michael Picheny,IBM T. J. Watson Research Center
NIPS,2018,Learning to Infer Graphics Programs from Hand-Drawn Images,Kevin Ellis,MIT
NIPS,2018,Learning to Infer Graphics Programs from Hand-Drawn Images,Daniel Ritchie,Brown University
NIPS,2018,Learning to Infer Graphics Programs from Hand-Drawn Images,Armando Solar-Lezama,MIT
NIPS,2018,Learning to Infer Graphics Programs from Hand-Drawn Images,Josh Tenenbaum,MIT
NIPS,2018,Graphical Generative Adversarial Networks,Chongxuan LI,Tsinghua University
NIPS,2018,Graphical Generative Adversarial Networks,Max Welling,University of Amsterdam / Qualcomm AI Research
NIPS,2018,Graphical Generative Adversarial Networks,Jun Zhu,Tsinghua University
NIPS,2018,Graphical Generative Adversarial Networks,Bo Zhang,Xiaomi Corp.
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Ho Chung Law,University of Oxford
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Dino Sejdinovic,University of Oxford
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Ewan Cameron,
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Tim  Lucas,University of Oxford
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Seth Flaxman,Imperial College London
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Katherine  Battle,University of Oxford
NIPS,2018,Variational Learning on Aggregate Outputs with Gaussian Processes,Kenji Fukumizu,Institute of Statistical Mathematics
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Boyuan Pan,Zhejiang University
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Yazheng Yang,Zhejiang University
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Hao Li,Zhejiang University
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Zhou Zhao,Zhejiang University
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Yueting Zhuang,Zhejiang University
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Deng Cai,Zhejiang University
NIPS,2018,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models,Xiaofei He,Zhejiang University
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Ali Shafahi,University of Maryland
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Ronny Huang,UMCP and EY
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Mahyar Najibi,University of Maryland
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Octavian Suciu,University of Maryland
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Christoph Studer,Cornell University
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Tudor Dumitras,University of Maryland
NIPS,2018,Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks,Tom Goldstein,University of Maryland
NIPS,2018,Information Constraints on Auto-Encoding Variational Bayes,Romain Lopez,UC Berkeley
NIPS,2018,Information Constraints on Auto-Encoding Variational Bayes,Jeff Regier,UC Berkeley
NIPS,2018,Information Constraints on Auto-Encoding Variational Bayes,Michael Jordan,UC Berkeley
NIPS,2018,Information Constraints on Auto-Encoding Variational Bayes,Nir Yosef,UC Berkeley
NIPS,2018,Recurrent Transformer Networks for Semantic Correspondence,Seungryong Kim,Yonsei University
NIPS,2018,Recurrent Transformer Networks for Semantic Correspondence,Stephen Lin,Microsoft Research
NIPS,2018,Recurrent Transformer Networks for Semantic Correspondence,SANG RYUL JEON,Yonsei University
NIPS,2018,Recurrent Transformer Networks for Semantic Correspondence,Dongbo Min,Ewha Womans University
NIPS,2018,Recurrent Transformer Networks for Semantic Correspondence,Kwanghoon Sohn,Yonsei Univ.
NIPS,2018,Online convex optimization for cumulative constraints,Jianjun Yuan,University of Minnesota
NIPS,2018,Online convex optimization for cumulative constraints,Andrew Lamperski,University of Minnesota
NIPS,2018,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer,David Madras,University of Toronto
NIPS,2018,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer,Toni Pitassi,University of Toronto
NIPS,2018,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer,Richard Zemel,Vector Institute/University of Toronto
NIPS,2018,Deep State Space Models for Unconditional Word Generation,Florian Schmidt,ETH Zürich
NIPS,2018,Deep State Space Models for Unconditional Word Generation,Thomas Hofmann,ETH Zurich
NIPS,2018,Transfer of Value Functions via Variational Methods,Andrea Tirinzoni,Politecnico di Milano
NIPS,2018,Transfer of Value Functions via Variational Methods,Rafael Rodriguez,Politecnico di Milano
NIPS,2018,Transfer of Value Functions via Variational Methods,Marcello Restelli,Politecnico di Milano
NIPS,2018,"The Cluster Description Problem - Complexity Results, Formulations and Approximations",Ian Davidson,U.C. Davis
NIPS,2018,"The Cluster Description Problem - Complexity Results, Formulations and Approximations",Antoine Gourru,University of Lyon - 2
NIPS,2018,"The Cluster Description Problem - Complexity Results, Formulations and Approximations",S Ravi,Biocomplexity Institute
